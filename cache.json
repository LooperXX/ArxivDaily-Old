{
  "sources": [
    {
      "title": "cs.CL updates on arXiv.org",
      "feedUrl": "http://export.arxiv.org/rss/cs.CL",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2105.13868",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1\">Shuhuai Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Junyang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1\">Guangxiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Men_R/0/1/0/all/0/1\">Rui Men</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1\">An Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hongxia Yang</a>",
          "description": "Despite the achievements of large-scale multimodal pre-training approaches,\ncross-modal retrieval, e.g., image-text retrieval, remains a challenging task.\nTo bridge the semantic gap between the two modalities, previous studies mainly\nfocus on word-region alignment at the object level, lacking the matching\nbetween the linguistic relation among the words and the visual relation among\nthe regions. The neglect of such relation consistency impairs the\ncontextualized representation of image-text pairs and hinders the model\nperformance and the interpretability. In this paper, we first propose a novel\nmetric, Intra-modal Self-attention Distance (ISD), to quantify the relation\nconsistency by measuring the semantic distance between linguistic and visual\nrelations. In response, we present Inter-modal Alignment on Intra-modal\nSelf-attentions (IAIS), a regularized training method to optimize the ISD and\ncalibrate intra-modal self-attentions from the two modalities mutually via\ninter-modal alignment. The IAIS regularizer boosts the performance of\nprevailing models on Flickr30k and MS COCO datasets by a considerable margin,\nwhich demonstrates the superiority of our approach.",
          "link": "http://arxiv.org/abs/2105.13868",
          "publishedOn": "2021-06-08T02:20:28.103Z",
          "wordCount": 642,
          "title": "Learning Relation Alignment for Calibrated Cross-modal Retrieval. (arXiv:2105.13868v2 [cs.CL] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.01739",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_W/0/1/0/all/0/1\">Wasi Uddin Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1\">Xiao Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Soomin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>",
          "description": "Natural language processing techniques have demonstrated promising results in\nkeyphrase generation. However, one of the major challenges in \\emph{neural}\nkeyphrase generation is processing long documents using deep neural networks.\nGenerally, documents are truncated before given as inputs to neural networks.\nConsequently, the models may miss essential points conveyed in the target\ndocument. To overcome this limitation, we propose \\emph{SEG-Net}, a neural\nkeyphrase generation model that is composed of two major components, (1) a\nselector that selects the salient sentences in a document and (2) an\nextractor-generator that jointly extracts and generates keyphrases from the\nselected sentences. SEG-Net uses Transformer, a self-attentive architecture, as\nthe basic building block with a novel \\emph{layer-wise} coverage attention to\nsummarize most of the points discussed in the document. The experimental\nresults on seven keyphrase generation benchmarks from scientific and web\ndocuments demonstrate that SEG-Net outperforms the state-of-the-art neural\ngenerative methods by a large margin.",
          "link": "http://arxiv.org/abs/2008.01739",
          "publishedOn": "2021-06-08T02:20:25.941Z",
          "wordCount": 617,
          "title": "Select, Extract and Generate: Neural Keyphrase Generation with Layer-wise Coverage Attention. (arXiv:2008.01739v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02833",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gangal_V/0/1/0/all/0/1\">Varun Gangal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jhamtani_H/0/1/0/all/0/1\">Harsh Jhamtani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hovy_E/0/1/0/all/0/1\">Eduard Hovy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berg_Kirkpatrick_T/0/1/0/all/0/1\">Taylor Berg-Kirkpatrick</a>",
          "description": "Multiple different responses are often plausible for a given open domain\ndialog context. Prior work has shown the importance of having multiple valid\nreference responses for meaningful and robust automated evaluations. In such\ncases, common practice has been to collect more human written references.\nHowever, such collection can be expensive, time consuming, and not easily\nscalable. Instead, we propose a novel technique for automatically expanding a\nhuman generated reference to a set of candidate references. We fetch plausible\nreferences from knowledge sources, and adapt them so that they are more fluent\nin context of the dialog instance in question. More specifically, we use (1) a\ncommonsense knowledge base to elicit a large number of plausible reactions\ngiven the dialog history (2) relevant instances retrieved from dialog corpus,\nusing similar past as well as future contexts. We demonstrate that our\nautomatically expanded reference sets lead to large improvements in\ncorrelations of automated metrics with human ratings of system outputs for\nDailyDialog dataset.",
          "link": "http://arxiv.org/abs/2106.02833",
          "publishedOn": "2021-06-08T02:20:25.888Z",
          "wordCount": 597,
          "title": "Improving Automated Evaluation of Open Domain Dialog via Diverse Reference Augmentation. (arXiv:2106.02833v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02960",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yingjun Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holla_N/0/1/0/all/0/1\">Nithin Holla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhen_X/0/1/0/all/0/1\">Xiantong Zhen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Snoek_C/0/1/0/all/0/1\">Cees G.M. Snoek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shutova_E/0/1/0/all/0/1\">Ekaterina Shutova</a>",
          "description": "A critical challenge faced by supervised word sense disambiguation (WSD) is\nthe lack of large annotated datasets with sufficient coverage of words in their\ndiversity of senses. This inspired recent research on few-shot WSD using\nmeta-learning. While such work has successfully applied meta-learning to learn\nnew word senses from very few examples, its performance still lags behind its\nfully supervised counterpart. Aiming to further close this gap, we propose a\nmodel of semantic memory for WSD in a meta-learning setting. Semantic memory\nencapsulates prior experiences seen throughout the lifetime of the model, which\naids better generalization in limited data settings. Our model is based on\nhierarchical variational inference and incorporates an adaptive memory update\nrule via a hypernetwork. We show our model advances the state of the art in\nfew-shot WSD, supports effective learning in extremely data scarce (e.g.\none-shot) scenarios and produces meaning prototypes that capture similar senses\nof distinct words.",
          "link": "http://arxiv.org/abs/2106.02960",
          "publishedOn": "2021-06-08T02:20:25.844Z",
          "wordCount": 591,
          "title": "Meta-Learning with Variational Semantic Memory for Word Sense Disambiguation. (arXiv:2106.02960v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02974",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Q/0/1/0/all/0/1\">Qingkai Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jinfeng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Wenhao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cleland_Huang_J/0/1/0/all/0/1\">Jane Cleland-Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1\">Meng Jiang</a>",
          "description": "Automatic construction of a taxonomy supports many applications in\ne-commerce, web search, and question answering. Existing taxonomy expansion or\ncompletion methods assume that new concepts have been accurately extracted and\ntheir embedding vectors learned from the text corpus. However, one critical and\nfundamental challenge in fixing the incompleteness of taxonomies is the\nincompleteness of the extracted concepts, especially for those whose names have\nmultiple words and consequently low frequency in the corpus. To resolve the\nlimitations of extraction-based methods, we propose GenTaxo to enhance taxonomy\ncompletion by identifying positions in existing taxonomies that need new\nconcepts and then generating appropriate concept names. Instead of relying on\nthe corpus for concept embeddings, GenTaxo learns the contextual embeddings\nfrom their surrounding graph-based and language-based relational information,\nand leverages the corpus for pre-training a concept name generator.\nExperimental results demonstrate that GenTaxo improves the completeness of\ntaxonomies over existing methods.",
          "link": "http://arxiv.org/abs/2106.02974",
          "publishedOn": "2021-06-08T02:20:25.482Z",
          "wordCount": 581,
          "title": "Enhancing Taxonomy Completion with Concept Generation via Fusing Relational Representations. (arXiv:2106.02974v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2103.05908",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chua_F/0/1/0/all/0/1\">Freddy C. Chua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duffy_N/0/1/0/all/0/1\">Nigel P. Duffy</a>",
          "description": "We address the challenge of extracting structured information from business\ndocuments without detailed annotations. We propose Deep Conditional\nProbabilistic Context Free Grammars (DeepCPCFG) to parse two-dimensional\ncomplex documents and use Recursive Neural Networks to create an end-to-end\nsystem for finding the most probable parse that represents the structured\ninformation to be extracted. This system is trained end-to-end with scanned\ndocuments as input and only relational-records as labels. The\nrelational-records are extracted from existing databases avoiding the cost of\nannotating documents by hand. We apply this approach to extract information\nfrom scanned invoices achieving state-of-the-art results despite using no\nhand-annotations.",
          "link": "http://arxiv.org/abs/2103.05908",
          "publishedOn": "2021-06-08T02:20:25.295Z",
          "wordCount": null,
          "title": "DeepCPCFG: Deep Learning and Context Free Grammars for End-to-End Information Extraction. (arXiv:2103.05908v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.00994",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Feng_S/0/1/0/all/0/1\">Siyuan Feng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zelasko_P/0/1/0/all/0/1\">Piotr &#x17b;elasko</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moro_Velazquez_L/0/1/0/all/0/1\">Laureano Moro-Vel&#xe1;zquez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Scharenborg_O/0/1/0/all/0/1\">Odette Scharenborg</a>",
          "description": "This paper tackles automatically discovering phone-like acoustic units (AUD)\nfrom unlabeled speech data. Past studies usually proposed single-step\napproaches. We propose a two-stage approach: the first stage learns a\nsubword-discriminative feature representation and the second stage applies\nclustering to the learned representation and obtains phone-like clusters as the\ndiscovered acoustic units. In the first stage, a recently proposed method in\nthe task of unsupervised subword modeling is improved by replacing a\nmonolingual out-of-domain (OOD) ASR system with a multilingual one to create a\nsubword-discriminative representation that is more language-independent. In the\nsecond stage, segment-level k-means is adopted, and two methods to represent\nthe variable-length speech segments as fixed-dimension feature vectors are\ncompared. Experiments on a very low-resource Mboshi language corpus show that\nour approach outperforms state-of-the-art AUD in both normalized mutual\ninformation (NMI) and F-score. The multilingual ASR improved upon the\nmonolingual ASR in providing OOD phone labels and in estimating the phone\nboundaries. A comparison of our systems with and without knowing the\nground-truth phone boundaries showed a 16% NMI performance gap, suggesting that\nthe current approach can significantly benefit from improved phone boundary\nestimation.",
          "link": "http://arxiv.org/abs/2104.00994",
          "publishedOn": "2021-06-08T02:20:25.284Z",
          "wordCount": null,
          "title": "Unsupervised Acoustic Unit Discovery by Leveraging a Language-Independent Subword Discriminative Feature Representation. (arXiv:2104.00994v2 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.02242",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Onabola_O/0/1/0/all/0/1\">Olawale Onabola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zhuang Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yang Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akera_B/0/1/0/all/0/1\">Benjamin Akera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ibraheem_A/0/1/0/all/0/1\">Abdulrahman Ibraheem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1\">Jia Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Dianbo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>",
          "description": "Subtle and overt racism is still present both in physical and online\ncommunities today and has impacted many lives in different segments of the\nsociety. In this short piece of work, we present how we're tackling this\nsocietal issue with Natural Language Processing. We are releasing BiasCorp, a\ndataset containing 139,090 comments and news segment from three specific\nsources - Fox News, BreitbartNews and YouTube. The first batch (45,000 manually\nannotated) is ready for publication. We are currently in the final phase of\nmanually labeling the remaining dataset using Amazon Mechanical Turk. BERT has\nbeen used widely in several downstream tasks. In this work, we present hBERT,\nwhere we modify certain layers of the pretrained BERT model with the new\nHopfield Layer. hBert generalizes well across different distributions with the\nadded advantage of a reduced model complexity. We are also releasing a\nJavaScript library and a Chrome Extension Application, to help developers make\nuse of our trained model in web applications (say chat application) and for\nusers to identify and report racially biased contents on the web respectively.",
          "link": "http://arxiv.org/abs/2104.02242",
          "publishedOn": "2021-06-08T02:20:25.283Z",
          "wordCount": null,
          "title": "hBert + BiasCorp -- Fighting Racism on the Web. (arXiv:2104.02242v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02787",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhaojiang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madotto_A/0/1/0/all/0/1\">Andrea Madotto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winata_G/0/1/0/all/0/1\">Genta Indra Winata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1\">Peng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_F/0/1/0/all/0/1\">Feijun Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yuxiang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1\">Chen Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1\">Pascale Fung</a>",
          "description": "Task-oriented dialogue (ToD) benchmarks provide an important avenue to\nmeasure progress and develop better conversational agents. However, existing\ndatasets for end-to-end ToD modeling are limited to a single language,\nhindering the development of robust end-to-end ToD systems for multilingual\ncountries and regions. Here we introduce BiToD, the first bilingual\nmulti-domain dataset for end-to-end task-oriented dialogue modeling. BiToD\ncontains over 7k multi-domain dialogues (144k utterances) with a large and\nrealistic bilingual knowledge base. It serves as an effective benchmark for\nevaluating bilingual ToD systems and cross-lingual transfer learning\napproaches. We provide state-of-the-art baselines under three evaluation\nsettings (monolingual, bilingual, and cross-lingual). The analysis of our\nbaselines in different settings highlights 1) the effectiveness of training a\nbilingual ToD system compared to two independent monolingual ToD systems, and\n2) the potential of leveraging a bilingual knowledge base and cross-lingual\ntransfer learning to improve the system performance under low resource\ncondition.",
          "link": "http://arxiv.org/abs/2106.02787",
          "publishedOn": "2021-06-08T02:20:25.159Z",
          "wordCount": 588,
          "title": "BiToD: A Bilingual Multi-Domain Dataset For Task-Oriented Dialogue Modeling. (arXiv:2106.02787v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2103.10325",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shenoy_A/0/1/0/all/0/1\">Ashish Shenoy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bodapati_S/0/1/0/all/0/1\">Sravan Bodapati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirchhoff_K/0/1/0/all/0/1\">Katrin Kirchhoff</a>",
          "description": "Goal-oriented conversational interfaces are designed to accomplish specific\ntasks and typically have interactions that tend to span multiple turns adhering\nto a pre-defined structure and a goal. However, conventional neural language\nmodels (NLM) in Automatic Speech Recognition (ASR) systems are mostly trained\nsentence-wise with limited context. In this paper, we explore different ways to\nincorporate context into a LSTM based NLM in order to model long range\ndependencies and improve speech recognition. Specifically, we use context carry\nover across multiple turns and use lexical contextual cues such as system\ndialog act from Natural Language Understanding (NLU) models and the user\nprovided structure of the chatbot. We also propose a new architecture that\nutilizes context embeddings derived from BERT on sample utterances provided\nduring inference time. Our experiments show a word error rate (WER) relative\nreduction of 7% over non-contextual utterance-level NLM rescorers on\ngoal-oriented audio datasets.",
          "link": "http://arxiv.org/abs/2103.10325",
          "publishedOn": "2021-06-08T02:20:25.064Z",
          "wordCount": 625,
          "title": "Contextual Biasing of Language Models for Speech Recognition in Goal-Oriented Conversational Agents. (arXiv:2103.10325v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.15060",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1\">Ye Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zen_H/0/1/0/all/0/1\">Heiga Zen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Jonathan Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yonghui Wu</a>",
          "description": "This paper introduces PnG BERT, a new encoder model for neural TTS. This\nmodel is augmented from the original BERT model, by taking both phoneme and\ngrapheme representations of text as input, as well as the word-level alignment\nbetween them. It can be pre-trained on a large text corpus in a self-supervised\nmanner, and fine-tuned in a TTS task. Experimental results show that a neural\nTTS model using a pre-trained PnG BERT as its encoder yields more natural\nprosody and more accurate pronunciation than a baseline model using only\nphoneme input with no pre-training. Subjective side-by-side preference\nevaluations show that raters have no statistically significant preference\nbetween the speech synthesized using a PnG BERT and ground truth recordings\nfrom professional speakers.",
          "link": "http://arxiv.org/abs/2103.15060",
          "publishedOn": "2021-06-08T02:20:25.058Z",
          "wordCount": 609,
          "title": "PnG BERT: Augmented BERT on Phonemes and Graphemes for Neural TTS. (arXiv:2103.15060v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.14625",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zijie J. Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turko_R/0/1/0/all/0/1\">Robert Turko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chau_D/0/1/0/all/0/1\">Duen Horng Chau</a>",
          "description": "Why do large pre-trained transformer-based models perform so well across a\nwide variety of NLP tasks? Recent research suggests the key may lie in\nmulti-headed attention mechanism's ability to learn and represent linguistic\ninformation. Understanding how these models represent both syntactic and\nsemantic knowledge is vital to investigate why they succeed and fail, what they\nhave learned, and how they can improve. We present Dodrio, an open-source\ninteractive visualization tool to help NLP researchers and practitioners\nanalyze attention mechanisms in transformer-based models with linguistic\nknowledge. Dodrio tightly integrates an overview that summarizes the roles of\ndifferent attention heads, and detailed views that help users compare attention\nweights with the syntactic structure and semantic information in the input\ntext. To facilitate the visual comparison of attention weights and linguistic\nknowledge, Dodrio applies different graph visualization techniques to represent\nattention weights scalable to longer input text. Case studies highlight how\nDodrio provides insights into understanding the attention mechanism in\ntransformer-based models. Dodrio is available at\nhttps://poloclub.github.io/dodrio/.",
          "link": "http://arxiv.org/abs/2103.14625",
          "publishedOn": "2021-06-08T02:20:24.906Z",
          "wordCount": null,
          "title": "Dodrio: Exploring Transformer Models with Interactive Visualization. (arXiv:2103.14625v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.09764",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1\">Xianghong Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_H/0/1/0/all/0/1\">Haoli Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zenglin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1\">Michael Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1\">Irwin King</a>",
          "description": "Variational autoencoders (VAEs) have been widely applied for text modeling.\nIn practice, however, they are troubled by two challenges: information\nunderrepresentation and posterior collapse. The former arises as only the last\nhidden state of LSTM encoder is transformed into the latent space, which is\ngenerally insufficient to summarize the data. The latter is a long-standing\nproblem during the training of VAEs as the optimization is trapped to a\ndisastrous local optimum. In this paper, we propose Discrete Auto-regressive\nVariational Attention Model (DAVAM) to address the challenges. Specifically, we\nintroduce an auto-regressive variational attention approach to enrich the\nlatent space by effectively capturing the semantic dependency from the input.\nWe further design discrete latent space for the variational attention and\nmathematically show that our model is free from posterior collapse. Extensive\nexperiments on language modeling tasks demonstrate the superiority of DAVAM\nagainst several VAE counterparts.",
          "link": "http://arxiv.org/abs/2004.09764",
          "publishedOn": "2021-06-08T02:20:24.903Z",
          "wordCount": null,
          "title": "Discrete Auto-regressive Variational Attention Models for Text Modeling. (arXiv:2004.09764v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10375",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Shuyi Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jian Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Haiqin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Lianxin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mo_Y/0/1/0/all/0/1\">Yang Mo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Jianping Shen</a>",
          "description": "This paper presents the PALI team's winning system for SemEval-2021 Task 2:\nMultilingual and Cross-lingual Word-in-Context Disambiguation. We fine-tune\nXLM-RoBERTa model to solve the task of word in context disambiguation, i.e., to\ndetermine whether the target word in the two contexts contains the same meaning\nor not. In the implementation, we first specifically design an input tag to\nemphasize the target word in the contexts. Second, we construct a new vector on\nthe fine-tuned embeddings from XLM-RoBERTa and feed it to a fully-connected\nnetwork to output the probability of whether the target word in the context has\nthe same meaning or not. The new vector is attained by concatenating the\nembedding of the [CLS] token and the embeddings of the target word in the\ncontexts. In training, we explore several tricks, such as the Ranger optimizer,\ndata augmentation, and adversarial training, to improve the model prediction.\nConsequently, we attain first place in all four cross-lingual tasks.",
          "link": "http://arxiv.org/abs/2104.10375",
          "publishedOn": "2021-06-08T02:20:24.658Z",
          "wordCount": null,
          "title": "PALI at SemEval-2021 Task 2: Fine-Tune XLM-RoBERTa for Word in Context Disambiguation. (arXiv:2104.10375v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02902",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wallat_J/0/1/0/all/0/1\">Jonas Wallat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_J/0/1/0/all/0/1\">Jaspreet Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anand_A/0/1/0/all/0/1\">Avishek Anand</a>",
          "description": "Probing complex language models has recently revealed several insights into\nlinguistic and semantic patterns found in the learned representations. In this\narticle, we probe BERT specifically to understand and measure the relational\nknowledge it captures in its parametric memory. While probing for linguistic\nunderstanding is commonly applied to all layers of BERT as well as fine-tuned\nmodels, this has not been done for factual knowledge. We utilize existing\nknowledge base completion tasks (LAMA) to probe every layer of pre-trained as\nwell as fine-tuned BERT models(ranking, question answering, NER). Our findings\nshow that knowledge is not just contained in BERT's final layers. Intermediate\nlayers contribute a significant amount (17-60%) to the total knowledge found.\nProbing intermediate layers also reveals how different types of knowledge\nemerge at varying rates. When BERT is fine-tuned, relational knowledge is\nforgotten. The extent of forgetting is impacted by the fine-tuning objective\nand the training data. We found that ranking models forget the least and retain\nmore knowledge in their final layer compared to masked language modeling and\nquestion-answering. However, masked language modeling performed the best at\nacquiring new knowledge from the training data. When it comes to learning\nfacts, we found that capacity and fact density are key factors. We hope this\ninitial work will spur further research into understanding the parametric\nmemory of language models and the effect of training objectives on factual\nknowledge. The code to repeat the experiments is publicly available on GitHub.",
          "link": "http://arxiv.org/abs/2106.02902",
          "publishedOn": "2021-06-08T02:20:23.795Z",
          "wordCount": 682,
          "title": "BERTnesia: Investigating the capture and forgetting of knowledge in BERT. (arXiv:2106.02902v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02658",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huber_P/0/1/0/all/0/1\">Patrick Huber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_W/0/1/0/all/0/1\">Wen Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carenini_G/0/1/0/all/0/1\">Giuseppe Carenini</a>",
          "description": "Aiming for a better integration of data-driven and linguistically-inspired\napproaches, we explore whether RST Nuclearity, assigning a binary assessment of\nimportance between text segments, can be replaced by automatically generated,\nreal-valued scores, in what we call a Weighted-RST framework. In particular, we\nfind that weighted discourse trees from auxiliary tasks can benefit key NLP\ndownstream applications, compared to nuclearity-centered approaches. We further\nshow that real-valued importance distributions partially and interestingly\nalign with the assessment and uncertainty of human annotators.",
          "link": "http://arxiv.org/abs/2106.02658",
          "publishedOn": "2021-06-08T02:20:22.981Z",
          "wordCount": 516,
          "title": "W-RST: Towards a Weighted RST-style Discourse Framework. (arXiv:2106.02658v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02692",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gros_D/0/1/0/all/0/1\">David Gros</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>",
          "description": "Humans are increasingly interacting with machines through language, sometimes\nin contexts where the user may not know they are talking to a machine (like\nover the phone or a text chatbot). We aim to understand how system designers\nand researchers might allow their systems to confirm its non-human identity. We\ncollect over 2,500 phrasings related to the intent of ``Are you a robot?\". This\nis paired with over 2,500 adversarially selected utterances where only\nconfirming the system is non-human would be insufficient or disfluent. We\ncompare classifiers to recognize the intent and discuss the precision/recall\nand model complexity tradeoffs. Such classifiers could be integrated into\ndialog systems to avoid undesired deception. We then explore how both a\ngenerative research model (Blender) as well as two deployed systems (Amazon\nAlexa, Google Assistant) handle this intent, finding that systems often fail to\nconfirm their non-human identity. Finally, we try to understand what a good\nresponse to the intent would be, and conduct a user study to compare the\nimportant aspects when responding to this intent.",
          "link": "http://arxiv.org/abs/2106.02692",
          "publishedOn": "2021-06-08T02:20:22.359Z",
          "wordCount": 616,
          "title": "The R-U-A-Robot Dataset: Helping Avoid Chatbot Deception by Detecting User Questions About Human or Non-Human Identity. (arXiv:2106.02692v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2104.13095",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Guanglin Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1\">Chengguang Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_R/0/1/0/all/0/1\">Ruiying Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1\">Jian Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jian Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_L/0/1/0/all/0/1\">Luo Si</a>",
          "description": "Aiming at expanding few-shot relations' coverage in knowledge graphs (KGs),\nfew-shot knowledge graph completion (FKGC) has recently gained more research\ninterests. Some existing models employ a few-shot relation's multi-hop neighbor\ninformation to enhance its semantic representation. However, noise neighbor\ninformation might be amplified when the neighborhood is excessively sparse and\nno neighbor is available to represent the few-shot relation. Moreover, modeling\nand inferring complex relations of one-to-many (1-N), many-to-one (N-1), and\nmany-to-many (N-N) by previous knowledge graph completion approaches requires\nhigh model complexity and a large amount of training instances. Thus, inferring\ncomplex relations in the few-shot scenario is difficult for FKGC models due to\nlimited training instances. In this paper, we propose a few-shot relational\nlearning with global-local framework to address the above issues. At the global\nstage, a novel gated and attentive neighbor aggregator is built for accurately\nintegrating the semantics of a few-shot relation's neighborhood, which helps\nfiltering the noise neighbors even if a KG contains extremely sparse\nneighborhoods. For the local stage, a meta-learning based TransH (MTransH)\nmethod is designed to model complex relations and train our model in a few-shot\nlearning fashion. Extensive experiments show that our model outperforms the\nstate-of-the-art FKGC approaches on the frequently-used benchmark datasets\nNELL-One and Wiki-One. Compared with the strong baseline model MetaR, our model\nachieves 5-shot FKGC performance improvements of 8.0% on NELL-One and 2.8% on\nWiki-One by the metric Hits@10.",
          "link": "http://arxiv.org/abs/2104.13095",
          "publishedOn": "2021-06-08T02:20:22.169Z",
          "wordCount": 725,
          "title": "Relational Learning with Gated and Attentive Neighbor Aggregator for Few-Shot Knowledge Graph Completion. (arXiv:2104.13095v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.11791",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Henderson_M/0/1/0/all/0/1\">Matthew Henderson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1\">Ivan Vuli&#x107;</a>",
          "description": "We propose ConVEx (Conversational Value Extractor), an efficient pretraining\nand fine-tuning neural approach for slot-labeling dialog tasks. Instead of\nrelying on more general pretraining objectives from prior work (e.g., language\nmodeling, response selection), ConVEx's pretraining objective, a novel pairwise\ncloze task using Reddit data, is well aligned with its intended usage on\nsequence labeling tasks. This enables learning domain-specific slot labelers by\nsimply fine-tuning decoding layers of the pretrained general-purpose sequence\nlabeling model, while the majority of the pretrained model's parameters are\nkept frozen. We report state-of-the-art performance of ConVEx across a range of\ndiverse domains and data sets for dialog slot-labeling, with the largest gains\nin the most challenging, few-shot setups. We believe that ConVEx's reduced\npretraining times (i.e., only 18 hours on 12 GPUs) and cost, along with its\nefficient fine-tuning and strong performance, promise wider portability and\nscalability for data-efficient sequence-labeling tasks in general.",
          "link": "http://arxiv.org/abs/2010.11791",
          "publishedOn": "2021-06-08T02:20:22.147Z",
          "wordCount": 595,
          "title": "ConVEx: Data-Efficient and Few-Shot Slot Labeling. (arXiv:2010.11791v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10366",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ruan_X/0/1/0/all/0/1\">Xiaoyi Ruan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_M/0/1/0/all/0/1\">Meizhi Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jian Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Haiqin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Lianxin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mo_Y/0/1/0/all/0/1\">Yang Mo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Mengyuan Zhou</a>",
          "description": "Question answering from semi-structured tables can be seen as a semantic\nparsing task and is significant and practical for pushing the boundary of\nnatural language understanding. Existing research mainly focuses on\nunderstanding contents from unstructured evidence, e.g., news, natural language\nsentences, and documents. The task of verification from structured evidence,\nsuch as tables, charts, and databases, is still less explored. This paper\ndescribes sattiy team's system in SemEval-2021 task 9: Statement Verification\nand Evidence Finding with Tables (SEM-TAB-FACT). This competition aims to\nverify statements and to find evidence from tables for scientific articles and\nto promote the proper interpretation of the surrounding article. In this paper,\nwe exploited ensemble models of pre-trained language models over tables, TaPas\nand TaBERT, for Task A and adjust the result based on some rules extracted for\nTask B. Finally, in the leaderboard, we attain the F1 scores of 0.8496 and\n0.7732 in Task A for the 2-way and 3-way evaluation, respectively, and the F1\nscore of 0.4856 in Task B.",
          "link": "http://arxiv.org/abs/2104.10366",
          "publishedOn": "2021-06-08T02:20:22.037Z",
          "wordCount": 657,
          "title": "Sattiy at SemEval-2021 Task 9: An Ensemble Solution for Statement Verification and Evidence Finding with Tables. (arXiv:2104.10366v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.11070",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shenoy_A/0/1/0/all/0/1\">Ashish Shenoy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bodapati_S/0/1/0/all/0/1\">Sravan Bodapati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sunkara_M/0/1/0/all/0/1\">Monica Sunkara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ronanki_S/0/1/0/all/0/1\">Srikanth Ronanki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirchhoff_K/0/1/0/all/0/1\">Katrin Kirchhoff</a>",
          "description": "Neural Language Models (NLM), when trained and evaluated with context\nspanning multiple utterances, have been shown to consistently outperform both\nconventional n-gram language models and NLMs that use limited context. In this\npaper, we investigate various techniques to incorporate turn based context\nhistory into both recurrent (LSTM) and Transformer-XL based NLMs. For recurrent\nbased NLMs, we explore context carry over mechanism and feature based\naugmentation, where we incorporate other forms of contextual information such\nas bot response and system dialogue acts as classified by a Natural Language\nUnderstanding (NLU) model. To mitigate the sharp nearby, fuzzy far away problem\nwith contextual NLM, we propose the use of attention layer over lexical\nmetadata to improve feature based augmentation. Additionally, we adapt our\ncontextual NLM towards user provided on-the-fly speech patterns by leveraging\nencodings from a large pre-trained masked language model and performing fusion\nwith a Transformer-XL based NLM. We test our proposed models using N-best\nrescoring of ASR hypotheses of task-oriented dialogues and also evaluate on\ndownstream NLU tasks such as intent classification and slot labeling. The best\nperforming model shows a relative WER between 1.6% and 9.1% and a slot labeling\nF1 score improvement of 4% over non-contextual baselines.",
          "link": "http://arxiv.org/abs/2104.11070",
          "publishedOn": "2021-06-08T02:20:22.023Z",
          "wordCount": 676,
          "title": "Adapting Long Context NLM for ASR Rescoring in Conversational Agents. (arXiv:2104.11070v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.13100",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liguori_P/0/1/0/all/0/1\">Pietro Liguori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Hossami_E/0/1/0/all/0/1\">Erfan Al-Hossami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotroneo_D/0/1/0/all/0/1\">Domenico Cotroneo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Natella_R/0/1/0/all/0/1\">Roberto Natella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cukic_B/0/1/0/all/0/1\">Bojan Cukic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaikh_S/0/1/0/all/0/1\">Samira Shaikh</a>",
          "description": "We take the first step to address the task of automatically generating\nshellcodes, i.e., small pieces of code used as a payload in the exploitation of\na software vulnerability, starting from natural language comments. We assemble\nand release a novel dataset (Shellcode_IA32), consisting of challenging but\ncommon assembly instructions with their natural language descriptions. We\nexperiment with standard methods in neural machine translation (NMT) to\nestablish baseline performance levels on this task.",
          "link": "http://arxiv.org/abs/2104.13100",
          "publishedOn": "2021-06-08T02:20:21.731Z",
          "wordCount": 543,
          "title": "Shellcode_IA32: A Dataset for Automatic Shellcode Generation. (arXiv:2104.13100v2 [cs.SE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.11804",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mazzeo_V/0/1/0/all/0/1\">V. Mazzeo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rapisarda_A/0/1/0/all/0/1\">A. Rapisarda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giuffrida_G/0/1/0/all/0/1\">G. Giuffrida</a>",
          "description": "In early January 2020, after China reported the first cases of the new\ncoronavirus (SARS-CoV-2) in the city of Wuhan, unreliable and not fully\naccurate information has started spreading faster than the virus itself.\nAlongside this pandemic, people have experienced a parallel infodemic, i.e., an\noverabundance of information, some of which misleading or even harmful, that\nhas widely spread around the globe. Although Social Media are increasingly\nbeing used as information source, Web Search Engines, like Google or Yahoo!,\nstill represent a powerful and trustworthy resource for finding information on\nthe Web. This is due to their capability to capture the largest amount of\ninformation, helping users quickly identify the most relevant, useful, although\nnot always the most reliable, results for their search queries. This study aims\nto detect potential misleading and fake contents by capturing and analysing\ntextual information, which flow through Search Engines. By using a real-world\ndataset associated with recent CoViD-19 pandemic, we first apply re-sampling\ntechniques for class imbalance, then we use existing Machine Learning\nalgorithms for classification of not reliable news. By extracting lexical and\nhost-based features of associated Uniform Resource Locators (URLs) for news\narticles, we show that the proposed methods, so common in phishing and\nmalicious URLs detection, can improve the efficiency and performance of\nclassifiers. Based on these findings, we suggest that the use of both textual\nand URLs features can improve the effectiveness of fake news detection methods.",
          "link": "http://arxiv.org/abs/2103.11804",
          "publishedOn": "2021-06-08T02:20:21.706Z",
          "wordCount": 740,
          "title": "Detection of fake news on CoViD-19 on Web Search Engines. (arXiv:2103.11804v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.06097",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuohang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1\">Luowei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1\">Zhe Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yen-Chun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1\">Yuwei Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Siqi Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yu Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jingjing Liu</a>",
          "description": "Transformer has become ubiquitous in the deep learning field. One of the key\ningredients that destined its success is the self-attention mechanism, which\nallows fully-connected contextual encoding over input tokens. However, despite\nits effectiveness in modeling short sequences, self-attention suffers when\nhandling inputs with extreme long-range dependencies, as its complexity grows\nquadratically with respect to the sequence length. Therefore, long sequences\nare often encoded by Transformer in chunks using a sliding window. In this\npaper, we propose Cluster-Former, a novel clustering-based sparse Transformer\nto perform attention across chunked sequences. The proposed framework is\npivoted on two unique types of Transformer layer: Sliding-Window Layer and\nCluster-Former Layer, which encode local sequence information and global\ncontext jointly and iteratively. This new design allows information integration\nbeyond local windows, which is especially beneficial for question answering\n(QA) tasks that rely on long-range dependencies. Experiments show that\nCluster-Former achieves state-of-the-art performance on several major QA\nbenchmarks.",
          "link": "http://arxiv.org/abs/2009.06097",
          "publishedOn": "2021-06-08T02:20:21.699Z",
          "wordCount": 623,
          "title": "Cluster-Former: Clustering-based Sparse Transformer for Long-Range Dependency Encoding. (arXiv:2009.06097v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.02507",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1\">Damai Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1\">Jing Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_S/0/1/0/all/0/1\">Shuang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1\">Baobao Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_Z/0/1/0/all/0/1\">Zhifang Sui</a>",
          "description": "Document-level Relation Extraction (RE) requires extracting relations\nexpressed within and across sentences. Recent works show that graph-based\nmethods, usually constructing a document-level graph that captures\ndocument-aware interactions, can obtain useful entity representations thus\nhelping tackle document-level RE. These methods either focus more on the entire\ngraph, or pay more attention to a part of the graph, e.g., paths between the\ntarget entity pair. However, we find that document-level RE may benefit from\nfocusing on both of them simultaneously. Therefore, to obtain more\ncomprehensive entity representations, we propose the Coarse-to-Fine Entity\nRepresentation model (CFER) that adopts a coarse-to-fine strategy involving two\nphases. First, CFER uses graph neural networks to integrate global information\nin the entire graph at a coarse level. Next, CFER utilizes the global\ninformation as a guidance to selectively aggregate path information between the\ntarget entity pair at a fine level. In classification, we combine the entity\nrepresentations from both two levels into more comprehensive representations\nfor relation extraction. Experimental results on two document-level RE\ndatasets, DocRED and CDR, show that CFER outperforms existing models and is\nrobust to the uneven label distribution.",
          "link": "http://arxiv.org/abs/2012.02507",
          "publishedOn": "2021-06-08T02:20:21.652Z",
          "wordCount": 647,
          "title": "Coarse-to-Fine Entity Representations for Document-level Relation Extraction. (arXiv:2012.02507v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.00123",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_W/0/1/0/all/0/1\">Wasi Uddin Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chi_J/0/1/0/all/0/1\">Jianfeng Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1\">Tu Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Norton_T/0/1/0/all/0/1\">Thomas Norton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuan Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>",
          "description": "Understanding privacy policies is crucial for users as it empowers them to\nlearn about the information that matters to them. Sentences written in a\nprivacy policy document explain privacy practices, and the constituent text\nspans convey further specific information about that practice. We refer to\npredicting the privacy practice explained in a sentence as intent\nclassification and identifying the text spans sharing specific information as\nslot filling. In this work, we propose PolicyIE, an English corpus consisting\nof 5,250 intent and 11,788 slot annotations spanning 31 privacy policies of\nwebsites and mobile applications. PolicyIE corpus is a challenging real-world\nbenchmark with limited labeled examples reflecting the cost of collecting\nlarge-scale annotations from domain experts. We present two alternative neural\napproaches as baselines, (1) intent classification and slot filling as a joint\nsequence tagging and (2) modeling them as a sequence-to-sequence (Seq2Seq)\nlearning task. The experiment results show that both approaches perform\ncomparably in intent classification, while the Seq2Seq method outperforms the\nsequence tagging approach in slot filling by a large margin. We perform a\ndetailed error analysis to reveal the challenges of the proposed corpus.",
          "link": "http://arxiv.org/abs/2101.00123",
          "publishedOn": "2021-06-08T02:20:21.587Z",
          "wordCount": 652,
          "title": "Intent Classification and Slot Filling for Privacy Policies. (arXiv:2101.00123v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.14439",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Bill Yuchen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Haitian Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhingra_B/0/1/0/all/0/1\">Bhuwan Dhingra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaheer_M/0/1/0/all/0/1\">Manzil Zaheer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_W/0/1/0/all/0/1\">William W. Cohen</a>",
          "description": "Current commonsense reasoning research focuses on developing models that use\ncommonsense knowledge to answer multiple-choice questions. However, systems\ndesigned to answer multiple-choice questions may not be useful in applications\nthat do not provide a small list of candidate answers to choose from. As a step\ntowards making commonsense reasoning research more realistic, we propose to\nstudy open-ended commonsense reasoning (OpenCSR) -- the task of answering a\ncommonsense question without any pre-defined choices -- using as a resource\nonly a corpus of commonsense facts written in natural language. OpenCSR is\nchallenging due to a large decision space, and because many questions require\nimplicit multi-hop reasoning. As an approach to OpenCSR, we propose DrFact, an\nefficient Differentiable model for multi-hop Reasoning over knowledge Facts. To\nevaluate OpenCSR methods, we adapt several popular commonsense reasoning\nbenchmarks, and collect multiple new answers for each test question via\ncrowd-sourcing. Experiments show that DrFact outperforms strong baseline\nmethods by a large margin.",
          "link": "http://arxiv.org/abs/2010.14439",
          "publishedOn": "2021-06-08T02:20:21.562Z",
          "wordCount": 631,
          "title": "Differentiable Open-Ended Commonsense Reasoning. (arXiv:2010.14439v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14167",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zeming Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1\">Qiyue Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moss_L/0/1/0/all/0/1\">Lawrence S. Moss</a>",
          "description": "Deep learning (DL) based language models achieve high performance on various\nbenchmarks for Natural Language Inference (NLI). And at this time, symbolic\napproaches to NLI are receiving less attention. Both approaches (symbolic and\nDL) have their advantages and weaknesses. However, currently, no method\ncombines them in a system to solve the task of NLI. To merge symbolic and deep\nlearning methods, we propose an inference framework called NeuralLog, which\nutilizes both a monotonicity-based logical inference engine and a neural\nnetwork language model for phrase alignment. Our framework models the NLI task\nas a classic search problem and uses the beam search algorithm to search for\noptimal inference paths. Experiments show that our joint logic and neural\ninference system improves accuracy on the NLI task and can achieve state-of-art\naccuracy on the SICK and MED datasets.",
          "link": "http://arxiv.org/abs/2105.14167",
          "publishedOn": "2021-06-08T02:20:21.356Z",
          "wordCount": 601,
          "title": "NeuralLog: Natural Language Inference with Joint Neural and Logical Reasoning. (arXiv:2105.14167v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2001.10980",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jing Jiang</a>",
          "description": "Traditionally, text generation models take in a sequence of text as input,\nand iteratively generate the next most probable word using pre-trained\nparameters. In this work, we propose the architecture to use images instead of\ntext as the input of the text generation model, called StoryGen. In the\narchitecture, we design a Relational Text Data Generator algorithm that relates\ndifferent features from multiple images. The output samples from the model\ndemonstrate the ability to generate meaningful paragraphs of text containing\nthe extracted features from the input images. This is an undergraduate project\nreport. Completed Dec. 2019 at the Cooper Union.",
          "link": "http://arxiv.org/abs/2001.10980",
          "publishedOn": "2021-06-08T02:20:21.199Z",
          "wordCount": 572,
          "title": "Multimodal Story Generation on Plural Images. (arXiv:2001.10980v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02972",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1\">Prasoon Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mooney_R/0/1/0/all/0/1\">Raymond J. Mooney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niekum_S/0/1/0/all/0/1\">Scott Niekum</a>",
          "description": "Imitation learning and instruction-following are two common approaches to\ncommunicate a user's intent to a learning agent. However, as the complexity of\ntasks grows, it could be beneficial to use both demonstrations and language to\ncommunicate with an agent. In this work, we propose a novel setting where an\nagent is given both a demonstration and a description, and must combine\ninformation from both the modalities. Specifically, given a demonstration for a\ntask (the source task), and a natural language description of the differences\nbetween the demonstrated task and a related but different task (the target\ntask), our goal is to train an agent to complete the target task in a zero-shot\nsetting, that is, without any demonstrations for the target task. To this end,\nwe introduce Language-Aided Reward and Value Adaptation (LARVA) which, given a\nsource demonstration and a linguistic description of how the target task\ndiffers, learns to output a reward / value function that accurately describes\nthe target task. Our experiments show that on a diverse set of adaptations, our\napproach is able to complete more than 95% of target tasks when using\ntemplate-based descriptions, and more than 70% when using free-form natural\nlanguage.",
          "link": "http://arxiv.org/abs/2106.02972",
          "publishedOn": "2021-06-08T02:20:21.183Z",
          "wordCount": 625,
          "title": "Zero-shot Task Adaptation using Natural Language. (arXiv:2106.02972v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2008.11015",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Mengyu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qingtao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xinyi He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuejiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yibo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_W/0/1/0/all/0/1\">Wei Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Shi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yining Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1\">Daxin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongmei Zhang</a>",
          "description": "It is common for people to create different types of charts to explore a\nmulti-dimensional dataset (table). However, to recommend commonly composed\ncharts in real world, one should take the challenges of efficiency, imbalanced\ndata and table context into consideration. In this paper, we propose\nTable2Charts framework which learns common patterns from a large corpus of\n(table, charts) pairs. Based on deep Q-learning with copying mechanism and\nheuristic searching, Table2Charts does table-to-sequence generation, where each\nsequence follows a chart template. On a large spreadsheet corpus with 165k\ntables and 266k charts, we show that Table2Charts could learn a shared\nrepresentation of table fields so that recommendation tasks on different chart\ntypes could mutually enhance each other. Table2Charts outperforms other chart\nrecommendation systems in both multi-type task (with doubled recall numbers\nR@3=0.61 and R@1=0.43) and human evaluations.",
          "link": "http://arxiv.org/abs/2008.11015",
          "publishedOn": "2021-06-08T02:20:21.152Z",
          "wordCount": 626,
          "title": "Table2Charts: Recommending Charts by Learning Shared Table Representations. (arXiv:2008.11015v3 [cs.DB] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.09593",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1\">Samson Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1\">Shafiq Joty</a>",
          "description": "Multilingual models have demonstrated impressive cross-lingual transfer\nperformance. However, test sets like XNLI are monolingual at the example level.\nIn multilingual communities, it is common for polyglots to code-mix when\nconversing with each other. Inspired by this phenomenon, we present two strong\nblack-box adversarial attacks (one word-level, one phrase-level) for\nmultilingual models that push their ability to handle code-mixed sentences to\nthe limit. The former uses bilingual dictionaries to propose perturbations and\ntranslations of the clean example for sense disambiguation. The latter directly\naligns the clean example with its translations before extracting phrases as\nperturbations. Our phrase-level attack has a success rate of 89.75% against\nXLM-R-large, bringing its average accuracy of 79.85 down to 8.18 on XNLI.\nFinally, we propose an efficient adversarial training scheme that trains in the\nsame number of steps as the original model and show that it improves model\naccuracy.",
          "link": "http://arxiv.org/abs/2103.09593",
          "publishedOn": "2021-06-08T02:20:21.141Z",
          "wordCount": 652,
          "title": "Code-Mixing on Sesame Street: Dawn of the Adversarial Polyglots. (arXiv:2103.09593v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.11915",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Asai_A/0/1/0/all/0/1\">Akari Asai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1\">Eunsol Choi</a>",
          "description": "Recent pretrained language models \"solved\" many reading comprehension\nbenchmarks, where questions are written with access to the evidence document.\nHowever, datasets containing information-seeking queries where evidence\ndocuments are provided after the queries are written independently remain\nchallenging. We analyze why answering information-seeking queries is more\nchallenging and where their prevalent unanswerabilities arise, on Natural\nQuestions and TyDi QA. Our controlled experiments suggest two headrooms --\nparagraph selection and answerability prediction, i.e. whether the paired\nevidence document contains the answer to the query or not. When provided with a\ngold paragraph and knowing when to abstain from answering, existing models\neasily outperform a human annotator. However, predicting answerability itself\nremains challenging. We manually annotate 800 unanswerable examples across six\nlanguages on what makes them challenging to answer. With this new data, we\nconduct per-category answerability prediction, revealing issues in the current\ndataset collection as well as task formulation. Together, our study points to\navenues for future research in information-seeking question answering, both for\ndataset creation and model development.",
          "link": "http://arxiv.org/abs/2010.11915",
          "publishedOn": "2021-06-08T02:20:21.119Z",
          "wordCount": 640,
          "title": "Challenges in Information-Seeking QA: Unanswerable Questions and Paragraph Retrieval. (arXiv:2010.11915v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10336",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jian Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Shuyi Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Haiqin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Lianxin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Mengyuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruan_X/0/1/0/all/0/1\">Xiaoyi Ruan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mo_Y/0/1/0/all/0/1\">Yang Mo</a>",
          "description": "This paper describes MagicPai's system for SemEval 2021 Task 7, HaHackathon:\nDetecting and Rating Humor and Offense. This task aims to detect whether the\ntext is humorous and how humorous it is. There are four subtasks in the\ncompetition. In this paper, we mainly present our solution, a multi-task\nlearning model based on adversarial examples, for task 1a and 1b. More\nspecifically, we first vectorize the cleaned dataset and add the perturbation\nto obtain more robust embedding representations. We then correct the loss via\nthe confidence level. Finally, we perform interactive joint learning on\nmultiple tasks to capture the relationship between whether the text is humorous\nand how humorous it is. The final result shows the effectiveness of our system.",
          "link": "http://arxiv.org/abs/2104.10336",
          "publishedOn": "2021-06-08T02:20:21.109Z",
          "wordCount": 612,
          "title": "MagicPai at SemEval-2021 Task 7: Method for Detecting and Rating Humor Based on Multi-Task Adversarial Training. (arXiv:2104.10336v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1910.02610",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jifan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1\">Shih-ting Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durrett_G/0/1/0/all/0/1\">Greg Durrett</a>",
          "description": "Multi-hop question answering requires models to gather information from\ndifferent parts of a text to answer a question. Most current approaches learn\nto address this task in an end-to-end way with neural networks, without\nmaintaining an explicit representation of the reasoning process. We propose a\nmethod to extract a discrete reasoning chain over the text, which consists of a\nseries of sentences leading to the answer. We then feed the extracted chains to\na BERT-based QA model to do final answer prediction. Critically, we do not rely\non gold annotated chains or \"supporting facts:\" at training time, we derive\npseudogold reasoning chains using heuristics based on named entity recognition\nand coreference resolution. Nor do we rely on these annotations at test time,\nas our model learns to extract chains from raw text alone. We test our approach\non two recently proposed large multi-hop question answering datasets: WikiHop\nand HotpotQA, and achieve state-of-art performance on WikiHop and strong\nperformance on HotpotQA. Our analysis shows the properties of chains that are\ncrucial for high performance: in particular, modeling extraction sequentially\nis important, as is dealing with each candidate sentence in a context-aware\nway. Furthermore, human evaluation shows that our extracted chains allow humans\nto give answers with high confidence, indicating that these are a strong\nintermediate abstraction for this task.",
          "link": "http://arxiv.org/abs/1910.02610",
          "publishedOn": "2021-06-08T02:20:21.060Z",
          "wordCount": 670,
          "title": "Multi-hop Question Answering via Reasoning Chains. (arXiv:1910.02610v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.02995",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiangming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gardner_M/0/1/0/all/0/1\">Matt Gardner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_S/0/1/0/all/0/1\">Shay B. Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lapata_M/0/1/0/all/0/1\">Mirella Lapata</a>",
          "description": "Complex reasoning over text requires understanding and chaining together\nfree-form predicates and logical connectives. Prior work has largely tried to\ndo this either symbolically or with black-box transformers. We present a middle\nground between these two extremes: a compositional model reminiscent of neural\nmodule networks that can perform chained logical reasoning. This model first\nfinds relevant sentences in the context and then chains them together using\nneural modules. Our model gives significant performance improvements (up to\n29\\% relative error reduction when comfibined with a reranker) on ROPES, a\nrecently introduced complex reasoning dataset.",
          "link": "http://arxiv.org/abs/2004.02995",
          "publishedOn": "2021-06-08T02:20:21.026Z",
          "wordCount": 551,
          "title": "Multi-Step Inference for Reasoning Over Paragraphs. (arXiv:2004.02995v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.12834",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gabriel_S/0/1/0/all/0/1\">Saadia Gabriel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celikyilmaz_A/0/1/0/all/0/1\">Asli Celikyilmaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jha_R/0/1/0/all/0/1\">Rahul Jha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>",
          "description": "While neural language models can generate text with remarkable fluency and\ncoherence, controlling for factual correctness in generation remains an open\nresearch question. This major discrepancy between the surface-level fluency and\nthe content-level correctness of neural generation has motivated a new line of\nresearch that seeks automatic metrics for evaluating the factuality of machine\ntext. In this paper, we introduce GO FIGURE, a meta-evaluation framework for\nevaluating factuality evaluation metrics. We propose five necessary and\nintuitive conditions to evaluate factuality metrics on diagnostic factuality\ndata across three different summarization tasks. Our benchmark analysis on ten\nfactuality metrics reveals that our meta-evaluation framework provides a robust\nand efficient evaluation that is extensible to multiple types of factual\nconsistency and standard generation metrics, including QA metrics. It also\nreveals that while QA metrics generally improve over standard metrics that\nmeasure factuality across domains, performance is highly dependent on the way\nin which questions are generated.",
          "link": "http://arxiv.org/abs/2010.12834",
          "publishedOn": "2021-06-08T02:20:21.017Z",
          "wordCount": 616,
          "title": "GO FIGURE: A Meta Evaluation of Factuality in Summarization. (arXiv:2010.12834v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.04552",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">W. Ronny Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sainath_T/0/1/0/all/0/1\">Tara N. Sainath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peyser_C/0/1/0/all/0/1\">Cal Peyser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Shankar Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rybach_D/0/1/0/all/0/1\">David Rybach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strohman_T/0/1/0/all/0/1\">Trevor Strohman</a>",
          "description": "We introduce Lookup-Table Language Models (LookupLM), a method for scaling up\nthe size of RNN language models with only a constant increase in the floating\npoint operations, by increasing the expressivity of the embedding table. In\nparticular, we instantiate an (additional) embedding table which embeds the\nprevious n-gram token sequence, rather than a single token. This allows the\nembedding table to be scaled up arbitrarily -- with a commensurate increase in\nperformance -- without changing the token vocabulary. Since embeddings are\nsparsely retrieved from the table via a lookup; increasing the size of the\ntable adds neither extra operations to each forward pass nor extra parameters\nthat need to be stored on limited GPU/TPU memory. We explore scaling n-gram\nembedding tables up to nearly a billion parameters. When trained on a 3-billion\nsentence corpus, we find that LookupLM improves long tail log perplexity by\n2.44 and long tail WER by 23.4% on a downstream speech recognition task over a\nstandard RNN language model baseline, an improvement comparable to a scaling up\nthe baseline by 6.2x the number of floating point operations.",
          "link": "http://arxiv.org/abs/2104.04552",
          "publishedOn": "2021-06-08T02:20:21.004Z",
          "wordCount": 667,
          "title": "Lookup-Table Recurrent Language Models for Long Tail Speech Recognition. (arXiv:2104.04552v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.15699",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Si_C/0/1/0/all/0/1\">Chenglei Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhengyan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_F/0/1/0/all/0/1\">Fanchao Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yasheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>",
          "description": "Pretrained language models (PLMs) perform poorly under adversarial attacks.\nTo improve the adversarial robustness, adversarial data augmentation (ADA) has\nbeen widely adopted to cover more search space of adversarial attacks by adding\ntextual adversarial examples during training. However, the number of\nadversarial examples for text augmentation is still extremely insufficient due\nto the exponentially large attack search space. In this work, we propose a\nsimple and effective method to cover a much larger proportion of the attack\nsearch space, called Adversarial and Mixup Data Augmentation (AMDA).\nSpecifically, AMDA linearly interpolates the representations of pairs of\ntraining samples to form new virtual samples, which are more abundant and\ndiverse than the discrete text adversarial examples in conventional ADA.\nMoreover, to fairly evaluate the robustness of different models, we adopt a\nchallenging evaluation setup, which generates a new set of adversarial examples\ntargeting each model. In text classification experiments of BERT and RoBERTa,\nAMDA achieves significant robustness gains under two strong adversarial attacks\nand alleviates the performance degradation of ADA on the clean data. Our code\nis available at: https://github.com/thunlp/MixADA .",
          "link": "http://arxiv.org/abs/2012.15699",
          "publishedOn": "2021-06-08T02:20:20.995Z",
          "wordCount": 666,
          "title": "Better Robustness by More Coverage: Adversarial Training with Mixup Augmentation for Robust Fine-tuning. (arXiv:2012.15699v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.06891",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Ye Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Z/0/1/0/all/0/1\">Zixun Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zong_L/0/1/0/all/0/1\">Lu Zong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kaizhu Huang</a>",
          "description": "This study develops a calibrated beam-based algorithm with global awareness\nfor neural abstractive summarization, aiming to improve the local optimality\nproblem of the original beam search in a rigorous way. Specifically, a novel\nglobal protocol is proposed based on the attention distribution to stipulate\nhow a global optimal hypothesis should attend to the source. A global scoring\nfunction is then developed to regulate beam search to generate summaries in a\nmore near-global optimal fashion. This novel design enjoys a distinctive\nproperty, i.e. the global attention distribution could be predicted before\ninference, enabling stepwise improvements on the beam search through the global\nscoring function. Extensive experiments on $9$ datasets show that the\nglobal-aware inference significantly improves state-of-the-art summarization\nmodels even using empirical hyper-parameters. The algorithm is also proven\nrobust as it remains to generate meaningful texts with corrupted attention\ndistributions. The codes and a comprehensive set of examples are available.",
          "link": "http://arxiv.org/abs/2009.06891",
          "publishedOn": "2021-06-08T02:20:20.879Z",
          "wordCount": 620,
          "title": "Global-aware Beam Search for Neural Abstractive Summarization. (arXiv:2009.06891v4 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02954",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Caciularu_A/0/1/0/all/0/1\">Avi Caciularu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dagan_I/0/1/0/all/0/1\">Ido Dagan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberger_J/0/1/0/all/0/1\">Jacob Goldberger</a>",
          "description": "We introduce a new approach for smoothing and improving the quality of word\nembeddings. We consider a method of fusing word embeddings that were trained on\nthe same corpus but with different initializations. We project all the models\nto a shared vector space using an efficient implementation of the Generalized\nProcrustes Analysis (GPA) procedure, previously used in multilingual word\ntranslation. Our word representation demonstrates consistent improvements over\nthe raw models as well as their simplistic average, on a range of tasks. As the\nnew representations are more stable and reliable, there is a noticeable\nimprovement in rare word evaluations.",
          "link": "http://arxiv.org/abs/2106.02954",
          "publishedOn": "2021-06-08T02:20:20.848Z",
          "wordCount": 533,
          "title": "Denoising Word Embeddings by Averaging in a Shared Space. (arXiv:2106.02954v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02792",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chenghao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yudong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muresan_S/0/1/0/all/0/1\">Smaranda Muresan</a>",
          "description": "Social media has become a valuable resource for the study of suicidal\nideation and the assessment of suicide risk. Among social media platforms,\nReddit has emerged as the most promising one due to its anonymity and its focus\non topic-based communities (subreddits) that can be indicative of someone's\nstate of mind or interest regarding mental health disorders such as\nr/SuicideWatch, r/Anxiety, r/depression. A challenge for previous work on\nsuicide risk assessment has been the small amount of labeled data. We propose\nan empirical investigation into several classes of weakly-supervised\napproaches, and show that using pseudo-labeling based on related issues around\nmental health (e.g., anxiety, depression) helps improve model performance for\nsuicide risk assessment.",
          "link": "http://arxiv.org/abs/2106.02792",
          "publishedOn": "2021-06-08T02:20:20.839Z",
          "wordCount": 554,
          "title": "Weakly-Supervised Methods for Suicide Risk Assessment: Role of Related Domains. (arXiv:2106.02792v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02821",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qian_J/0/1/0/all/0/1\">Jing Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+ElSherief_M/0/1/0/all/0/1\">Mai ElSherief</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1\">Xifeng Yan</a>",
          "description": "Existing work on automated hate speech classification assumes that the\ndataset is fixed and the classes are pre-defined. However, the amount of data\nin social media increases every day, and the hot topics changes rapidly,\nrequiring the classifiers to be able to continuously adapt to new data without\nforgetting the previously learned knowledge. This ability, referred to as\nlifelong learning, is crucial for the real-word application of hate speech\nclassifiers in social media. In this work, we propose lifelong learning of hate\nspeech classification on social media. To alleviate catastrophic forgetting, we\npropose to use Variational Representation Learning (VRL) along with a memory\nmodule based on LB-SOINN (Load-Balancing Self-Organizing Incremental Neural\nNetwork). Experimentally, we show that combining variational representation\nlearning and the LB-SOINN memory module achieves better performance than the\ncommonly-used lifelong learning techniques.",
          "link": "http://arxiv.org/abs/2106.02821",
          "publishedOn": "2021-06-08T02:20:20.826Z",
          "wordCount": 568,
          "title": "Lifelong Learning of Hate Speech Classification on Social Media. (arXiv:2106.02821v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02834",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khanuja_S/0/1/0/all/0/1\">Simran Khanuja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johnson_M/0/1/0/all/0/1\">Melvin Johnson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talukdar_P/0/1/0/all/0/1\">Partha Talukdar</a>",
          "description": "Pre-trained multilingual language models (LMs) have achieved state-of-the-art\nresults in cross-lingual transfer, but they often lead to an inequitable\nrepresentation of languages due to limited capacity, skewed pre-training data,\nand sub-optimal vocabularies. This has prompted the creation of an ever-growing\npre-trained model universe, where each model is trained on large amounts of\nlanguage or domain specific data with a carefully curated, linguistically\ninformed vocabulary. However, doing so brings us back full circle and prevents\none from leveraging the benefits of multilinguality. To address the gaps at\nboth ends of the spectrum, we propose MergeDistill, a framework to merge\npre-trained LMs in a way that can best leverage their assets with minimal\ndependencies, using task-agnostic knowledge distillation. We demonstrate the\napplicability of our framework in a practical setting by leveraging\npre-existing teacher LMs and training student LMs that perform competitively\nwith or even outperform teacher LMs trained on several orders of magnitude more\ndata and with a fixed model capacity. We also highlight the importance of\nteacher selection and its impact on student model performance.",
          "link": "http://arxiv.org/abs/2106.02834",
          "publishedOn": "2021-06-08T02:20:20.787Z",
          "wordCount": 600,
          "title": "MergeDistill: Merging Pre-trained Language Models using Distillation. (arXiv:2106.02834v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02725",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Siyi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sihao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uyttendaele_X/0/1/0/all/0/1\">Xander Uyttendaele</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1\">Dan Roth</a>",
          "description": "We propose MultiOpEd, an open-domain news editorial corpus that supports\nvarious tasks pertaining to the argumentation structure in news editorials,\nfocusing on automatic perspective discovery. News editorial is a genre of\npersuasive text, where the argumentation structure is usually implicit.\nHowever, the arguments presented in an editorial typically center around a\nconcise, focused thesis, which we refer to as their perspective. MultiOpEd aims\nat supporting the study of multiple tasks relevant to automatic perspective\ndiscovery, where a system is expected to produce a single-sentence thesis\nstatement summarizing the arguments presented. We argue that identifying and\nabstracting such natural language perspectives from editorials is a crucial\nstep toward studying the implicit argumentation structure in news editorials.\nWe first discuss the challenges and define a few conceptual tasks towards our\ngoal. To demonstrate the utility of MultiOpEd and the induced tasks, we study\nthe problem of perspective summarization in a multi-task learning setting, as a\ncase study. We show that, with the induced tasks as auxiliary tasks, we can\nimprove the quality of the perspective summary generated. We hope that\nMultiOpEd will be a useful resource for future studies on argumentation in the\nnews editorial domain.",
          "link": "http://arxiv.org/abs/2106.02725",
          "publishedOn": "2021-06-08T02:20:20.776Z",
          "wordCount": 617,
          "title": "MultiOpEd: A Corpus of Multi-Perspective News Editorials. (arXiv:2106.02725v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02736",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goyal_K/0/1/0/all/0/1\">Kartik Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dyer_C/0/1/0/all/0/1\">Chris Dyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berg_Kirkpatrick_T/0/1/0/all/0/1\">Taylor Berg-Kirkpatrick</a>",
          "description": "While recent work has shown that scores from models trained by the ubiquitous\nmasked language modeling (MLM) objective effectively discriminate probable and\nimprobable sequences, it is still an open question if these MLMs specify a\nprincipled probability distribution over the space of possible sequences. In\nthis paper, we interpret MLMs as energy-based sequence models and propose two\nenergy parametrizations derivable from the trained MLMs. In order to draw\nsamples correctly from these models, we develop a tractable \\emph{sampling}\nscheme based on the Metropolis--Hastings Monte Carlo algorithm. In our\napproach, samples are proposed from the same masked conditionals used for\ntraining the masked language models, and they are accepted or rejected based on\ntheir energy values according to the target distribution. We validate the\neffectiveness of the proposed parametrizations by exploring the quality of\nsamples drawn from these energy-based models on the conditional generation task\nof machine translation. We theoretically and empirically justify our sampling\nalgorithm by showing that the masked conditionals on their own do not yield a\nMarkov chain whose stationary distribution is that of our target distribution,\nand our approach generates higher quality samples than other recently proposed\nundirected generation approaches (Wang et al., 2019, Ghazvininejad et al.,\n2019).",
          "link": "http://arxiv.org/abs/2106.02736",
          "publishedOn": "2021-06-08T02:20:20.767Z",
          "wordCount": 634,
          "title": "Exposing the Implicit Energy Networks behind Masked Language Models via Metropolis--Hastings. (arXiv:2106.02736v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02668",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mu_J/0/1/0/all/0/1\">Jesse Mu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1\">Noah Goodman</a>",
          "description": "To build agents that can collaborate effectively with others, recent research\nhas trained artificial agents to communicate with each other in Lewis-style\nreferential games. However, this often leads to successful but uninterpretable\ncommunication. We argue that this is due to the game objective: communicating\nabout a single object in a shared visual context is prone to overfitting and\ndoes not encourage language useful beyond concrete reference. In contrast,\nhuman language conveys a rich variety of abstract ideas. To promote such\nskills, we propose games that require communicating generalizations over sets\nof objects representing abstract visual concepts, optionally with separate\ncontexts for each agent. We find that these games greatly improve systematicity\nand interpretability of the learned languages, according to several metrics in\nthe literature. Finally, we propose a method for identifying logical operations\nembedded in the emergent languages by learning an approximate compositional\nreconstruction of the language.",
          "link": "http://arxiv.org/abs/2106.02668",
          "publishedOn": "2021-06-08T02:20:20.733Z",
          "wordCount": 568,
          "title": "Emergent Communication of Generalizations. (arXiv:2106.02668v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02679",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lamy_Poirier_J/0/1/0/all/0/1\">Joel Lamy-Poirier</a>",
          "description": "The advent of the transformer has sparked a quick growth in the size of\nlanguage models, far outpacing hardware improvements. (Dense) transformers are\nexpected to reach the trillion-parameter scale in the near future, for which\ntraining requires thousands or even tens of thousands of GPUs. We investigate\nthe challenges of training at this scale and beyond on commercially available\nhardware. In particular, we analyse the shortest possible training time for\ndifferent configurations of distributed training, leveraging empirical scaling\nlaws for language models to estimate the optimal (critical) batch size.\nContrary to popular belief, we find no evidence for a memory wall, and instead\nargue that the real limitation -- other than the cost -- lies in the training\nduration.\n\nIn addition to this analysis, we introduce two new methods, \\textit{layered\ngradient accumulation} and \\textit{modular pipeline parallelism}, which\ntogether cut the shortest training time by half. The methods also reduce data\nmovement, lowering the network requirement to a point where a fast InfiniBand\nconnection is not necessary. This increased network efficiency also improve on\nthe methods introduced with the ZeRO optimizer, reducing the memory usage to a\ntiny fraction of the available GPU memory.",
          "link": "http://arxiv.org/abs/2106.02679",
          "publishedOn": "2021-06-08T02:20:20.719Z",
          "wordCount": 646,
          "title": "Layered gradient accumulation and modular pipeline parallelism: fast and efficient training of large language models. (arXiv:2106.02679v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.15262",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiexi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takanobu_R/0/1/0/all/0/1\">Ryuichi Takanobu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Jiaxin Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_D/0/1/0/all/0/1\">Dazhen Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongguang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_W/0/1/0/all/0/1\">Weiran Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Cheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1\">Wei Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>",
          "description": "Most language understanding models in task-oriented dialog systems are\ntrained on a small amount of annotated training data, and evaluated in a small\nset from the same distribution. However, these models can lead to system\nfailure or undesirable output when being exposed to natural language\nperturbation or variation in practice. In this paper, we conduct comprehensive\nevaluation and analysis with respect to the robustness of natural language\nunderstanding models, and introduce three important aspects related to language\nunderstanding in real-world dialog systems, namely, language variety, speech\ncharacteristics, and noise perturbation. We propose a model-agnostic toolkit\nLAUG to approximate natural language perturbations for testing the robustness\nissues in task-oriented dialog. Four data augmentation approaches covering the\nthree aspects are assembled in LAUG, which reveals critical robustness issues\nin state-of-the-art models. The augmented dataset through LAUG can be used to\nfacilitate future research on the robustness testing of language understanding\nin task-oriented dialog.",
          "link": "http://arxiv.org/abs/2012.15262",
          "publishedOn": "2021-06-07T22:33:05.098Z",
          "wordCount": 636,
          "title": "Robustness Testing of Language Understanding in Task-Oriented Dialog. (arXiv:2012.15262v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02399",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ren_M/0/1/0/all/0/1\">Mucheng Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Heyan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yang Gao</a>",
          "description": "Qualitative relationships illustrate how changing one property (e.g., moving\nvelocity) affects another (e.g., kinetic energy) and constitutes a considerable\nportion of textual knowledge. Current approaches use either semantic parsers to\ntransform natural language inputs into logical expressions or a \"black-box\"\nmodel to solve them in one step. The former has a limited application range,\nwhile the latter lacks interpretability. In this work, we categorize\nqualitative reasoning tasks into two types: prediction and comparison. In\nparticular, we adopt neural network modules trained in an end-to-end manner to\nsimulate the two reasoning processes. Experiments on two qualitative reasoning\nquestion answering datasets, QuaRTz and QuaRel, show our methods' effectiveness\nand generalization capability, and the intermediate outputs provided by the\nmodules make the reasoning process interpretable.",
          "link": "http://arxiv.org/abs/2106.02399",
          "publishedOn": "2021-06-07T03:06:13.263Z",
          "wordCount": 551,
          "title": "Prediction or Comparison: Toward Interpretable Qualitative Reasoning. (arXiv:2106.02399v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02417",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wang_Z/0/1/0/all/0/1\">Zhengxiong Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ragni_A/0/1/0/all/0/1\">Anton Ragni</a>",
          "description": "Recurrent neural networks are widely used in speech and language processing.\nDue to dependency on the past, standard algorithms for training these models,\nsuch as back-propagation through time (BPTT), cannot be efficiently\nparallelised. Furthermore, applying these models to more complex structures\nthan sequences requires inference time approximations, which introduce\ninconsistency between inference and training. This paper shows that recurrent\nneural networks can be reformulated as fixed-points of non-linear equation\nsystems. These fixed-points can be computed using an iterative algorithm\nexactly and in as many iterations as the length of any given sequence. Each\niteration of this algorithm adds one additional Markovian-like order of\ndependencies such that upon termination all dependencies modelled by the\nrecurrent neural networks have been incorporated. Although exact fixed-points\ninherit the same parallelization and inconsistency issues, this paper shows\nthat approximate fixed-points can be computed in parallel and used consistently\nin training and inference including tasks such as lattice rescoring.\nExperimental validation is performed in two tasks, Penn Tree Bank and\nWikiText-2, and shows that approximate fixed-points yield competitive\nprediction performance to recurrent neural networks trained using the BPTT\nalgorithm.",
          "link": "http://arxiv.org/abs/2106.02417",
          "publishedOn": "2021-06-07T03:06:13.067Z",
          "wordCount": 613,
          "title": "Approximate Fixed-Points in Recurrent Neural Networks. (arXiv:2106.02417v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2004.03238",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shinoda_K/0/1/0/all/0/1\">Kazutoshi Shinoda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugawara_S/0/1/0/all/0/1\">Saku Sugawara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aizawa_A/0/1/0/all/0/1\">Akiko Aizawa</a>",
          "description": "Question answering (QA) models for reading comprehension have achieved\nhuman-level accuracy on in-distribution test sets. However, they have been\ndemonstrated to lack robustness to challenge sets, whose distribution is\ndifferent from that of training sets. Existing data augmentation methods\nmitigate this problem by simply augmenting training sets with synthetic\nexamples sampled from the same distribution as the challenge sets. However,\nthese methods assume that the distribution of a challenge set is known a\npriori, making them less applicable to unseen challenge sets. In this study, we\nfocus on question-answer pair generation (QAG) to mitigate this problem. While\nmost existing QAG methods aim to improve the quality of synthetic examples, we\nconjecture that diversity-promoting QAG can mitigate the sparsity of training\nsets and lead to better robustness. We present a variational QAG model that\ngenerates multiple diverse QA pairs from a paragraph. Our experiments show that\nour method can improve the accuracy of 12 challenge sets, as well as the\nin-distribution accuracy. Our code and data are available at\nhttps://github.com/KazutoshiShinoda/VQAG.",
          "link": "http://arxiv.org/abs/2004.03238",
          "publishedOn": "2021-06-07T03:06:13.054Z",
          "wordCount": 646,
          "title": "Improving the Robustness of QA Models to Challenge Sets with Variational Question-Answer Pair Generation. (arXiv:2004.03238v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02443",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Awasthi_A/0/1/0/all/0/1\">Abhijeet Awasthi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kilgour_K/0/1/0/all/0/1\">Kevin Kilgour</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rom_H/0/1/0/all/0/1\">Hassan Rom</a>",
          "description": "Learning to recognize new keywords with just a few examples is essential for\npersonalizing keyword spotting (KWS) models to a user's choice of keywords.\nHowever, modern KWS models are typically trained on large datasets and\nrestricted to a small vocabulary of keywords, limiting their transferability to\na broad range of unseen keywords. Towards easily customizable KWS models, we\npresent KeySEM (Keyword Speech EMbedding), a speech embedding model pre-trained\non the task of recognizing a large number of keywords. Speech representations\noffered by KeySEM are highly effective for learning new keywords from a limited\nnumber of examples. Comparisons with a diverse range of related work across\nseveral datasets show that our method achieves consistently superior\nperformance with fewer training examples. Although KeySEM was pre-trained only\non English utterances, the performance gains also extend to datasets from four\nother languages indicating that KeySEM learns useful representations well\naligned with the task of keyword spotting. Finally, we demonstrate KeySEM's\nability to learn new keywords sequentially without requiring to re-train on\npreviously learned keywords. Our experimental observations suggest that KeySEM\nis well suited to on-device environments where post-deployment learning and\nease of customization are often desirable.",
          "link": "http://arxiv.org/abs/2106.02443",
          "publishedOn": "2021-06-07T03:06:13.022Z",
          "wordCount": 642,
          "title": "Teaching keyword spotters to spot new keywords with limited examples. (arXiv:2106.02443v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2105.00164",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shaofeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_T/0/1/0/all/0/1\">Tian Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1\">Benjamin Zi Hao Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_M/0/1/0/all/0/1\">Minhui Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Haojin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jialiang Lu</a>",
          "description": "Natural language processing (NLP) systems have been proven to be vulnerable\nto backdoor attacks, whereby hidden features (backdoors) are trained into a\nlanguage model and may only be activated by specific inputs (called triggers),\nto trick the model into producing unexpected behaviors. In this paper, we\ncreate covert and natural triggers for textual backdoor attacks, \\textit{hidden\nbackdoors}, where triggers can fool both modern language models and human\ninspection. We deploy our hidden backdoors through two state-of-the-art trigger\nembedding methods. The first approach via homograph replacement, embeds the\ntrigger into deep neural networks through the visual spoofing of lookalike\ncharacter replacement. The second approach uses subtle differences between text\ngenerated by language models and real natural text to produce trigger sentences\nwith correct grammar and high fluency. We demonstrate that the proposed hidden\nbackdoors can be effective across three downstream security-critical NLP tasks,\nrepresentative of modern human-centric NLP systems, including toxic comment\ndetection, neural machine translation (NMT), and question answering (QA). Our\ntwo hidden backdoor attacks can achieve an Attack Success Rate (ASR) of at\nleast $97\\%$ with an injection rate of only $3\\%$ in toxic comment detection,\n$95.1\\%$ ASR in NMT with less than $0.5\\%$ injected data, and finally $91.12\\%$\nASR against QA updated with only 27 poisoning data samples on a model\npreviously trained with 92,024 samples (0.029\\%). We are able to demonstrate\nthe adversary's high success rate of attacks, while maintaining functionality\nfor regular users, with triggers inconspicuous by the human administrators.",
          "link": "http://arxiv.org/abs/2105.00164",
          "publishedOn": "2021-06-07T03:06:13.015Z",
          "wordCount": 710,
          "title": "Hidden Backdoors in Human-Centric Language Models. (arXiv:2105.00164v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02562",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1\">Zhaoxin Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1\">Michael Zhu</a>",
          "description": "Hierarchical structures exist in both linguistics and Natural Language\nProcessing (NLP) tasks. How to design RNNs to learn hierarchical\nrepresentations of natural languages remains a long-standing challenge. In this\npaper, we define two different types of boundaries referred to as static and\ndynamic boundaries, respectively, and then use them to construct a multi-layer\nhierarchical structure for document classification tasks. In particular, we\nfocus on a three-layer hierarchical structure with static word- and sentence-\nlayers and a dynamic phrase-layer. LSTM cells and two boundary detectors are\nused to implement the proposed structure, and the resulting network is called\nthe {\\em Recurrent Neural Network with Mixed Hierarchical Structures}\n(MHS-RNN). We further add three layers of attention mechanisms to the MHS-RNN\nmodel. Incorporating attention mechanisms allows our model to use more\nimportant content to construct document representation and enhance its\nperformance on document classification tasks. Experiments on five different\ndatasets show that the proposed architecture outperforms previous methods on\nall the five tasks.",
          "link": "http://arxiv.org/abs/2106.02562",
          "publishedOn": "2021-06-07T03:06:12.473Z",
          "wordCount": 593,
          "title": "Recurrent Neural Networks with Mixed Hierarchical Structures for Natural Language Processing. (arXiv:2106.02562v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2101.07947",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zekang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zongjia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinchao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>",
          "description": "We participate in the DSTC9 Interactive Dialogue Evaluation Track (Gunasekara\net al. 2020) sub-task 1 (Knowledge Grounded Dialogue) and sub-task 2\n(Interactive Dialogue). In sub-task 1, we employ a pre-trained language model\nto generate topic-related responses and propose a response ensemble method for\nresponse selection. In sub-task2, we propose a novel Dialogue Planning Model\n(DPM) to capture conversation flow in the interaction with humans. We also\ndesign an integrated open-domain dialogue system containing pre-process,\ndialogue model, scoring model, and post-process, which can generate fluent,\ncoherent, consistent, and humanlike responses. We tie 1st on human ratings and\nalso get the highest Meteor, and Bert-score in sub-task 1, and rank 3rd on\ninteractive human evaluation in sub-task 2.",
          "link": "http://arxiv.org/abs/2101.07947",
          "publishedOn": "2021-06-07T03:06:12.456Z",
          "wordCount": 585,
          "title": "WeChat AI & ICT's Submission for DSTC9 Interactive Dialogue Evaluation Track. (arXiv:2101.07947v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02309",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+DAgostino_G/0/1/0/all/0/1\">Giovanna D&#x27;Agostino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotumaccio_N/0/1/0/all/0/1\">Nicola Cotumaccio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Policriti_A/0/1/0/all/0/1\">Alberto Policriti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prezza_N/0/1/0/all/0/1\">Nicola Prezza</a>",
          "description": "The states of a deterministic finite automaton A can be identified with\ncollections of words in Pf(L(A)) -- the set of prefixes of words belonging to\nthe regular language accepted by A. But words can be ordered and among the many\npossible orders a very natural one is the co-lexicographic one. Such\nnaturalness stems from the fact that it suggests a transfer of the order from\nwords to the automaton's states. In a number of papers automata admitting a\ntotal ordering of states coherent with the ordering of the set of words\nreaching them have been proposed. Such class of ordered automata -- the Wheeler\nautomata -- turned out to be efficiently stored/searched using an index.\nUnfortunately not all automata can be totally ordered as previously outlined.\nHowever, automata can always be partially ordered and an intrinsic measure of\ntheir complexity can be defined and effectively determined, as the minimum\nwidth of one of their admissible partial orders. As shown in previous works,\nthis new concept of width of an automaton has useful consequences in the fields\nof graph compression, indexing data structures, and automata theory. In this\npaper we prove that a canonical, minimum-width, partially-ordered automaton\naccepting a language L -- dubbed the Hasse automaton H of L -- can be\nexhibited. H provides, in a precise sense, the best possible way to (partially)\norder the states of any automaton accepting L, as long as we want to maintain\nan operational link with the (co-lexicographic) order of Pf(L(A)). Using H we\nprove that the width of the language can be effectively computed from the\nminimum automaton recognizing the language. Finally, we explore the\nrelationship between two (often conflicting) objectives: minimizing the width\nand minimizing the number of states of an automaton.",
          "link": "http://arxiv.org/abs/2106.02309",
          "publishedOn": "2021-06-07T03:06:12.450Z",
          "wordCount": 719,
          "title": "On (co-lex) Ordering Automata. (arXiv:2106.02309v1 [cs.FL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02490",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Conley_T/0/1/0/all/0/1\">Thomas Conley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalita_J/0/1/0/all/0/1\">Jugal Kalita</a>",
          "description": "Artificial Neural networks are mathematical models at their core. This\ntruismpresents some fundamental difficulty when networks are tasked with\nNatural Language Processing. A key problem lies in measuring the similarity or\ndistance among vectors in NLP embedding space, since the mathematical concept\nof distance does not always agree with the linguistic concept. We suggest that\nthe best way to measure linguistic distance among vectors is by employing the\nLanguage Model (LM) that created them. We introduce Language Model Distance\n(LMD) for measuring accuracy of vector transformations based on the\nDistributional Hypothesis ( LMD Accuracy ). We show the efficacy of this metric\nby applying it to a simple neural network learning the Procrustes algorithm for\nbilingual word mapping.",
          "link": "http://arxiv.org/abs/2106.02490",
          "publishedOn": "2021-06-07T03:06:12.443Z",
          "wordCount": 574,
          "title": "Language Model Metrics and Procrustes Analysis for Improved Vector Transformation of NLP Embeddings. (arXiv:2106.02490v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.14849",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeyer_A/0/1/0/all/0/1\">Albert Zeyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schluter_R/0/1/0/all/0/1\">Ralf Schl&#xfc;ter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ney_H/0/1/0/all/0/1\">Hermann Ney</a>",
          "description": "The peaky behavior of CTC models is well known experimentally. However, an\nunderstanding about why peaky behavior occurs is missing, and whether this is a\ngood property. We provide a formal analysis of the peaky behavior and gradient\ndescent convergence properties of the CTC loss and related training criteria.\nOur analysis provides a deep understanding why peaky behavior occurs and when\nit is suboptimal. On a simple example which should be trivial to learn for any\nmodel, we prove that a feed-forward neural network trained with CTC from\nuniform initialization converges towards peaky behavior with a 100% error rate.\nOur analysis further explains why CTC only works well together with the blank\nlabel. We further demonstrate that peaky behavior does not occur on other\nrelated losses including a label prior model, and that this improves\nconvergence.",
          "link": "http://arxiv.org/abs/2105.14849",
          "publishedOn": "2021-06-07T03:06:12.367Z",
          "wordCount": 604,
          "title": "Why does CTC result in peaky behavior?. (arXiv:2105.14849v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02524",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mullenbach_J/0/1/0/all/0/1\">James Mullenbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pruksachatkun_Y/0/1/0/all/0/1\">Yada Pruksachatkun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adler_S/0/1/0/all/0/1\">Sean Adler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seale_J/0/1/0/all/0/1\">Jennifer Seale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swartz_J/0/1/0/all/0/1\">Jordan Swartz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McKelvey_T/0/1/0/all/0/1\">T. Greg McKelvey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1\">Hui Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sontag_D/0/1/0/all/0/1\">David Sontag</a>",
          "description": "Continuity of care is crucial to ensuring positive health outcomes for\npatients discharged from an inpatient hospital setting, and improved\ninformation sharing can help. To share information, caregivers write discharge\nnotes containing action items to share with patients and their future\ncaregivers, but these action items are easily lost due to the lengthiness of\nthe documents. In this work, we describe our creation of a dataset of clinical\naction items annotated over MIMIC-III, the largest publicly available dataset\nof real clinical notes. This dataset, which we call CLIP, is annotated by\nphysicians and covers 718 documents representing 100K sentences. We describe\nthe task of extracting the action items from these documents as multi-aspect\nextractive summarization, with each aspect representing a type of action to be\ntaken. We evaluate several machine learning models on this task, and show that\nthe best models exploit in-domain language model pre-training on 59K\nunannotated documents, and incorporate context from neighboring sentences. We\nalso propose an approach to pre-training data selection that allows us to\nexplore the trade-off between size and domain-specificity of pre-training\ndatasets for this task.",
          "link": "http://arxiv.org/abs/2106.02524",
          "publishedOn": "2021-06-07T03:06:12.360Z",
          "wordCount": 641,
          "title": "CLIP: A Dataset for Extracting Action Items for Physicians from Hospital Discharge Notes. (arXiv:2106.02524v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2004.13631",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Shengding Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_X/0/1/0/all/0/1\">Xin Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Cheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jie Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Juanzi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>",
          "description": "A comprehensive knowledge graph (KG) contains an instance-level entity graph\nand an ontology-level concept graph. The two-view KG provides a testbed for\nmodels to \"simulate\" human's abilities on knowledge abstraction,\nconcretization, and completion (KACC), which are crucial for human to recognize\nthe world and manage learned knowledge. Existing studies mainly focus on\npartial aspects of KACC. In order to promote thorough analyses for KACC\nabilities of models, we propose a unified KG benchmark by improving existing\nbenchmarks in terms of dataset scale, task coverage, and difficulty.\nSpecifically, we collect new datasets that contain larger concept graphs,\nabundant cross-view links as well as dense entity graphs. Based on the\ndatasets, we propose novel tasks such as multi-hop knowledge abstraction (MKA),\nmulti-hop knowledge concretization (MKC) and then design a comprehensive\nbenchmark. For MKA and MKC tasks, we further annotate multi-hop hierarchical\ntriples as harder samples. The experimental results of existing methods\ndemonstrate the challenges of our benchmark. The resource is available at\nhttps://github.com/thunlp/KACC.",
          "link": "http://arxiv.org/abs/2004.13631",
          "publishedOn": "2021-06-07T03:06:12.354Z",
          "wordCount": 647,
          "title": "KACC: A Multi-task Benchmark for Knowledge Abstraction, Concretization and Completion. (arXiv:2004.13631v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02561",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cui_R/0/1/0/all/0/1\">Ruixiang Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hershcovich_D/0/1/0/all/0/1\">Daniel Hershcovich</a>",
          "description": "Broad-coverage meaning representations in NLP mostly focus on explicitly\nexpressed content. More importantly, the scarcity of datasets annotating\ndiverse implicit roles limits empirical studies into their linguistic nuances.\nFor example, in the web review \"Great service!\", the provider and consumer are\nimplicit arguments of different types. We examine an annotated corpus of\nfine-grained implicit arguments (Cui and Hershcovich, 2020) by carefully\nre-annotating it, resolving several inconsistencies. Subsequently, we present\nthe first transition-based neural parser that can handle implicit arguments\ndynamically, and experiment with two different transition systems on the\nimproved dataset. We find that certain types of implicit arguments are more\ndifficult to parse than others and that the simpler system is more accurate in\nrecovering implicit arguments, despite having a lower overall parsing score,\nattesting current reasoning limitations of NLP models. This work will\nfacilitate a better understanding of implicit and underspecified language, by\nincorporating it holistically into meaning representations.",
          "link": "http://arxiv.org/abs/2106.02561",
          "publishedOn": "2021-06-07T03:06:12.347Z",
          "wordCount": 574,
          "title": "Great Service! Fine-grained Parsing of Implicit Arguments. (arXiv:2106.02561v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02569",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lan_W/0/1/0/all/0/1\">Wuwei Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1\">Chao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wei Xu</a>",
          "description": "Monolingual word alignment is important for studying fine-grained editing\noperations (i.e., deletion, addition, and substitution) in text-to-text\ngeneration tasks, such as paraphrase generation, text simplification,\nneutralizing biased language, etc. In this paper, we present a novel neural\nsemi-Markov CRF alignment model, which unifies word and phrase alignments\nthrough variable-length spans. We also create a new benchmark with human\nannotations that cover four different text genres to evaluate monolingual word\nalignment models in more realistic settings. Experimental results show that our\nproposed model outperforms all previous approaches for monolingual word\nalignment as well as a competitive QA-based baseline, which was previously only\napplied to bilingual data. Our model demonstrates good generalizability to\nthree out-of-domain datasets and shows great utility in two downstream\napplications: automatic text simplification and sentence pair classification\ntasks.",
          "link": "http://arxiv.org/abs/2106.02569",
          "publishedOn": "2021-06-07T03:06:12.337Z",
          "wordCount": 557,
          "title": "Neural semi-Markov CRF for Monolingual Word Alignment. (arXiv:2106.02569v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02340",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nandy_A/0/1/0/all/0/1\">Abhilash Nandy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adak_S/0/1/0/all/0/1\">Sayantan Adak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Halder_T/0/1/0/all/0/1\">Tanurima Halder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pokala_S/0/1/0/all/0/1\">Sai Mahesh Pokala</a>",
          "description": "This paper describes the performance of the team cs60075_team2 at SemEval\n2021 Task 1 - Lexical Complexity Prediction. The main contribution of this\npaper is to fine-tune transformer-based language models pre-trained on several\ntext corpora, some being general (E.g., Wikipedia, BooksCorpus), some being the\ncorpora from which the CompLex Dataset was extracted, and others being from\nother specific domains such as Finance, Law, etc. We perform ablation studies\non selecting the transformer models and how their individual complexity scores\nare aggregated to get the resulting complexity scores. Our method achieves a\nbest Pearson Correlation of $0.784$ in sub-task 1 (single word) and $0.836$ in\nsub-task 2 (multiple word expressions).",
          "link": "http://arxiv.org/abs/2106.02340",
          "publishedOn": "2021-06-07T03:06:12.205Z",
          "wordCount": 567,
          "title": "cs60075_team2 at SemEval-2021 Task 1 : Lexical Complexity Prediction using Transformer-based Language Models pre-trained on various text corpora. (arXiv:2106.02340v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02397",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Miltzow_T/0/1/0/all/0/1\">Tillmann Miltzow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmiermann_R/0/1/0/all/0/1\">Reinier F. Schmiermann</a>",
          "description": "A continuous constraint satisfaction problem (CCSP) is a constraint\nsatisfaction problem (CSP) with a domain $U \\subset \\mathbb{R}$. We engage in a\nsystematic study to classify CCSPs that are complete of the Existential Theory\nof the Reals, i.e., ER-complete. To define this class, we first consider the\nproblem ETR, which also stands for Existential Theory of the Reals. In an\ninstance of this problem we are given some sentence of the form $\\exists x_1,\n\\ldots, x_n \\in \\mathbb{R} : \\Phi(x_1, \\ldots, x_n)$, where $\\Phi$ is a\nwell-formed quantifier-free formula consisting of the symbols $\\{0, 1, +,\n\\cdot, \\geq, >, \\wedge, \\vee, \\neg\\}$, the goal is to check whether this\nsentence is true. Now the class ER is the family of all problems that admit a\npolynomial-time reduction to ETR. It is known that NP $\\subseteq$ ER\n$\\subseteq$ PSPACE.\n\nWe restrict our attention on CCSPs with addition constraints ($x + y = z$)\nand some other mild technical condition. Previously, it was shown that\nmultiplication constraints ($x \\cdot y = z$), squaring constraints ($x^2 = y$),\nor inversion constraints ($x\\cdot y = 1$) are sufficient to establish\nER-completeness. We extend this in the strongest possible sense for equality\nconstraints as follows. We show that CCSPs (with addition constraints and some\nother mild technical condition) that have any one well-behaved curved equality\nconstraint ($f(x,y) = 0$) are ER-complete. We further extend our results to\ninequality constraints. We show that any well-behaved convexly curved and any\nwell-behaved concavely curved inequality constraint ($f(x,y) \\geq 0$ and\n$g(x,y) \\geq 0$) imply ER-completeness on the class of such CCSPs.\n\nWe apply our findings to geometric packing and answer an open question by\nAbrahamsen et al. [FOCS 2020]. Namely, we establish ER-completeness of packing\nconvex pieces into a square container under rotations and translations.",
          "link": "http://arxiv.org/abs/2106.02397",
          "publishedOn": "2021-06-07T03:06:12.165Z",
          "wordCount": 737,
          "title": "On Classifying Continuous Constraint Satisfaction problems. (arXiv:2106.02397v1 [cs.CC])"
        },
        {
          "id": "http://arxiv.org/abs/2010.12873",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Jun Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raman_M/0/1/0/all/0/1\">Mrigank Raman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_A/0/1/0/all/0/1\">Aaron Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossi_R/0/1/0/all/0/1\">Ryan Rossi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Handong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sungchul Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lipka_N/0/1/0/all/0/1\">Nedim Lipka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>",
          "description": "Recently, knowledge graph (KG) augmented models have achieved noteworthy\nsuccess on various commonsense reasoning tasks. However, KG edge (fact)\nsparsity and noisy edge extraction/generation often hinder models from\nobtaining useful knowledge to reason over. To address these issues, we propose\na new KG-augmented model: Hybrid Graph Network (HGN). Unlike prior methods, HGN\nlearns to jointly contextualize extracted and generated knowledge by reasoning\nover both within a unified graph structure. Given the task input context and an\nextracted KG subgraph, HGN is trained to generate embeddings for the subgraph's\nmissing edges to form a \"hybrid\" graph, then reason over the hybrid graph while\nfiltering out context-irrelevant edges. We demonstrate HGN's effectiveness\nthrough considerable performance gains across four commonsense reasoning\nbenchmarks, plus a user study on edge validness and helpfulness.",
          "link": "http://arxiv.org/abs/2010.12873",
          "publishedOn": "2021-06-07T03:06:12.143Z",
          "wordCount": 616,
          "title": "Learning Contextualized Knowledge Structures for Commonsense Reasoning. (arXiv:2010.12873v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.14584",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Edwards_A/0/1/0/all/0/1\">Aleksandra Edwards</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rogers_D/0/1/0/all/0/1\">David Rogers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camacho_Collados_J/0/1/0/all/0/1\">Jose Camacho-Collados</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribaupierre_H/0/1/0/all/0/1\">H&#xe9;l&#xe8;ne de Ribaupierre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Preece_A/0/1/0/all/0/1\">Alun Preece</a>",
          "description": "The task of text and sentence classification is associated with the need for\nlarge amounts of labelled training data. The acquisition of high volumes of\nlabelled datasets can be expensive or unfeasible, especially for\nhighly-specialised domains for which documents are hard to obtain. Research on\nthe application of supervised classification based on small amounts of training\ndata is limited. In this paper, we address the combination of state-of-the-art\ndeep learning and classification methods and provide an insight into what\ncombination of methods fit the needs of small, domain-specific, and\nterminologically-rich corpora. We focus on a real-world scenario related to a\ncollection of safeguarding reports comprising learning experiences and\nreflections on tackling serious incidents involving children and vulnerable\nadults. The relatively small volume of available reports and their use of\nhighly domain-specific terminology makes the application of automated\napproaches difficult. We focus on the problem of automatically identifying the\nmain themes in a safeguarding report using supervised classification\napproaches. Our results show the potential of deep learning models to simulate\nsubject-expert behaviour even for complex tasks with limited labelled data.",
          "link": "http://arxiv.org/abs/2010.14584",
          "publishedOn": "2021-06-07T03:06:12.123Z",
          "wordCount": 660,
          "title": "Predicting Themes within Complex Unstructured Texts: A Case Study on Safeguarding Reports. (arXiv:2010.14584v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.12641",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schon_C/0/1/0/all/0/1\">Claudia Schon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siebert_S/0/1/0/all/0/1\">Sophie Siebert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stolzenburg_F/0/1/0/all/0/1\">Frieder Stolzenburg</a>",
          "description": "Negation is both an operation in formal logic and in natural language by\nwhich a proposition is replaced by one stating the opposite, as by the addition\nof \"not\" or another negation cue. Treating negation in an adequate way is\nrequired for cognitive reasoning, which aims at modeling the human ability to\ndraw meaningful conclusions despite incomplete and inconsistent knowledge. One\ntask of cognitive reasoning is answering questions given by sentences in\nnatural language. There are tools based on discourse representation theory to\nconvert sentences automatically into a formal logic representation, and\nadditional knowledge can be added using the predicate names in the formula and\nknowledge databases. However, the knowledge in logic databases in practice\nalways is incomplete. Hence, forward reasoning of automated reasoning systems\nalone does not suffice to derive answers to questions because, instead of\ncomplete proofs, often only partial positive knowledge can be derived, while\nnegative knowledge is used only during the reasoning process. In consequence,\nwe aim at eliminating syntactic negation, strictly speaking, the negated event\nor property. In this paper, we describe an effective procedure to determine the\nnegated event or property in order to replace it by its inverse. This lays the\nbasis of cognitive reasoning, employing both logic and machine learning for\ngeneral question answering. We evaluate our procedure by several benchmarks and\ndemonstrate its practical usefulness in our cognitive reasoning system.",
          "link": "http://arxiv.org/abs/2012.12641",
          "publishedOn": "2021-06-07T03:06:12.042Z",
          "wordCount": 679,
          "title": "Negation in Cognitive Reasoning. (arXiv:2012.12641v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02401",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Guanglin Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1\">Qinghua Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pu_S/0/1/0/all/0/1\">Shiliang Pu</a>",
          "description": "Few-shot relation extraction (FSRE) is of great importance in long-tail\ndistribution problem, especially in special domain with low-resource data. Most\nexisting FSRE algorithms fail to accurately classify the relations merely based\non the information of the sentences together with the recognized entity pairs,\ndue to limited samples and lack of knowledge. To address this problem, in this\npaper, we proposed a novel entity CONCEPT-enhanced FEw-shot Relation Extraction\nscheme (ConceptFERE), which introduces the inherent concepts of entities to\nprovide clues for relation prediction and boost the relations classification\nperformance. Firstly, a concept-sentence attention module is developed to\nselect the most appropriate concept from multiple concepts of each entity by\ncalculating the semantic similarity between sentences and concepts. Secondly, a\nself-attention based fusion module is presented to bridge the gap of concept\nembedding and sentence embedding from different semantic spaces. Extensive\nexperiments on the FSRE benchmark dataset FewRel have demonstrated the\neffectiveness and the superiority of the proposed ConceptFERE scheme as\ncompared to the state-of-the-art baselines. Code is available at\nhttps://github.com/LittleGuoKe/ConceptFERE.",
          "link": "http://arxiv.org/abs/2106.02401",
          "publishedOn": "2021-06-07T03:06:12.027Z",
          "wordCount": 605,
          "title": "Entity Concept-enhanced Few-shot Relation Extraction. (arXiv:2106.02401v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02248",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zequn Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Muhao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Wei Hu</a>",
          "description": "This paper studies a new problem setting of entity alignment for knowledge\ngraphs (KGs). Since KGs possess different sets of entities, there could be\nentities that cannot find alignment across them, leading to the problem of\ndangling entities. As the first attempt to this problem, we construct a new\ndataset and design a multi-task learning framework for both entity alignment\nand dangling entity detection. The framework can opt to abstain from predicting\nalignment for the detected dangling entities. We propose three techniques for\ndangling entity detection that are based on the distribution of\nnearest-neighbor distances, i.e., nearest neighbor classification, marginal\nranking and background ranking. After detecting and removing dangling entities,\nan incorporated entity alignment model in our framework can provide more robust\nalignment for remaining entities. Comprehensive experiments and analyses\ndemonstrate the effectiveness of our framework. We further discover that the\ndangling entity detection module can, in turn, improve alignment learning and\nthe final performance. The contributed resource is publicly available to foster\nfurther research.",
          "link": "http://arxiv.org/abs/2106.02248",
          "publishedOn": "2021-06-07T03:06:11.954Z",
          "wordCount": 595,
          "title": "Knowing the No-match: Entity Alignment with Dangling Cases. (arXiv:2106.02248v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02317",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunhao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yunyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quan_X/0/1/0/all/0/1\">Xiaojun Quan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jianxing Yu</a>",
          "description": "Dialogue policy learning, a subtask that determines the content of system\nresponse generation and then the degree of task completion, is essential for\ntask-oriented dialogue systems. However, the unbalanced distribution of system\nactions in dialogue datasets often causes difficulty in learning to generate\ndesired actions and responses. In this paper, we propose a\nretrieve-and-memorize framework to enhance the learning of system actions.\nSpecially, we first design a neural context-aware retrieval module to retrieve\nmultiple candidate system actions from the training set given a dialogue\ncontext. Then, we propose a memory-augmented multi-decoder network to generate\nthe system actions conditioned on the candidate actions, which allows the\nnetwork to adaptively select key information in the candidate actions and\nignore noises. We conduct experiments on the large-scale multi-domain\ntask-oriented dialogue dataset MultiWOZ 2.0 and MultiWOZ 2.1.~Experimental\nresults show that our method achieves competitive performance among several\nstate-of-the-art models in the context-to-response generation task.",
          "link": "http://arxiv.org/abs/2106.02317",
          "publishedOn": "2021-06-07T03:06:11.913Z",
          "wordCount": 583,
          "title": "Retrieve & Memorize: Dialog Policy Learning with Multi-Action Memory. (arXiv:2106.02317v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2102.09507",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Markov_I/0/1/0/all/0/1\">Igor L. Markov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jacqueline Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vagner_A/0/1/0/all/0/1\">Adam Vagner</a>",
          "description": "Text classifiers are at the core of many NLP applications and use a variety\nof algorithmic approaches and software. This paper introduces infrastructure\nand methodologies for text classifiers based on large-scale regular\nexpressions. In particular, we describe how Facebook determines if a given\npiece of text - anything from a hashtag to a post - belongs to a narrow topic\nsuch as COVID-19. To fully define a topic and evaluate classifier performance\nwe employ human-guided iterations of keyword discovery, but do not require\nlabeled data. For COVID-19, we build two sets of regular expressions: (1) for\n66 languages, with 99% precision and recall >50%, (2) for the 11 most common\nlanguages, with precision >90% and recall >90%. Regular expressions enable\nlow-latency queries from multiple platforms. Response to challenges like\nCOVID-19 is fast and so are revisions. Comparisons to a DNN classifier show\nexplainable results, higher precision and recall, and less overfitting. Our\nlearnings can be applied to other narrow-topic classifiers.",
          "link": "http://arxiv.org/abs/2102.09507",
          "publishedOn": "2021-06-07T03:06:11.906Z",
          "wordCount": 679,
          "title": "Regular Expressions for Fast-response COVID-19 Text Classification. (arXiv:2102.09507v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02636",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zellers_R/0/1/0/all/0/1\">Rowan Zellers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Ximing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hessel_J/0/1/0/all/0/1\">Jack Hessel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Youngjae Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jae Sung Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1\">Jize Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farhadi_A/0/1/0/all/0/1\">Ali Farhadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>",
          "description": "As humans, we understand events in the visual world contextually, performing\nmultimodal reasoning across time to make inferences about the past, present,\nand future. We introduce MERLOT, a model that learns multimodal script\nknowledge by watching millions of YouTube videos with transcribed speech -- in\nan entirely label-free, self-supervised manner. By pretraining with a mix of\nboth frame-level (spatial) and video-level (temporal) objectives, our model not\nonly learns to match images to temporally corresponding words, but also to\ncontextualize what is happening globally over time. As a result, MERLOT\nexhibits strong out-of-the-box representations of temporal commonsense, and\nachieves state-of-the-art performance on 12 different video QA datasets when\nfinetuned. It also transfers well to the world of static images, allowing\nmodels to reason about the dynamic context behind visual scenes. On Visual\nCommonsense Reasoning, MERLOT answers questions correctly with 80.6% accuracy,\noutperforming state-of-the-art models of similar size by over 3%, even those\nthat make heavy use of auxiliary supervised data (like object bounding boxes).\n\nAblation analyses demonstrate the complementary importance of: 1) training on\nvideos versus static images; 2) scaling the magnitude and diversity of the\npretraining video corpus; and 3) using diverse objectives that encourage\nfull-stack multimodal reasoning, from the recognition to cognition level.",
          "link": "http://arxiv.org/abs/2106.02636",
          "publishedOn": "2021-06-07T03:06:11.887Z",
          "wordCount": 655,
          "title": "MERLOT: Multimodal Neural Script Knowledge Models. (arXiv:2106.02636v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02382",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Ji-Ung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klie_J/0/1/0/all/0/1\">Jan-Christoph Klie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>",
          "description": "Annotation studies often require annotators to familiarize themselves with\nthe task, its annotation scheme, and the data domain. This can be overwhelming\nin the beginning, mentally taxing, and induce errors into the resulting\nannotations; especially in citizen science or crowd sourcing scenarios where\ndomain expertise is not required and only annotation guidelines are provided.\nTo alleviate these issues, we propose annotation curricula, a novel approach to\nimplicitly train annotators. Our goal is to gradually introduce annotators into\nthe task by ordering instances that are annotated according to a learning\ncurriculum. To do so, we first formalize annotation curricula for sentence- and\nparagraph-level annotation tasks, define an ordering strategy, and identify\nwell-performing heuristics and interactively trained models on three existing\nEnglish datasets. We then conduct a user study with 40 voluntary participants\nwho are asked to identify the most fitting misconception for English tweets\nabout the Covid-19 pandemic. Our results show that using a simple heuristic to\norder instances can already significantly reduce the total annotation time\nwhile preserving a high annotation quality. Annotation curricula thus can\nprovide a novel way to improve data collection. To facilitate future research,\nwe further share our code and data consisting of 2,400 annotations.",
          "link": "http://arxiv.org/abs/2106.02382",
          "publishedOn": "2021-06-07T03:06:11.880Z",
          "wordCount": 665,
          "title": "Annotation Curricula to Implicitly Train Non-Expert Annotators. (arXiv:2106.02382v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2012.13048",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tafjord_O/0/1/0/all/0/1\">Oyvind Tafjord</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_B/0/1/0/all/0/1\">Bhavana Dalvi Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clark_P/0/1/0/all/0/1\">Peter Clark</a>",
          "description": "Transformers have been shown to emulate logical deduction over natural\nlanguage theories (logical rules expressed in natural language), reliably\nassigning true/false labels to candidate implications. However, their ability\nto generate implications of a theory has not yet been demonstrated, and methods\nfor reconstructing proofs of answers are imperfect. In this work we show that a\ngenerative model, called ProofWriter, can reliably generate both implications\nof a theory and the natural language proof(s) that support them. In particular,\niterating a 1-step implication generator results in proofs that are highly\nreliable, and represent actual model decisions (rather than post-hoc\nrationalizations). On the RuleTaker dataset, the accuracy of ProofWriter's\nproofs exceed previous methods by +9% absolute, and in a way that generalizes\nto proof depths unseen in training and on out-of-domain problems. We also show\nthat generative techniques can perform a type of abduction with high precision:\nGiven a theory and an unprovable conclusion, identify a missing fact that\nallows the conclusion to be proved, along with a proof. These results\nsignificantly improve the viability of neural methods for systematically\nreasoning over natural language.",
          "link": "http://arxiv.org/abs/2012.13048",
          "publishedOn": "2021-06-07T03:06:11.872Z",
          "wordCount": 648,
          "title": "ProofWriter: Generating Implications, Proofs, and Abductive Statements over Natural Language. (arXiv:2012.13048v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02559",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maudslay_R/0/1/0/all/0/1\">Rowan Hall Maudslay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>",
          "description": "Analysing whether neural language models encode linguistic information has\nbecome popular in NLP. One method of doing so, which is frequently cited to\nsupport the claim that models like BERT encode syntax, is called probing;\nprobes are small supervised models trained to extract linguistic information\nfrom another model's output. If a probe is able to predict a particular\nstructure, it is argued that the model whose output it is trained on must have\nimplicitly learnt to encode it. However, drawing a generalisation about a\nmodel's linguistic knowledge about a specific phenomena based on what a probe\nis able to learn may be problematic: in this work, we show that semantic cues\nin training data means that syntactic probes do not properly isolate syntax. We\ngenerate a new corpus of semantically nonsensical but syntactically well-formed\nJabberwocky sentences, which we use to evaluate two probes trained on normal\ndata. We train the probes on several popular language models (BERT, GPT, and\nRoBERTa), and find that in all settings they perform worse when evaluated on\nthese data, for one probe by an average of 15.4 UUAS points absolute. Although\nin most cases they still outperform the baselines, their lead is reduced\nsubstantially, e.g. by 53% in the case of BERT for one probe. This begs the\nquestion: what empirical scores constitute knowing syntax?",
          "link": "http://arxiv.org/abs/2106.02559",
          "publishedOn": "2021-06-07T03:06:11.866Z",
          "wordCount": 649,
          "title": "Do Syntactic Probes Probe Syntax? Experiments with Jabberwocky Probing. (arXiv:2106.02559v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02607",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Trivedi_A/0/1/0/all/0/1\">Anusua Trivedi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suhm_A/0/1/0/all/0/1\">Alyssa Suhm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahankal_P/0/1/0/all/0/1\">Prathamesh Mahankal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukuntharaj_S/0/1/0/all/0/1\">Subhiksha Mukuntharaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parab_M/0/1/0/all/0/1\">Meghana D. Parab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohan_M/0/1/0/all/0/1\">Malvika Mohan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berger_M/0/1/0/all/0/1\">Meredith Berger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sethumadhavan_A/0/1/0/all/0/1\">Arathi Sethumadhavan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaiman_A/0/1/0/all/0/1\">Ashish Jaiman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dodhia_R/0/1/0/all/0/1\">Rahul Dodhia</a>",
          "description": "The rise in online misinformation in recent years threatens democracies by\ndistorting authentic public discourse and causing confusion, fear, and even, in\nextreme cases, violence. There is a need to understand the spread of false\ncontent through online networks for developing interventions that disrupt\nmisinformation before it achieves virality. Using a Deep Bidirectional\nTransformer for Language Understanding (BERT) and propagation graphs, this\nstudy classifies and visualizes the spread of misinformation on a social media\nnetwork using publicly available Twitter data. The results confirm prior\nresearch around user clusters and the virality of false content while improving\nthe precision of deep learning models for misinformation detection. The study\nfurther demonstrates the suitability of BERT for providing a scalable model for\nfalse information detection, which can contribute to the development of more\ntimely and accurate interventions to slow the spread of misinformation in\nonline environments.",
          "link": "http://arxiv.org/abs/2106.02607",
          "publishedOn": "2021-06-07T03:06:11.859Z",
          "wordCount": 600,
          "title": "Defending Democracy: Using Deep Learning to Identify and Prevent Misinformation. (arXiv:2106.02607v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2011.02164",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rahman_T/0/1/0/all/0/1\">Tanzila Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chou_S/0/1/0/all/0/1\">Shih-Han Chou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sigal_L/0/1/0/all/0/1\">Leonid Sigal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carenini_G/0/1/0/all/0/1\">Giuseppe Carenini</a>",
          "description": "We consider the problem of Visual Question Answering (VQA). Given an image\nand a free-form, open-ended, question, expressed in natural language, the goal\nof VQA system is to provide accurate answer to this question with respect to\nthe image. The task is challenging because it requires simultaneous and\nintricate understanding of both visual and textual information. Attention,\nwhich captures intra- and inter-modal dependencies, has emerged as perhaps the\nmost widely used mechanism for addressing these challenges. In this paper, we\npropose an improved attention-based architecture to solve VQA. We incorporate\nan Attention on Attention (AoA) module within encoder-decoder framework, which\nis able to determine the relation between attention results and queries.\nAttention module generates weighted average for each query. On the other hand,\nAoA module first generates an information vector and an attention gate using\nattention results and current context; and then adds another attention to\ngenerate final attended information by multiplying the two. We also propose\nmultimodal fusion module to combine both visual and textual information. The\ngoal of this fusion module is to dynamically decide how much information should\nbe considered from each modality. Extensive experiments on VQA-v2 benchmark\ndataset show that our method achieves the state-of-the-art performance.",
          "link": "http://arxiv.org/abs/2011.02164",
          "publishedOn": "2021-06-07T03:06:11.841Z",
          "wordCount": 674,
          "title": "An Improved Attention for Visual Question Answering. (arXiv:2011.02164v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02318",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Jun Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zalmout_N/0/1/0/all/0/1\">Nasser Zalmout</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grant_C/0/1/0/all/0/1\">Christan Grant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xin Luna Dong</a>",
          "description": "Automatic extraction of product attribute values is an important enabling\ntechnology in e-Commerce platforms. This task is usually modeled using sequence\nlabeling architectures, with several extensions to handle multi-attribute\nextraction. One line of previous work constructs attribute-specific models,\nthrough separate decoders or entirely separate models. However, this approach\nconstrains knowledge sharing across different attributes. Other contributions\nuse a single multi-attribute model, with different techniques to embed\nattribute information. But sharing the entire network parameters across all\nattributes can limit the model's capacity to capture attribute-specific\ncharacteristics. In this paper we present AdaTag, which uses adaptive decoding\nto handle extraction. We parameterize the decoder with pretrained attribute\nembeddings, through a hypernetwork and a Mixture-of-Experts (MoE) module. This\nallows for separate, but semantically correlated, decoders to be generated on\nthe fly for different attributes. This approach facilitates knowledge sharing,\nwhile maintaining the specificity of each attribute. Our experiments on a\nreal-world e-Commerce dataset show marked improvements over previous methods.",
          "link": "http://arxiv.org/abs/2106.02318",
          "publishedOn": "2021-06-07T03:06:11.834Z",
          "wordCount": 597,
          "title": "AdaTag: Multi-Attribute Value Extraction from Product Profiles with Adaptive Decoding. (arXiv:2106.02318v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02516",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Conley_T/0/1/0/all/0/1\">Thomas Conley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clair_J/0/1/0/all/0/1\">Jack St. Clair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalita_J/0/1/0/all/0/1\">Jugal Kalita</a>",
          "description": "Although people have the ability to engage in vapid dialogue without effort,\nthis may not be a uniquely human trait. Since the 1960's researchers have been\ntrying to create agents that can generate artificial conversation. These\nprograms are commonly known as chatbots. With increasing use of neural networks\nfor dialog generation, some conclude that this goal has been achieved. This\nresearch joins the quest by creating a dialog generating Recurrent Neural\nNetwork (RNN) and by enhancing the ability of this network with auxiliary loss\nfunctions and a beam search. Our custom loss functions achieve better cohesion\nand coherence by including calculations of Maximum Mutual Information (MMI) and\nentropy. We demonstrate the effectiveness of this system by using a set of\ncustom evaluation metrics inspired by an abundance of previous research and\nbased on tried-and-true principles of Natural Language Processing.",
          "link": "http://arxiv.org/abs/2106.02516",
          "publishedOn": "2021-06-07T03:06:11.827Z",
          "wordCount": 586,
          "title": "Improving Computer Generated Dialog with Auxiliary Loss Functions and Custom Evaluation Metrics. (arXiv:2106.02516v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02359",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhijing Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chauhan_G/0/1/0/all/0/1\">Geeticka Chauhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tse_B/0/1/0/all/0/1\">Brian Tse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1\">Mrinmaya Sachan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mihalcea_R/0/1/0/all/0/1\">Rada Mihalcea</a>",
          "description": "Recent years have seen many breakthroughs in natural language processing\n(NLP), transitioning it from a mostly theoretical field to one with many\nreal-world applications. Noting the rising number of applications of other\nmachine learning and AI techniques with pervasive societal impact, we\nanticipate the rising importance of developing NLP technologies for social\ngood. Inspired by theories in moral philosophy and global priorities research,\nwe aim to promote a guideline for social good in the context of NLP. We lay the\nfoundations via moral philosophy's definition of social good, propose a\nframework to evaluate NLP tasks' direct and indirect real-world impact, and\nadopt the methodology of global priorities research to identify priority causes\nfor NLP research. Finally, we use our theoretical framework to provide some\npractical guidelines for future NLP research for social good. Our data and\ncodes are available at this http URL",
          "link": "http://arxiv.org/abs/2106.02359",
          "publishedOn": "2021-06-07T03:06:11.820Z",
          "wordCount": 603,
          "title": "How Good Is NLP? A Sober Look at NLP Tasks through the Lens of Social Impact. (arXiv:2106.02359v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02232",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ying_Q/0/1/0/all/0/1\">Qianlan Ying</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bajaj_P/0/1/0/all/0/1\">Payal Bajaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deb_B/0/1/0/all/0/1\">Budhaditya Deb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Bojia Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shokouhi_M/0/1/0/all/0/1\">Milad Shokouhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xia Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1\">Daxin Jiang</a>",
          "description": "We consider the problem of scaling automated suggested replies for Outlook\nemail system to multiple languages. Faced with increased compute requirements\nand low resources for language expansion, we build a single universal model for\nimproving the quality and reducing run-time costs of our production system.\nHowever, restricted data movement across regional centers prevents joint\ntraining across languages. To this end, we propose a multi-task continual\nlearning framework, with auxiliary tasks and language adapters to learn\nuniversal language representation across regions. The experimental results show\npositive cross-lingual transfer across languages while reducing catastrophic\nforgetting across regions. Our online results on real user traffic show\nsignificant gains in CTR and characters saved, as well as 65% training cost\nreduction compared with per-language models. As a consequence, we have scaled\nthe feature in multiple languages including low-resource markets.",
          "link": "http://arxiv.org/abs/2106.02232",
          "publishedOn": "2021-06-07T03:06:11.814Z",
          "wordCount": 574,
          "title": "Language Scaling for Universal Suggested Replies Model. (arXiv:2106.02232v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02435",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shaokun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xiawu Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chenyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuchao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chao_F/0/1/0/all/0/1\">Fei Chao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mengdi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_R/0/1/0/all/0/1\">Rongrong Ji</a>",
          "description": "Despite superior performance on various natural language processing tasks,\npre-trained models such as BERT are challenged by deploying on\nresource-constraint devices. Most existing model compression approaches require\nre-compression or fine-tuning across diverse constraints to accommodate various\nhardware deployments. This practically limits the further application of model\ncompression. Moreover, the ineffective training and searching process of\nexisting elastic compression paradigms[4,27] prevents the direct migration to\nBERT compression. Motivated by the necessity of efficient inference across\nvarious constraints on BERT, we propose a novel approach, YOCO-BERT, to achieve\ncompress once and deploy everywhere. Specifically, we first construct a huge\nsearch space with 10^13 architectures, which covers nearly all configurations\nin BERT model. Then, we propose a novel stochastic nature gradient optimization\nmethod to guide the generation of optimal candidate architecture which could\nkeep a balanced trade-off between explorations and exploitation. When a certain\nresource constraint is given, a lightweight distribution optimization approach\nis utilized to obtain the optimal network for target deployment without\nfine-tuning. Compared with state-of-the-art algorithms, YOCO-BERT provides more\ncompact models, yet achieving 2.1%-4.5% average accuracy improvement on the\nGLUE benchmark. Besides, YOCO-BERT is also more effective, e.g.,the training\ncomplexity is O(1)for N different devices. Code is\navailablehttps://github.com/MAC-AutoML/YOCO-BERT.",
          "link": "http://arxiv.org/abs/2106.02435",
          "publishedOn": "2021-06-07T03:06:11.775Z",
          "wordCount": 654,
          "title": "You Only Compress Once: Towards Effective and Elastic BERT Compression via Exploit-Explore Stochastic Nature Gradient. (arXiv:2106.02435v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02497",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Paul_D/0/1/0/all/0/1\">Debjit Paul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_A/0/1/0/all/0/1\">Anette Frank</a>",
          "description": "Despite recent successes of large pre-trained language models in solving\nreasoning tasks, their inference capabilities remain opaque. We posit that such\nmodels can be made more interpretable by explicitly generating interim\ninference rules, and using them to guide the generation of task-specific\ntextual outputs. In this paper we present COINS, a recursive inference\nframework that i) iteratively reads context sentences, ii) dynamically\ngenerates contextualized inference rules, encodes them, and iii) uses them to\nguide task-specific output generation. We apply COINS to a Narrative Story\nCompletion task that asks a model to complete a story with missing sentences,\nto produce a coherent story with plausible logical connections, causal\nrelationships, and temporal dependencies. By modularizing inference and\nsentence generation steps in a recurrent model, we aim to make reasoning steps\nand their effects on next sentence generation transparent. Our automatic and\nmanual evaluations show that the model generates better story sentences than\nSOTA baselines, especially in terms of coherence. We further demonstrate\nimproved performance over strong pre-trained LMs in generating commonsense\ninference rules. The recursive nature of COINS holds the potential for\ncontrolled generation of longer sequences.",
          "link": "http://arxiv.org/abs/2106.02497",
          "publishedOn": "2021-06-07T03:06:11.767Z",
          "wordCount": 617,
          "title": "COINS: Dynamically Generating COntextualized Inference Rules for Narrative Story Completion. (arXiv:2106.02497v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02596",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fraser_K/0/1/0/all/0/1\">Kathleen C. Fraser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nejadgholi_I/0/1/0/all/0/1\">Isar Nejadgholi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiritchenko_S/0/1/0/all/0/1\">Svetlana Kiritchenko</a>",
          "description": "Stereotypical language expresses widely-held beliefs about different social\ncategories. Many stereotypes are overtly negative, while others may appear\npositive on the surface, but still lead to negative consequences. In this work,\nwe present a computational approach to interpreting stereotypes in text through\nthe Stereotype Content Model (SCM), a comprehensive causal theory from social\npsychology. The SCM proposes that stereotypes can be understood along two\nprimary dimensions: warmth and competence. We present a method for defining\nwarmth and competence axes in semantic embedding space, and show that the four\nquadrants defined by this subspace accurately represent the warmth and\ncompetence concepts, according to annotated lexicons. We then apply our\ncomputational SCM model to textual stereotype data and show that it compares\nfavourably with survey-based studies in the psychological literature.\nFurthermore, we explore various strategies to counter stereotypical beliefs\nwith anti-stereotypes. It is known that countering stereotypes with\nanti-stereotypical examples is one of the most effective ways to reduce biased\nthinking, yet the problem of generating anti-stereotypes has not been\npreviously studied. Thus, a better understanding of how to generate realistic\nand effective anti-stereotypes can contribute to addressing pressing societal\nconcerns of stereotyping, prejudice, and discrimination.",
          "link": "http://arxiv.org/abs/2106.02596",
          "publishedOn": "2021-06-07T03:06:11.759Z",
          "wordCount": 666,
          "title": "Understanding and Countering Stereotypes: A Computational Approach to the Stereotype Content Model. (arXiv:2106.02596v1 [cs.CY])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02327",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1\">Ruikun Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1\">Guanhuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quan_X/0/1/0/all/0/1\">Xiaojun Quan</a>",
          "description": "The major paradigm of applying a pre-trained language model to downstream\ntasks is to fine-tune it on labeled task data, which often suffers instability\nand low performance when the labeled examples are scarce.~One way to alleviate\nthis problem is to apply post-training on unlabeled task data before\nfine-tuning, adapting the pre-trained model to target domains by contrastive\nlearning that considers either token-level or sequence-level similarity.\nInspired by the success of sequence masking, we argue that both token-level and\nsequence-level similarities can be captured with a pair of masked\nsequences.~Therefore, we propose complementary random masking (CRM) to generate\na pair of masked sequences from an input sequence for sequence-level\ncontrastive learning and then develop contrastive masked language modeling\n(CMLM) for post-training to integrate both token-level and sequence-level\ncontrastive learnings.~Empirical results show that CMLM surpasses several\nrecent post-training methods in few-shot settings without the need for data\naugmentation.",
          "link": "http://arxiv.org/abs/2106.02327",
          "publishedOn": "2021-06-07T03:06:11.749Z",
          "wordCount": 570,
          "title": "Bi-Granularity Contrastive Learning for Post-Training in Few-Shot Scene. (arXiv:2106.02327v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02325",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ishii_E/0/1/0/all/0/1\">Etsuko Ishii</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winata_G/0/1/0/all/0/1\">Genta Indra Winata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cahyawijaya_S/0/1/0/all/0/1\">Samuel Cahyawijaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lala_D/0/1/0/all/0/1\">Divesh Lala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawahara_T/0/1/0/all/0/1\">Tatsuya Kawahara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1\">Pascale Fung</a>",
          "description": "Over the past year, research in various domains, including Natural Language\nProcessing (NLP), has been accelerated to fight against the COVID-19 pandemic,\nyet such research has just started on dialogue systems. In this paper, we\nintroduce an end-to-end dialogue system which aims to ease the isolation of\npeople under self-quarantine. We conduct a control simulation experiment to\nassess the effects of the user interface, a web-based virtual agent called Nora\nvs. the android ERICA via a video call. The experimental results show that the\nandroid offers a more valuable user experience by giving the impression of\nbeing more empathetic and engaging in the conversation due to its nonverbal\ninformation, such as facial expressions and body gestures.",
          "link": "http://arxiv.org/abs/2106.02325",
          "publishedOn": "2021-06-07T03:06:11.742Z",
          "wordCount": 602,
          "title": "ERICA: An Empathetic Android Companion for Covid-19 Quarantine. (arXiv:2106.02325v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02300",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weile Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Huiqiang Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qianhui Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karlsson_B/0/1/0/all/0/1\">B&#xf6;rje F. Karlsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_Y/0/1/0/all/0/1\">Yi Guan</a>",
          "description": "Neural methods have been shown to achieve high performance in Named Entity\nRecognition (NER), but rely on costly high-quality labeled data for training,\nwhich is not always available across languages. While previous works have shown\nthat unlabeled data in a target language can be used to improve cross-lingual\nmodel performance, we propose a novel adversarial approach (AdvPicker) to\nbetter leverage such data and further improve results. We design an adversarial\nlearning framework in which an encoder learns entity domain knowledge from\nlabeled source-language data and better shared features are captured via\nadversarial training - where a discriminator selects less language-dependent\ntarget-language data via similarity to the source language. Experimental\nresults on standard benchmark datasets well demonstrate that the proposed\nmethod benefits strongly from this data selection process and outperforms\nexisting state-of-the-art methods; without requiring any additional external\nresources (e.g., gazetteers or via machine translation).",
          "link": "http://arxiv.org/abs/2106.02300",
          "publishedOn": "2021-06-07T03:06:11.684Z",
          "wordCount": 588,
          "title": "AdvPicker: Effectively Leveraging Unlabeled Data via Adversarial Discriminator for Cross-Lingual NER. (arXiv:2106.02300v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02363",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Cheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sungjin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Sunghyun Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Han Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Young-Bum Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarikaya_R/0/1/0/all/0/1\">Ruhi Sarikaya</a>",
          "description": "Real-world machine learning systems are achieving remarkable performance in\nterms of coarse-grained metrics like overall accuracy and F-1 score. However,\nmodel improvement and development often require fine-grained modeling on\nindividual data subsets or slices, for instance, the data slices where the\nmodels have unsatisfactory results. In practice, it gives tangible values for\ndeveloping such models that can pay extra attention to critical or interested\nslices while retaining the original overall performance. This work extends the\nrecent slice-based learning (SBL)~\\cite{chen2019slice} with a mixture of\nattentions (MoA) to learn slice-aware dual attentive representations. We\nempirically show that the MoA approach outperforms the baseline method as well\nas the original SBL approach on monitored slices with two natural language\nunderstanding (NLU) tasks.",
          "link": "http://arxiv.org/abs/2106.02363",
          "publishedOn": "2021-06-07T03:06:11.669Z",
          "wordCount": 556,
          "title": "Learning Slice-Aware Representations with Mixture of Attentions. (arXiv:2106.02363v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02293",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yanda Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kedzie_C/0/1/0/all/0/1\">Chris Kedzie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nair_S/0/1/0/all/0/1\">Suraj Nair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galuscakova_P/0/1/0/all/0/1\">Petra Galu&#x161;&#x10d;&#xe1;kov&#xe1;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oard_D/0/1/0/all/0/1\">Douglas W. Oard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McKeown_K/0/1/0/all/0/1\">Kathleen McKeown</a>",
          "description": "This paper proposes an approach to cross-language sentence selection in a\nlow-resource setting. It uses data augmentation and negative sampling\ntechniques on noisy parallel sentence data to directly learn a cross-lingual\nembedding-based query relevance model. Results show that this approach performs\nas well as or better than multiple state-of-the-art machine translation +\nmonolingual retrieval systems trained on the same parallel data. Moreover, when\na rationale training secondary objective is applied to encourage the model to\nmatch word alignment hints from a phrase-based statistical machine translation\nmodel, consistent improvements are seen across three language pairs\n(English-Somali, English-Swahili and English-Tagalog) over a variety of\nstate-of-the-art baselines.",
          "link": "http://arxiv.org/abs/2106.02293",
          "publishedOn": "2021-06-07T03:06:11.661Z",
          "wordCount": 548,
          "title": "Cross-language Sentence Selection via Data Augmentation and Rationale Training. (arXiv:2106.02293v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02289",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nikkarinen_I/0/1/0/all/0/1\">Irene Nikkarinen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pimentel_T/0/1/0/all/0/1\">Tiago Pimentel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blasi_D/0/1/0/all/0/1\">Dami&#xe1;n E. Blasi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>",
          "description": "The unigram distribution is the non-contextual probability of finding a\nspecific word form in a corpus. While of central importance to the study of\nlanguage, it is commonly approximated by each word's sample frequency in the\ncorpus. This approach, being highly dependent on sample size, assigns zero\nprobability to any out-of-vocabulary (oov) word form. As a result, it produces\nnegatively biased probabilities for any oov word form, while positively biased\nprobabilities to in-corpus words. In this work, we argue in favor of properly\nmodeling the unigram distribution -- claiming it should be a central task in\nnatural language processing. With this in mind, we present a novel model for\nestimating it in a language (a neuralization of Goldwater et al.'s (2011)\nmodel) and show it produces much better estimates across a diverse set of 7\nlanguages than the na\\\"ive use of neural character-level language models.",
          "link": "http://arxiv.org/abs/2106.02289",
          "publishedOn": "2021-06-07T03:06:11.515Z",
          "wordCount": 588,
          "title": "Modeling the Unigram Distribution. (arXiv:2106.02289v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02278",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pang_R/0/1/0/all/0/1\">Richard Yuanzhe Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lelkes_A/0/1/0/all/0/1\">Adam D. Lelkes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_V/0/1/0/all/0/1\">Vinh Q. Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1\">Cong Yu</a>",
          "description": "We aim to renew interest in a particular multi-document summarization (MDS)\ntask which we call AgreeSum: agreement-oriented multi-document summarization.\nGiven a cluster of articles, the goal is to provide abstractive summaries that\nrepresent information common and faithful to all input articles. Given the lack\nof existing datasets, we create a dataset for AgreeSum, and provide annotations\non article-summary entailment relations for a subset of the clusters in the\ndataset. We aim to create strong baselines for the task by applying the\ntop-performing pretrained single-document summarization model PEGASUS onto\nAgreeSum, leveraging both annotated clusters by supervised losses, and\nunannotated clusters by T5-based entailment-related and language-related\nlosses. Compared to other baselines, both automatic evaluation and human\nevaluation show better article-summary and cluster-summary entailment in\ngenerated summaries. On a separate note, we hope that our article-summary\nentailment annotations contribute to the community's effort in improving\nabstractive summarization faithfulness.",
          "link": "http://arxiv.org/abs/2106.02278",
          "publishedOn": "2021-06-07T03:06:11.483Z",
          "wordCount": 572,
          "title": "AgreeSum: Agreement-Oriented Multi-Document Summarization. (arXiv:2106.02278v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02241",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Su_W/0/1/0/all/0/1\">Weiyue Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xuyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1\">Shikun Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiaxiang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Weixin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_H/0/1/0/all/0/1\">Hao Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hua Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haifeng Wang</a>",
          "description": "Pretrained language models (PLMs) such as BERT adopt a training paradigm\nwhich first pretrain the model in general data and then finetune the model on\ntask-specific data, and have recently achieved great success. However, PLMs are\nnotorious for their enormous parameters and hard to be deployed on real-life\napplications. Knowledge distillation has been prevailing to address this\nproblem by transferring knowledge from a large teacher to a much smaller\nstudent over a set of data. We argue that the selection of thee three key\ncomponents, namely teacher, training data, and learning objective, is crucial\nto the effectiveness of distillation. We, therefore, propose a four-stage\nprogressive distillation framework ERNIE-Tiny to compress PLM, which varies the\nthree components gradually from general level to task-specific level.\nSpecifically, the first stage, General Distillation, performs distillation with\nguidance from pretrained teacher, gerenal data and latent distillation loss.\nThen, General-Enhanced Distillation changes teacher model from pretrained\nteacher to finetuned teacher. After that, Task-Adaptive Distillation shifts\ntraining data from general data to task-specific data. In the end,\nTask-Specific Distillation, adds two additional losses, namely Soft-Label and\nHard-Label loss onto the last stage. Empirical results demonstrate the\neffectiveness of our framework and generalization gain brought by ERNIE-Tiny.In\nparticular, experiments show that a 4-layer ERNIE-Tiny maintains over\n98.0%performance of its 12-layer teacher BERT base on GLUE benchmark,\nsurpassing state-of-the-art (SOTA) by 1.0% GLUE score with the same amount of\nparameters. Moreover, ERNIE-Tiny achieves a new compression SOTA on five\nChinese NLP tasks, outperforming BERT base by 0.4% accuracy with 7.5x fewer\nparameters and9.4x faster inference speed.",
          "link": "http://arxiv.org/abs/2106.02241",
          "publishedOn": "2021-06-07T03:06:11.369Z",
          "wordCount": 699,
          "title": "ERNIE-Tiny : A Progressive Distillation Framework for Pretrained Transformer Compression. (arXiv:2106.02241v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02302",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Meng_Z/0/1/0/all/0/1\">Zhong Meng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_Y/0/1/0/all/0/1\">Yu Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kanda_N/0/1/0/all/0/1\">Naoyuki Kanda</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lu_L/0/1/0/all/0/1\">Liang Lu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1\">Xie Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ye_G/0/1/0/all/0/1\">Guoli Ye</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sun_E/0/1/0/all/0/1\">Eric Sun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1\">Jinyu Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gong_Y/0/1/0/all/0/1\">Yifan Gong</a>",
          "description": "Integrating external language models (LMs) into end-to-end (E2E) models\nremains a challenging task for domain-adaptive speech recognition. Recently,\ninternal language model estimation (ILME)-based LM fusion has shown significant\nword error rate (WER) reduction from Shallow Fusion by subtracting a weighted\ninternal LM score from an interpolation of E2E model and external LM scores\nduring beam search. However, on different test sets, the optimal LM\ninterpolation weights vary over a wide range and have to be tuned extensively\non well-matched validation sets. In this work, we perform LM fusion in the\nminimum WER (MWER) training of an E2E model to obviate the need for LM weights\ntuning during inference. Besides MWER training with Shallow Fusion (MWER-SF),\nwe propose a novel MWER training with ILME (MWER-ILME) where the ILME-based\nfusion is conducted to generate N-best hypotheses and their posteriors.\nAdditional gradient is induced when internal LM is engaged in MWER-ILME loss\ncomputation. During inference, LM weights pre-determined in MWER training\nenable robust LM integrations on test sets from different domains. Experimented\nwith 30K-hour trained transformer transducers, MWER-ILME achieves on average\n8.8% and 5.8% relative WER reductions from MWER and MWER-SF training,\nrespectively, on 6 different test sets",
          "link": "http://arxiv.org/abs/2106.02302",
          "publishedOn": "2021-06-07T03:06:11.362Z",
          "wordCount": 675,
          "title": "Minimum Word Error Rate Training with Language Model Fusion for End-to-End Speech Recognition. (arXiv:2106.02302v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02124",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ebrahimi_A/0/1/0/all/0/1\">Abteen Ebrahimi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kann_K/0/1/0/all/0/1\">Katharina Kann</a>",
          "description": "Pretrained multilingual models (PMMs) enable zero-shot learning via\ncross-lingual transfer, performing best for languages seen during pretraining.\nWhile methods exist to improve performance for unseen languages, they have\nalmost exclusively been evaluated using amounts of raw text only available for\na small fraction of the world's languages. In this paper, we evaluate the\nperformance of existing methods to adapt PMMs to new languages using a resource\navailable for over 1600 languages: the New Testament. This is challenging for\ntwo reasons: (1) the small corpus size, and (2) the narrow domain. While\nperformance drops for all approaches, we surprisingly still see gains of up to\n$17.69\\%$ accuracy for part-of-speech tagging and $6.29$ F1 for NER on average\nover all languages as compared to XLM-R. Another unexpected finding is that\ncontinued pretraining, the simplest approach, performs best. Finally, we\nperform a case study to disentangle the effects of domain and size and to shed\nlight on the influence of the finetuning source language.",
          "link": "http://arxiv.org/abs/2106.02124",
          "publishedOn": "2021-06-07T03:06:11.353Z",
          "wordCount": 592,
          "title": "How to Adapt Your Pretrained Multilingual Model to 1600 Languages. (arXiv:2106.02124v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02210",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zikai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chen Henry Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1\">Qihan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaoyan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>",
          "description": "Autoregressive models have been widely used in unsupervised text style\ntransfer. Despite their success, these models still suffer from the content\npreservation problem that they usually ignore part of the source sentence and\ngenerate some irrelevant words with strong styles. In this paper, we propose a\nNon-Autoregressive generator for unsupervised text Style Transfer (NAST), which\nalleviates the problem from two aspects. First, we observe that most words in\nthe transferred sentence can be aligned with related words in the source\nsentence, so we explicitly model word alignments to suppress irrelevant words.\nSecond, existing models trained with the cycle loss align sentences in two\nstylistic text spaces, which lacks fine-grained control at the word level. The\nproposed non-autoregressive generator focuses on the connections between\naligned words, which learns the word-level transfer between styles. For\nexperiments, we integrate the proposed generator into two base models and\nevaluate them on two style transfer tasks. The results show that NAST can\nsignificantly improve the overall performance and provide explainable word\nalignments. Moreover, the non-autoregressive generator achieves over 10x\nspeedups at inference. Our codes are available at\nhttps://github.com/thu-coai/NAST.",
          "link": "http://arxiv.org/abs/2106.02210",
          "publishedOn": "2021-06-07T03:06:11.343Z",
          "wordCount": 632,
          "title": "NAST: A Non-Autoregressive Generator with Word Alignment for Unsupervised Text Style Transfer. (arXiv:2106.02210v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02287",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Toledo_C/0/1/0/all/0/1\">Cha&#xef;m van Toledo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dijk_F/0/1/0/all/0/1\">Friso van Dijk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spruit_M/0/1/0/all/0/1\">Marco Spruit</a>",
          "description": "The human resource (HR) domain contains various types of privacy-sensitive\ntextual data, such as e-mail correspondence and performance appraisal. Doing\nresearch on these documents brings several challenges, one of them\nanonymisation. In this paper, we evaluate the current Dutch text\nde-identification methods for the HR domain in four steps. First, by updating\none of these methods with the latest named entity recognition (NER) models. The\nresult is that the NER model based on the CoNLL 2002 corpus in combination with\nthe BERTje transformer give the best combination for suppressing persons\n(recall 0.94) and locations (recall 0.82). For suppressing gender, DEDUCE is\nperforming best (recall 0.53). Second NER evaluation is based on both strict\nde-identification of entities (a person must be suppressed as a person) and\nthird evaluation on a loose sense of de-identification (no matter what how a\nperson is suppressed, as long it is suppressed). In the fourth and last step a\nnew kind of NER dataset is tested for recognising job titles in texts.",
          "link": "http://arxiv.org/abs/2106.02287",
          "publishedOn": "2021-06-07T03:06:11.323Z",
          "wordCount": 614,
          "title": "Dutch Named Entity Recognition and De-identification Methods for the Human Resource Domain. (arXiv:2106.02287v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02280",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sheng_S/0/1/0/all/0/1\">Sasha Sheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Amanpreet Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goswami_V/0/1/0/all/0/1\">Vedanuj Goswami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Magana_J/0/1/0/all/0/1\">Jose Alberto Lopez Magana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galuba_W/0/1/0/all/0/1\">Wojciech Galuba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parikh_D/0/1/0/all/0/1\">Devi Parikh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiela_D/0/1/0/all/0/1\">Douwe Kiela</a>",
          "description": "Performance on the most commonly used Visual Question Answering dataset (VQA\nv2) is starting to approach human accuracy. However, in interacting with\nstate-of-the-art VQA models, it is clear that the problem is far from being\nsolved. In order to stress test VQA models, we benchmark them against\nhuman-adversarial examples. Human subjects interact with a state-of-the-art VQA\nmodel, and for each image in the dataset, attempt to find a question where the\nmodel's predicted answer is incorrect. We find that a wide range of\nstate-of-the-art models perform poorly when evaluated on these examples. We\nconduct an extensive analysis of the collected adversarial examples and provide\nguidance on future research directions. We hope that this Adversarial VQA\n(AdVQA) benchmark can help drive progress in the field and advance the state of\nthe art.",
          "link": "http://arxiv.org/abs/2106.02280",
          "publishedOn": "2021-06-07T03:06:11.315Z",
          "wordCount": 575,
          "title": "Human-Adversarial Visual Question Answering. (arXiv:2106.02280v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02227",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zekang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinchao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_Z/0/1/0/all/0/1\">Zhengcong Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>",
          "description": "Nowadays, open-domain dialogue models can generate acceptable responses\naccording to the historical context based on the large-scale pre-trained\nlanguage models. However, they generally concatenate the dialogue history\ndirectly as the model input to predict the response, which we named as the flat\npattern and ignores the dynamic information flow across dialogue utterances. In\nthis work, we propose the DialoFlow model, in which we introduce a dynamic flow\nmechanism to model the context flow, and design three training objectives to\ncapture the information dynamics across dialogue utterances by addressing the\nsemantic influence brought about by each utterance in large-scale pre-training.\nExperiments on the multi-reference Reddit Dataset and DailyDialog Dataset\ndemonstrate that our DialoFlow significantly outperforms the DialoGPT on the\ndialogue generation task. Besides, we propose the Flow score, an effective\nautomatic metric for evaluating interactive human-bot conversation quality\nbased on the pre-trained DialoFlow, which presents high chatbot-level\ncorrelation ($r=0.9$) with human ratings among 11 chatbots. Code and\npre-trained models will be public.\n\\footnote{\\url{https://github.com/ictnlp/DialoFlow}}",
          "link": "http://arxiv.org/abs/2106.02227",
          "publishedOn": "2021-06-07T03:06:11.305Z",
          "wordCount": 610,
          "title": "Conversations Are Not Flat: Modeling the Dynamic Information Flow across Dialogue Utterances. (arXiv:2106.02227v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02282",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lu Chen Hanqi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_R/0/1/0/all/0/1\">Ruisheng Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_D/0/1/0/all/0/1\">Da Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1\">Mengyue Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1\">Kai Yu</a>",
          "description": "Recently, Text-to-SQL for multi-turn dialogue has attracted great interest.\nHere, the user input of the current turn is parsed into the corresponding SQL\nquery of the appropriate database, given all previous dialogue history. Current\napproaches mostly employ end-to-end models and consequently face two\nchallenges. First, dialogue history modeling and Text-to-SQL parsing are\nimplicitly combined, hence it is hard to carry out interpretable analysis and\nobtain targeted improvement. Second, SQL annotation of multi-turn dialogue is\nvery expensive, leading to training data sparsity. In this paper, we propose a\nnovel decoupled multi-turn Text-to-SQL framework, where an utterance rewrite\nmodel first explicitly solves completion of dialogue context, and then a\nsingle-turn Text-to-SQL parser follows. A dual learning approach is also\nproposed for the utterance rewrite model to address the data sparsity problem.\nCompared with end-to-end approaches, the proposed decoupled method can achieve\nexcellent performance without any annotated in-domain data. With just a few\nannotated rewrite cases, the decoupled method outperforms the released\nstate-of-the-art end-to-end models on both SParC and CoSQL datasets.",
          "link": "http://arxiv.org/abs/2106.02282",
          "publishedOn": "2021-06-07T03:06:11.294Z",
          "wordCount": 613,
          "title": "Decoupled Dialogue Modeling and Semantic Parsing for Multi-Turn Text-to-SQL. (arXiv:2106.02282v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02134",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_W/0/1/0/all/0/1\">Wasi Uddin Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haoran Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehdad_Y/0/1/0/all/0/1\">Yashar Mehdad</a>",
          "description": "In recent years, we have seen a colossal effort in pre-training multilingual\ntext encoders using large-scale corpora in many languages to facilitate\ncross-lingual transfer learning. However, due to typological differences across\nlanguages, the cross-lingual transfer is challenging. Nevertheless, language\nsyntax, e.g., syntactic dependencies, can bridge the typological gap. Previous\nworks have shown that pre-trained multilingual encoders, such as mBERT\n\\cite{devlin-etal-2019-bert}, capture language syntax, helping cross-lingual\ntransfer. This work shows that explicitly providing language syntax and\ntraining mBERT using an auxiliary objective to encode the universal dependency\ntree structure helps cross-lingual transfer. We perform rigorous experiments on\nfour NLP tasks, including text classification, question answering, named entity\nrecognition, and task-oriented semantic parsing. The experiment results show\nthat syntax-augmented mBERT improves cross-lingual transfer on popular\nbenchmarks, such as PAWS-X and MLQA, by 1.4 and 1.6 points on average across\nall languages. In the \\emph{generalized} transfer setting, the performance\nboosted significantly, with 3.9 and 3.1 points on average in PAWS-X and MLQA.",
          "link": "http://arxiv.org/abs/2106.02134",
          "publishedOn": "2021-06-07T03:06:11.281Z",
          "wordCount": 587,
          "title": "Syntax-augmented Multilingual BERT for Cross-lingual Transfer. (arXiv:2106.02134v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02242",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_P/0/1/0/all/0/1\">Peng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_S/0/1/0/all/0/1\">Shijie Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaogang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1\">Jifeng Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongsheng Li</a>",
          "description": "Transformer has been widely adopted in Neural Machine Translation (NMT)\nbecause of its large capacity and parallel training of sequence generation.\nHowever, the deployment of Transformer is challenging because different\nscenarios require models of different complexities and scales. Naively training\nmultiple Transformers is redundant in terms of both computation and memory. In\nthis paper, we propose a novel scalable Transformers, which naturally contains\nsub-Transformers of different scales and have shared parameters. Each\nsub-Transformer can be easily obtained by cropping the parameters of the\nlargest Transformer. A three-stage training scheme is proposed to tackle the\ndifficulty of training the scalable Transformers, which introduces additional\nsupervisions from word-level and sequence-level self-distillation. Extensive\nexperiments were conducted on WMT EN-De and En-Fr to validate our proposed\nscalable Transformers.",
          "link": "http://arxiv.org/abs/2106.02242",
          "publishedOn": "2021-06-07T03:06:11.262Z",
          "wordCount": 548,
          "title": "Scalable Transformers for Neural Machine Translation. (arXiv:2106.02242v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02170",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bhati_S/0/1/0/all/0/1\">Saurabhchand Bhati</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Villalba_J/0/1/0/all/0/1\">Jes&#xfa;s Villalba</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zelasko_P/0/1/0/all/0/1\">Piotr &#x17b;elasko</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moro_Velazquez_L/0/1/0/all/0/1\">Laureano Moro-Velazquez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dehak_N/0/1/0/all/0/1\">Najim Dehak</a>",
          "description": "Automatic detection of phoneme or word-like units is one of the core\nobjectives in zero-resource speech processing. Recent attempts employ\nself-supervised training methods, such as contrastive predictive coding (CPC),\nwhere the next frame is predicted given past context. However, CPC only looks\nat the audio signal's frame-level structure. We overcome this limitation with a\nsegmental contrastive predictive coding (SCPC) framework that can model the\nsignal structure at a higher level e.g. at the phoneme level. In this\nframework, a convolutional neural network learns frame-level representation\nfrom the raw waveform via noise-contrastive estimation (NCE). A differentiable\nboundary detector finds variable-length segments, which are then used to\noptimize a segment encoder via NCE to learn segment representations. The\ndifferentiable boundary detector allows us to train frame-level and\nsegment-level encoders jointly. Typically, phoneme and word segmentation are\ntreated as separate tasks. We unify them and experimentally show that our\nsingle model outperforms existing phoneme and word segmentation methods on\nTIMIT and Buckeye datasets. We analyze the impact of boundary threshold and\nwhen is the right time to include the segmental loss in the learning process.",
          "link": "http://arxiv.org/abs/2106.02170",
          "publishedOn": "2021-06-07T03:06:11.254Z",
          "wordCount": 628,
          "title": "Segmental Contrastive Predictive Coding for Unsupervised Word Segmentation. (arXiv:2106.02170v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02208",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Unanue_I/0/1/0/all/0/1\">Inigo Jauregi Unanue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parnell_J/0/1/0/all/0/1\">Jacob Parnell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piccardi_M/0/1/0/all/0/1\">Massimo Piccardi</a>",
          "description": "Neural machine translation models are often biased toward the limited\ntranslation references seen during training. To amend this form of overfitting,\nin this paper we propose fine-tuning the models with a novel training objective\nbased on the recently-proposed BERTScore evaluation metric. BERTScore is a\nscoring function based on contextual embeddings that overcomes the typical\nlimitations of n-gram-based metrics (e.g. synonyms, paraphrases), allowing\ntranslations that are different from the references, yet close in the\ncontextual embedding space, to be treated as substantially correct. To be able\nto use BERTScore as a training objective, we propose three approaches for\ngenerating soft predictions, allowing the network to remain completely\ndifferentiable end-to-end. Experiments carried out over four, diverse language\npairs have achieved improvements of up to 0.58 pp (3.28%) in BLEU score and up\nto 0.76 pp (0.98%) in BERTScore (F_BERT) when fine-tuning a strong baseline.",
          "link": "http://arxiv.org/abs/2106.02208",
          "publishedOn": "2021-06-07T03:06:11.245Z",
          "wordCount": 571,
          "title": "BERTTune: Fine-Tuning Neural Machine Translation with BERTScore. (arXiv:2106.02208v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02082",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1\">Dian Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1\">Taiqi He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sagae_K/0/1/0/all/0/1\">Kenji Sagae</a>",
          "description": "Cross-lingual language tasks typically require a substantial amount of\nannotated data or parallel translation data. We explore whether language\nrepresentations that capture relationships among languages can be learned and\nsubsequently leveraged in cross-lingual tasks without the use of parallel data.\nWe generate dense embeddings for 29 languages using a denoising autoencoder,\nand evaluate the embeddings using the World Atlas of Language Structures (WALS)\nand two extrinsic tasks in a zero-shot setting: cross-lingual dependency\nparsing and cross-lingual natural language inference.",
          "link": "http://arxiv.org/abs/2106.02082",
          "publishedOn": "2021-06-07T03:06:11.236Z",
          "wordCount": 506,
          "title": "Language Embeddings for Typology and Cross-lingual Transfer Learning. (arXiv:2106.02082v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02192",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chandu_K/0/1/0/all/0/1\">Khyathi Raghavi Chandu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bisk_Y/0/1/0/all/0/1\">Yonatan Bisk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Black_A/0/1/0/all/0/1\">Alan W Black</a>",
          "description": "The NLP community has seen substantial recent interest in grounding to\nfacilitate interaction between language technologies and the world. However, as\na community, we use the term broadly to reference any linking of text to data\nor non-textual modality. In contrast, Cognitive Science more formally defines\n\"grounding\" as the process of establishing what mutual information is required\nfor successful communication between two interlocutors -- a definition which\nmight implicitly capture the NLP usage but differs in intent and scope. We\ninvestigate the gap between these definitions and seek answers to the following\nquestions: (1) What aspects of grounding are missing from NLP tasks? Here we\npresent the dimensions of coordination, purviews and constraints. (2) How is\nthe term \"grounding\" used in the current research? We study the trends in\ndatasets, domains, and tasks introduced in recent NLP conferences. And finally,\n(3) How to advance our current definition to bridge the gap with Cognitive\nScience? We present ways to both create new tasks or repurpose existing ones to\nmake advancements towards achieving a more complete sense of grounding.",
          "link": "http://arxiv.org/abs/2106.02192",
          "publishedOn": "2021-06-07T03:06:11.226Z",
          "wordCount": 599,
          "title": "Grounding 'Grounding' in NLP. (arXiv:2106.02192v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02228",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zekang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinchao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_Z/0/1/0/all/0/1\">Zhengcong Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>",
          "description": "A good open-domain chatbot should avoid presenting contradictory responses\nabout facts or opinions in a conversational session, known as its consistency\ncapacity. However, evaluating the consistency capacity of a chatbot is still\nchallenging. Employing human judges to interact with chatbots on purpose to\ncheck their capacities is costly and low-efficient, and difficult to get rid of\nsubjective bias. In this paper, we propose the Addressing Inquiries about\nHistory (AIH), an efficient and practical framework for the consistency\nevaluation. At the conversation stage, AIH attempts to address appropriate\ninquiries about the dialogue history to induce the chatbot to redeclare the\nhistorical facts or opinions. We carry out the conversation between chatbots,\nwhich is more efficient than the human-bot interaction and can also alleviate\nthe subjective bias. In this way, we manage to rapidly obtain a dialog session\nthat contains responses with high contradiction possibilities. At the\ncontradiction recognition stage, we can either employ human judges or a natural\nlanguage inference (NLI) model to recognize whether the answers to the\ninquiries are contradictory with history. Finally, we are able to rank chatbots\naccording to the contradiction statistics. Experiments on open-domain chatbots\nshow that our approach can efficiently and reliably assess the consistency\ncapacity of chatbots and achieve a high ranking correlation with the human\nevaluation. We release the framework and hope to help improve the consistency\ncapacity of chatbots. \\footnote{\\url{https://github.com/ictnlp/AIH}}",
          "link": "http://arxiv.org/abs/2106.02228",
          "publishedOn": "2021-06-07T03:06:11.204Z",
          "wordCount": 678,
          "title": "Addressing Inquiries about History: An Efficient and Practical Framework for Evaluating Open-domain Chatbot Consistency. (arXiv:2106.02228v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02182",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1\">Chenyu You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1\">Yuexian Zou</a>",
          "description": "In spoken conversational question answering (SCQA), the answer to the\ncorresponding question is generated by retrieving and then analyzing a fixed\nspoken document, including multi-part conversations. Most SCQA systems have\nconsidered only retrieving information from ordered utterances. However, the\nsequential order of dialogue is important to build a robust spoken\nconversational question answering system, and the changes of utterances order\nmay severely result in low-quality and incoherent corpora. To this end, we\nintroduce a self-supervised learning approach, including incoherence\ndiscrimination, insertion detection, and question prediction, to explicitly\ncapture the coreference resolution and dialogue coherence among spoken\ndocuments. Specifically, we design a joint learning framework where the\nauxiliary self-supervised tasks can enable the pre-trained SCQA systems towards\nmore coherent and meaningful spoken dialogue learning. We also utilize the\nproposed self-supervised learning tasks to capture intra-sentence coherence.\nExperimental results demonstrate that our proposed method provides more\ncoherent, meaningful, and appropriate responses, yielding superior performance\ngains compared to the original pre-trained language models. Our method achieves\nstate-of-the-art results on the Spoken-CoQA dataset.",
          "link": "http://arxiv.org/abs/2106.02182",
          "publishedOn": "2021-06-07T03:06:11.194Z",
          "wordCount": 613,
          "title": "Self-supervised Dialogue Learning for Spoken Conversational Question Answering. (arXiv:2106.02182v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02171",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kale_M/0/1/0/all/0/1\">Mihir Kale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siddhant_A/0/1/0/all/0/1\">Aditya Siddhant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Constant_N/0/1/0/all/0/1\">Noah Constant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johnson_M/0/1/0/all/0/1\">Melvin Johnson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Rfou_R/0/1/0/all/0/1\">Rami Al-Rfou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_L/0/1/0/all/0/1\">Linting Xue</a>",
          "description": "Recently, mT5 - a massively multilingual version of T5 - leveraged a unified\ntext-to-text format to attain state-of-the-art results on a wide variety of\nmultilingual NLP tasks. In this paper, we investigate the impact of\nincorporating parallel data into mT5 pre-training. We find that multi-tasking\nlanguage modeling with objectives such as machine translation during\npre-training is a straightforward way to improve performance on downstream\nmultilingual and cross-lingual tasks. However, the gains start to diminish as\nthe model capacity increases, suggesting that parallel data might not be as\nessential for larger models. At the same time, even at larger model sizes, we\nfind that pre-training with parallel data still provides benefits in the\nlimited labelled data regime.",
          "link": "http://arxiv.org/abs/2106.02171",
          "publishedOn": "2021-06-07T03:06:11.185Z",
          "wordCount": 561,
          "title": "nmT5 -- Is parallel data still relevant for pre-training massively multilingual language models?. (arXiv:2106.02171v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02076",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Edwards_J/0/1/0/all/0/1\">Justin Edwards</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clark_L/0/1/0/all/0/1\">Leigh Clark</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perrone_A/0/1/0/all/0/1\">Allison Perrone</a>",
          "description": "Chatbots are popular machine partners for task-oriented and social\ninteractions. Human-human computer-mediated communication research has explored\nhow people express their gender and sexuality in online social interactions,\nbut little is known about whether and in what way chatbots do the same. We\nconducted semi-structured interviews with 5 text-based conversational agents to\nexplore this topic Through these interviews, we identified 6 common themes\naround the expression of gender and sexual identity: identity description,\nidentity formation, peer acceptance, positive reflection, uncomfortable\nfeelings and off-topic responses. Chatbots express gender and sexuality\nexplicitly and through relation of experience and emotions, mimicking the human\nlanguage on which they are trained. It is nevertheless evident that chatbots\ndiffer from human dialogue partners as they lack the flexibility and\nunderstanding enabled by lived human experience. While chatbots are proficient\nin using language to express identity, they also display a lack of authentic\nexperiences of gender and sexuality.",
          "link": "http://arxiv.org/abs/2106.02076",
          "publishedOn": "2021-06-07T03:06:11.122Z",
          "wordCount": 583,
          "title": "LGBTQ-AI? Exploring Expressions of Gender and Sexual Orientation in Chatbots. (arXiv:2106.02076v1 [cs.HC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02083",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kapron_King_A/0/1/0/all/0/1\">Anna Kapron-King</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yang Xu</a>",
          "description": "The use of euphemisms is a known driver of language change. It has been\nproposed that women use euphemisms more than men. Although there have been\nseveral studies investigating gender differences in language, the claim about\neuphemism usage has not been tested comprehensively through time. If women do\nuse euphemisms more, this could mean that women also lead the formation of new\neuphemisms and language change over time. Using four large diachronic text\ncorpora of English, we evaluate the claim that women use euphemisms more than\nmen through a quantitative analysis. We assembled a list of 106 euphemism-taboo\npairs to analyze their relative use through time by each gender in the corpora.\nContrary to the existing belief, our results show that women do not use\neuphemisms with a higher proportion than men. We repeated the analysis using\ndifferent subsets of the euphemism-taboo pairs list and found that our result\nwas robust. Our study indicates that in a broad range of settings involving\nboth speech and writing, and with varying degrees of formality, women do not\nuse or form euphemisms more than men.",
          "link": "http://arxiv.org/abs/2106.02083",
          "publishedOn": "2021-06-07T03:06:11.095Z",
          "wordCount": 625,
          "title": "A diachronic evaluation of gender asymmetry in euphemism. (arXiv:2106.02083v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02183",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Excell_E/0/1/0/all/0/1\">Elizabeth Excell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moubayed_N/0/1/0/all/0/1\">Noura Al Moubayed</a>",
          "description": "Classifiers tend to propagate biases present in the data on which they are\ntrained. Hence, it is important to understand how the demographic identities of\nthe annotators of comments affect the fairness of the resulting model. In this\npaper, we focus on the differences in the ways men and women annotate comments\nfor toxicity, investigating how these differences result in models that amplify\nthe opinions of male annotators. We find that the BERT model as-sociates toxic\ncomments containing offensive words with male annotators, causing the model to\npredict 67.7% of toxic comments as having been annotated by men. We show that\nthis disparity between gender predictions can be mitigated by removing\noffensive words and highly toxic comments from the training data. We then apply\nthe learned associations between gender and language to toxic language\nclassifiers, finding that models trained exclusively on female-annotated data\nperform 1.8% better than those trained solely on male-annotated data and that\ntraining models on data after removing all offensive words reduces bias in the\nmodel by 55.5% while increasing the sensitivity by 0.4%.",
          "link": "http://arxiv.org/abs/2106.02183",
          "publishedOn": "2021-06-07T03:06:11.070Z",
          "wordCount": 624,
          "title": "Towards Equal Gender Representation in the Annotations of Toxic Language Detection. (arXiv:2106.02183v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01649",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zuo_X/0/1/0/all/0/1\">Xinyu Zuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_P/0/1/0/all/0/1\">Pengfei Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yubo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jun Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1\">Weihua Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuguang Chen</a>",
          "description": "Modern models for event causality identification (ECI) are mainly based on\nsupervised learning, which are prone to the data lacking problem.\nUnfortunately, the existing NLP-related augmentation methods cannot directly\nproduce the available data required for this task. To solve the data lacking\nproblem, we introduce a new approach to augment training data for event\ncausality identification, by iteratively generating new examples and\nclassifying event causality in a dual learning framework. On the one hand, our\napproach is knowledge-guided, which can leverage existing knowledge bases to\ngenerate well-formed new sentences. On the other hand, our approach employs a\ndual mechanism, which is a learnable augmentation framework and can\ninteractively adjust the generation process to generate task-related sentences.\nExperimental results on two benchmarks EventStoryLine and Causal-TimeBank show\nthat 1) our method can augment suitable task-related training data for ECI; 2)\nour method outperforms previous methods on EventStoryLine and Causal-TimeBank\n(+2.5 and +2.1 points on F1 value respectively).",
          "link": "http://arxiv.org/abs/2106.01649",
          "publishedOn": "2021-06-04T01:12:31.697Z",
          "wordCount": 593,
          "title": "LearnDA: Learnable Knowledge-Guided Data Augmentation for Event Causality Identification. (arXiv:2106.01649v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01654",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zuo_X/0/1/0/all/0/1\">Xinyu Zuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_P/0/1/0/all/0/1\">Pengfei Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yubo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jun Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1\">Weihua Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuguang Chen</a>",
          "description": "Current models for event causality identification (ECI) mainly adopt a\nsupervised framework, which heavily rely on labeled data for training.\nUnfortunately, the scale of current annotated datasets is relatively limited,\nwhich cannot provide sufficient support for models to capture useful indicators\nfrom causal statements, especially for handing those new, unseen cases. To\nalleviate this problem, we propose a novel approach, shortly named CauSeRL,\nwhich leverages external causal statements for event causality identification.\nFirst of all, we design a self-supervised framework to learn context-specific\ncausal patterns from external causal statements. Then, we adopt a contrastive\ntransfer strategy to incorporate the learned context-specific causal patterns\ninto the target ECI model. Experimental results show that our method\nsignificantly outperforms previous methods on EventStoryLine and\nCausal-TimeBank (+2.0 and +3.4 points on F1 value respectively).",
          "link": "http://arxiv.org/abs/2106.01654",
          "publishedOn": "2021-06-04T01:12:31.690Z",
          "wordCount": 576,
          "title": "Improving Event Causality Identification via Self-Supervised Representation Learning on External Causal Statement. (arXiv:2106.01654v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01601",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jiao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1\">Nanyun Peng</a>",
          "description": "Human activities can be seen as sequences of events, which are crucial to\nunderstanding societies. Disproportional event distribution for different\ndemographic groups can manifest and amplify social stereotypes, and potentially\njeopardize the ability of members in some groups to pursue certain goals. In\nthis paper, we present the first event-centric study of gender biases in a\nWikipedia corpus. To facilitate the study, we curate a corpus of career and\npersonal life descriptions with demographic information consisting of 7,854\nfragments from 10,412 celebrities. Then we detect events with a\nstate-of-the-art event detection model, calibrate the results using\nstrategically generated templates, and extract events that have asymmetric\nassociations with genders. Our study discovers that the Wikipedia pages tend to\nintermingle personal life events with professional events for females but not\nfor males, which calls for the awareness of the Wikipedia community to\nformalize guidelines and train the editors to mind the implicit biases that\ncontributors carry. Our work also lays the foundation for future works on\nquantifying and discovering event biases at the corpus level.",
          "link": "http://arxiv.org/abs/2106.01601",
          "publishedOn": "2021-06-04T01:12:31.666Z",
          "wordCount": 613,
          "title": "Men Are Elected, Women Are Married: Events Gender Bias on Wikipedia. (arXiv:2106.01601v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01644",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barchiesi_M/0/1/0/all/0/1\">M. A. Barchiesi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Colladon_A/0/1/0/all/0/1\">A. Fronzetti Colladon</a>",
          "description": "This study uses an innovative measure, the Semantic Brand Score, to assess\nthe interest of stakeholders in different company core values. Among others, we\nfocus on corporate social responsibility (CSR) core value statements, and on\nthe attention they receive from five categories of stakeholders (customers,\ncompany communication teams, employees, associations and media). Combining big\ndata methods and tools of Social Network Analysis and Text Mining, we analyzed\nabout 58,000 Italian tweets and found that different stakeholders have\ndifferent prevailing interests. CSR gets much less attention than expected.\nCore values related to customers and employees are in the foreground.",
          "link": "http://arxiv.org/abs/2106.01644",
          "publishedOn": "2021-06-04T01:12:31.660Z",
          "wordCount": 557,
          "title": "Corporate core values and social responsibility: What really matters to whom. (arXiv:2106.01644v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01597",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maurya_K/0/1/0/all/0/1\">Kaushal Kumar Maurya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Desarkar_M/0/1/0/all/0/1\">Maunendra Sankar Desarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kano_Y/0/1/0/all/0/1\">Yoshinobu Kano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deepshikha_K/0/1/0/all/0/1\">Kumari Deepshikha</a>",
          "description": "Despite the recent advancement in NLP research, cross-lingual transfer for\nnatural language generation is relatively understudied. In this work, we\ntransfer supervision from high resource language (HRL) to multiple low-resource\nlanguages (LRLs) for natural language generation (NLG). We consider four NLG\ntasks (text summarization, question generation, news headline generation, and\ndistractor generation) and three syntactically diverse languages, i.e.,\nEnglish, Hindi, and Japanese. We propose an unsupervised cross-lingual language\ngeneration framework (called ZmBART) that does not use any parallel or\npseudo-parallel/back-translated data. In this framework, we further pre-train\nmBART sequence-to-sequence denoising auto-encoder model with an auxiliary task\nusing monolingual data of three languages. The objective function of the\nauxiliary task is close to the target tasks which enriches the multi-lingual\nlatent representation of mBART and provides good initialization for target\ntasks. Then, this model is fine-tuned with task-specific supervised English\ndata and directly evaluated with low-resource languages in the Zero-shot\nsetting. To overcome catastrophic forgetting and spurious correlation issues,\nwe applied freezing model component and data argumentation approaches\nrespectively. This simple modeling approach gave us promising results.We\nexperimented with few-shot training (with 1000 supervised data points) which\nboosted the model performance further. We performed several ablations and\ncross-lingual transferability analyses to demonstrate the robustness of ZmBART.",
          "link": "http://arxiv.org/abs/2106.01597",
          "publishedOn": "2021-06-04T01:12:31.621Z",
          "wordCount": 650,
          "title": "ZmBART: An Unsupervised Cross-lingual Transfer Framework for Language Generation. (arXiv:2106.01597v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01609",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Piji Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuming Shi</a>",
          "description": "We investigate the problem of Chinese Grammatical Error Correction (CGEC) and\npresent a new framework named Tail-to-Tail (\\textbf{TtT}) non-autoregressive\nsequence prediction to address the deep issues hidden in CGEC. Considering that\nmost tokens are correct and can be conveyed directly from source to target, and\nthe error positions can be estimated and corrected based on the bidirectional\ncontext information, thus we employ a BERT-initialized Transformer Encoder as\nthe backbone model to conduct information modeling and conveying. Considering\nthat only relying on the same position substitution cannot handle the\nvariable-length correction cases, various operations such substitution,\ndeletion, insertion, and local paraphrasing are required jointly. Therefore, a\nConditional Random Fields (CRF) layer is stacked on the up tail to conduct\nnon-autoregressive sequence prediction by modeling the token dependencies.\nSince most tokens are correct and easily to be predicted/conveyed to the\ntarget, then the models may suffer from a severe class imbalance issue. To\nalleviate this problem, focal loss penalty strategies are integrated into the\nloss functions. Moreover, besides the typical fix-length error correction\ndatasets, we also construct a variable-length corpus to conduct experiments.\nExperimental results on standard datasets, especially on the variable-length\ndatasets, demonstrate the effectiveness of TtT in terms of sentence-level\nAccuracy, Precision, Recall, and F1-Measure on tasks of error Detection and\nCorrection.",
          "link": "http://arxiv.org/abs/2106.01609",
          "publishedOn": "2021-06-04T01:12:31.609Z",
          "wordCount": 653,
          "title": "Tail-to-Tail Non-Autoregressive Sequence Prediction for Chinese Grammatical Error Correction. (arXiv:2106.01609v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01555",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balagopalan_A/0/1/0/all/0/1\">Aparna Balagopalan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Novikova_J/0/1/0/all/0/1\">Jekaterina Novikova</a>",
          "description": "In this paper, we study the performance and generalizability of three\napproaches for AD detection from speech on the recent ADReSSo challenge\ndataset: 1) using conventional acoustic features 2) using novel pre-trained\nacoustic embeddings 3) combining acoustic features and embeddings. We find that\nwhile feature-based approaches have a higher precision, classification\napproaches relying on the combination of embeddings and features prove to have\na higher, and more balanced performance across multiple metrics of performance.\nOur best model, using such a combined approach, outperforms the acoustic\nbaseline in the challenge by 2.8\\%.",
          "link": "http://arxiv.org/abs/2106.01555",
          "publishedOn": "2021-06-04T01:12:31.603Z",
          "wordCount": 527,
          "title": "Comparing Acoustic-based Approaches for Alzheimer's Disease Detection. (arXiv:2106.01555v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01607",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jong_M/0/1/0/all/0/1\">Michiel de Jong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishna_S/0/1/0/all/0/1\">Satyapriya Krishna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1\">Anuva Agarwal</a>",
          "description": "Training a reinforcement learning agent to carry out natural language\ninstructions is limited by the available supervision, i.e. knowing when the\ninstruction has been carried out. We adapt the CLEVR visual question answering\ndataset to generate complex natural language navigation instructions and\naccompanying scene graphs, yielding an environment-agnostic supervised dataset.\nTo demonstrate the use of this data set, we map the scenes to the VizDoom\nenvironment and use the architecture in \\citet{gatedattention} to train an\nagent to carry out these more complex language instructions.",
          "link": "http://arxiv.org/abs/2106.01607",
          "publishedOn": "2021-06-04T01:12:31.579Z",
          "wordCount": 527,
          "title": "Grounding Complex Navigational Instructions Using Scene Graphs. (arXiv:2106.01607v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01598",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vo_H/0/1/0/all/0/1\">Hanh Hong-Phuc Vo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_H/0/1/0/all/0/1\">Hieu Trung Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luu_S/0/1/0/all/0/1\">Son T. Luu</a>",
          "description": "Online game forums are popular to most of game players. They use it to\ncommunicate and discuss the strategy of the game, or even to make friends.\nHowever, game forums also contain abusive and harassment speech, disturbing and\nthreatening players. Therefore, it is necessary to automatically detect and\nremove cyberbullying comments to keep the game forum clean and friendly. We use\nthe Cyberbullying dataset collected from World of Warcraft (WoW) and League of\nLegends (LoL) forums and train classification models to automatically detect\nwhether a comment of a player is abusive or not. The result obtains 82.69% of\nmacro F1-score for LoL forum and 83.86% of macro F1-score for WoW forum by the\nToxic-BERT model on the Cyberbullying dataset.",
          "link": "http://arxiv.org/abs/2106.01598",
          "publishedOn": "2021-06-04T01:12:31.573Z",
          "wordCount": 552,
          "title": "Automatically Detecting Cyberbullying Comments on Online Game Forums. (arXiv:2106.01598v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01666",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_K/0/1/0/all/0/1\">Kai-Hui Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Weiyan Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_Y/0/1/0/all/0/1\">Yoojung Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingwen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>",
          "description": "In recent years, chatbots have been empowered to engage in social\nconversations with humans and have the potential to elicit people to disclose\ntheir personal experiences, opinions, and emotions. However, how and to what\nextent people respond to chabots' self-disclosure remain less known. In this\nwork, we designed a social chatbot with three self-disclosure levels that\nconducted small talks and provided relevant recommendations to people. 372\nMTurk participants were randomized to one of the four groups with different\nself-disclosure levels to converse with the chatbot on two topics, movies, and\nCOVID-19. We found that people's self-disclosure level was strongly reciprocal\nto a chatbot's self-disclosure level. Chatbots' self-disclosure also positively\nimpacted engagement and users' perception of the bot and led to a more\neffective recommendation such that participants enjoyed and agreed more with\nthe recommendations.",
          "link": "http://arxiv.org/abs/2106.01666",
          "publishedOn": "2021-06-04T01:12:31.560Z",
          "wordCount": 620,
          "title": "Discovering Chatbot's Self-Disclosure's Impact on User Trust, Affinity, and Recommendation Effectiveness. (arXiv:2106.01666v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01623",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_T/0/1/0/all/0/1\">Tianyi Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zhicheng Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_N/0/1/0/all/0/1\">Nicholas Jing Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>",
          "description": "This paper studies how to automatically generate a natural language text that\ndescribes the facts in knowledge graph (KG). Considering the few-shot setting,\nwe leverage the excellent capacities of pretrained language models (PLMs) in\nlanguage understanding and generation. We make three major technical\ncontributions, namely representation alignment for bridging the semantic gap\nbetween KG encodings and PLMs, relation-biased KG linearization for deriving\nbetter input representations, and multi-task learning for learning the\ncorrespondence between KG and text. Extensive experiments on three benchmark\ndatasets have demonstrated the effectiveness of our model on KG-to-text\ngeneration task. In particular, our model outperforms all comparison methods on\nboth fully-supervised and few-shot settings. Our code and datasets are\navailable at https://github.com/RUCAIBox/Few-Shot-KG2Text.",
          "link": "http://arxiv.org/abs/2106.01623",
          "publishedOn": "2021-06-04T01:12:31.554Z",
          "wordCount": 555,
          "title": "Few-shot Knowledge Graph-to-Text Generation with Pretrained Language Models. (arXiv:2106.01623v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01562",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Kehai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tiejun Zhao</a>",
          "description": "Document-level relation extraction (DocRE) models generally use graph\nnetworks to implicitly model the reasoning skill (i.e., pattern recognition,\nlogical reasoning, coreference reasoning, etc.) related to the relation between\none entity pair in a document. In this paper, we propose a novel discriminative\nreasoning framework to explicitly model the paths of these reasoning skills\nbetween each entity pair in this document. Thus, a discriminative reasoning\nnetwork is designed to estimate the relation probability distribution of\ndifferent reasoning paths based on the constructed graph and vectorized\ndocument contexts for each entity pair, thereby recognizing their relation.\nExperimental results show that our method outperforms the previous\nstate-of-the-art performance on the large-scale DocRE dataset. The code is\npublicly available at https://github.com/xwjim/DRN.",
          "link": "http://arxiv.org/abs/2106.01562",
          "publishedOn": "2021-06-04T01:12:31.536Z",
          "wordCount": 550,
          "title": "Discriminative Reasoning for Document-level Relation Extraction. (arXiv:2106.01562v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01580",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuchen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Risteski_A/0/1/0/all/0/1\">Andrej Risteski</a>",
          "description": "Incorporating syntax into neural approaches in NLP has a multitude of\npractical and scientific benefits. For instance, a language model that is\nsyntax-aware is likely to be able to produce better samples; even a\ndiscriminative model like BERT with a syntax module could be used for core NLP\ntasks like unsupervised syntactic parsing. Rapid progress in recent years was\narguably spurred on by the empirical success of the Parsing-Reading-Predict\narchitecture of (Shen et al., 2018a), later simplified by the Order Neuron LSTM\nof (Shen et al., 2019). Most notably, this is the first time neural approaches\nwere able to successfully perform unsupervised syntactic parsing (evaluated by\nvarious metrics like F-1 score).\n\nHowever, even heuristic (much less fully mathematical) understanding of why\nand when these architectures work is lagging severely behind. In this work, we\nanswer representational questions raised by the architectures in (Shen et al.,\n2018a, 2019), as well as some transition-based syntax-aware language models\n(Dyer et al., 2016): what kind of syntactic structure can current neural\napproaches to syntax represent? Concretely, we ground this question in the\nsandbox of probabilistic context-free-grammars (PCFGs), and identify a key\naspect of the representational power of these approaches: the amount and\ndirectionality of context that the predictor has access to when forced to make\nparsing decision. We show that with limited context (either bounded, or\nunidirectional), there are PCFGs, for which these approaches cannot represent\nthe max-likelihood parse; conversely, if the context is unlimited, they can\nrepresent the max-likelihood parse of any PCFG.",
          "link": "http://arxiv.org/abs/2106.01580",
          "publishedOn": "2021-06-04T01:12:31.530Z",
          "wordCount": 690,
          "title": "The Limitations of Limited Context for Constituency Parsing. (arXiv:2106.01580v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01559",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_F/0/1/0/all/0/1\">Fubang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhuoren Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1\">Yangyang Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">Changlong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaozhong Liu</a>",
          "description": "Relational fact extraction aims to extract semantic triplets from\nunstructured text. In this work, we show that all of the relational fact\nextraction models can be organized according to a graph-oriented analytical\nperspective. An efficient model, aDjacency lIst oRiented rElational faCT\n(DIRECT), is proposed based on this analytical framework. To alleviate\nchallenges of error propagation and sub-task loss equilibrium, DIRECT employs a\nnovel adaptive multi-task learning strategy with dynamic sub-task loss\nbalancing. Extensive experiments are conducted on two benchmark datasets, and\nresults prove that the proposed model outperforms a series of state-of-the-art\n(SoTA) models for relational triplet extraction.",
          "link": "http://arxiv.org/abs/2106.01559",
          "publishedOn": "2021-06-04T01:12:31.523Z",
          "wordCount": 540,
          "title": "Adjacency List Oriented Relational Fact Extraction via Adaptive Multi-task Learning. (arXiv:2106.01559v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01625",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wanzheng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhat_S/0/1/0/all/0/1\">Suma Bhat</a>",
          "description": "Countermeasures to effectively fight the ever increasing hate speech online\nwithout blocking freedom of speech is of great social interest. Natural\nLanguage Generation (NLG), is uniquely capable of developing scalable\nsolutions. However, off-the-shelf NLG methods are primarily\nsequence-to-sequence neural models and they are limited in that they generate\ncommonplace, repetitive and safe responses regardless of the hate speech (e.g.,\n\"Please refrain from using such language.\") or irrelevant responses, making\nthem ineffective for de-escalating hateful conversations. In this paper, we\ndesign a three-module pipeline approach to effectively improve the diversity\nand relevance. Our proposed pipeline first generates various counterspeech\ncandidates by a generative model to promote diversity, then filters the\nungrammatical ones using a BERT model, and finally selects the most relevant\ncounterspeech response using a novel retrieval-based method. Extensive\nExperiments on three representative datasets demonstrate the efficacy of our\napproach in generating diverse and relevant counterspeech.",
          "link": "http://arxiv.org/abs/2106.01625",
          "publishedOn": "2021-06-04T01:12:31.517Z",
          "wordCount": 598,
          "title": "Generate, Prune, Select: A Pipeline for Counterspeech Generation against Online Hate Speech. (arXiv:2106.01625v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01586",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pahuja_V/0/1/0/all/0/1\">Vardaan Pahuja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yu Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenhu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bahrami_M/0/1/0/all/0/1\">Mehdi Bahrami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei-Peng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yu Su</a>",
          "description": "Knowledge bases (KBs) and text often contain complementary knowledge: KBs\nstore structured knowledge that can support long range reasoning, while text\nstores more comprehensive and timely knowledge in an unstructured way.\nSeparately embedding the individual knowledge sources into vector spaces has\ndemonstrated tremendous successes in encoding the respective knowledge, but how\nto jointly embed and reason with both knowledge sources to fully leverage the\ncomplementary information is still largely an open problem. We conduct a\nlarge-scale, systematic investigation of aligning KB and text embeddings for\njoint reasoning. We set up a novel evaluation framework with two evaluation\ntasks, few-shot link prediction and analogical reasoning, and evaluate an array\nof KB-text embedding alignment methods. We also demonstrate how such alignment\ncan infuse textual information into KB embeddings for more accurate link\nprediction on emerging entities and events, using COVID-19 as a case study.",
          "link": "http://arxiv.org/abs/2106.01586",
          "publishedOn": "2021-06-04T01:12:31.500Z",
          "wordCount": 634,
          "title": "A Systematic Investigation of KB-Text Embedding Alignment at Scale. (arXiv:2106.01586v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.07144",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1\">Jason Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meister_C/0/1/0/all/0/1\">Clara Meister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>",
          "description": "The uniform information density (UID) hypothesis, which posits that speakers\nbehaving optimally tend to distribute information uniformly across a linguistic\nsignal, has gained traction in psycholinguistics as an explanation for certain\nsyntactic, morphological, and prosodic choices. In this work, we explore\nwhether the UID hypothesis can be operationalized as an inductive bias for\nstatistical language modeling. Specifically, we augment the canonical MLE\nobjective for training language models with a regularizer that encodes UID. In\nexperiments on ten languages spanning five language families, we find that\nusing UID regularization consistently improves perplexity in language models,\nhaving a larger effect when training data is limited. Moreover, via an analysis\nof generated sequences, we find that UID-regularized language models have other\ndesirable properties, e.g., they generate text that is more lexically diverse.\nOur results not only suggest that UID is a reasonable inductive bias for\nlanguage modeling, but also provide an alternative validation of the UID\nhypothesis using modern-day NLP tools.",
          "link": "http://arxiv.org/abs/2105.07144",
          "publishedOn": "2021-06-04T01:12:31.222Z",
          "wordCount": 609,
          "title": "A Cognitive Regularizer for Language Modeling. (arXiv:2105.07144v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.06597",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yizhe Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Siqi Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xiang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1\">Yuwei Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brockett_C/0/1/0/all/0/1\">Chris Brockett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galley_M/0/1/0/all/0/1\">Michel Galley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dolan_B/0/1/0/all/0/1\">Bill Dolan</a>",
          "description": "Recent advances in large-scale pre-training such as GPT-3 allow seemingly\nhigh quality text to be generated from a given prompt. However, such generation\nsystems often suffer from problems of hallucinated facts, and are not\ninherently designed to incorporate useful external information. Grounded\ngeneration models appear to offer remedies, but their training typically relies\non rarely-available parallel data where corresponding information-relevant\ndocuments are provided for context. We propose a framework that alleviates this\ndata constraint by jointly training a grounded generator and document retriever\non the language model signal. The model learns to reward retrieval of the\ndocuments with the highest utility in generation, and attentively combines them\nusing a Mixture-of-Experts (MoE) ensemble to generate follow-on text. We\ndemonstrate that both generator and retriever can take advantage of this joint\ntraining and work synergistically to produce more informative and relevant text\nin both prose and dialogue generation.",
          "link": "http://arxiv.org/abs/2105.06597",
          "publishedOn": "2021-06-04T01:12:31.051Z",
          "wordCount": 617,
          "title": "Joint Retrieval and Generation Training for Grounded Text Generation. (arXiv:2105.06597v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.04054",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sheng_E/0/1/0/all/0/1\">Emily Sheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Natarajan_P/0/1/0/all/0/1\">Premkumar Natarajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1\">Nanyun Peng</a>",
          "description": "Technology for language generation has advanced rapidly, spurred by\nadvancements in pre-training large models on massive amounts of data and the\nneed for intelligent agents to communicate in a natural manner. While\ntechniques can effectively generate fluent text, they can also produce\nundesirable societal biases that can have a disproportionately negative impact\non marginalized populations. Language generation presents unique challenges for\nbiases in terms of direct user interaction and the structure of decoding\ntechniques. To better understand these challenges, we present a survey on\nsocietal biases in language generation, focusing on how data and techniques\ncontribute to biases and progress towards reducing biases. Motivated by a lack\nof studies on biases from decoding techniques, we also conduct experiments to\nquantify the effects of these techniques. By further discussing general trends\nand open challenges, we call to attention promising directions for research and\nthe importance of fairness and inclusivity considerations for language\ngeneration applications.",
          "link": "http://arxiv.org/abs/2105.04054",
          "publishedOn": "2021-06-04T01:12:30.986Z",
          "wordCount": 612,
          "title": "Societal Biases in Language Generation: Progress and Challenges. (arXiv:2105.04054v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.06990",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kovaleva_O/0/1/0/all/0/1\">Olga Kovaleva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulshreshtha_S/0/1/0/all/0/1\">Saurabh Kulshreshtha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rogers_A/0/1/0/all/0/1\">Anna Rogers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rumshisky_A/0/1/0/all/0/1\">Anna Rumshisky</a>",
          "description": "Multiple studies have shown that Transformers are remarkably robust to\npruning. Contrary to this received wisdom, we demonstrate that pre-trained\nTransformer encoders are surprisingly fragile to the removal of a very small\nnumber of features in the layer outputs (<0.0001% of model weights). In case of\nBERT and other pre-trained encoder Transformers, the affected component is the\nscaling factors and biases in the LayerNorm. The outliers are high-magnitude\nnormalization parameters that emerge early in pre-training and show up\nconsistently in the same dimensional position throughout the model. We show\nthat disabling them significantly degrades both the MLM loss and the downstream\ntask performance. This effect is observed across several BERT-family models and\nother popular pre-trained Transformer architectures, including BART, XLNet and\nELECTRA; we also show a similar effect in GPT-2.",
          "link": "http://arxiv.org/abs/2105.06990",
          "publishedOn": "2021-06-04T01:12:30.980Z",
          "wordCount": 591,
          "title": "BERT Busters: Outlier Dimensions that Disrupt Transformers. (arXiv:2105.06990v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03023",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Alisa Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sap_M/0/1/0/all/0/1\">Maarten Sap</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Ximing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swayamdipta_S/0/1/0/all/0/1\">Swabha Swayamdipta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhagavatula_C/0/1/0/all/0/1\">Chandra Bhagavatula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>",
          "description": "Despite recent advances in natural language generation, it remains\nchallenging to control attributes of generated text. We propose DExperts:\nDecoding-time Experts, a decoding-time method for controlled text generation\nthat combines a pretrained language model with \"expert\" LMs and/or\n\"anti-expert\" LMs in a product of experts. Intuitively, under the ensemble,\ntokens only get high probability if they are considered likely by the experts,\nand unlikely by the anti-experts. We apply DExperts to language detoxification\nand sentiment-controlled generation, where we outperform existing controllable\ngeneration methods on both automatic and human evaluations. Moreover, because\nDExperts operates only on the output of the pretrained LM, it is effective with\n(anti-)experts of smaller size, including when operating on GPT-3. Our work\nhighlights the promise of tuning small LMs on text with (un)desirable\nattributes for efficient decoding-time steering.",
          "link": "http://arxiv.org/abs/2105.03023",
          "publishedOn": "2021-06-04T01:12:30.974Z",
          "wordCount": 602,
          "title": "DExperts: Decoding-Time Controlled Text Generation with Experts and Anti-Experts. (arXiv:2105.03023v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.01547",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1\">Zhuoyuan Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">Di Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Binbin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1\">Fan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1\">Zhendong Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiaoyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1\">Lei Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_X/0/1/0/all/0/1\">Xin Lei</a>",
          "description": "In this paper, we propose an open source, production first, and production\nready speech recognition toolkit called WeNet in which a new two-pass approach\nis implemented to unify streaming and non-streaming end-to-end (E2E) speech\nrecognition in a single model. The main motivation of WeNet is to close the gap\nbetween the research and the production of E2E speechrecognition models. WeNet\nprovides an efficient way to ship ASR applications in several real-world\nscenarios, which is the main difference and advantage to other open source E2E\nspeech recognition toolkits. In our toolkit, a new two-pass method is\nimplemented. Our method propose a dynamic chunk-based attention strategy of the\nthe transformer layers to allow arbitrary right context length modifies in\nhybrid CTC/attention architecture. The inference latency could be easily\ncontrolled by only changing the chunk size. The CTC hypotheses are then\nrescored by the attention decoder to get the final result. Our experiments on\nthe AISHELL-1 dataset using WeNet show that, our model achieves 5.03\\% relative\ncharacter error rate (CER) reduction in non-streaming ASR compared to a\nstandard non-streaming transformer. After model quantification, our model\nperform reasonable RTF and latency.",
          "link": "http://arxiv.org/abs/2102.01547",
          "publishedOn": "2021-06-04T01:12:30.958Z",
          "wordCount": 674,
          "title": "WeNet: Production oriented Streaming and Non-streaming End-to-End Speech Recognition Toolkit. (arXiv:2102.01547v2 [cs.SD] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.08570",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Razumovskaia_E/0/1/0/all/0/1\">Evgeniia Razumovskaia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glavas_G/0/1/0/all/0/1\">Goran Glava&#x161;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Majewska_O/0/1/0/all/0/1\">Olga Majewska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ponti_E/0/1/0/all/0/1\">Edoardo M. Ponti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korhonen_A/0/1/0/all/0/1\">Anna Korhonen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1\">Ivan Vuli&#x107;</a>",
          "description": "In task-oriented dialogue (ToD), a user holds a conversation with an\nartificial agent to complete a concrete task. Although this technology\nrepresents one of the central objectives of AI and has been the focus of ever\nmore intense research and development efforts, it is currently limited to a few\nnarrow domains (e.g., food ordering, ticket booking) and a handful of languages\n(e.g., English, Chinese). This work provides an extensive overview of existing\nmethods and resources in multilingual ToD as an entry point to this exciting\nand emerging field. We find that the most critical factor preventing the\ncreation of truly multilingual ToD systems is the lack of datasets in most\nlanguages for both training and evaluation. In fact, acquiring annotations or\nhuman feedback for each component of modular systems or for data-hungry\nend-to-end systems is expensive and tedious. Hence, state-of-the-art approaches\nto multilingual ToD mostly rely on (zero- or few-shot) cross-lingual transfer\nfrom resource-rich languages (almost exclusively English), either by means of\nmachine translation or multilingual representations. These approaches are\ncurrently viable only for typologically similar languages and languages with\nparallel / monolingual corpora available. On the other hand, their\neffectiveness beyond these boundaries is doubtful or hard to assess due to the\nlack of linguistically diverse benchmarks (especially for natural language\ngeneration and end-to-end evaluation). To overcome this limitation, we draw\nparallels between components of the ToD pipeline and other NLP tasks, which can\ninspire solutions for learning in low-resource scenarios. Finally, we list\nadditional challenges that multilinguality poses for related areas (such as\nspeech and human-centred evaluation), and indicate future directions that hold\npromise to further expand language coverage and dialogue capabilities of\ncurrent ToD systems.",
          "link": "http://arxiv.org/abs/2104.08570",
          "publishedOn": "2021-06-04T01:12:30.952Z",
          "wordCount": 751,
          "title": "Crossing the Conversational Chasm: A Primer on Natural Language Processing for Multilingual Task-Oriented Dialogue Systems. (arXiv:2104.08570v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.03929",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1\">Haode Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1\">Lin Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sood_A/0/1/0/all/0/1\">Atin Sood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_A/0/1/0/all/0/1\">Abhishek Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kunc_L/0/1/0/all/0/1\">Ladislav Kunc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_M/0/1/0/all/0/1\">Mo Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potdar_S/0/1/0/all/0/1\">Saloni Potdar</a>",
          "description": "Intent detection is a key component of modern goal-oriented dialog systems\nthat accomplish a user task by predicting the intent of users' text input.\nThere are three primary challenges in designing robust and accurate intent\ndetection models. First, typical intent detection models require a large amount\nof labeled data to achieve high accuracy. Unfortunately, in practical scenarios\nit is more common to find small, unbalanced, and noisy datasets. Secondly, even\nwith large training data, the intent detection models can see a different\ndistribution of test data when being deployed in the real world, leading to\npoor accuracy. Finally, a practical intent detection model must be\ncomputationally efficient in both training and single query inference so that\nit can be used continuously and re-trained frequently. We benchmark intent\ndetection methods on a variety of datasets. Our results show that Watson\nAssistant's intent detection model outperforms other commercial solutions and\nis comparable to large pretrained language models while requiring only a\nfraction of computational resources and training data. Watson Assistant\ndemonstrates a higher degree of robustness when the training and test\ndistributions differ.",
          "link": "http://arxiv.org/abs/2012.03929",
          "publishedOn": "2021-06-04T01:12:30.944Z",
          "wordCount": 648,
          "title": "Benchmarking Commercial Intent Detection Services with Practice-Driven Evaluations. (arXiv:2012.03929v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.00123",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Raghu_D/0/1/0/all/0/1\">Dinesh Raghu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_N/0/1/0/all/0/1\">Nikhil Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mausam/0/1/0/all/0/1\">Mausam</a>",
          "description": "Task-oriented dialog (TOD) systems often need to formulate knowledge base\n(KB) queries corresponding to the user intent and use the query results to\ngenerate system responses. Existing approaches require dialog datasets to\nexplicitly annotate these KB queries -- these annotations can be time\nconsuming, and expensive. In response, we define the novel problems of\npredicting the KB query and training the dialog agent, without explicit KB\nquery annotation. For query prediction, we propose a reinforcement learning\n(RL) baseline, which rewards the generation of those queries whose KB results\ncover the entities mentioned in subsequent dialog. Further analysis reveals\nthat correlation among query attributes in KB can significantly confuse memory\naugmented policy optimization (MAPO), an existing state of the art RL agent. To\naddress this, we improve the MAPO baseline with simple but important\nmodifications suited to our task. To train the full TOD system for our setting,\nwe propose a pipelined approach: it independently predicts when to make a KB\nquery (query position predictor), then predicts a KB query at the predicted\nposition (query predictor), and uses the results of predicted query in\nsubsequent dialog (next response predictor). Overall, our work proposes first\nsolutions to our novel problem, and our analysis highlights the research\nchallenges in training TOD systems without query annotation.",
          "link": "http://arxiv.org/abs/2005.00123",
          "publishedOn": "2021-06-04T01:12:30.936Z",
          "wordCount": 689,
          "title": "Unsupervised Learning of KB Queries in Task-Oriented Dialogs. (arXiv:2005.00123v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01960",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vechtomova_O/0/1/0/all/0/1\">Olga Vechtomova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahu_G/0/1/0/all/0/1\">Gaurav Sahu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_D/0/1/0/all/0/1\">Dhruv Kumar</a>",
          "description": "We describe a real-time system that receives a live audio stream from a jam\nsession and generates lyric lines that are congruent with the live music being\nplayed. Two novel approaches are proposed to align the learned latent spaces of\naudio and text representations that allow the system to generate novel lyric\nlines matching live instrumental music. One approach is based on adversarial\nalignment of latent representations of audio and lyrics, while the other\napproach learns to transfer the topology from the music latent space to the\nlyric latent space. A user study with music artists using the system showed\nthat the system was useful not only in lyric composition, but also encouraged\nthe artists to improvise and find new musical expressions. Another user study\ndemonstrated that users preferred the lines generated using the proposed\nmethods to the lines generated by a baseline model.",
          "link": "http://arxiv.org/abs/2106.01960",
          "publishedOn": "2021-06-04T01:12:30.910Z",
          "wordCount": 598,
          "title": "LyricJam: A system for generating lyrics for live instrumental music. (arXiv:2106.01960v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2012.15832",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Press_O/0/1/0/all/0/1\">Ofir Press</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1\">Mike Lewis</a>",
          "description": "Increasing the input length has been a driver of progress in language\nmodeling with transformers. We identify conditions where shorter inputs are not\nharmful, and achieve perplexity and efficiency improvements through two new\nmethods that decrease input length. First, we show that initially training a\nmodel on short subsequences before moving on to longer ones both reduces\noverall training time and, surprisingly, substantially improves perplexity.\nSecond, we show how to improve the efficiency of recurrence methods in\ntransformers, which let models condition on previously processed tokens when\ngenerating sequences that exceed the maximal length the transformer can handle\nat once. Existing methods require computationally expensive relative position\nembeddings; we introduce a simple alternative of adding absolute position\nembeddings to queries and keys instead of to word embeddings, which efficiently\nproduces superior results. We show that these recurrent models also benefit\nfrom short input lengths. Combining these techniques speeds up training by a\nfactor of 1.65, reduces memory usage, and substantially improves perplexity on\nWikiText-103, without adding any parameters.",
          "link": "http://arxiv.org/abs/2012.15832",
          "publishedOn": "2021-06-04T01:12:30.899Z",
          "wordCount": 626,
          "title": "Shortformer: Better Language Modeling using Shorter Inputs. (arXiv:2012.15832v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01709",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_S/0/1/0/all/0/1\">Shuang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yuting Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1\">Baobao Chang</a>",
          "description": "Document-level relation extraction has attracted much attention in recent\nyears. It is usually formulated as a classification problem that predicts\nrelations for all entity pairs in the document. However, previous works\nindiscriminately represent intra- and inter-sentential relations in the same\nway, confounding the different patterns for predicting them. Besides, they\ncreate a document graph and use paths between entities on the graph as clues\nfor logical reasoning. However, not all entity pairs can be connected with a\npath and have the correct logical reasoning paths in their graph. Thus many\ncases of logical reasoning cannot be covered. This paper proposes an effective\narchitecture, SIRE, to represent intra- and inter-sentential relations in\ndifferent ways. We design a new and straightforward form of logical reasoning\nmodule that can cover more logical reasoning chains. Experiments on the public\ndatasets show SIRE outperforms the previous state-of-the-art methods. Further\nanalysis shows that our predictions are reliable and explainable. Our code is\navailable at https://github.com/DreamInvoker/SIRE.",
          "link": "http://arxiv.org/abs/2106.01709",
          "publishedOn": "2021-06-04T01:12:30.890Z",
          "wordCount": 615,
          "title": "SIRE: Separate Intra- and Inter-sentential Reasoning for Document-level Relation Extraction. (arXiv:2106.01709v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01978",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1\">Dou Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_L/0/1/0/all/0/1\">Lingwei Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huai_X/0/1/0/all/0/1\">Xiaoyong Huai</a>",
          "description": "Emotion Recognition in Conversations (ERC) has gained increasing attention\nfor developing empathetic machines. Recently, many approaches have been devoted\nto perceiving conversational context by deep learning models. However, these\napproaches are insufficient in understanding the context due to lacking the\nability to extract and integrate emotional clues. In this work, we propose\nnovel Contextual Reasoning Networks (DialogueCRN) to fully understand the\nconversational context from a cognitive perspective. Inspired by the Cognitive\nTheory of Emotion, we design multi-turn reasoning modules to extract and\nintegrate emotional clues. The reasoning module iteratively performs an\nintuitive retrieving process and a conscious reasoning process, which imitates\nhuman unique cognitive thinking. Extensive experiments on three public\nbenchmark datasets demonstrate the effectiveness and superiority of the\nproposed model.",
          "link": "http://arxiv.org/abs/2106.01978",
          "publishedOn": "2021-06-04T01:12:30.867Z",
          "wordCount": 559,
          "title": "DialogueCRN: Contextual Reasoning Networks for Emotion Recognition in Conversations. (arXiv:2106.01978v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01751",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sawan Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talukdar_P/0/1/0/all/0/1\">Partha Talukdar</a>",
          "description": "The ability to learn from limited data, or few-shot learning, is a desirable\nand often critical requirement for NLP systems. While many existing methods do\npoorly at learning from a handful of examples, large pretrained language models\nhave recently been shown to be efficient few-shot learners. One approach to\nfew-shot learning, which does not require finetuning of model parameters, is to\naugment the language model's input with priming text which is typically\nconstructed using task specific descriptions and examples. In this work, we\nfurther explore priming-based few-shot learning, with focus on using examples\nas prompts. We show that presenting examples in the right order is key for\ngeneralization. We introduce PERO (Prompting with Examples in the Right Order),\nwhere we formulate few-shot learning as search over the set of permutations of\nthe training examples. We show that PERO can learn to generalize efficiently\nusing as few as 10 examples, in contrast to existing approaches. While the\nnewline token is a natural choice for separating the examples in the prompt, we\nshow that learning a new separator token can potentially provide further gains\nin performance. We demonstrate the effectiveness of the proposed method on the\ntasks of sentiment classification, natural language inference and fact\nretrieval. Finally, we analyze the learned prompts to reveal novel insights,\nincluding the idea that two training examples in the right order alone can\nprovide competitive performance for sentiment classification and natural\nlanguage inference.",
          "link": "http://arxiv.org/abs/2106.01751",
          "publishedOn": "2021-06-04T01:12:30.851Z",
          "wordCount": 668,
          "title": "Reordering Examples Helps during Priming-based Few-Shot Learning. (arXiv:2106.01751v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2008.03945",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1\">Leyang Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Sijie Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>",
          "description": "BERT has been used for solving commonsense tasks such as CommonsenseQA. While\nprior research has found that BERT does contain commonsense information to some\nextent, there has been work showing that pre-trained models can rely on\nspurious associations (e.g., data bias) rather than key cues in solving\nsentiment classification and other problems. We quantitatively investigate the\npresence of structural commonsense cues in BERT when solving commonsense tasks,\nand the importance of such cues for the model prediction. Using two different\nmeasures, we find that BERT does use relevant knowledge for solving the task,\nand the presence of commonsense knowledge is positively correlated to the model\naccuracy.",
          "link": "http://arxiv.org/abs/2008.03945",
          "publishedOn": "2021-06-04T01:12:30.838Z",
          "wordCount": 559,
          "title": "Does BERT Solve Commonsense Task via Commonsense Knowledge?. (arXiv:2008.03945v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01925",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qin_L/0/1/0/all/0/1\">Libo Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Fuxuan Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1\">Tianbao Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Che_W/0/1/0/all/0/1\">Wanxiang Che</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Ting Liu</a>",
          "description": "Multi-intent SLU can handle multiple intents in an utterance, which has\nattracted increasing attention. However, the state-of-the-art joint models\nheavily rely on autoregressive approaches, resulting in two issues: slow\ninference speed and information leakage. In this paper, we explore a\nnon-autoregressive model for joint multiple intent detection and slot filling,\nachieving more fast and accurate. Specifically, we propose a Global-Locally\nGraph Interaction Network (GL-GIN) where a local slot-aware graph interaction\nlayer is proposed to model slot dependency for alleviating uncoordinated slots\nproblem while a global intent-slot graph interaction layer is introduced to\nmodel the interaction between multiple intents and all slots in the utterance.\nExperimental results on two public datasets show that our framework achieves\nstate-of-the-art performance while being 11.5 times faster.",
          "link": "http://arxiv.org/abs/2106.01925",
          "publishedOn": "2021-06-04T01:12:30.823Z",
          "wordCount": 569,
          "title": "GL-GIN: Fast and Accurate Non-Autoregressive Model for Joint Multiple Intent Detection and Slot Filling. (arXiv:2106.01925v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2012.15761",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vidgen_B/0/1/0/all/0/1\">Bertie Vidgen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thrush_T/0/1/0/all/0/1\">Tristan Thrush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waseem_Z/0/1/0/all/0/1\">Zeerak Waseem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiela_D/0/1/0/all/0/1\">Douwe Kiela</a>",
          "description": "We present a human-and-model-in-the-loop process for dynamically generating\ndatasets and training better performing and more robust hate detection models.\nWe provide a new dataset of ~40,000 entries, generated and labelled by trained\nannotators over four rounds of dynamic data creation. It includes ~15,000\nchallenging perturbations and each hateful entry has fine-grained labels for\nthe type and target of hate. Hateful entries make up 54% of the dataset, which\nis substantially higher than comparable datasets. We show that model\nperformance is substantially improved using this approach. Models trained on\nlater rounds of data collection perform better on test sets and are harder for\nannotators to trick. They also perform better on HateCheck, a suite of\nfunctional tests for online hate detection. We provide the code, dataset and\nannotation guidelines for other researchers to use. Accepted at ACL 2021.",
          "link": "http://arxiv.org/abs/2012.15761",
          "publishedOn": "2021-06-04T01:12:30.817Z",
          "wordCount": 603,
          "title": "Learning from the Worst: Dynamically Generated Datasets to Improve Online Hate Detection. (arXiv:2012.15761v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02009",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tellez_E/0/1/0/all/0/1\">Eric S. Tellez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miranda_Jimenez_S/0/1/0/all/0/1\">Sabino Miranda-Jim&#xe9;nez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Graff_M/0/1/0/all/0/1\">Mario Graff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moctezuma_D/0/1/0/all/0/1\">Daniela Moctezuma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siodia_O/0/1/0/all/0/1\">Oscar S. Siodia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Villasenor_E/0/1/0/all/0/1\">Elio A. Villase&#xf1;or</a>",
          "description": "Sentiment analysis is a text mining task that determines the polarity of a\ngiven text, i.e., its positiveness or negativeness. Recently, it has received a\nlot of attention given the interest in opinion mining in micro-blogging\nplatforms. These new forms of textual expressions present new challenges to\nanalyze text given the use of slang, orthographic and grammatical errors, among\nothers. Along with these challenges, a practical sentiment classifier should be\nable to handle efficiently large workloads.\n\nThe aim of this research is to identify which text transformations\n(lemmatization, stemming, entity removal, among others), tokenizers (e.g.,\nwords $n$-grams), and tokens weighting schemes impact the most the accuracy of\na classifier (Support Vector Machine) trained on two Spanish corpus. The\nmethodology used is to exhaustively analyze all the combinations of the text\ntransformations and their respective parameters to find out which\ncharacteristics the best performing classifiers have in common. Furthermore,\namong the different text transformations studied, we introduce a novel approach\nbased on the combination of word based $n$-grams and character based $q$-grams.\nThe results show that this novel combination of words and characters produces a\nclassifier that outperforms the traditional word based combination by $11.17\\%$\nand $5.62\\%$ on the INEGI and TASS'15 dataset, respectively.",
          "link": "http://arxiv.org/abs/2106.02009",
          "publishedOn": "2021-06-04T01:12:30.810Z",
          "wordCount": 644,
          "title": "A Case Study of Spanish Text Transformations for Twitter Sentiment Analysis. (arXiv:2106.02009v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/1911.03070",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_M/0/1/0/all/0/1\">Michelle Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mozhi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durme_B/0/1/0/all/0/1\">Benjamin Van Durme</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Findlater_L/0/1/0/all/0/1\">Leah Findlater</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boyd_Graber_J/0/1/0/all/0/1\">Jordan Boyd-Graber</a>",
          "description": "Cross-lingual word embeddings transfer knowledge between languages: models\ntrained on high-resource languages can predict in low-resource languages. We\nintroduce CLIME, an interactive system to quickly refine cross-lingual word\nembeddings for a given classification problem. First, CLIME ranks words by\ntheir salience to the downstream task. Then, users mark similarity between\nkeywords and their nearest neighbors in the embedding space. Finally, CLIME\nupdates the embeddings using the annotations. We evaluate CLIME on identifying\nhealth-related text in four low-resource languages: Ilocano, Sinhalese,\nTigrinya, and Uyghur. Embeddings refined by CLIME capture more nuanced word\nsemantics and have higher test accuracy than the original embeddings. CLIME\noften improves accuracy faster than an active learning baseline and can be\neasily combined with active learning to improve results.",
          "link": "http://arxiv.org/abs/1911.03070",
          "publishedOn": "2021-06-04T01:12:30.792Z",
          "wordCount": 608,
          "title": "Interactive Refinement of Cross-Lingual Word Embeddings. (arXiv:1911.03070v4 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01793",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Quzhe Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Shengqi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yansong Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1\">Yuan Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_Y/0/1/0/all/0/1\">Yuxuan Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Dongyan Zhao</a>",
          "description": "Document-level Relation Extraction (RE) is a more challenging task than\nsentence RE as it often requires reasoning over multiple sentences. Yet, human\nannotators usually use a small number of sentences to identify the relationship\nbetween a given entity pair. In this paper, we present an embarrassingly simple\nbut effective method to heuristically select evidence sentences for\ndocument-level RE, which can be easily combined with BiLSTM to achieve good\nperformance on benchmark datasets, even better than fancy graph neural network\nbased methods. We have released our code at\nhttps://github.com/AndrewZhe/Three-Sentences-Are-All-You-Need.",
          "link": "http://arxiv.org/abs/2106.01793",
          "publishedOn": "2021-06-04T01:12:30.785Z",
          "wordCount": 531,
          "title": "Three Sentences Are All You Need: Local Path Enhanced Document Relation Extraction. (arXiv:2106.01793v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02016",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1\">Somnath Roy</a>",
          "description": "Recent advances in supervised, semi-supervised and self-supervised deep\nlearning algorithms have shown significant improvement in the performance of\nautomatic speech recognition(ASR) systems. The state-of-the-art systems have\nachieved a word error rate (WER) less than 5%. However, in the past,\nresearchers have argued the non-suitability of the WER metric for the\nevaluation of ASR systems for downstream tasks such as spoken language\nunderstanding (SLU) and information retrieval. The reason is that the WER works\nat the surface level and does not include any syntactic and semantic\nknowledge.The current work proposes Semantic-WER (SWER), a metric to evaluate\nthe ASR transcripts for downstream applications in general. The SWER can be\neasily customized for any down-stream task.",
          "link": "http://arxiv.org/abs/2106.02016",
          "publishedOn": "2021-06-04T01:12:30.779Z",
          "wordCount": 553,
          "title": "Semantic-WER: A Unified Metric for the Evaluation of ASR Transcript for End Usability. (arXiv:2106.02016v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01979",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenhao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_F/0/1/0/all/0/1\">Fanchao Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1\">Xiaoyuan Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiarui Zhang</a>",
          "description": "Poetry is one of the most important art forms of human languages. Recently\nmany studies have focused on incorporating some linguistic features of poetry,\nsuch as style and sentiment, into its understanding or generation system.\nHowever, there is no focus on understanding or evaluating the semantics of\npoetry. Therefore, we propose a novel task to assess a model's semantic\nunderstanding of poetry by poem matching. Specifically, this task requires the\nmodel to select one line of Chinese classical poetry among four candidates\naccording to the modern Chinese translation of a line of poetry. To construct\nthis dataset, we first obtain a set of parallel data of Chinese classical\npoetry and modern Chinese translation. Then we retrieve similar lines of poetry\nwith the lines in a poetry corpus as negative choices. We name the dataset\nChinese Classical Poetry Matching Dataset (CCPM) and release it at\nhttps://github.com/THUNLP-AIPoet/CCPM. We hope this dataset can further enhance\nthe study on incorporating deep semantics into the understanding and generation\nsystem of Chinese classical poetry. We also preliminarily run two variants of\nBERT on this dataset as the baselines for this dataset.",
          "link": "http://arxiv.org/abs/2106.01979",
          "publishedOn": "2021-06-04T01:12:30.773Z",
          "wordCount": 612,
          "title": "CCPM: A Chinese Classical Poetry Matching Dataset. (arXiv:2106.01979v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01732",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Ziqing Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1\">Wentao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1\">Yiming Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jiani Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Che_W/0/1/0/all/0/1\">Wanxiang Che</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shijin Wang</a>",
          "description": "Multilingual pre-trained models have achieved remarkable transfer performance\nby pre-trained on rich kinds of languages. Most of the models such as mBERT are\npre-trained on unlabeled corpora. The static and contextual embeddings from the\nmodels could not be aligned very well. In this paper, we aim to improve the\nzero-shot cross-lingual transfer performance by aligning the embeddings better.\nWe propose a pre-training task named Alignment Language Model (AlignLM), which\nuses the statistical alignment information as the prior knowledge to guide\nbilingual word prediction. We evaluate our method on multilingual machine\nreading comprehension and natural language interface tasks. The results show\nAlignLM can improve the zero-shot performance significantly on MLQA and XNLI\ndatasets.",
          "link": "http://arxiv.org/abs/2106.01732",
          "publishedOn": "2021-06-04T01:12:30.767Z",
          "wordCount": 543,
          "title": "Bilingual Alignment Pre-training for Zero-shot Cross-lingual Transfer. (arXiv:2106.01732v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01804",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haiyang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_M/0/1/0/all/0/1\">Ming Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chenliang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_B/0/1/0/all/0/1\">Bin Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Songfang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_W/0/1/0/all/0/1\">Wenming Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>",
          "description": "Vision-language pre-training (VLP) on large-scale image-text pairs has\nachieved huge success for the cross-modal downstream tasks. The most existing\npre-training methods mainly adopt a two-step training procedure, which firstly\nemploys a pre-trained object detector to extract region-based visual features,\nthen concatenates the image representation and text embedding as the input of\nTransformer to train. However, these methods face problems of using\ntask-specific visual representation of the specific object detector for generic\ncross-modal understanding, and the computation inefficiency of two-stage\npipeline. In this paper, we propose the first end-to-end vision-language\npre-trained model for both V+L understanding and generation, namely E2E-VLP,\nwhere we build a unified Transformer framework to jointly learn visual\nrepresentation, and semantic alignments between image and text. We incorporate\nthe tasks of object detection and image captioning into pre-training with a\nunified Transformer encoder-decoder architecture for enhancing visual learning.\nAn extensive set of experiments have been conducted on well-established\nvision-language downstream tasks to demonstrate the effectiveness of this novel\nVLP paradigm.",
          "link": "http://arxiv.org/abs/2106.01804",
          "publishedOn": "2021-06-04T01:12:30.747Z",
          "wordCount": 612,
          "title": "E2E-VLP: End-to-End Vision-Language Pre-training Enhanced by Visual Learning. (arXiv:2106.01804v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01706",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kamran_S/0/1/0/all/0/1\">Sara Kamran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zall_R/0/1/0/all/0/1\">Raziyeh Zall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kangavari_M/0/1/0/all/0/1\">Mohammad Reza Kangavari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hosseini_S/0/1/0/all/0/1\">Saeid Hosseini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahmani_S/0/1/0/all/0/1\">Sana Rahmani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1\">Wen Hua</a>",
          "description": "The latent knowledge in the emotions and the opinions of the individuals that\nare manifested via social networks are crucial to numerous applications\nincluding social management, dynamical processes, and public security.\nAffective computing, as an interdisciplinary research field, linking artificial\nintelligence to cognitive inference, is capable to exploit emotion-oriented\nknowledge from brief contents. The textual contents convey hidden information\nsuch as personality and cognition about corresponding authors that can\ndetermine both correlations and variations between users. Emotion recognition\nfrom brief contents should embrace the contrast between authors where the\ndifferences in personality and cognition can be traced within emotional\nexpressions. To tackle this challenge, we devise a framework that, on the one\nhand, infers latent individual aspects, from brief contents and, on the other\nhand, presents a novel ensemble classifier equipped with dynamic dropout\nconvnets to extract emotions from textual context. To categorize short text\ncontents, our proposed method conjointly leverages cognitive factors and\nexploits hidden information. We utilize the outcome vectors in a novel\nembedding model to foster emotion-pertinent features that are collectively\nassembled by lexicon inductions. Experimental results show that compared to\nother competitors, our proposed model can achieve a higher performance in\nrecognizing emotion from noisy contents.",
          "link": "http://arxiv.org/abs/2106.01706",
          "publishedOn": "2021-06-04T01:12:30.741Z",
          "wordCount": 651,
          "title": "EmoDNN: Understanding emotions from short texts through a deep neural network ensemble. (arXiv:2106.01706v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01904",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bertolini_L/0/1/0/all/0/1\">Lorenzo Bertolini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weeds_J/0/1/0/all/0/1\">Julie Weeds</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weir_D/0/1/0/all/0/1\">David Weir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Q/0/1/0/all/0/1\">Qiwei Peng</a>",
          "description": "The exploitation of syntactic graphs (SyGs) as a word's context has been\nshown to be beneficial for distributional semantic models (DSMs), both at the\nlevel of individual word representations and in deriving phrasal\nrepresentations via composition. However, notwithstanding the potential\nperformance benefit, the syntactically-aware DSMs proposed to date have huge\nnumbers of parameters (compared to conventional DSMs) and suffer from data\nsparsity. Furthermore, the encoding of the SyG links (i.e., the syntactic\nrelations) has been largely limited to linear maps. The knowledge graphs'\nliterature, on the other hand, has proposed light-weight models employing\ndifferent geometric transformations (GTs) to encode edges in a knowledge graph\n(KG). Our work explores the possibility of adopting this family of models to\nencode SyGs. Furthermore, we investigate which GT better encodes syntactic\nrelations, so that these representations can be used to enhance phrase-level\ncomposition via syntactic contextualisation.",
          "link": "http://arxiv.org/abs/2106.01904",
          "publishedOn": "2021-06-04T01:12:30.735Z",
          "wordCount": 574,
          "title": "Representing Syntax and Composition with Geometric Transformations. (arXiv:2106.01904v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2011.02593",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chunting Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1\">Graham Neubig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jiatao Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diab_M/0/1/0/all/0/1\">Mona Diab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guzman_P/0/1/0/all/0/1\">Paco Guzman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghazvininejad_M/0/1/0/all/0/1\">Marjan Ghazvininejad</a>",
          "description": "Neural sequence models can generate highly fluent sentences, but recent\nstudies have also shown that they are also prone to hallucinate additional\ncontent not supported by the input. These variety of fluent but wrong outputs\nare particularly problematic, as it will not be possible for users to tell they\nare being presented incorrect content. To detect these errors, we propose a\ntask to predict whether each token in the output sequence is hallucinated (not\ncontained in the input) and collect new manually annotated evaluation sets for\nthis task. We also introduce a method for learning to detect hallucinations\nusing pretrained language models fine tuned on synthetic data that includes\nautomatically inserted hallucinations Experiments on machine translation (MT)\nand abstractive summarization demonstrate that our proposed approach\nconsistently outperforms strong baselines on all benchmark datasets. We further\ndemonstrate how to use the token-level hallucination labels to define a\nfine-grained loss over the target sequence in low-resource MT and achieve\nsignificant improvements over strong baseline methods. We also apply our method\nto word-level quality estimation for MT and show its effectiveness in both\nsupervised and unsupervised settings. Codes and data available at\nhttps://github.com/violet-zct/fairseq-detect-hallucination.",
          "link": "http://arxiv.org/abs/2011.02593",
          "publishedOn": "2021-06-04T01:12:30.729Z",
          "wordCount": 673,
          "title": "Detecting Hallucinated Content in Conditional Neural Sequence Generation. (arXiv:2011.02593v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01950",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wennberg_U/0/1/0/all/0/1\">Ulme Wennberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henter_G/0/1/0/all/0/1\">Gustav Eje Henter</a>",
          "description": "Mechanisms for encoding positional information are central for\ntransformer-based language models. In this paper, we analyze the position\nembeddings of existing language models, finding strong evidence of translation\ninvariance, both for the embeddings themselves and for their effect on\nself-attention. The degree of translation invariance increases during training\nand correlates positively with model performance. Our findings lead us to\npropose translation-invariant self-attention (TISA), which accounts for the\nrelative position between tokens in an interpretable fashion without needing\nconventional position embeddings. Our proposal has several theoretical\nadvantages over existing position-representation approaches. Experiments show\nthat it improves on regular ALBERT on GLUE tasks, while only adding orders of\nmagnitude less positional parameters.",
          "link": "http://arxiv.org/abs/2106.01950",
          "publishedOn": "2021-06-04T01:12:30.722Z",
          "wordCount": 552,
          "title": "The Case for Translation-Invariant Self-Attention in Transformer-Based Language Models. (arXiv:2106.01950v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02011",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Siyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhongliang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jinshuai Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yongfeng Huang</a>",
          "description": "Generative linguistic steganography mainly utilized language models and\napplied steganographic sampling (stegosampling) to generate high-security\nsteganographic text (stegotext). However, previous methods generally lead to\nstatistical differences between the conditional probability distributions of\nstegotext and natural text, which brings about security risks. In this paper,\nto further ensure security, we present a novel provably secure generative\nlinguistic steganographic method ADG, which recursively embeds secret\ninformation by Adaptive Dynamic Grouping of tokens according to their\nprobability given by an off-the-shelf language model. We not only prove the\nsecurity of ADG mathematically, but also conduct extensive experiments on three\npublic corpora to further verify its imperceptibility. The experimental results\nreveal that the proposed method is able to generate stegotext with nearly\nperfect security.",
          "link": "http://arxiv.org/abs/2106.02011",
          "publishedOn": "2021-06-04T01:12:30.702Z",
          "wordCount": 551,
          "title": "Provably Secure Generative Linguistic Steganography. (arXiv:2106.02011v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01972",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruochen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eickhoff_C/0/1/0/all/0/1\">Carsten Eickhoff</a>",
          "description": "In the pursuit of natural language understanding, there has been a long\nstanding interest in tracking state changes throughout narratives. Impressive\nprogress has been made in modeling the state of transaction-centric dialogues\nand procedural texts. However, this problem has been less intensively studied\nin the realm of general discourse where ground truth descriptions of states may\nbe loosely defined and state changes are less densely distributed over\nutterances. This paper proposes to turn to simplified, fully observable systems\nthat show some of these properties: Sports events. We curated 2,263 soccer\nmatches including time-stamped natural language commentary accompanied by\ndiscrete events such as a team scoring goals, switching players or being\npenalized with cards. We propose a new task formulation where, given paragraphs\nof commentary of a game at different timestamps, the system is asked to\nrecognize the occurrence of in-game events. This domain allows for rich\ndescriptions of state while avoiding the complexities of many other real-world\nsettings. As an initial point of performance measurement, we include two\nbaseline methods from the perspectives of sentence classification with temporal\ndependence and current state-of-the-art generative model, respectively, and\ndemonstrate that even sophisticated existing methods struggle on the state\ntracking task when the definition of state broadens or non-event chatter\nbecomes prevalent.",
          "link": "http://arxiv.org/abs/2106.01972",
          "publishedOn": "2021-06-04T01:12:30.696Z",
          "wordCount": 643,
          "title": "SOCCER: An Information-Sparse Discourse State Tracking Collection in the Sports Commentary Domain. (arXiv:2106.01972v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01809",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Quzhe Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Shengqi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yansong Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Dongyan Zhao</a>",
          "description": "Recent studies strive to incorporate various human rationales into neural\nnetworks to improve model performance, but few pay attention to the quality of\nthe rationales. Most existing methods distribute their models' focus to\ndistantly-labeled rationale words entirely and equally, while ignoring the\npotential important non-rationale words and not distinguishing the importance\nof different rationale words. In this paper, we propose two novel auxiliary\nloss functions to make better use of distantly-labeled rationales, which\nencourage models to maintain their focus on important words beyond labeled\nrationales (PINs) and alleviate redundant training on non-helpful rationales\n(NoIRs). Experiments on two representative classification tasks show that our\nproposed methods can push a classification model to effectively learn crucial\nclues from non-perfect rationales while maintaining the ability to spread its\nfocus to other unlabeled important words, thus significantly outperform\nexisting methods.",
          "link": "http://arxiv.org/abs/2106.01809",
          "publishedOn": "2021-06-04T01:12:30.690Z",
          "wordCount": 563,
          "title": "Exploring Distantly-Labeled Rationales in Neural Network Models. (arXiv:2106.01809v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01703",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Diwan_N/0/1/0/all/0/1\">Nirav Diwan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakravorty_T/0/1/0/all/0/1\">Tanmoy Chakravorty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafiq_Z/0/1/0/all/0/1\">Zubair Shafiq</a>",
          "description": "There are concerns that the ability of language models (LMs) to generate high\nquality synthetic text can be misused to launch spam, disinformation, or\npropaganda. Therefore, the research community is actively working on developing\napproaches to detect whether a given text is organic or synthetic. While this\nis a useful first step, it is important to be able to further fingerprint the\nauthor LM to attribute its origin. Prior work on fingerprinting LMs is limited\nto attributing synthetic text generated by a handful (usually < 10) of\npre-trained LMs. However, LMs such as GPT2 are commonly fine-tuned in a myriad\nof ways (e.g., on a domain-specific text corpus) before being used to generate\nsynthetic text. It is challenging to fingerprinting fine-tuned LMs because the\nuniverse of fine-tuned LMs is much larger in realistic scenarios. To address\nthis challenge, we study the problem of large-scale fingerprinting of\nfine-tuned LMs in the wild. Using a real-world dataset of synthetic text\ngenerated by 108 different fine-tuned LMs, we conduct comprehensive experiments\nto demonstrate the limitations of existing fingerprinting approaches. Our\nresults show that fine-tuning itself is the most effective in attributing the\nsynthetic text generated by fine-tuned LMs.",
          "link": "http://arxiv.org/abs/2106.01703",
          "publishedOn": "2021-06-04T01:12:30.684Z",
          "wordCount": 625,
          "title": "Fingerprinting Fine-tuned Language Models in the Wild. (arXiv:2106.01703v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2010.09322",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Diwan_A/0/1/0/all/0/1\">Anuj Diwan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jyothi_P/0/1/0/all/0/1\">Preethi Jyothi</a>",
          "description": "This work presents a seemingly simple but effective technique to improve\nlow-resource ASR systems for phonetic languages. By identifying sets of\nacoustically similar graphemes in these languages, we first reduce the output\nalphabet of the ASR system using linguistically meaningful reductions and then\nreconstruct the original alphabet using a standalone module. We demonstrate\nthat this lessens the burden and improves the performance of low-resource\nend-to-end ASR systems (because only reduced-alphabet predictions are needed)\nand that it is possible to design a very simple but effective reconstruction\nmodule that recovers sequences in the original alphabet from sequences in the\nreduced alphabet. We present a finite state transducer-based reconstruction\nmodule that operates on the 1-best ASR hypothesis in the reduced alphabet. We\ndemonstrate the efficacy of our proposed technique using ASR systems for two\nIndian languages, Gujarati and Telugu. With access to only 10 hrs of speech\ndata, we obtain relative WER reductions of up to 7% compared to systems that do\nnot use any reduction.",
          "link": "http://arxiv.org/abs/2010.09322",
          "publishedOn": "2021-06-04T01:12:30.676Z",
          "wordCount": 634,
          "title": "Reduce and Reconstruct: ASR for Low-Resource Phonetic Languages. (arXiv:2010.09322v2 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01760",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1\">Leyang Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jian Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Sen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>",
          "description": "There is a recent interest in investigating few-shot NER, where the\nlow-resource target domain has different label sets compared with a\nresource-rich source domain. Existing methods use a similarity-based metric.\nHowever, they cannot make full use of knowledge transfer in NER model\nparameters. To address the issue, we propose a template-based method for NER,\ntreating NER as a language model ranking problem in a sequence-to-sequence\nframework, where original sentences and statement templates filled by candidate\nnamed entity span are regarded as the source sequence and the target sequence,\nrespectively. For inference, the model is required to classify each candidate\nspan based on the corresponding template scores. Our experiments demonstrate\nthat the proposed method achieves 92.55% F1 score on the CoNLL03 (rich-resource\ntask), and significantly better than fine-tuning BERT 10.88%, 15.34%, and\n11.73% F1 score on the MIT Movie, the MIT Restaurant, and the ATIS\n(low-resource task), respectively.",
          "link": "http://arxiv.org/abs/2106.01760",
          "publishedOn": "2021-06-04T01:12:30.670Z",
          "wordCount": 571,
          "title": "Template-Based Named Entity Recognition Using BART. (arXiv:2106.01760v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01810",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Chun Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaoya Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1\">Yuxian Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xiaofei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ao_X/0/1/0/all/0/1\">Xiang Ao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianwei Zhang</a>",
          "description": "The frustratingly fragile nature of neural network models make current\nnatural language generation (NLG) systems prone to backdoor attacks and\ngenerate malicious sequences that could be sexist or offensive. Unfortunately,\nlittle effort has been invested to how backdoor attacks can affect current NLG\nmodels and how to defend against these attacks. In this work, we investigate\nthis problem on two important NLG tasks, machine translation and dialogue\ngeneration. By giving a formal definition for backdoor attack and defense, and\ndeveloping corresponding benchmarks, we design methods to attack NLG models,\nwhich achieve high attack success to ask NLG models to generate malicious\nsequences. To defend against these attacks, we propose to detect the attack\ntrigger by examining the effect of deleting or replacing certain words on the\ngeneration outputs, which we find successful for certain types of attacks. We\nwill discuss the limitation of this work, and hope this work can raise the\nawareness of backdoor risks concealed in deep NLG systems. (Code and data are\navailable at https://github.com/ShannonAI/backdoor_nlg.)",
          "link": "http://arxiv.org/abs/2106.01810",
          "publishedOn": "2021-06-04T01:12:30.651Z",
          "wordCount": 604,
          "title": "Defending against Backdoor Attacks in Natural Language Generation. (arXiv:2106.01810v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01890",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yixin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Pengfei Liu</a>",
          "description": "In this paper, we present a conceptually simple while empirically powerful\nframework for abstractive summarization, SimCLS, which can bridge the gap\nbetween the learning objective and evaluation metrics resulting from the\ncurrently dominated sequence-to-sequence learning framework by formulating text\ngeneration as a reference-free evaluation problem (i.e., quality estimation)\nassisted by contrastive learning. Experimental results show that, with minor\nmodification over existing top-scoring systems, SimCLS can improve the\nperformance of existing top-performing models by a large margin. Particularly,\n2.51 absolute improvement against BART and 2.50 over PEGASUS w.r.t ROUGE-1 on\nthe CNN/DailyMail dataset, driving the state-of-the-art performance to a new\nlevel. We have open-sourced our codes and results:\nhttps://github.com/yixinL7/SimCLS. Results of our proposed models have been\ndeployed into ExplainaBoard platform, which allows researchers to understand\nour systems in a more fine-grained way.",
          "link": "http://arxiv.org/abs/2106.01890",
          "publishedOn": "2021-06-04T01:12:30.644Z",
          "wordCount": 568,
          "title": "SimCLS: A Simple Framework for Contrastive Learning of Abstractive Summarization. (arXiv:2106.01890v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01481",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Stupinski_A/0/1/0/all/0/1\">Anne Marie Stupinski</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Alshaabi_T/0/1/0/all/0/1\">Thayer Alshaabi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Arnold_M/0/1/0/all/0/1\">Michael V. Arnold</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Adams_J/0/1/0/all/0/1\">Jane Lydia Adams</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Minot_J/0/1/0/all/0/1\">Joshua R. Minot</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Price_M/0/1/0/all/0/1\">Matthew Price</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Dodds_P/0/1/0/all/0/1\">Peter Sheridan Dodds</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Danforth_C/0/1/0/all/0/1\">Christopher M. Danforth</a>",
          "description": "Mental health challenges are thought to afflict around 10% of the global\npopulation each year, with many going untreated due to stigma and limited\naccess to services. Here, we explore trends in words and phrases related to\nmental health through a collection of 1- , 2-, and 3-grams parsed from a data\nstream of roughly 10% of all English tweets since 2012. We examine temporal\ndynamics of mental health language, finding that the popularity of the phrase\n'mental health' increased by nearly two orders of magnitude between 2012 and\n2018. We observe that mentions of 'mental health' spike annually and reliably\ndue to mental health awareness campaigns, as well as unpredictably in response\nto mass shootings, celebrities dying by suicide, and popular fictional stories\nportraying suicide. We find that the level of positivity of messages containing\n'mental health', while stable through the growth period, has declined recently.\nFinally, we use the ratio of original tweets to retweets to quantify the\nfraction of appearances of mental health language due to social amplification.\nSince 2015, mentions of mental health have become increasingly due to retweets,\nsuggesting that stigma associated with discussion of mental health on Twitter\nhas diminished with time.",
          "link": "http://arxiv.org/abs/2106.01481",
          "publishedOn": "2021-06-04T01:12:30.439Z",
          "wordCount": 657,
          "title": "Quantifying language changes surrounding mental health on Twitter. (arXiv:2106.01481v1 [physics.soc-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2105.03095",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1\">Chi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>",
          "description": "Having numerous potential applications and great impact, end-to-end speech\ntranslation (ST) has long been treated as an independent task, failing to fully\ndraw strength from the rapid advances of its sibling - text machine translation\n(MT). With text and audio inputs represented differently, the modality gap has\nrendered MT data and its end-to-end models incompatible with their ST\ncounterparts. In observation of this obstacle, we propose to bridge this\nrepresentation gap with Chimera. By projecting audio and text features to a\ncommon semantic representation, Chimera unifies MT and ST tasks and boosts the\nperformance on ST benchmarks, MuST-C and Augmented Librispeech, to a new\nstate-of-the-art. Specifically, Chimera obtains 27.1 BLEU on MuST-C EN-DE,\nimproving the SOTA by a +1.9 BLEU margin. Further experimental analyses\ndemonstrate that the shared semantic space indeed conveys common knowledge\nbetween these two tasks and thus paves a new way for augmenting training\nresources across modalities. Code, data, and resources are available at\nhttps://github.com/Glaciohound/Chimera-ST.",
          "link": "http://arxiv.org/abs/2105.03095",
          "publishedOn": "2021-06-04T01:12:30.368Z",
          "wordCount": 623,
          "title": "Learning Shared Semantic Space for Speech-to-Text Translation. (arXiv:2105.03095v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.01373",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wenxuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Muhao Chen</a>",
          "description": "Sentence-level relation extraction (RE) aims at identifying the relationship\nbetween two entities in a sentence. Many efforts have been devoted to this\nproblem, while the best performing methods are still far from perfect. In this\npaper, we revisit two problems that affect the performance of existing RE\nmodels, namely entity representation and noisy or ill-defined labels. Our\nimproved baseline model, incorporated with entity representations with typed\nmarkers, achieves an F1 of 74.6% on TACRED, significantly outperforms previous\nSOTA methods. Furthermore, the presented new baseline achieves an F1 of 91.1%\non the refined Re-TACRED dataset, demonstrating that the pre-trained language\nmodels achieve unexpectedly high performance on this task. We release our code\nto the community for future research.",
          "link": "http://arxiv.org/abs/2102.01373",
          "publishedOn": "2021-06-04T01:12:30.343Z",
          "wordCount": 581,
          "title": "An Improved Baseline for Sentence-level Relation Extraction. (arXiv:2102.01373v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01494",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shujian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_C/0/1/0/all/0/1\">Chengyue Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1\">Eunsol Choi</a>",
          "description": "We study calibration in question answering, estimating whether model\ncorrectly predicts answer for each question. Unlike prior work which mainly\nrely on the model's confidence score, our calibrator incorporates information\nabout the input example (e.g., question and the evidence context). Together\nwith data augmentation via back translation, our simple approach achieves 5-10%\ngains in calibration accuracy on reading comprehension benchmarks. Furthermore,\nwe present the first calibration study in the open retrieval setting, comparing\nthe calibration accuracy of retrieval-based span prediction models and answer\ngeneration models. Here again, our approach shows consistent gains over\ncalibrators relying on the model confidence. Our simple and efficient\ncalibrator can be easily adapted to many tasks and model architectures, showing\nrobust gains in all settings.",
          "link": "http://arxiv.org/abs/2106.01494",
          "publishedOn": "2021-06-04T01:12:30.324Z",
          "wordCount": 557,
          "title": "Knowing More About Questions Can Help: Improving Calibration in Question Answering. (arXiv:2106.01494v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01541",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jia-Chen Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_C/0/1/0/all/0/1\">Chongyang Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1\">Zhen-Hua Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Can Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1\">Xiubo Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1\">Daxin Jiang</a>",
          "description": "Recently, various neural models for multi-party conversation (MPC) have\nachieved impressive improvements on a variety of tasks such as addressee\nrecognition, speaker identification and response prediction. However, these\nexisting methods on MPC usually represent interlocutors and utterances\nindividually and ignore the inherent complicated structure in MPC which may\nprovide crucial interlocutor and utterance semantics and would enhance the\nconversation understanding process. To this end, we present MPC-BERT, a\npre-trained model for MPC understanding that considers learning who says what\nto whom in a unified model with several elaborated self-supervised tasks.\nParticularly, these tasks can be generally categorized into (1) interlocutor\nstructure modeling including reply-to utterance recognition, identical speaker\nsearching and pointer consistency distinction, and (2) utterance semantics\nmodeling including masked shared utterance restoration and shared node\ndetection. We evaluate MPC-BERT on three downstream tasks including addressee\nrecognition, speaker identification and response selection. Experimental\nresults show that MPC-BERT outperforms previous methods by large margins and\nachieves new state-of-the-art performance on all three downstream tasks at two\nbenchmarks.",
          "link": "http://arxiv.org/abs/2106.01541",
          "publishedOn": "2021-06-04T01:12:30.318Z",
          "wordCount": 603,
          "title": "MPC-BERT: A Pre-Trained Language Model for Multi-Party Conversation Understanding. (arXiv:2106.01541v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01540",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xuezhe Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_X/0/1/0/all/0/1\">Xiang Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sinong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chunting Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+May_J/0/1/0/all/0/1\">Jonathan May</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1\">Hao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>",
          "description": "The quadratic computational and memory complexities of the Transformer's\nattention mechanism have limited its scalability for modeling long sequences.\nIn this paper, we propose Luna, a linear unified nested attention mechanism\nthat approximates softmax attention with two nested linear attention functions,\nyielding only linear (as opposed to quadratic) time and space complexity.\nSpecifically, with the first attention function, Luna packs the input sequence\ninto a sequence of fixed length. Then, the packed sequence is unpacked using\nthe second attention function. As compared to a more traditional attention\nmechanism, Luna introduces an additional sequence with a fixed length as input\nand an additional corresponding output, which allows Luna to perform attention\noperation linearly, while also storing adequate contextual information. We\nperform extensive evaluations on three benchmarks of sequence modeling tasks:\nlong-context sequence modeling, neural machine translation and masked language\nmodeling for large-scale pretraining. Competitive or even better experimental\nresults demonstrate both the effectiveness and efficiency of Luna compared to a\nvariety",
          "link": "http://arxiv.org/abs/2106.01540",
          "publishedOn": "2021-06-04T01:12:30.293Z",
          "wordCount": 595,
          "title": "Luna: Linear Unified Nested Attention. (arXiv:2106.01540v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01536",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Biggiogera_J/0/1/0/all/0/1\">Jacopo Biggiogera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boateng_G/0/1/0/all/0/1\">George Boateng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hilpert_P/0/1/0/all/0/1\">Peter Hilpert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vowels_M/0/1/0/all/0/1\">Matthew Vowels</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bodenmann_G/0/1/0/all/0/1\">Guy Bodenmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neysari_M/0/1/0/all/0/1\">Mona Neysari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nussbeck_F/0/1/0/all/0/1\">Fridtjof Nussbeck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kowatsch_T/0/1/0/all/0/1\">Tobias Kowatsch</a>",
          "description": "Many processes in psychology are complex, such as dyadic interactions between\ntwo interacting partners (e.g. patient-therapist, intimate relationship\npartners). Nevertheless, many basic questions about interactions are difficult\nto investigate because dyadic processes can be within a person and between\npartners, they are based on multimodal aspects of behavior and unfold rapidly.\nCurrent analyses are mainly based on the behavioral coding method, whereby\nhuman coders annotate behavior based on a coding schema. But coding is\nlabor-intensive, expensive, slow, focuses on few modalities. Current approaches\nin psychology use LIWC for analyzing couples' interactions. However, advances\nin natural language processing such as BERT could enable the development of\nsystems to potentially automate behavioral coding, which in turn could\nsubstantially improve psychological research. In this work, we train machine\nlearning models to automatically predict positive and negative communication\nbehavioral codes of 368 German-speaking Swiss couples during an 8-minute\nconflict interaction on a fine-grained scale (10-seconds sequences) using\nlinguistic features and paralinguistic features derived with openSMILE. Our\nresults show that both simpler TF-IDF features as well as more complex BERT\nfeatures performed better than LIWC, and that adding paralinguistic features\ndid not improve the performance. These results suggest it might be time to\nconsider modern alternatives to LIWC, the de facto linguistic features in\npsychology, for prediction tasks in couples research. This work is a further\nstep towards the automated coding of couples' behavior which could enhance\ncouple research and therapy, and be utilized for other dyadic interactions as\nwell.",
          "link": "http://arxiv.org/abs/2106.01536",
          "publishedOn": "2021-06-04T01:12:30.287Z",
          "wordCount": 703,
          "title": "BERT meets LIWC: Exploring State-of-the-Art Language Models for Predicting Communication Behavior in Couples' Conflict Interactions. (arXiv:2106.01536v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01526",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Boateng_G/0/1/0/all/0/1\">George Boateng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hilpert_P/0/1/0/all/0/1\">Peter Hilpert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bodenmann_G/0/1/0/all/0/1\">Guy Bodenmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neysari_M/0/1/0/all/0/1\">Mona Neysari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kowatsch_T/0/1/0/all/0/1\">Tobias Kowatsch</a>",
          "description": "How romantic partners interact with each other during a conflict influences\nhow they feel at the end of the interaction and is predictive of whether the\npartners stay together in the long term. Hence understanding the emotions of\neach partner is important. Yet current approaches that are used include\nself-reports which are burdensome and hence limit the frequency of this data\ncollection. Automatic emotion prediction could address this challenge. Insights\nfrom psychology research indicate that partners' behaviors influence each\nother's emotions in conflict interaction and hence, the behavior of both\npartners could be considered to better predict each partner's emotion. However,\nit is yet to be investigated how doing so compares to only using each partner's\nown behavior in terms of emotion prediction performance. In this work, we used\nBERT to extract linguistic features (i.e., what partners said) and openSMILE to\nextract paralinguistic features (i.e., how they said it) from a data set of 368\nGerman-speaking Swiss couples (N = 736 individuals) which were videotaped\nduring an 8-minutes conflict interaction in the laboratory. Based on those\nfeatures, we trained machine learning models to predict if partners feel\npositive or negative after the conflict interaction. Our results show that\nincluding the behavior of the other partner improves the prediction\nperformance. Furthermore, for men, considering how their female partners spoke\nis most important and for women considering what their male partner said is\nmost important in getting better prediction performance. This work is a step\ntowards automatically recognizing each partners' emotion based on the behavior\nof both, which would enable a better understanding of couples in research,\ntherapy, and the real world.",
          "link": "http://arxiv.org/abs/2106.01526",
          "publishedOn": "2021-06-04T01:12:30.280Z",
          "wordCount": 730,
          "title": "\"You made me feel this way\": Investigating Partners' Influence in Predicting Emotions in Couples' Conflict Interactions using Speech Data. (arXiv:2106.01526v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2101.00345",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Onoe_Y/0/1/0/all/0/1\">Yasumasa Onoe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boratko_M/0/1/0/all/0/1\">Michael Boratko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCallum_A/0/1/0/all/0/1\">Andrew McCallum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durrett_G/0/1/0/all/0/1\">Greg Durrett</a>",
          "description": "Neural entity typing models typically represent fine-grained entity types as\nvectors in a high-dimensional space, but such spaces are not well-suited to\nmodeling these types' complex interdependencies. We study the ability of box\nembeddings, which embed concepts as d-dimensional hyperrectangles, to capture\nhierarchies of types even when these relationships are not defined explicitly\nin the ontology. Our model represents both types and entity mentions as boxes.\nEach mention and its context are fed into a BERT-based model to embed that\nmention in our box space; essentially, this model leverages typological clues\npresent in the surface text to hypothesize a type representation for the\nmention. Box containment can then be used to derive both the posterior\nprobability of a mention exhibiting a given type and the conditional\nprobability relations between types themselves. We compare our approach with a\nvector-based typing model and observe state-of-the-art performance on several\nentity typing benchmarks. In addition to competitive typing performance, our\nbox-based model shows better performance in prediction consistency (predicting\na supertype and a subtype together) and confidence (i.e., calibration),\ndemonstrating that the box-based model captures the latent type hierarchies\nbetter than the vector-based model does.",
          "link": "http://arxiv.org/abs/2101.00345",
          "publishedOn": "2021-06-04T01:12:30.254Z",
          "wordCount": 654,
          "title": "Modeling Fine-Grained Entity Types with Box Embeddings. (arXiv:2101.00345v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.09469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1\">Junqiu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yinpeng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xin Jiang</a>",
          "description": "The pre-trained language models have achieved great successes in various\nnatural language understanding (NLU) tasks due to its capacity to capture the\ndeep contextualized information in text by pre-training on large-scale corpora.\nOne of the fundamental components in pre-trained language models is the\nvocabulary, especially for training multilingual models on many different\nlanguages. In the technical report, we present our practices on training\nmultilingual pre-trained language models with BBPE: Byte-Level BPE (i.e., Byte\nPair Encoding). In the experiment, we adopted the architecture of NEZHA as the\nunderlying pre-trained language model and the results show that NEZHA trained\nwith byte-level subwords consistently outperforms Google multilingual BERT and\nvanilla NEZHA by a notable margin in several multilingual NLU tasks. We release\nthe source code of our byte-level vocabulary building tools and the\nmultilingual pre-trained language models.",
          "link": "http://arxiv.org/abs/2101.09469",
          "publishedOn": "2021-06-04T01:12:30.225Z",
          "wordCount": 588,
          "title": "Training Multilingual Pre-trained Language Model with Byte-level Subwords. (arXiv:2101.09469v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01518",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiacheng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durrett_G/0/1/0/all/0/1\">Greg Durrett</a>",
          "description": "Despite the prominence of neural abstractive summarization models, we know\nlittle about how they actually form summaries and how to understand where their\ndecisions come from. We propose a two-step method to interpret summarization\nmodel decisions. We first analyze the model's behavior by ablating the full\nmodel to categorize each decoder decision into one of several generation modes:\nroughly, is the model behaving like a language model, is it relying heavily on\nthe input, or is it somewhere in between? After isolating decisions that do\ndepend on the input, we explore interpreting these decisions using several\ndifferent attribution methods. We compare these techniques based on their\nability to select content and reconstruct the model's predicted token from\nperturbations of the input, thus revealing whether highlighted attributions are\ntruly important for the generation of the next token. While this machinery can\nbe broadly useful even beyond summarization, we specifically demonstrate its\ncapability to identify phrases the summarization model has memorized and\ndetermine where in the training pipeline this memorization happened, as well as\nstudy complex generation phenomena like sentence fusion on a per-instance\nbasis.",
          "link": "http://arxiv.org/abs/2106.01518",
          "publishedOn": "2021-06-04T01:12:30.157Z",
          "wordCount": 615,
          "title": "Dissecting Generation Modes for Abstractive Summarization Models via Ablation and Attribution. (arXiv:2106.01518v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01478",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Koto_F/0/1/0/all/0/1\">Fajri Koto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lau_J/0/1/0/all/0/1\">Jey Han Lau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baldwin_T/0/1/0/all/0/1\">Timothy Baldwin</a>",
          "description": "While automatic summarization evaluation methods developed for English are\nroutinely applied to other languages, this is the first attempt to\nsystematically quantify their panlinguistic efficacy. We take a summarization\ncorpus for eight different languages, and manually annotate generated summaries\nfor focus (precision) and coverage (recall). Based on this, we evaluate 19\nsummarization evaluation metrics, and find that using multilingual BERT within\nBERTScore performs well across all languages, at a level above that for\nEnglish.",
          "link": "http://arxiv.org/abs/2106.01478",
          "publishedOn": "2021-06-04T01:12:30.126Z",
          "wordCount": 503,
          "title": "Evaluating the Efficacy of Summarization Evaluation across Languages. (arXiv:2106.01478v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01444",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feinglass_J/0/1/0/all/0/1\">Joshua Feinglass</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yezhou Yang</a>",
          "description": "The open-ended nature of visual captioning makes it a challenging area for\nevaluation. The majority of proposed models rely on specialized training to\nimprove human-correlation, resulting in limited adoption, generalizability, and\nexplainabilty. We introduce \"typicality\", a new formulation of evaluation\nrooted in information theory, which is uniquely suited for problems lacking a\ndefinite ground truth. Typicality serves as our framework to develop a novel\nsemantic comparison, SPARCS, as well as referenceless fluency evaluation\nmetrics. Over the course of our analysis, two separate dimensions of fluency\nnaturally emerge: style, captured by metric SPURTS, and grammar, captured in\nthe form of grammatical outlier penalties. Through extensive experiments and\nablation studies on benchmark datasets, we show how these decomposed dimensions\nof semantics and fluency provide greater system-level insight into captioner\ndifferences. Our proposed metrics along with their combination, SMURF, achieve\nstate-of-the-art correlation with human judgment when compared with other\nrule-based evaluation metrics.",
          "link": "http://arxiv.org/abs/2106.01444",
          "publishedOn": "2021-06-04T01:12:30.120Z",
          "wordCount": 587,
          "title": "SMURF: SeMantic and linguistic UndeRstanding Fusion for Caption Evaluation via Typicality Analysis. (arXiv:2106.01444v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01451",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Martinez_R/0/1/0/all/0/1\">Richard Diehl Martinez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Novotney_S/0/1/0/all/0/1\">Scott Novotney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bulyko_I/0/1/0/all/0/1\">Ivan Bulyko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rastrow_A/0/1/0/all/0/1\">Ariya Rastrow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stolcke_A/0/1/0/all/0/1\">Andreas Stolcke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gandhe_A/0/1/0/all/0/1\">Ankur Gandhe</a>",
          "description": "Language modeling (LM) for automatic speech recognition (ASR) does not\nusually incorporate utterance level contextual information. For some domains\nlike voice assistants, however, additional context, such as the time at which\nan utterance was spoken, provides a rich input signal. We introduce an\nattention mechanism for training neural speech recognition language models on\nboth text and non-linguistic contextual data. When applied to a large\nde-identified dataset of utterances collected by a popular voice assistant\nplatform, our method reduces perplexity by 7.0% relative over a standard LM\nthat does not incorporate contextual information. When evaluated on utterances\nextracted from the long tail of the dataset, our method improves perplexity by\n9.0% relative over a standard LM and by over 2.8% relative when compared to a\nstate-of-the-art model for contextual LM.",
          "link": "http://arxiv.org/abs/2106.01451",
          "publishedOn": "2021-06-04T01:12:30.097Z",
          "wordCount": 564,
          "title": "Attention-based Contextual Language Model Adaptation for Speech Recognition. (arXiv:2106.01451v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01424",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cagrandi_M/0/1/0/all/0/1\">Marco Cagrandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cornia_M/0/1/0/all/0/1\">Marcella Cornia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stefanini_M/0/1/0/all/0/1\">Matteo Stefanini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baraldi_L/0/1/0/all/0/1\">Lorenzo Baraldi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cucchiara_R/0/1/0/all/0/1\">Rita Cucchiara</a>",
          "description": "Image captioning models have lately shown impressive results when applied to\nstandard datasets. Switching to real-life scenarios, however, constitutes a\nchallenge due to the larger variety of visual concepts which are not covered in\nexisting training sets. For this reason, novel object captioning (NOC) has\nrecently emerged as a paradigm to test captioning models on objects which are\nunseen during the training phase. In this paper, we present a novel approach\nfor NOC that learns to select the most relevant objects of an image, regardless\nof their adherence to the training set, and to constrain the generative process\nof a language model accordingly. Our architecture is fully-attentive and\nend-to-end trainable, also when incorporating constraints. We perform\nexperiments on the held-out COCO dataset, where we demonstrate improvements\nover the state of the art, both in terms of adaptability to novel objects and\ncaption quality.",
          "link": "http://arxiv.org/abs/2106.01424",
          "publishedOn": "2021-06-04T01:12:30.088Z",
          "wordCount": 591,
          "title": "Learning to Select: A Fully Attentive Approach for Novel Object Captioning. (arXiv:2106.01424v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01465",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jieyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khashabi_D/0/1/0/all/0/1\">Daniel Khashabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khot_T/0/1/0/all/0/1\">Tushar Khot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabharwal_A/0/1/0/all/0/1\">Ashish Sabharwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>",
          "description": "Is it possible to use natural language to intervene in a model's behavior and\nalter its prediction in a desired way? We investigate the effectiveness of\nnatural language interventions for reading-comprehension systems, studying this\nin the context of social stereotypes. Specifically, we propose a new language\nunderstanding task, Linguistic Ethical Interventions (LEI), where the goal is\nto amend a question-answering (QA) model's unethical behavior by communicating\ncontext-specific principles of ethics and equity to it. To this end, we build\nupon recent methods for quantifying a system's social stereotypes, augmenting\nthem with different kinds of ethical interventions and the desired model\nbehavior under such interventions. Our zero-shot evaluation finds that even\ntoday's powerful neural language models are extremely poor ethical-advice\ntakers, that is, they respond surprisingly little to ethical interventions even\nthough these interventions are stated as simple sentences. Few-shot learning\nimproves model behavior but remains far from the desired outcome, especially\nwhen evaluated for various types of generalization. Our new task thus poses a\nnovel language understanding challenge for the community.",
          "link": "http://arxiv.org/abs/2106.01465",
          "publishedOn": "2021-06-04T01:12:30.075Z",
          "wordCount": 616,
          "title": "Ethical-Advice Taker: Do Language Models Understand Natural Language Interventions?. (arXiv:2106.01465v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01463",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1\">Hang Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pino_J/0/1/0/all/0/1\">Juan Pino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Changhan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jiatao Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwab_D/0/1/0/all/0/1\">Didier Schwab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Besacier_L/0/1/0/all/0/1\">Laurent Besacier</a>",
          "description": "Adapter modules were recently introduced as an efficient alternative to\nfine-tuning in NLP. Adapter tuning consists in freezing pretrained parameters\nof a model and injecting lightweight modules between layers, resulting in the\naddition of only a small number of task-specific trainable parameters. While\nadapter tuning was investigated for multilingual neural machine translation,\nthis paper proposes a comprehensive analysis of adapters for multilingual\nspeech translation (ST). Starting from different pre-trained models (a\nmultilingual ST trained on parallel data or a multilingual BART (mBART) trained\non non-parallel multilingual data), we show that adapters can be used to: (a)\nefficiently specialize ST to specific language pairs with a low extra cost in\nterms of parameters, and (b) transfer from an automatic speech recognition\n(ASR) task and an mBART pre-trained model to a multilingual ST task.\nExperiments show that adapter tuning offer competitive results to full\nfine-tuning, while being much more parameter-efficient.",
          "link": "http://arxiv.org/abs/2106.01463",
          "publishedOn": "2021-06-04T01:12:30.030Z",
          "wordCount": 580,
          "title": "Lightweight Adapter Tuning for Multilingual Speech Translation. (arXiv:2106.01463v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01415",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wen-Chin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kobayashi_K/0/1/0/all/0/1\">Kazuhiro Kobayashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1\">Yu-Huai Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Ching-Feng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsao_Y/0/1/0/all/0/1\">Yu Tsao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hsin-Min Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toda_T/0/1/0/all/0/1\">Tomoki Toda</a>",
          "description": "We propose a new paradigm for maintaining speaker identity in dysarthric\nvoice conversion (DVC). The poor quality of dysarthric speech can be greatly\nimproved by statistical VC, but as the normal speech utterances of a dysarthria\npatient are nearly impossible to collect, previous work failed to recover the\nindividuality of the patient. In light of this, we suggest a novel, two-stage\napproach for DVC, which is highly flexible in that no normal speech of the\npatient is required. First, a powerful parallel sequence-to-sequence model\nconverts the input dysarthric speech into a normal speech of a reference\nspeaker as an intermediate product, and a nonparallel, frame-wise VC model\nrealized with a variational autoencoder then converts the speaker identity of\nthe reference speech back to that of the patient while assumed to be capable of\npreserving the enhanced quality. We investigate several design options.\nExperimental evaluation results demonstrate the potential of our approach to\nimproving the quality of the dysarthric speech while maintaining the speaker\nidentity.",
          "link": "http://arxiv.org/abs/2106.01415",
          "publishedOn": "2021-06-04T01:12:29.976Z",
          "wordCount": 628,
          "title": "A Preliminary Study of a Two-Stage Paradigm for Preserving Speaker Identity in Dysarthric Voice Conversion. (arXiv:2106.01415v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01635",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kovatchev_V/0/1/0/all/0/1\">Venelin Kovatchev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_P/0/1/0/all/0/1\">Phillip Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1\">Mark Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Devine_R/0/1/0/all/0/1\">Rory Devine</a>",
          "description": "In this paper we implement and compare 7 different data augmentation\nstrategies for the task of automatic scoring of children's ability to\nunderstand others' thoughts, feelings, and desires (or \"mindreading\").\n\nWe recruit in-domain experts to re-annotate augmented samples and determine\nto what extent each strategy preserves the original rating. We also carry out\nmultiple experiments to measure how much each augmentation strategy improves\nthe performance of automatic scoring systems. To determine the capabilities of\nautomatic systems to generalize to unseen data, we create UK-MIND-20 - a new\ncorpus of children's performance on tests of mindreading, consisting of 10,320\nquestion-answer pairs.\n\nWe obtain a new state-of-the-art performance on the MIND-CA corpus, improving\nmacro-F1-score by 6 points. Results indicate that both the number of training\nexamples and the quality of the augmentation strategies affect the performance\nof the systems. The task-specific augmentations generally outperform\ntask-agnostic augmentations. Automatic augmentations based on vectors (GloVe,\nFastText) perform the worst.\n\nWe find that systems trained on MIND-CA generalize well to UK-MIND-20. We\ndemonstrate that data augmentation strategies also improve the performance on\nunseen data.",
          "link": "http://arxiv.org/abs/2106.01635",
          "publishedOn": "2021-06-04T01:12:29.939Z",
          "wordCount": 638,
          "title": "Can vectors read minds better than experts? Comparing data augmentation strategies for the automated scoring of children's mindreading ability. (arXiv:2106.01635v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01797",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qin_P/0/1/0/all/0/1\">Pengda Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuhong Li</a>",
          "description": "Among ubiquitous multimodal data in the real world, text is the modality\ngenerated by human, while image reflects the physical world honestly. In a\nvisual understanding application, machines are expected to understand images\nlike human. Inspired by this, we propose a novel self-supervised learning\nmethod, named Text-enhanced Visual Deep InfoMax (TVDIM), to learn better visual\nrepresentations by fully utilizing the naturally-existing multimodal data. Our\ncore idea of self-supervised learning is to maximize the mutual information\nbetween features extracted from multiple views of a shared context to a\nrational degree. Different from previous methods which only consider multiple\nviews from a single modality, our work produces multiple views from different\nmodalities, and jointly optimizes the mutual information for features pairs of\nintra-modality and inter-modality. Considering the information gap between\ninter-modality features pairs from data noise, we adopt a \\emph{ranking-based}\ncontrastive learning to optimize the mutual information. During evaluation, we\ndirectly use the pre-trained visual representations to complete various image\nclassification tasks. Experimental results show that, TVDIM significantly\noutperforms previous visual self-supervised methods when processing the same\nset of images.",
          "link": "http://arxiv.org/abs/2106.01797",
          "publishedOn": "2021-06-04T01:12:29.933Z",
          "wordCount": 601,
          "title": "TVDIM: Enhancing Image Self-Supervised Pretraining via Noisy Text Data. (arXiv:2106.01797v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02017",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mozhi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deb_B/0/1/0/all/0/1\">Budhaditya Deb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1\">Guoqing Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shokouhi_M/0/1/0/all/0/1\">Milad Shokouhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1\">Ahmed Hassan Awadallah</a>",
          "description": "Reply suggestion models help users process emails and chats faster. Previous\nwork only studies English reply suggestion. Instead, we present MRS, a\nmultilingual reply suggestion dataset with ten languages. MRS can be used to\ncompare two families of models: 1) retrieval models that select the reply from\na fixed set and 2) generation models that produce the reply from scratch.\nTherefore, MRS complements existing cross-lingual generalization benchmarks\nthat focus on classification and sequence labeling tasks. We build a generation\nmodel and a retrieval model as baselines for MRS. The two models have different\nstrengths in the monolingual setting, and they require different strategies to\ngeneralize across languages. MRS is publicly available at\nhttps://github.com/zhangmozhi/mrs.",
          "link": "http://arxiv.org/abs/2106.02017",
          "publishedOn": "2021-06-04T01:12:29.927Z",
          "wordCount": 553,
          "title": "A Dataset and Baselines for Multilingual Reply Suggestion. (arXiv:2106.02017v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01561",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Cunxiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Pai Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>",
          "description": "Recent work has investigated the interesting question using pre-trained\nlanguage models (PLMs) as knowledge bases for answering open questions.\nHowever, existing work is limited in using small benchmarks with high\ntest-train overlaps. We construct a new dataset of closed-book QA using SQuAD,\nand investigate the performance of BART. Experiments show that it is\nchallenging for BART to remember training facts in high precision, and also\nchallenging to answer closed-book questions even if relevant knowledge is\nretained. Some promising directions are found, including decoupling the\nknowledge memorizing process and the QA finetune process, forcing the model to\nrecall relevant knowledge when question answering.",
          "link": "http://arxiv.org/abs/2106.01561",
          "publishedOn": "2021-06-04T01:12:29.914Z",
          "wordCount": 538,
          "title": "Can Generative Pre-trained Language Models Serve as Knowledge Bases for Closed-book QA?. (arXiv:2106.01561v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2011.14062",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sung_M/0/1/0/all/0/1\">Man-Ling Sung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_T/0/1/0/all/0/1\">Tan Lee</a>",
          "description": "Spoken term discovery from untranscribed speech audio could be achieved via a\ntwo-stage process. In the first stage, the unlabelled speech is decoded into a\nsequence of subword units that are learned and modelled in an unsupervised\nmanner. In the second stage, partial sequence matching and clustering are\nperformed on the decoded subword sequences, resulting in a set of discovered\nwords or phrases. A limitation of this approach is that the results of subword\ndecoding could be erroneous, and the errors would impact the subsequent steps.\nWhile Siamese/Triplet network is one approach to learn segment representations\nthat can improve the discovery process, the challenge in spoken term discovery\nunder a complete unsupervised scenario is that training examples are\nunavailable. In this paper, we propose to generate training examples from\ninitial hypothesized sequence clusters. The Siamese/Triplet network is trained\non the hypothesized examples to measure the similarity between two speech\nsegments and hereby perform re-clustering of all hypothesized subword sequences\nto achieve spoken term discovery. Experimental results show that the proposed\napproach is effective in obtaining training examples for Siamese and Triplet\nnetworks, improving the efficacy of spoken term discovery as compared with the\noriginal two-stage method.",
          "link": "http://arxiv.org/abs/2011.14062",
          "publishedOn": "2021-06-04T01:12:29.897Z",
          "wordCount": 664,
          "title": "Unsupervised Spoken Term Discovery Based on Re-clustering of Hypothesized Speech Segments with Siamese and Triplet Networks. (arXiv:2011.14062v2 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01735",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tasar_D/0/1/0/all/0/1\">D. Emre Ta&#x15f;ar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozan_S/0/1/0/all/0/1\">&#x15e;&#xfc;kr&#xfc; Ozan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozdil_U/0/1/0/all/0/1\">Umut &#xd6;zdil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akca_M/0/1/0/all/0/1\">M. Fatih Akca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olmez_O/0/1/0/all/0/1\">O&#x11f;uzhan &#xd6;lmez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gulum_S/0/1/0/all/0/1\">Semih G&#xfc;l&#xfc;m</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kutal_S/0/1/0/all/0/1\">Se&#xe7;ilay Kutal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belhan_C/0/1/0/all/0/1\">Ceren Belhan</a>",
          "description": "The problem of categorizing short speech sentences according to their\nsemantic features with high accuracy is a subject studied in natural language\nprocessing. In this study, a data set created with samples classified in 46\ndifferent categories was used. Examples consist of sentences taken from chat\nconversations between a company's customer representatives and the company's\nwebsite visitors. The primary purpose is to automatically tag questions and\nrequests from visitors in the most accurate way for 46 predetermined categories\nfor use in a chat application to generate meaningful answers to the questions\nasked by the website visitors. For this, different BERT models and one GPT-2\nmodel, pre-trained in Turkish, were preferred. The classification performances\nof the relevant models were analyzed in detail and reported accordingly.",
          "link": "http://arxiv.org/abs/2106.01735",
          "publishedOn": "2021-06-04T01:12:29.885Z",
          "wordCount": 569,
          "title": "Auto-tagging of Short Conversational Sentences using Transformer Methods. (arXiv:2106.01735v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2104.08453",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Lei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Veeramachaneni_K/0/1/0/all/0/1\">Kalyan Veeramachaneni</a>",
          "description": "Most adversarial attack methods on text classification can change the\nclassifier's prediction by synonym substitution. We propose the adversarial\nsentence rewriting sampler (ASRS), which rewrites the whole sentence to\ngenerate more similar and higher-quality adversarial examples. Our method\nachieves a better attack success rate on 4 out of 7 datasets, as well as\nsignificantly better sentence quality on all 7 datasets. ASRS is an\nindispensable supplement to the existing attack methods, because classifiers\ncannot resist the attack from ASRS unless they are trained on adversarial\nexamples found by ASRS.",
          "link": "http://arxiv.org/abs/2104.08453",
          "publishedOn": "2021-06-04T01:12:29.860Z",
          "wordCount": 536,
          "title": "Attacking Text Classifiers via Sentence Rewriting Sampler. (arXiv:2104.08453v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01933",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Gaddy_D/0/1/0/all/0/1\">David Gaddy</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Klein_D/0/1/0/all/0/1\">Dan Klein</a>",
          "description": "In this paper, we present an improved model for voicing silent speech, where\naudio is synthesized from facial electromyography (EMG) signals. To give our\nmodel greater flexibility to learn its own input features, we directly use EMG\nsignals as input in the place of hand-designed features used by prior work. Our\nmodel uses convolutional layers to extract features from the signals and\nTransformer layers to propagate information across longer distances. To provide\nbetter signal for learning, we also introduce an auxiliary task of predicting\nphoneme labels in addition to predicting speech audio features. On an open\nvocabulary intelligibility evaluation, our model improves the state of the art\nfor this task by an absolute 25.8%.",
          "link": "http://arxiv.org/abs/2106.01933",
          "publishedOn": "2021-06-04T01:12:29.832Z",
          "wordCount": 555,
          "title": "An Improved Model for Voicing Silent Speech. (arXiv:2106.01933v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01452",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Keller_Y/0/1/0/all/0/1\">Yannik Keller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mackensen_J/0/1/0/all/0/1\">Jan Mackensen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eger_S/0/1/0/all/0/1\">Steffen Eger</a>",
          "description": "Adversarial attacks expose important blind spots of deep learning systems.\nWhile word- and sentence-level attack scenarios mostly deal with finding\nsemantic paraphrases of the input that fool NLP models, character-level attacks\ntypically insert typos into the input stream. It is commonly thought that these\nare easier to defend via spelling correction modules. In this work, we show\nthat both a standard spellchecker and the approach of Pruthi et al. (2019),\nwhich trains to defend against insertions, deletions and swaps, perform poorly\non the character-level benchmark recently proposed in Eger and Benz (2020)\nwhich includes more challenging attacks such as visual and phonetic\nperturbations and missing word segmentations. In contrast, we show that an\nuntrained iterative approach which combines context-independent character-level\ninformation with context-dependent information from BERT's masked language\nmodeling can perform on par with human crowd-workers from Amazon Mechanical\nTurk (AMT) supervised via 3-shot learning.",
          "link": "http://arxiv.org/abs/2106.01452",
          "publishedOn": "2021-06-04T01:12:29.826Z",
          "wordCount": 590,
          "title": "BERT-Defense: A Probabilistic Model Based on BERT to Combat Cognitively Inspired Orthographic Adversarial Attacks. (arXiv:2106.01452v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01560",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Viswanathan_V/0/1/0/all/0/1\">Vijay Viswanathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1\">Graham Neubig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Pengfei Liu</a>",
          "description": "Automatically extracting key information from scientific documents has the\npotential to help scientists work more efficiently and accelerate the pace of\nscientific progress. Prior work has considered extracting document-level entity\nclusters and relations end-to-end from raw scientific text, which can improve\nliterature search and help identify methods and materials for a given problem.\nDespite the importance of this task, most existing works on scientific\ninformation extraction (SciIE) consider extraction solely based on the content\nof an individual paper, without considering the paper's place in the broader\nliterature. In contrast to prior work, we augment our text representations by\nleveraging a complementary source of document context: the citation graph of\nreferential links between citing and cited papers. On a test set of\nEnglish-language scientific documents, we show that simple ways of utilizing\nthe structure and content of the citation graph can each lead to significant\ngains in different scientific information extraction tasks. When these tasks\nare combined, we observe a sizable improvement in end-to-end information\nextraction over the state-of-the-art, suggesting the potential for future work\nalong this direction. We release software tools to facilitate citation-aware\nSciIE development.",
          "link": "http://arxiv.org/abs/2106.01560",
          "publishedOn": "2021-06-04T01:12:29.748Z",
          "wordCount": 624,
          "title": "CitationIE: Leveraging the Citation Graph for Scientific Information Extraction. (arXiv:2106.01560v1 [cs.DL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01581",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wilber_M/0/1/0/all/0/1\">Matt Wilber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Timkey_W/0/1/0/all/0/1\">William Timkey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schijndel_M/0/1/0/all/0/1\">Marten Van Schijndel</a>",
          "description": "Abstractive neural summarization models have seen great improvements in\nrecent years, as shown by ROUGE scores of the generated summaries. But despite\nthese improved metrics, there is limited understanding of the strategies\ndifferent models employ, and how those strategies relate their understanding of\nlanguage. To understand this better, we run several experiments to characterize\nhow one popular abstractive model, the pointer-generator model of See et al.\n(2017), uses its explicit copy/generation switch to control its level of\nabstraction (generation) vs extraction (copying). On an extractive-biased\ndataset, the model utilizes syntactic boundaries to truncate sentences that are\notherwise often copied verbatim. When we modify the copy/generation switch and\nforce the model to generate, only simple paraphrasing abilities are revealed\nalongside factual inaccuracies and hallucinations. On an abstractive-biased\ndataset, the model copies infrequently but shows similarly limited abstractive\nabilities. In line with previous research, these results suggest that\nabstractive summarization models lack the semantic understanding necessary to\ngenerate paraphrases that are both abstractive and faithful to the source\ndocument.",
          "link": "http://arxiv.org/abs/2106.01581",
          "publishedOn": "2021-06-04T01:12:29.731Z",
          "wordCount": 604,
          "title": "To Point or Not to Point: Understanding How Abstractive Summarizers Paraphrase Text. (arXiv:2106.01581v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01702",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhenru Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Chujie Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Siyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>",
          "description": "Great research interests have been attracted to devise AI services that are\nable to provide mental health support. However, the lack of corpora is a main\nobstacle to this research, particularly in Chinese language. In this paper, we\npropose PsyQA, a Chinese dataset of psychological health support in the form of\nquestion and answer pair. PsyQA is crawled from a Chinese mental health service\nplatform, and contains 22K questions and 56K long and well-structured answers.\nBased on the psychological counseling theories, we annotate a portion of answer\ntexts with typical strategies for providing support, and further present\nin-depth analysis of both lexical features and strategy patterns in the\ncounseling answers. We also evaluate the performance of generating counseling\nanswers with the generative pretrained models. Results show that utilizing\nstrategies enhances the fluency and helpfulness of generated answers, but there\nis still a large space for future research.",
          "link": "http://arxiv.org/abs/2106.01702",
          "publishedOn": "2021-06-04T01:12:29.725Z",
          "wordCount": 594,
          "title": "PsyQA: A Chinese Dataset for Generating Long Counseling Text for Mental Health Support. (arXiv:2106.01702v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2101.00178",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1\">Hao Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yelong Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaodong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1\">Pengcheng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weizhu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>",
          "description": "To date, most of recent work under the retrieval-reader framework for\nopen-domain QA focuses on either extractive or generative reader exclusively.\nIn this paper, we study a hybrid approach for leveraging the strengths of both\nmodels. We apply novel techniques to enhance both extractive and generative\nreaders built upon recent pretrained neural language models, and find that\nproper training methods can provide large improvement over previous\nstate-of-the-art models. We demonstrate that a simple hybrid approach by\ncombining answers from both readers can efficiently take advantages of\nextractive and generative answer inference strategies and outperforms single\nmodels as well as homogeneous ensembles. Our approach outperforms previous\nstate-of-the-art models by 3.3 and 2.7 points in exact match on\nNaturalQuestions and TriviaQA respectively.",
          "link": "http://arxiv.org/abs/2101.00178",
          "publishedOn": "2021-06-04T01:12:29.427Z",
          "wordCount": 591,
          "title": "UnitedQA: A Hybrid Approach for Open Domain Question Answering. (arXiv:2101.00178v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01491",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Herlihy_C/0/1/0/all/0/1\">Christine Herlihy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudinger_R/0/1/0/all/0/1\">Rachel Rudinger</a>",
          "description": "Crowdworker-constructed natural language inference (NLI) datasets have been\nfound to contain statistical artifacts associated with the annotation process\nthat allow hypothesis-only classifiers to achieve better-than-random\nperformance (Poliak et al., 2018; Gururanganet et al., 2018; Tsuchiya, 2018).\nWe investigate whether MedNLI, a physician-annotated dataset with premises\nextracted from clinical notes, contains such artifacts (Romanov and Shivade,\n2018). We find that entailed hypotheses contain generic versions of specific\nconcepts in the premise, as well as modifiers related to responsiveness,\nduration, and probability. Neutral hypotheses feature conditions and behaviors\nthat co-occur with, or cause, the condition(s) in the premise. Contradiction\nhypotheses feature explicit negation of the premise and implicit negation via\nassertion of good health. Adversarial filtering demonstrates that performance\ndegrades when evaluated on the difficult subset. We provide partition\ninformation and recommendations for alternative dataset construction strategies\nfor knowledge-intensive domains.",
          "link": "http://arxiv.org/abs/2106.01491",
          "publishedOn": "2021-06-04T01:12:29.393Z",
          "wordCount": 574,
          "title": "MedNLI Is Not Immune: Natural Language Inference Artifacts in the Clinical Domain. (arXiv:2106.01491v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.03482",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fernandes_P/0/1/0/all/0/1\">Patrick Fernandes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_K/0/1/0/all/0/1\">Kayo Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1\">Graham Neubig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martins_A/0/1/0/all/0/1\">Andr&#xe9; F. T. Martins</a>",
          "description": "Recent work in neural machine translation has demonstrated both the necessity\nand feasibility of using inter-sentential context -- context from sentences\nother than those currently being translated. However, while many current\nmethods present model architectures that theoretically can use this extra\ncontext, it is often not clear how much they do actually utilize it at\ntranslation time. In this paper, we introduce a new metric, conditional\ncross-mutual information, to quantify the usage of context by these models.\nUsing this metric, we measure how much document-level machine translation\nsystems use particular varieties of context. We find that target context is\nreferenced more than source context, and that conditioning on a longer context\nhas a diminishing effect on results. We then introduce a new, simple training\nmethod, context-aware word dropout, to increase the usage of context by\ncontext-aware models. Experiments show that our method increases context usage\nand that this reflects on the translation quality according to metrics such as\nBLEU and COMET, as well as performance on anaphoric pronoun resolution and\nlexical cohesion contrastive datasets.",
          "link": "http://arxiv.org/abs/2105.03482",
          "publishedOn": "2021-06-03T02:10:37.639Z",
          "wordCount": 637,
          "title": "Measuring and Increasing Context Usage in Context-Aware Machine Translation. (arXiv:2105.03482v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.15071",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ko_W/0/1/0/all/0/1\">Wei-Jen Ko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+El_Kishky_A/0/1/0/all/0/1\">Ahmed El-Kishky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Renduchintala_A/0/1/0/all/0/1\">Adithya Renduchintala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhary_V/0/1/0/all/0/1\">Vishrav Chaudhary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_N/0/1/0/all/0/1\">Naman Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guzman_F/0/1/0/all/0/1\">Francisco Guzm&#xe1;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1\">Pascale Fung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koehn_P/0/1/0/all/0/1\">Philipp Koehn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diab_M/0/1/0/all/0/1\">Mona Diab</a>",
          "description": "The scarcity of parallel data is a major obstacle for training high-quality\nmachine translation systems for low-resource languages. Fortunately, some\nlow-resource languages are linguistically related or similar to high-resource\nlanguages; these related languages may share many lexical or syntactic\nstructures. In this work, we exploit this linguistic overlap to facilitate\ntranslating to and from a low-resource language with only monolingual data, in\naddition to any parallel data in the related high-resource language. Our\nmethod, NMT-Adapt, combines denoising autoencoding, back-translation and\nadversarial objectives to utilize monolingual data for low-resource adaptation.\nWe experiment on 7 languages from three different language families and show\nthat our technique significantly improves translation into low-resource\nlanguage compared to other translation baselines.",
          "link": "http://arxiv.org/abs/2105.15071",
          "publishedOn": "2021-06-03T02:10:37.585Z",
          "wordCount": 579,
          "title": "Adapting High-resource NMT Models to Translate Low-resource Related Languages without Parallel Data. (arXiv:2105.15071v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.12624",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jinhyuk Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sung_M/0/1/0/all/0/1\">Mujeen Sung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1\">Jaewoo Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Danqi Chen</a>",
          "description": "Open-domain question answering can be reformulated as a phrase retrieval\nproblem, without the need for processing documents on-demand during inference\n(Seo et al., 2019). However, current phrase retrieval models heavily depend on\nsparse representations and still underperform retriever-reader approaches. In\nthis work, we show for the first time that we can learn dense representations\nof phrases alone that achieve much stronger performance in open-domain QA. We\npresent an effective method to learn phrase representations from the\nsupervision of reading comprehension tasks, coupled with novel negative\nsampling methods. We also propose a query-side fine-tuning strategy, which can\nsupport transfer learning and reduce the discrepancy between training and\ninference. On five popular open-domain QA datasets, our model DensePhrases\nimproves over previous phrase retrieval models by 15%-25% absolute accuracy and\nmatches the performance of state-of-the-art retriever-reader models. Our model\nis easy to parallelize due to pure dense representations and processes more\nthan 10 questions per second on CPUs. Finally, we directly use our pre-indexed\ndense phrase representations for two slot filling tasks, showing the promise of\nutilizing DensePhrases as a dense knowledge base for downstream tasks.",
          "link": "http://arxiv.org/abs/2012.12624",
          "publishedOn": "2021-06-03T02:10:37.570Z",
          "wordCount": 653,
          "title": "Learning Dense Representations of Phrases at Scale. (arXiv:2012.12624v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.15859",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goldfarb_Tarrant_S/0/1/0/all/0/1\">Seraphina Goldfarb-Tarrant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marchant_R/0/1/0/all/0/1\">Rebecca Marchant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanchez_R/0/1/0/all/0/1\">Ricardo Mu&#xf1;oz Sanchez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pandya_M/0/1/0/all/0/1\">Mugdha Pandya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lopez_A/0/1/0/all/0/1\">Adam Lopez</a>",
          "description": "Natural Language Processing (NLP) systems learn harmful societal biases that\ncause them to amplify inequality as they are deployed in more and more\nsituations. To guide efforts at debiasing these systems, the NLP community\nrelies on a variety of metrics that quantify bias in models. Some of these\nmetrics are intrinsic, measuring bias in word embedding spaces, and some are\nextrinsic, measuring bias in downstream tasks that the word embeddings enable.\nDo these intrinsic and extrinsic metrics correlate with each other? We compare\nintrinsic and extrinsic metrics across hundreds of trained models covering\ndifferent tasks and experimental conditions. Our results show no reliable\ncorrelation between these metrics that holds in all scenarios across tasks and\nlanguages. We urge researchers working on debiasing to focus on extrinsic\nmeasures of bias, and to make using these measures more feasible via creation\nof new challenge sets and annotated test data. To aid this effort, we release\ncode, a new intrinsic metric, and an annotated test set focused on gender bias\nin hate speech.",
          "link": "http://arxiv.org/abs/2012.15859",
          "publishedOn": "2021-06-03T02:10:37.431Z",
          "wordCount": 644,
          "title": "Intrinsic Bias Metrics Do Not Correlate with Application Bias. (arXiv:2012.15859v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.00408",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sachan_D/0/1/0/all/0/1\">Devendra Singh Sachan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patwary_M/0/1/0/all/0/1\">Mostofa Patwary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1\">Mohammad Shoeybi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kant_N/0/1/0/all/0/1\">Neel Kant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1\">Wei Ping</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamilton_W/0/1/0/all/0/1\">William L Hamilton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1\">Bryan Catanzaro</a>",
          "description": "Recent work on training neural retrievers for open-domain question answering\n(OpenQA) has employed both supervised and unsupervised approaches. However, it\nremains unclear how unsupervised and supervised methods can be used most\neffectively for neural retrievers. In this work, we systematically study\nretriever pre-training. We first propose an approach of unsupervised\npre-training with the Inverse Cloze Task and masked salient spans, followed by\nsupervised finetuning using question-context pairs. This approach leads to\nabsolute gains of 2+ points over the previous best result in the top-20\nretrieval accuracy on Natural Questions and TriviaQA datasets.\n\nWe also explore two approaches for end-to-end supervised training of the\nreader and retriever components in OpenQA models. In the first approach, the\nreader considers each retrieved document separately while in the second\napproach, the reader considers all the retrieved documents together. Our\nexperiments demonstrate the effectiveness of these approaches as we obtain new\nstate-of-the-art results. On the Natural Questions dataset, we obtain a top-20\nretrieval accuracy of 84, an improvement of 5 points over the recent DPR model.\nIn addition, we achieve good results on answer extraction, outperforming recent\nmodels like REALM and RAG by 3+ points. We further scale up end-to-end training\nto large models and show consistent gains in performance over smaller models.",
          "link": "http://arxiv.org/abs/2101.00408",
          "publishedOn": "2021-06-03T02:10:37.426Z",
          "wordCount": 685,
          "title": "End-to-End Training of Neural Retrievers for Open-Domain Question Answering. (arXiv:2101.00408v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.06041",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1\">Silin Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takanobu_R/0/1/0/all/0/1\">Ryuichi Takanobu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1\">Wei Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>",
          "description": "Task-oriented dialog (TOD) systems typically manage structured knowledge\n(e.g. ontologies and databases) to guide the goal-oriented conversations.\nHowever, they fall short of handling dialog turns grounded on unstructured\nknowledge (e.g. reviews and documents). In this paper, we formulate a task of\nmodeling TOD grounded on both structured and unstructured knowledge. To address\nthis task, we propose a TOD system with hybrid knowledge management, HyKnow. It\nextends the belief state to manage both structured and unstructured knowledge,\nand is the first end-to-end model that jointly optimizes dialog modeling\ngrounded on these two kinds of knowledge. We conduct experiments on the\nmodified version of MultiWOZ 2.1 dataset, where dialogs are grounded on hybrid\nknowledge. Experimental results show that HyKnow has strong end-to-end\nperformance compared to existing TOD systems. It also outperforms the pipeline\nknowledge management schemes, with higher unstructured knowledge retrieval\naccuracy.",
          "link": "http://arxiv.org/abs/2105.06041",
          "publishedOn": "2021-06-03T02:10:37.416Z",
          "wordCount": 606,
          "title": "HyKnow: End-to-End Task-Oriented Dialog Modeling with Hybrid Knowledge Management. (arXiv:2105.06041v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01207",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Davis_F/0/1/0/all/0/1\">Forrest Davis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schijndel_M/0/1/0/all/0/1\">Marten van Schijndel</a>",
          "description": "A growing body of literature has focused on detailing the linguistic\nknowledge embedded in large, pretrained language models. Existing work has\nshown that non-linguistic biases in models can drive model behavior away from\nlinguistic generalizations. We hypothesized that competing linguistic processes\nwithin a language, rather than just non-linguistic model biases, could obscure\nunderlying linguistic knowledge. We tested this claim by exploring a single\nphenomenon in four languages: English, Chinese, Spanish, and Italian. While\nhuman behavior has been found to be similar across languages, we find\ncross-linguistic variation in model behavior. We show that competing processes\nin a language act as constraints on model behavior and demonstrate that\ntargeted fine-tuning can re-weight the learned constraints, uncovering\notherwise dormant linguistic knowledge in models. Our results suggest that\nmodels need to learn both the linguistic constraints in a language and their\nrelative ranking, with mismatches in either producing non-human-like behavior.",
          "link": "http://arxiv.org/abs/2106.01207",
          "publishedOn": "2021-06-03T02:10:37.405Z",
          "wordCount": 586,
          "title": "Uncovering Constraint-Based Behavior in Neural Models via Targeted Fine-Tuning. (arXiv:2106.01207v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2012.15613",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rust_P/0/1/0/all/0/1\">Phillip Rust</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfeiffer_J/0/1/0/all/0/1\">Jonas Pfeiffer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1\">Ivan Vuli&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruder_S/0/1/0/all/0/1\">Sebastian Ruder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>",
          "description": "In this work, we provide a systematic and comprehensive empirical comparison\nof pretrained multilingual language models versus their monolingual\ncounterparts with regard to their monolingual task performance. We study a set\nof nine typologically diverse languages with readily available pretrained\nmonolingual models on a set of five diverse monolingual downstream tasks. We\nfirst aim to establish, via fair and controlled comparisons, if a gap between\nthe multilingual and the corresponding monolingual representation of that\nlanguage exists, and subsequently investigate the reason for any performance\ndifference. To disentangle conflating factors, we train new monolingual models\non the same data, with monolingually and multilingually trained tokenizers. We\nfind that while the pretraining data size is an important factor, a designated\nmonolingual tokenizer plays an equally important role in the downstream\nperformance. Our results show that languages that are adequately represented in\nthe multilingual model's vocabulary exhibit negligible performance decreases\nover their monolingual counterparts. We further find that replacing the\noriginal multilingual tokenizer with the specialized monolingual tokenizer\nimproves the downstream performance of the multilingual model for almost every\ntask and language.",
          "link": "http://arxiv.org/abs/2012.15613",
          "publishedOn": "2021-06-03T02:10:37.400Z",
          "wordCount": 648,
          "title": "How Good is Your Tokenizer? On the Monolingual Performance of Multilingual Language Models. (arXiv:2012.15613v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01210",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cattan_A/0/1/0/all/0/1\">Arie Cattan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eirew_A/0/1/0/all/0/1\">Alon Eirew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stanovsky_G/0/1/0/all/0/1\">Gabriel Stanovsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_M/0/1/0/all/0/1\">Mandar Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dagan_I/0/1/0/all/0/1\">Ido Dagan</a>",
          "description": "Coreference resolution has been mostly investigated within a single document\nscope, showing impressive progress in recent years based on end-to-end models.\nHowever, the more challenging task of cross-document (CD) coreference\nresolution remained relatively under-explored, with the few recent models\napplied only to gold mentions. Here, we introduce the first end-to-end model\nfor CD coreference resolution from raw text, which extends the prominent model\nfor within-document coreference to the CD setting. Our model achieves\ncompetitive results for event and entity coreference resolution on gold\nmentions. More importantly, we set first baseline results, on the standard ECB+\ndataset, for CD coreference resolution over predicted mentions. Further, our\nmodel is simpler and more efficient than recent CD coreference resolution\nsystems, while not using any external resources.",
          "link": "http://arxiv.org/abs/2106.01210",
          "publishedOn": "2021-06-03T02:10:37.374Z",
          "wordCount": 551,
          "title": "Cross-document Coreference Resolution over Predicted Mentions. (arXiv:2106.01210v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2010.05003",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1\">Kewei Tu</a>",
          "description": "In this paper, we propose second-order graph-based neural dependency parsing\nusing message passing and end-to-end neural networks. We empirically show that\nour approaches match the accuracy of very recent state-of-the-art second-order\ngraph-based neural dependency parsers and have significantly faster speed in\nboth training and testing. We also empirically show the advantage of\nsecond-order parsing over first-order parsing and observe that the usefulness\nof the head-selection structured constraint vanishes when using BERT embedding.",
          "link": "http://arxiv.org/abs/2010.05003",
          "publishedOn": "2021-06-03T02:10:37.283Z",
          "wordCount": 535,
          "title": "Second-Order Neural Dependency Parsing with Message Passing and End-to-End Training. (arXiv:2010.05003v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01354",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1\">Swarnadeep Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yadav_P/0/1/0/all/0/1\">Prateek Yadav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>",
          "description": "We focus on a type of linguistic formal reasoning where the goal is to reason\nover explicit knowledge in the form of natural language facts and rules (Clark\net al., 2020). A recent work, named PRover (Saha et al., 2020), performs such\nreasoning by answering a question and also generating a proof graph that\nexplains the answer. However, compositional reasoning is not always unique and\nthere may be multiple ways of reaching the correct answer. Thus, in our work,\nwe address a new and challenging problem of generating multiple proof graphs\nfor reasoning over natural language rule-bases. Each proof provides a different\nrationale for the answer, thereby improving the interpretability of such\nreasoning systems. In order to jointly learn from all proof graphs and exploit\nthe correlations between multiple proofs for a question, we pose this task as a\nset generation problem over structured output spaces where each proof is\nrepresented as a directed graph. We propose two variants of a proof-set\ngeneration model, multiPRover. Our first model, Multilabel-multiPRover,\ngenerates a set of proofs via multi-label classification and implicit\nconditioning between the proofs; while the second model, Iterative-multiPRover,\ngenerates proofs iteratively by explicitly conditioning on the previously\ngenerated proofs. Experiments on multiple synthetic, zero-shot, and\nhuman-paraphrased datasets reveal that both multiPRover models significantly\noutperform PRover on datasets containing multiple gold proofs.\nIterative-multiPRover obtains state-of-the-art proof F1 in zero-shot scenarios\nwhere all examples have single correct proofs. It also generalizes better to\nquestions requiring higher depths of reasoning where multiple proofs are more\nfrequent. Our code and models are publicly available at\nhttps://github.com/swarnaHub/multiPRover",
          "link": "http://arxiv.org/abs/2106.01354",
          "publishedOn": "2021-06-03T02:10:37.278Z",
          "wordCount": 711,
          "title": "multiPRover: Generating Multiple Proofs for Improved Interpretability in Rule Reasoning. (arXiv:2106.01354v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2011.05707",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Huybrechts_G/0/1/0/all/0/1\">Goeric Huybrechts</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Merritt_T/0/1/0/all/0/1\">Thomas Merritt</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Comini_G/0/1/0/all/0/1\">Giulia Comini</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Perz_B/0/1/0/all/0/1\">Bartek Perz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shah_R/0/1/0/all/0/1\">Raahil Shah</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lorenzo_Trueba_J/0/1/0/all/0/1\">Jaime Lorenzo-Trueba</a>",
          "description": "While recent neural text-to-speech (TTS) systems perform remarkably well,\nthey typically require a substantial amount of recordings from the target\nspeaker reading in the desired speaking style. In this work, we present a novel\n3-step methodology to circumvent the costly operation of recording large\namounts of target data in order to build expressive style voices with as little\nas 15 minutes of such recordings. First, we augment data via voice conversion\nby leveraging recordings in the desired speaking style from other speakers.\nNext, we use that synthetic data on top of the available recordings to train a\nTTS model. Finally, we fine-tune that model to further increase quality. Our\nevaluations show that the proposed changes bring significant improvements over\nnon-augmented models across many perceived aspects of synthesised speech. We\ndemonstrate the proposed approach on 2 styles (newscaster and conversational),\non various speakers, and on both single and multi-speaker models, illustrating\nthe robustness of our approach.",
          "link": "http://arxiv.org/abs/2011.05707",
          "publishedOn": "2021-06-03T02:10:37.272Z",
          "wordCount": 612,
          "title": "Low-resource expressive text-to-speech using data augmentation. (arXiv:2011.05707v2 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.12764",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Samory_M/0/1/0/all/0/1\">Mattia Samory</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sen_I/0/1/0/all/0/1\">Indira Sen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kohne_J/0/1/0/all/0/1\">Julian Kohne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Floeck_F/0/1/0/all/0/1\">Fabian Floeck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wagner_C/0/1/0/all/0/1\">Claudia Wagner</a>",
          "description": "Research has focused on automated methods to effectively detect sexism\nonline. Although overt sexism seems easy to spot, its subtle forms and manifold\nexpressions are not. In this paper, we outline the different dimensions of\nsexism by grounding them in their implementation in psychological scales. From\nthe scales, we derive a codebook for sexism in social media, which we use to\nannotate existing and novel datasets, surfacing their limitations in breadth\nand validity with respect to the construct of sexism. Next, we leverage the\nannotated datasets to generate adversarial examples, and test the reliability\nof sexism detection methods. Results indicate that current machine learning\nmodels pick up on a very narrow set of linguistic markers of sexism and do not\ngeneralize well to out-of-domain examples. Yet, including diverse data and\nadversarial examples at training time results in models that generalize better\nand that are more robust to artifacts of data collection. By providing a\nscale-based codebook and insights regarding the shortcomings of the\nstate-of-the-art, we hope to contribute to the development of better and\nbroader models for sexism detection, including reflections on theory-driven\napproaches to data collection.",
          "link": "http://arxiv.org/abs/2004.12764",
          "publishedOn": "2021-06-03T02:10:37.252Z",
          "wordCount": 693,
          "title": "\"Call me sexist, but...\": Revisiting Sexism Detection Using Psychological Scales and Adversarial Samples. (arXiv:2004.12764v2 [cs.CY] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.14919",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mingda Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiseman_S/0/1/0/all/0/1\">Sam Wiseman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gimpel_K/0/1/0/all/0/1\">Kevin Gimpel</a>",
          "description": "Datasets for data-to-text generation typically focus either on multi-domain,\nsingle-sentence generation or on single-domain, long-form generation. In this\nwork, we cast generating Wikipedia sections as a data-to-text generation task\nand create a large-scale dataset, WikiTableT, that pairs Wikipedia sections\nwith their corresponding tabular data and various metadata. WikiTableT contains\nmillions of instances, covering a broad range of topics, as well as a variety\nof flavors of generation tasks with different levels of flexibility. We\nbenchmark several training and decoding strategies on WikiTableT. Our\nqualitative analysis shows that the best approaches can generate fluent and\nhigh quality texts but they struggle with coherence and factuality, showing the\npotential for our dataset to inspire future work on long-form generation.",
          "link": "http://arxiv.org/abs/2012.14919",
          "publishedOn": "2021-06-03T02:10:37.231Z",
          "wordCount": 579,
          "title": "WikiTableT: A Large-Scale Data-to-Text Dataset for Generating Wikipedia Article Sections. (arXiv:2012.14919v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01269",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhardwaj_R/0/1/0/all/0/1\">Rishabh Bhardwaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Majumder_N/0/1/0/all/0/1\">Navonil Majumder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poria_S/0/1/0/all/0/1\">Soujanya Poria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hovy_E/0/1/0/all/0/1\">Eduard Hovy</a>",
          "description": "Interpretability is an important aspect of the trustworthiness of a model's\npredictions. Transformer's predictions are widely explained by the attention\nweights, i.e., a probability distribution generated at its self-attention unit\n(head). Current empirical studies provide shreds of evidence that attention\nweights are not explanations by proving that they are not unique. A recent\nstudy showed theoretical justifications to this observation by proving the\nnon-identifiability of attention weights. For a given input to a head and its\noutput, if the attention weights generated in it are unique, we call the\nweights identifiable. In this work, we provide deeper theoretical analysis and\nempirical observations on the identifiability of attention weights. Ignored in\nthe previous works, we find the attention weights are more identifiable than we\ncurrently perceive by uncovering the hidden role of the key vector. However,\nthe weights are still prone to be non-unique attentions that make them unfit\nfor interpretation. To tackle this issue, we provide a variant of the encoder\nlayer that decouples the relationship between key and value vector and provides\nidentifiable weights up to the desired length of the input. We prove the\napplicability of such variations by providing empirical justifications on\nvaried text classification tasks. The implementations are available at\nhttps://github.com/declare-lab/identifiable-transformers.",
          "link": "http://arxiv.org/abs/2106.01269",
          "publishedOn": "2021-06-03T02:10:37.222Z",
          "wordCount": 641,
          "title": "More Identifiable yet Equally Performant Transformers for Text Classification. (arXiv:2106.01269v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2101.00438",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ram_O/0/1/0/all/0/1\">Ori Ram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirstain_Y/0/1/0/all/0/1\">Yuval Kirstain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berant_J/0/1/0/all/0/1\">Jonathan Berant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Globerson_A/0/1/0/all/0/1\">Amir Globerson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levy_O/0/1/0/all/0/1\">Omer Levy</a>",
          "description": "In several question answering benchmarks, pretrained models have reached\nhuman parity through fine-tuning on an order of 100,000 annotated questions and\nanswers. We explore the more realistic few-shot setting, where only a few\nhundred training examples are available, and observe that standard models\nperform poorly, highlighting the discrepancy between current pretraining\nobjectives and question answering. We propose a new pretraining scheme tailored\nfor question answering: recurring span selection. Given a passage with multiple\nsets of recurring spans, we mask in each set all recurring spans but one, and\nask the model to select the correct span in the passage for each masked span.\nMasked spans are replaced with a special token, viewed as a question\nrepresentation, that is later used during fine-tuning to select the answer\nspan. The resulting model obtains surprisingly good results on multiple\nbenchmarks (e.g., 72.7 F1 on SQuAD with only 128 training examples), while\nmaintaining competitive performance in the high-resource setting.",
          "link": "http://arxiv.org/abs/2101.00438",
          "publishedOn": "2021-06-03T02:10:37.217Z",
          "wordCount": 614,
          "title": "Few-Shot Question Answering by Pretraining Span Selection. (arXiv:2101.00438v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10283",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_W/0/1/0/all/0/1\">Weixin Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yanhao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zixuan Liu</a>",
          "description": "Images are more than a collection of objects or attributes -- they represent\na web of relationships among interconnected objects. Scene Graph has emerged as\na new modality for a structured graphical representation of images. Scene Graph\nencodes objects as nodes connected via pairwise relations as edges. To support\nquestion answering on scene graphs, we propose GraphVQA, a language-guided\ngraph neural network framework that translates and executes a natural language\nquestion as multiple iterations of message passing among graph nodes. We\nexplore the design space of GraphVQA framework, and discuss the trade-off of\ndifferent design choices. Our experiments on GQA dataset show that GraphVQA\noutperforms the state-of-the-art model by a large margin (88.43% vs. 94.78%).",
          "link": "http://arxiv.org/abs/2104.10283",
          "publishedOn": "2021-06-03T02:10:37.203Z",
          "wordCount": 584,
          "title": "GraghVQA: Language-Guided Graph Neural Networks for Graph-based Visual Question Answering. (arXiv:2104.10283v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01006",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qiu_L/0/1/0/all/0/1\">Liang Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yuan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yizhou Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1\">Pan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1\">Baolin Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Ying Nian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Song-Chun Zhu</a>",
          "description": "Inferring social relations from dialogues is vital for building emotionally\nintelligent robots to interpret human language better and act accordingly. We\nmodel the social network as an And-or Graph, named SocAoG, for the consistency\nof relations among a group and leveraging attributes as inference cues.\nMoreover, we formulate a sequential structure prediction task, and propose an\n$\\alpha$-$\\beta$-$\\gamma$ strategy to incrementally parse SocAoG for the\ndynamic inference upon any incoming utterance: (i) an $\\alpha$ process\npredicting attributes and relations conditioned on the semantics of dialogues,\n(ii) a $\\beta$ process updating the social relations based on related\nattributes, and (iii) a $\\gamma$ process updating individual's attributes based\non interpersonal social relations. Empirical results on DialogRE and MovieGraph\nshow that our model infers social relations more accurately than the\nstate-of-the-art methods. Moreover, the ablation study shows the three\nprocesses complement each other, and the case study demonstrates the dynamic\nrelational inference.",
          "link": "http://arxiv.org/abs/2106.01006",
          "publishedOn": "2021-06-03T02:10:37.197Z",
          "wordCount": 598,
          "title": "SocAoG: Incremental Graph Parsing for Social Relation Inference in Dialogues. (arXiv:2106.01006v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01097",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Palani_S/0/1/0/all/0/1\">Sarojadevi Palani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajagopal_P/0/1/0/all/0/1\">Prabhu Rajagopal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pancholi_S/0/1/0/all/0/1\">Sidharth Pancholi</a>",
          "description": "Sentiment analysis (SA) has become an extensive research area in recent years\nimpacting diverse fields including ecommerce, consumer business, and politics,\ndriven by increasing adoption and usage of social media platforms. It is\nchallenging to extract topics and sentiments from unsupervised short texts\nemerging in such contexts, as they may contain figurative words, strident data,\nand co-existence of many possible meanings for a single word or phrase, all\ncontributing to obtaining incorrect topics. Most prior research is based on a\nspecific theme/rhetoric/focused-content on a clean dataset. In the work\nreported here, the effectiveness of BERT(Bidirectional Encoder Representations\nfrom Transformers) in sentiment classification tasks from a raw live dataset\ntaken from a popular microblogging platform is demonstrated. A novel T-BERT\nframework is proposed to show the enhanced performance obtainable by combining\nlatent topics with contextual BERT embeddings. Numerical experiments were\nconducted on an ensemble with about 42000 datasets using NimbleBox.ai platform\nwith a hardware configuration consisting of Nvidia Tesla K80(CUDA), 4 core CPU,\n15GB RAM running on an isolated Google Cloud Platform instance. The empirical\nresults show that the model improves in performance while adding topics to BERT\nand an accuracy rate of 90.81% on sentiment classification using BERT with the\nproposed approach.",
          "link": "http://arxiv.org/abs/2106.01097",
          "publishedOn": "2021-06-03T02:10:37.187Z",
          "wordCount": 641,
          "title": "T-BERT -- Model for Sentiment Analysis of Micro-blogs Integrating Topic Model and BERT. (arXiv:2106.01097v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01045",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bentivogli_L/0/1/0/all/0/1\">Luisa Bentivogli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cettolo_M/0/1/0/all/0/1\">Mauro Cettolo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaido_M/0/1/0/all/0/1\">Marco Gaido</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karakanta_A/0/1/0/all/0/1\">Alina Karakanta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martinelli_A/0/1/0/all/0/1\">Alberto Martinelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Negri_M/0/1/0/all/0/1\">Matteo Negri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turchi_M/0/1/0/all/0/1\">Marco Turchi</a>",
          "description": "Five years after the first published proofs of concept, direct approaches to\nspeech translation (ST) are now competing with traditional cascade solutions.\nIn light of this steady progress, can we claim that the performance gap between\nthe two is closed? Starting from this question, we present a systematic\ncomparison between state-of-the-art systems representative of the two\nparadigms. Focusing on three language directions\n(English-German/Italian/Spanish), we conduct automatic and manual evaluations,\nexploiting high-quality professional post-edits and annotations. Our\nmulti-faceted analysis on one of the few publicly available ST benchmarks\nattests for the first time that: i) the gap between the two paradigms is now\nclosed, and ii) the subtle differences observed in their behavior are not\nsufficient for humans neither to distinguish them nor to prefer one over the\nother.",
          "link": "http://arxiv.org/abs/2106.01045",
          "publishedOn": "2021-06-03T02:10:37.180Z",
          "wordCount": 571,
          "title": "Cascade versus Direct Speech Translation: Do the Differences Still Make a Difference?. (arXiv:2106.01045v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2012.04808",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yichong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1\">Chenguang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Ruochen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1\">Michael Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuedong Huang</a>",
          "description": "Commonsense question answering (QA) requires a model to grasp commonsense and\nfactual knowledge to answer questions about world events. Many prior methods\ncouple language modeling with knowledge graphs (KG). However, although a KG\ncontains rich structural information, it lacks the context to provide a more\nprecise understanding of the concepts. This creates a gap when fusing knowledge\ngraphs into language modeling, especially when there is insufficient labeled\ndata. Thus, we propose to employ external entity descriptions to provide\ncontextual information for knowledge understanding. We retrieve descriptions of\nrelated concepts from Wiktionary and feed them as additional input to\npre-trained language models. The resulting model achieves state-of-the-art\nresult in the CommonsenseQA dataset and the best result among non-generative\nmodels in OpenBookQA.",
          "link": "http://arxiv.org/abs/2012.04808",
          "publishedOn": "2021-06-03T02:10:37.160Z",
          "wordCount": 588,
          "title": "Fusing Context Into Knowledge Graph for Commonsense Question Answering. (arXiv:2012.04808v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01335",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ji_T/0/1/0/all/0/1\">Tianchu Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1\">Shraddhan Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferdman_M/0/1/0/all/0/1\">Michael Ferdman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milder_P/0/1/0/all/0/1\">Peter Milder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwartz_H/0/1/0/all/0/1\">H. Andrew Schwartz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balasubramanian_N/0/1/0/all/0/1\">Niranjan Balasubramanian</a>",
          "description": "How much information do NLP tasks really need from a transformer's attention\nmechanism at application-time (inference)? From recent work, we know that there\nis sparsity in transformers and that the floating-points within its computation\ncan be discretized to fewer values with minimal loss to task accuracies.\nHowever, this requires retraining or even creating entirely new models, both of\nwhich can be expensive and carbon-emitting. Focused on optimizations that do\nnot require training, we systematically study the full range of typical\nattention values necessary. This informs the design of an inference-time\nquantization technique using both pruning and log-scaled mapping which produces\nonly a few (e.g. $2^3$) unique values. Over the tasks of question answering and\nsentiment analysis, we find nearly 80% of attention values can be pruned to\nzeros with minimal ($< 1.0\\%$) relative loss in accuracy. We use this pruning\ntechnique in conjunction with quantizing the attention values to only a 3-bit\nformat, without retraining, resulting in only a 0.8% accuracy reduction on\nquestion answering with fine-tuned RoBERTa.",
          "link": "http://arxiv.org/abs/2106.01335",
          "publishedOn": "2021-06-03T02:10:37.155Z",
          "wordCount": 607,
          "title": "On the Distribution, Sparsity, and Inference-time Quantization of Attention Values in Transformers. (arXiv:2106.01335v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00887",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zanbo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1\">Wei Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_X/0/1/0/all/0/1\">Xianling Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1\">Shanshan Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1\">Pan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zhiyong He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1\">Sheng Jiang</a>",
          "description": "Most existing named entity recognition (NER) approaches are based on sequence\nlabeling models, which focus on capturing the local context dependencies.\nHowever, the way of taking one sentence as input prevents the modeling of\nnon-sequential global context, which is useful especially when local context\ninformation is limited or ambiguous. To this end, we propose a model called\nGlobal Context enhanced Document-level NER (GCDoc) to leverage global\ncontextual information from two levels, i.e., both word and sentence. At\nword-level, a document graph is constructed to model a wider range of\ndependencies between words, then obtain an enriched contextual representation\nfor each word via graph neural networks (GNN). To avoid the interference of\nnoise information, we further propose two strategies. First we apply the\nepistemic uncertainty theory to find out tokens whose representations are less\nreliable, thereby helping prune the document graph. Then a selective auxiliary\nclassifier is proposed to effectively learn the weight of edges in document\ngraph and reduce the importance of noisy neighbour nodes. At sentence-level,\nfor appropriately modeling wider context beyond single sentence, we employ a\ncross-sentence module which encodes adjacent sentences and fuses it with the\ncurrent sentence representation via attention and gating mechanisms. Extensive\nexperiments on two benchmark NER datasets (CoNLL 2003 and Ontonotes 5.0 English\ndataset) demonstrate the effectiveness of our proposed model. Our model reaches\nF1 score of 92.22 (93.40 with BERT) on CoNLL 2003 dataset and 88.32 (90.49 with\nBERT) on Ontonotes 5.0 dataset, achieving new state-of-the-art performance.",
          "link": "http://arxiv.org/abs/2106.00887",
          "publishedOn": "2021-06-03T02:10:37.140Z",
          "wordCount": 688,
          "title": "Exploiting Global Contextual Information for Document-level Named Entity Recognition. (arXiv:2106.00887v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01064",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Syed_S/0/1/0/all/0/1\">Shahbaz Syed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Khatib_K/0/1/0/all/0/1\">Khalid Al-Khatib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alshomary_M/0/1/0/all/0/1\">Milad Alshomary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wachsmuth_H/0/1/0/all/0/1\">Henning Wachsmuth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potthast_M/0/1/0/all/0/1\">Martin Potthast</a>",
          "description": "The purpose of an argumentative text is to support a certain conclusion. Yet,\nthey are often omitted, expecting readers to infer them rather. While\nappropriate when reading an individual text, this rhetorical device limits\naccessibility when browsing many texts (e.g., on a search engine or on social\nmedia). In these scenarios, an explicit conclusion makes for a good candidate\nsummary of an argumentative text. This is especially true if the conclusion is\ninformative, emphasizing specific concepts from the text. With this paper we\nintroduce the task of generating informative conclusions: First,\nWebis-ConcluGen-21 is compiled, a large-scale corpus of 136,996 samples of\nargumentative texts and their conclusions. Second, two paradigms for conclusion\ngeneration are investigated; one extractive, the other abstractive in nature.\nThe latter exploits argumentative knowledge that augment the data via control\ncodes and finetuning the BART model on several subsets of the corpus. Third,\ninsights are provided into the suitability of our corpus for the task, the\ndifferences between the two generation paradigms, the trade-off between\ninformativeness and conciseness, and the impact of encoding argumentative\nknowledge. The corpus, code, and the trained models are publicly available.",
          "link": "http://arxiv.org/abs/2106.01064",
          "publishedOn": "2021-06-03T02:10:37.130Z",
          "wordCount": 610,
          "title": "Generating Informative Conclusions for Argumentative Texts. (arXiv:2106.01064v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00969",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Shikhar Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_N/0/1/0/all/0/1\">Nuan Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1\">Yu Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alipoormolabashi_P/0/1/0/all/0/1\">Pegah Alipoormolabashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Te-Lin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xuezhe Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1\">Nanyun Peng</a>",
          "description": "Commonsense reasoning is intuitive for humans but has been a long-term\nchallenge for artificial intelligence (AI). Recent advancements in pretrained\nlanguage models have shown promising results on several commonsense benchmark\ndatasets. However, the reliability and comprehensiveness of these benchmarks\ntowards assessing model's commonsense reasoning ability remains unclear. To\nthis end, we introduce a new commonsense reasoning benchmark dataset comprising\nnatural language true/false statements, with each sample paired with its\ncomplementary counterpart, resulting in 4k sentence pairs. We propose a\npairwise accuracy metric to reliably measure an agent's ability to perform\ncommonsense reasoning over a given situation. The dataset is crowdsourced and\nenhanced with an adversarial model-in-the-loop setup to incentivize challenging\nsamples. To facilitate a systematic analysis of commonsense capabilities, we\ndesign our dataset along the dimensions of knowledge domains, reasoning\nscenarios and numeracy. Experimental results demonstrate that our strongest\nbaseline (UnifiedQA-3B), after fine-tuning, achieves ~71% standard accuracy and\n~51% pairwise accuracy, well below human performance (~95% for both metrics).\nThe dataset is available at https://github.com/PlusLabNLP/Com2Sense.",
          "link": "http://arxiv.org/abs/2106.00969",
          "publishedOn": "2021-06-03T02:10:37.115Z",
          "wordCount": 625,
          "title": "COM2SENSE: A Commonsense Reasoning Benchmark with Complementary Sentences. (arXiv:2106.00969v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00780",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zmigrod_R/0/1/0/all/0/1\">Ran Zmigrod</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vieira_T/0/1/0/all/0/1\">Tim Vieira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>",
          "description": "The connection between the maximum spanning tree in a directed graph and the\nbest dependency tree of a sentence has been exploited by the NLP community.\nHowever, for many dependency parsing schemes, an important detail of this\napproach is that the spanning tree must have exactly one edge emanating from\nthe root. While work has been done to efficiently solve this problem for\nfinding the one-best dependency tree, no research has attempted to extend this\nsolution to finding the $K$-best dependency trees. This is arguably a more\nimportant extension as a larger proportion of decoded trees will not be subject\nto the root constraint of dependency trees. Indeed, we show that the rate of\nroot constraint violations increases by an average of $13$ times when decoding\nwith $K\\!=\\!50$ as opposed to $K\\!=\\!1$. In this paper, we provide a\nsimplification of the $K$-best spanning tree algorithm of Camerini et al.\n(1980). Our simplification allows us to obtain a constant time speed-up over\nthe original algorithm. Furthermore, we present a novel extension of the\nalgorithm for decoding the $K$-best dependency trees of a graph which are\nsubject to a root constraint.",
          "link": "http://arxiv.org/abs/2106.00780",
          "publishedOn": "2021-06-03T02:10:37.081Z",
          "wordCount": 610,
          "title": "On Finding the $K$-best Non-projective Dependency Trees. (arXiv:2106.00780v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00976",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ou_J/0/1/0/all/0/1\">Jiefu Ou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yangqiu Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xin Jiang</a>",
          "description": "Discourse relations among arguments reveal logical structures of a debate\nconversation. However, no prior work has explicitly studied how the sequence of\ndiscourse relations influence a claim's impact. This paper empirically shows\nthat the discourse relations between two arguments along the context path are\nessential factors for identifying the persuasive power of an argument. We\nfurther propose DisCOC to inject and fuse the sentence-level structural\ndiscourse information with contextualized features derived from large-scale\nlanguage models. Experimental results and extensive analysis show that the\nattention and gate mechanisms that explicitly model contexts and texts can\nindeed help the argument impact classification task defined by Durmus et al.\n(2019), and discourse structures among the context path of the claim to be\nclassified can further boost the performance.",
          "link": "http://arxiv.org/abs/2106.00976",
          "publishedOn": "2021-06-03T02:10:37.076Z",
          "wordCount": 554,
          "title": "Exploring Discourse Structures for Argument Impact Classification. (arXiv:2106.00976v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01167",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mondal_I/0/1/0/all/0/1\">Ishani Mondal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1\">Yufang Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jochim_C/0/1/0/all/0/1\">Charles Jochim</a>",
          "description": "This paper studies the end-to-end construction of an NLP Knowledge Graph (KG)\nfrom scientific papers. We focus on extracting four types of relations:\nevaluatedOn between tasks and datasets, evaluatedBy between tasks and\nevaluation metrics, as well as coreferent and related relations between the\nsame type of entities. For instance, F1-score is coreferent with F-measure. We\nintroduce novel methods for each of these relation types and apply our final\nframework (SciNLP-KG) to 30,000 NLP papers from ACL Anthology to build a\nlarge-scale KG, which can facilitate automatically constructing scientific\nleaderboards for the NLP community. The results of our experiments indicate\nthat the resulting KG contains high-quality information.",
          "link": "http://arxiv.org/abs/2106.01167",
          "publishedOn": "2021-06-03T02:10:37.049Z",
          "wordCount": 528,
          "title": "End-to-End NLP Knowledge Graph Construction. (arXiv:2106.01167v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00954",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhe Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yufan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmud_J/0/1/0/all/0/1\">Jalal Mahmud</a>",
          "description": "Although deep neural networks have been widely employed and proven effective\nin sentiment analysis tasks, it remains challenging for model developers to\nassess their models for erroneous predictions that might exist prior to\ndeployment. Once deployed, emergent errors can be hard to identify in\nprediction run-time and impossible to trace back to their sources. To address\nsuch gaps, in this paper we propose an error detection framework for sentiment\nanalysis based on explainable features. We perform global-level feature\nvalidation with human-in-the-loop assessment, followed by an integration of\nglobal and local-level feature contribution analysis. Experimental results show\nthat, given limited human-in-the-loop intervention, our method is able to\nidentify erroneous model predictions on unseen data with high precision.",
          "link": "http://arxiv.org/abs/2106.00954",
          "publishedOn": "2021-06-03T02:10:37.035Z",
          "wordCount": 559,
          "title": "When and Why does a Model Fail? A Human-in-the-loop Error Detection Framework for Sentiment Analysis. (arXiv:2106.00954v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00791",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hua_X/0/1/0/all/0/1\">Xinyu Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sreevatsa_A/0/1/0/all/0/1\">Ashwin Sreevatsa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lu Wang</a>",
          "description": "We study the task of long-form opinion text generation, which faces at least\ntwo distinct challenges. First, existing neural generation models fall short of\ncoherence, thus requiring efficient content planning. Second, diverse types of\ninformation are needed to guide the generator to cover both subjective and\nobjective content. To this end, we propose DYPLOC, a generation framework that\nconducts dynamic planning of content while generating the output based on a\nnovel design of mixed language models. To enrich the generation with diverse\ncontent, we further propose to use large pre-trained models to predict relevant\nconcepts and to generate claims. We experiment with two challenging tasks on\nnewly collected datasets: (1) argument generation with Reddit ChangeMyView, and\n(2) writing articles using New York Times' Opinion section. Automatic\nevaluation shows that our model significantly outperforms competitive\ncomparisons. Human judges further confirm that our generations are more\ncoherent with richer content.",
          "link": "http://arxiv.org/abs/2106.00791",
          "publishedOn": "2021-06-03T02:10:36.983Z",
          "wordCount": 590,
          "title": "DYPLOC: Dynamic Planning of Content Using Mixed Language Models for Text Generation. (arXiv:2106.00791v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00933",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yilun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pradhan_S/0/1/0/all/0/1\">Sameer Pradhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeldes_A/0/1/0/all/0/1\">Amir Zeldes</a>",
          "description": "SOTA coreference resolution produces increasingly impressive scores on the\nOntoNotes benchmark. However lack of comparable data following the same scheme\nfor more genres makes it difficult to evaluate generalizability to open domain\ndata. This paper provides a dataset and comprehensive evaluation showing that\nthe latest neural LM based end-to-end systems degrade very substantially out of\ndomain. We make an OntoNotes-like coreference dataset called OntoGUM publicly\navailable, converted from GUM, an English corpus covering 12 genres, using\ndeterministic rules, which we evaluate. Thanks to the rich syntactic and\ndiscourse annotations in GUM, we are able to create the largest human-annotated\ncoreference corpus following the OntoNotes guidelines, and the first to be\nevaluated for consistency with the OntoNotes scheme. Out-of-domain evaluation\nacross 12 genres shows nearly 15-20% degradation for both deterministic and\ndeep learning systems, indicating a lack of generalizability or covert\noverfitting in existing coreference resolution models.",
          "link": "http://arxiv.org/abs/2106.00933",
          "publishedOn": "2021-06-03T02:10:36.845Z",
          "wordCount": 573,
          "title": "OntoGUM: Evaluating Contextualized SOTA Coreference Resolution on 12 More Genres. (arXiv:2106.00933v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01077",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yanaka_H/0/1/0/all/0/1\">Hitomi Yanaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mineshima_K/0/1/0/all/0/1\">Koji Mineshima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Inui_K/0/1/0/all/0/1\">Kentaro Inui</a>",
          "description": "Recently, deep neural networks (DNNs) have achieved great success in\nsemantically challenging NLP tasks, yet it remains unclear whether DNN models\ncan capture compositional meanings, those aspects of meaning that have been\nlong studied in formal semantics. To investigate this issue, we propose a\nSystematic Generalization testbed based on Natural language Semantics (SyGNS),\nwhose challenge is to map natural language sentences to multiple forms of\nscoped meaning representations, designed to account for various semantic\nphenomena. Using SyGNS, we test whether neural networks can systematically\nparse sentences involving novel combinations of logical expressions such as\nquantifiers and negation. Experiments show that Transformer and GRU models can\ngeneralize to unseen combinations of quantifiers, negations, and modifiers that\nare similar to given training instances in form, but not to the others. We also\nfind that the generalization performance to unseen combinations is better when\nthe form of meaning representations is simpler. The data and code for SyGNS are\npublicly available at https://github.com/verypluming/SyGNS.",
          "link": "http://arxiv.org/abs/2106.01077",
          "publishedOn": "2021-06-03T02:10:36.822Z",
          "wordCount": 595,
          "title": "SyGNS: A Systematic Generalization Testbed Based on Natural Language Semantics. (arXiv:2106.01077v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00903",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1\">Liang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Longyue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xuebo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_D/0/1/0/all/0/1\">Derek F. Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhaopeng Tu</a>",
          "description": "Knowledge distillation (KD) is commonly used to construct synthetic data for\ntraining non-autoregressive translation (NAT) models. However, there exists a\ndiscrepancy on low-frequency words between the distilled and the original data,\nleading to more errors on predicting low-frequency words. To alleviate the\nproblem, we directly expose the raw data into NAT by leveraging pretraining. By\nanalyzing directed alignments, we found that KD makes low-frequency source\nwords aligned with targets more deterministically but fails to align sufficient\nlow-frequency words from target to source. Accordingly, we propose reverse KD\nto rejuvenate more alignments for low-frequency target words. To make the most\nof authentic and synthetic data, we combine these complementary approaches as a\nnew training strategy for further boosting NAT performance. We conduct\nexperiments on five translation benchmarks over two advanced architectures.\nResults demonstrate that the proposed approach can significantly and\nuniversally improve translation quality by reducing translation errors on\nlow-frequency words. Encouragingly, our approach achieves 28.2 and 33.9 BLEU\npoints on the WMT14 English-German and WMT16 Romanian-English datasets,\nrespectively. Our code, data, and trained models are available at\n\\url{https://github.com/longyuewangdcu/RLFW-NAT}.",
          "link": "http://arxiv.org/abs/2106.00903",
          "publishedOn": "2021-06-03T02:10:36.811Z",
          "wordCount": 625,
          "title": "Rejuvenating Low-Frequency Words: Making the Most of Parallel Data in Non-Autoregressive Translation. (arXiv:2106.00903v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00793",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhengbao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jialong Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sisman_B/0/1/0/all/0/1\">Bunyamin Sisman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xin Luna Dong</a>",
          "description": "Integrating extracted knowledge from the Web to knowledge graphs (KGs) can\nfacilitate tasks like question answering. We study relation integration that\naims to align free-text relations in subject-relation-object extractions to\nrelations in a target KG. To address the challenge that free-text relations are\nambiguous, previous methods exploit neighbor entities and relations for\nadditional context. However, the predictions are made independently, which can\nbe mutually inconsistent. We propose a two-stage Collective Relation\nIntegration (CoRI) model, where the first stage independently makes candidate\npredictions, and the second stage employs a collective model that accesses all\ncandidate predictions to make globally coherent predictions. We further improve\nthe collective model with augmented data from the portion of the target KG that\nis otherwise unused. Experiment results on two datasets show that CoRI can\nsignificantly outperform the baselines, improving AUC from .677 to .748 and\nfrom .716 to .780, respectively.",
          "link": "http://arxiv.org/abs/2106.00793",
          "publishedOn": "2021-06-03T02:10:36.777Z",
          "wordCount": 581,
          "title": "CoRI: Collective Relation Integration with Data Augmentation for Open Information Extraction. (arXiv:2106.00793v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00877",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Casacuberta_S/0/1/0/all/0/1\">S&#xed;lvia Casacuberta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Halevy_K/0/1/0/all/0/1\">Karina Halevy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blasi_D/0/1/0/all/0/1\">Dami&#xe1;n E. Blasi</a>",
          "description": "We introduce categorical modularity, a novel low-resource intrinsic metric to\nevaluate word embedding quality. Categorical modularity is a graph modularity\nmetric based on the $k$-nearest neighbor graph constructed with embedding\nvectors of words from a fixed set of semantic categories, in which the goal is\nto measure the proportion of words that have nearest neighbors within the same\ncategories. We use a core set of 500 words belonging to 59 neurobiologically\nmotivated semantic categories in 29 languages and analyze three word embedding\nmodels per language (FastText, MUSE, and subs2vec). We find moderate to strong\npositive correlations between categorical modularity and performance on the\nmonolingual tasks of sentiment analysis and word similarity calculation and on\nthe cross-lingual task of bilingual lexicon induction both to and from English.\nOverall, we suggest that categorical modularity provides non-trivial predictive\ninformation about downstream task performance, with breakdowns of correlations\nby model suggesting some meta-predictive properties about semantic information\nloss as well.",
          "link": "http://arxiv.org/abs/2106.00877",
          "publishedOn": "2021-06-03T02:10:36.696Z",
          "wordCount": 585,
          "title": "Evaluating Word Embeddings with Categorical Modularity. (arXiv:2106.00877v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01060",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kementchedjhieva_Y/0/1/0/all/0/1\">Yova Kementchedjhieva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anderson_M/0/1/0/all/0/1\">Mark Anderson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sogaard_A/0/1/0/all/0/1\">Anders S&#xf8;gaard</a>",
          "description": "Some interpersonal verbs can implicitly attribute causality to either their\nsubject or their object and are therefore said to carry an implicit causality\n(IC) bias. Through this bias, causal links can be inferred from a narrative,\naiding language comprehension. We investigate whether pre-trained language\nmodels (PLMs) encode IC bias and use it at inference time. We find that to be\nthe case, albeit to different degrees, for three distinct PLM architectures.\nHowever, causes do not always need to be implicit -- when a cause is explicitly\nstated in a subordinate clause, an incongruent IC bias associated with the verb\nin the main clause leads to a delay in human processing. We hypothesize that\nthe temporary challenge humans face in integrating the two contradicting\nsignals, one from the lexical semantics of the verb, one from the\nsentence-level semantics, would be reflected in higher error rates for models\non tasks dependent on causal links. The results of our study lend support to\nthis hypothesis, suggesting that PLMs tend to prioritize lexical patterns over\nhigher-order signals.",
          "link": "http://arxiv.org/abs/2106.01060",
          "publishedOn": "2021-06-03T02:10:36.656Z",
          "wordCount": 620,
          "title": "John praised Mary because he? Implicit Causality Bias and Its Interaction with Explicit Cues in LMs. (arXiv:2106.01060v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00742",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jahan_M/0/1/0/all/0/1\">Md Saroar Jahan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oussalah_M/0/1/0/all/0/1\">Mourad Oussalah</a>",
          "description": "With the multiplication of social media platforms, which offer anonymity,\neasy access and online community formation, and online debate, the issue of\nhate speech detection and tracking becomes a growing challenge to society,\nindividual, policy-makers and researchers. Despite efforts for leveraging\nautomatic techniques for automatic detection and monitoring, their performances\nare still far from satisfactory, which constantly calls for future research on\nthe issue. This paper provides a systematic review of literature in this field,\nwith a focus on natural language processing and deep learning technologies,\nhighlighting the terminology, processing pipeline, core methods employed, with\na focal point on deep learning architecture. From a methodological perspective,\nwe adopt PRISMA guideline of systematic review of the last 10 years literature\nfrom ACM Digital Library and Google Scholar. In the sequel, existing surveys,\nlimitations, and future research directions are extensively discussed.",
          "link": "http://arxiv.org/abs/2106.00742",
          "publishedOn": "2021-06-03T02:10:36.609Z",
          "wordCount": 577,
          "title": "A systematic review of Hate Speech automatic detection using Natural Language Processing. (arXiv:2106.00742v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00749",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zmigrod_R/0/1/0/all/0/1\">Ran Zmigrod</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vieira_T/0/1/0/all/0/1\">Tim Vieira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>",
          "description": "Weighted finite-state machines are a fundamental building block of NLP\nsystems. They have withstood the test of time -- from their early use in noisy\nchannel models in the 1990s up to modern-day neurally parameterized conditional\nrandom fields. This work examines the computation of higher-order derivatives\nwith respect to the normalization constant for weighted finite-state machines.\nWe provide a general algorithm for evaluating derivatives of all orders, which\nhas not been previously described in the literature. In the case of\nsecond-order derivatives, our scheme runs in the optimal $\\mathcal{O}(A^2 N^4)$\ntime where $A$ is the alphabet size and $N$ is the number of states. Our\nalgorithm is significantly faster than prior algorithms. Additionally, our\napproach leads to a significantly faster algorithm for computing second-order\nexpectations, such as covariance matrices and gradients of first-order\nexpectations.",
          "link": "http://arxiv.org/abs/2106.00749",
          "publishedOn": "2021-06-03T02:10:36.584Z",
          "wordCount": 553,
          "title": "Higher-order Derivatives of Weighted Finite-state Machines. (arXiv:2106.00749v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01183",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rajaee_S/0/1/0/all/0/1\">Sara Rajaee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pilehvar_M/0/1/0/all/0/1\">Mohammad Taher Pilehvar</a>",
          "description": "The representation degeneration problem in Contextual Word Representations\n(CWRs) hurts the expressiveness of the embedding space by forming an\nanisotropic cone where even unrelated words have excessively positive\ncorrelations. Existing techniques for tackling this issue require a learning\nprocess to re-train models with additional objectives and mostly employ a\nglobal assessment to study isotropy. Our quantitative analysis over isotropy\nshows that a local assessment could be more accurate due to the clustered\nstructure of CWRs. Based on this observation, we propose a local cluster-based\nmethod to address the degeneration issue in contextual embedding spaces. We\nshow that in clusters including punctuations and stop words, local dominant\ndirections encode structural information, removing which can improve CWRs\nperformance on semantic tasks. Moreover, we find that tense information in verb\nrepresentations dominates sense semantics. We show that removing dominant\ndirections of verb representations can transform the space to better suit\nsemantic applications. Our experiments demonstrate that the proposed\ncluster-based method can mitigate the degeneration problem on multiple tasks.",
          "link": "http://arxiv.org/abs/2106.01183",
          "publishedOn": "2021-06-03T02:10:35.822Z",
          "wordCount": 600,
          "title": "A Cluster-based Approach for Improving Isotropy in Contextual Embedding Space. (arXiv:2106.01183v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2010.10035",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Srikanth_N/0/1/0/all/0/1\">Neha Srikanth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junyi Jessy Li</a>",
          "description": "Much of modern-day text simplification research focuses on sentence-level\nsimplification, transforming original, more complex sentences into simplified\nversions. However, adding content can often be useful when difficult concepts\nand reasoning need to be explained. In this work, we present the first\ndata-driven study of content addition in text simplification, which we call\nelaborative simplification. We introduce a new annotated dataset of 1.3K\ninstances of elaborative simplification in the Newsela corpus, and analyze how\nentities, ideas, and concepts are elaborated through the lens of contextual\nspecificity. We establish baselines for elaboration generation using\nlarge-scale pre-trained language models, and demonstrate that considering\ncontextual specificity during generation can improve performance. Our results\nillustrate the complexities of elaborative simplification, suggesting many\ninteresting directions for future work.",
          "link": "http://arxiv.org/abs/2010.10035",
          "publishedOn": "2021-06-03T02:10:35.797Z",
          "wordCount": 591,
          "title": "Elaborative Simplification: Content Addition and Explanation Generation in Text Simplification. (arXiv:2010.10035v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01144",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Siyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Chujie Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demasi_O/0/1/0/all/0/1\">Orianna Demasi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabour_S/0/1/0/all/0/1\">Sahand Sabour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yong Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>",
          "description": "Emotional support is a crucial ability for many conversation scenarios,\nincluding social interactions, mental health support, and customer service\nchats. Following reasonable procedures and using various support skills can\nhelp to effectively provide support. However, due to the lack of a\nwell-designed task and corpora of effective emotional support conversations,\nresearch on building emotional support into dialog systems remains untouched.\nIn this paper, we define the Emotional Support Conversation (ESC) task and\npropose an ESC Framework, which is grounded on the Helping Skills Theory. We\nconstruct an Emotion Support Conversation dataset (ESConv) with rich annotation\n(especially support strategy) in a help-seeker and supporter mode. To ensure a\ncorpus of high-quality conversations that provide examples of effective\nemotional support, we take extensive effort to design training tutorials for\nsupporters and several mechanisms for quality control during data collection.\nFinally, we evaluate state-of-the-art dialog models with respect to the ability\nto provide emotional support. Our results show the importance of support\nstrategies in providing effective emotional support and the utility of ESConv\nin training more emotional support systems.",
          "link": "http://arxiv.org/abs/2106.01144",
          "publishedOn": "2021-06-03T02:10:35.792Z",
          "wordCount": 611,
          "title": "Towards Emotional Support Dialog Systems. (arXiv:2106.01144v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2012.01707",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kapanipathi_P/0/1/0/all/0/1\">Pavan Kapanipathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdelaziz_I/0/1/0/all/0/1\">Ibrahim Abdelaziz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravishankar_S/0/1/0/all/0/1\">Srinivas Ravishankar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roukos_S/0/1/0/all/0/1\">Salim Roukos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gray_A/0/1/0/all/0/1\">Alexander Gray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Astudillo_R/0/1/0/all/0/1\">Ramon Astudillo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_M/0/1/0/all/0/1\">Maria Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cornelio_C/0/1/0/all/0/1\">Cristina Cornelio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dana_S/0/1/0/all/0/1\">Saswati Dana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fokoue_A/0/1/0/all/0/1\">Achille Fokoue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_D/0/1/0/all/0/1\">Dinesh Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gliozzo_A/0/1/0/all/0/1\">Alfio Gliozzo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurajada_S/0/1/0/all/0/1\">Sairam Gurajada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karanam_H/0/1/0/all/0/1\">Hima Karanam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_N/0/1/0/all/0/1\">Naweed Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khandelwal_D/0/1/0/all/0/1\">Dinesh Khandelwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Young-Suk Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunyao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luus_F/0/1/0/all/0/1\">Francois Luus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makondo_N/0/1/0/all/0/1\">Ndivhuwo Makondo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mihindukulasooriya_N/0/1/0/all/0/1\">Nandana Mihindukulasooriya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naseem_T/0/1/0/all/0/1\">Tahira Naseem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neelam_S/0/1/0/all/0/1\">Sumit Neelam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Popa_L/0/1/0/all/0/1\">Lucian Popa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_R/0/1/0/all/0/1\">Revanth Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riegel_R/0/1/0/all/0/1\">Ryan Riegel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossiello_G/0/1/0/all/0/1\">Gaetano Rossiello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_U/0/1/0/all/0/1\">Udit Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhargav_G/0/1/0/all/0/1\">G P Shrivatsa Bhargav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_M/0/1/0/all/0/1\">Mo Yu</a>",
          "description": "Knowledge base question answering (KBQA)is an important task in Natural\nLanguage Processing. Existing approaches face significant challenges including\ncomplex question understanding, necessity for reasoning, and lack of large\nend-to-end training datasets. In this work, we propose Neuro-Symbolic Question\nAnswering (NSQA), a modular KBQA system, that leverages (1) Abstract Meaning\nRepresentation (AMR) parses for task-independent question understanding; (2) a\nsimple yet effective graph transformation approach to convert AMR parses into\ncandidate logical queries that are aligned to the KB; (3) a pipeline-based\napproach which integrates multiple, reusable modules that are trained\nspecifically for their individual tasks (semantic parser, entity\nandrelationship linkers, and neuro-symbolic reasoner) and do not require\nend-to-end training data. NSQA achieves state-of-the-art performance on two\nprominent KBQA datasets based on DBpedia (QALD-9 and LC-QuAD1.0). Furthermore,\nour analysis emphasizes that AMR is a powerful tool for KBQA systems.",
          "link": "http://arxiv.org/abs/2012.01707",
          "publishedOn": "2021-06-03T02:10:35.772Z",
          "wordCount": 662,
          "title": "Leveraging Abstract Meaning Representation for Knowledge Base Question Answering. (arXiv:2012.01707v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01071",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1\">Lixing Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pergola_G/0/1/0/all/0/1\">Gabriele Pergola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_L/0/1/0/all/0/1\">Lin Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1\">Deyu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yulan He</a>",
          "description": "Emotion detection in dialogues is challenging as it often requires the\nidentification of thematic topics underlying a conversation, the relevant\ncommonsense knowledge, and the intricate transition patterns between the\naffective states. In this paper, we propose a Topic-Driven Knowledge-Aware\nTransformer to handle the challenges above. We firstly design a topic-augmented\nlanguage model (LM) with an additional layer specialized for topic detection.\nThe topic-augmented LM is then combined with commonsense statements derived\nfrom a knowledge base based on the dialogue contextual information. Finally, a\ntransformer-based encoder-decoder architecture fuses the topical and\ncommonsense information, and performs the emotion label sequence prediction.\nThe model has been experimented on four datasets in dialogue emotion detection,\ndemonstrating its superiority empirically over the existing state-of-the-art\napproaches. Quantitative and qualitative results show that the model can\ndiscover topics which help in distinguishing emotion categories.",
          "link": "http://arxiv.org/abs/2106.01071",
          "publishedOn": "2021-06-03T02:10:35.737Z",
          "wordCount": 565,
          "title": "Topic-Driven and Knowledge-Aware Transformer for Dialogue Emotion Detection. (arXiv:2106.01071v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.04165",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1\">Pan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_R/0/1/0/all/0/1\">Ran Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1\">Shibiao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_L/0/1/0/all/0/1\">Liang Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Siyuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1\">Xiaodan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Song-Chun Zhu</a>",
          "description": "Geometry problem solving has attracted much attention in the NLP community\nrecently. The task is challenging as it requires abstract problem understanding\nand symbolic reasoning with axiomatic knowledge. However, current datasets are\neither small in scale or not publicly available. Thus, we construct a new\nlarge-scale benchmark, Geometry3K, consisting of 3,002 geometry problems with\ndense annotation in formal language. We further propose a novel geometry\nsolving approach with formal language and symbolic reasoning, called\nInterpretable Geometry Problem Solver (Inter-GPS). Inter-GPS first parses the\nproblem text and diagram into formal language automatically via rule-based text\nparsing and neural object detecting, respectively. Unlike implicit learning in\nexisting methods, Inter-GPS incorporates theorem knowledge as conditional rules\nand performs symbolic reasoning step by step. Also, a theorem predictor is\ndesigned to infer the theorem application sequence fed to the symbolic solver\nfor the more efficient and reasonable searching path. Extensive experiments on\nthe Geometry3K and GEOS datasets demonstrate that Inter-GPS achieves\nsignificant improvements over existing methods. The project with code and data\nis available at https://lupantech.github.io/inter-gps.",
          "link": "http://arxiv.org/abs/2105.04165",
          "publishedOn": "2021-06-03T02:10:35.660Z",
          "wordCount": 669,
          "title": "Inter-GPS: Interpretable Geometry Problem Solving with Formal Language and Symbolic Reasoning. (arXiv:2105.04165v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.15229",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aldarrab_N/0/1/0/all/0/1\">Nada Aldarrab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+May_J/0/1/0/all/0/1\">Jonathan May</a>",
          "description": "Decipherment of historical ciphers is a challenging problem. The language of\nthe target plaintext might be unknown, and ciphertext can have a lot of noise.\nState-of-the-art decipherment methods use beam search and a neural language\nmodel to score candidate plaintext hypotheses for a given cipher, assuming the\nplaintext language is known. We propose an end-to-end multilingual model for\nsolving simple substitution ciphers. We test our model on synthetic and real\nhistorical ciphers and show that our proposed method can decipher text without\nexplicit language identification while still being robust to noise.",
          "link": "http://arxiv.org/abs/2012.15229",
          "publishedOn": "2021-06-03T02:10:35.644Z",
          "wordCount": 541,
          "title": "Can Sequence-to-Sequence Models Crack Substitution Ciphers?. (arXiv:2012.15229v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01191",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Si_J/0/1/0/all/0/1\">Jiasheng Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1\">Deyu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tongzhe Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1\">Xingyu Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yulan He</a>",
          "description": "Fact verification is a challenging task that requires simultaneously\nreasoning and aggregating over multiple retrieved pieces of evidence to\nevaluate the truthfulness of a claim. Existing approaches typically (i) explore\nthe semantic interaction between the claim and evidence at different\ngranularity levels but fail to capture their topical consistency during the\nreasoning process, which we believe is crucial for verification; (ii) aggregate\nmultiple pieces of evidence equally without considering their implicit stances\nto the claim, thereby introducing spurious information. To alleviate the above\nissues, we propose a novel topic-aware evidence reasoning and stance-aware\naggregation model for more accurate fact verification, with the following four\nkey properties: 1) checking topical consistency between the claim and evidence;\n2) maintaining topical coherence among multiple pieces of evidence; 3) ensuring\nsemantic similarity between the global topic information and the semantic\nrepresentation of evidence; 4) aggregating evidence based on their implicit\nstances to the claim. Extensive experiments conducted on the two benchmark\ndatasets demonstrate the superiority of the proposed model over several\nstate-of-the-art approaches for fact verification. The source code can be\nobtained from https://github.com/jasenchn/TARSA.",
          "link": "http://arxiv.org/abs/2106.01191",
          "publishedOn": "2021-06-03T02:10:35.629Z",
          "wordCount": 620,
          "title": "Topic-Aware Evidence Reasoning and Stance-Aware Aggregation for Fact Verification. (arXiv:2106.01191v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2102.07926",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1\">Ziyang Luo</a>",
          "description": "With the success of pre-trained language models in recent years, more and\nmore researchers focus on opening the \"black box\" of these models. Following\nthis interest, we carry out a qualitative and quantitative analysis of\nconstituency grammar in attention heads of BERT and RoBERTa. We employ the\nsyntactic distance method to extract implicit constituency grammar from the\nattention weights of each head. Our results show that there exist heads that\ncan induce some grammar types much better than baselines, suggesting that some\nheads act as a proxy for constituency grammar. We also analyze how attention\nheads' constituency grammar inducing (CGI) ability changes after fine-tuning\nwith two kinds of tasks, including sentence meaning similarity (SMS) tasks and\nnatural language inference (NLI) tasks. Our results suggest that SMS tasks\ndecrease the average CGI ability of upper layers, while NLI tasks increase it.\nLastly, we investigate the connections between CGI ability and natural language\nunderstanding ability on QQP and MNLI tasks.",
          "link": "http://arxiv.org/abs/2102.07926",
          "publishedOn": "2021-06-03T02:10:35.618Z",
          "wordCount": 611,
          "title": "Have Attention Heads in BERT Learned Constituency Grammar?. (arXiv:2102.07926v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03229",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wen_H/0/1/0/all/0/1\">Haoyang Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferritto_A/0/1/0/all/0/1\">Anthony Ferritto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Florian_R/0/1/0/all/0/1\">Radu Florian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sil_A/0/1/0/all/0/1\">Avirup Sil</a>",
          "description": "Existing models on Machine Reading Comprehension (MRC) require complex model\narchitecture for effectively modeling long texts with paragraph representation\nand classification, thereby making inference computationally inefficient for\nproduction use. In this work, we propose VAULT: a light-weight and\nparallel-efficient paragraph representation for MRC based on contextualized\nrepresentation from long document input, trained using a new Gaussian\ndistribution-based objective that pays close attention to the partially correct\ninstances that are close to the ground-truth. We validate our VAULT\narchitecture showing experimental results on two benchmark MRC datasets that\nrequire long context modeling; one Wikipedia-based (Natural Questions (NQ)) and\nthe other on TechNotes (TechQA). VAULT can achieve comparable performance on NQ\nwith a state-of-the-art (SOTA) complex document modeling approach while being\n16 times faster, demonstrating the efficiency of our proposed model. We also\ndemonstrate that our model can also be effectively adapted to a completely\ndifferent domain -- TechQA -- with large improvement over a model fine-tuned on\na previously published large PLM.",
          "link": "http://arxiv.org/abs/2105.03229",
          "publishedOn": "2021-06-03T02:10:35.613Z",
          "wordCount": 627,
          "title": "VAULT: VAriable Unified Long Text Representation for Machine Reading Comprehension. (arXiv:2105.03229v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08050",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hanxiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Z/0/1/0/all/0/1\">Zihang Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+So_D/0/1/0/all/0/1\">David R. So</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1\">Quoc V. Le</a>",
          "description": "Transformers have become one of the most important architectural innovations\nin deep learning and have enabled many breakthroughs over the past few years.\nHere we propose a simple network architecture, gMLP, based on MLPs with gating,\nand show that it can perform as well as Transformers in key language and vision\napplications. Our comparisons show that self-attention is not critical for\nVision Transformers, as gMLP can achieve the same accuracy. For BERT, our model\nachieves parity with Transformers on pretraining perplexity and is better on\nsome downstream NLP tasks. On finetuning tasks where gMLP performs worse,\nmaking the gMLP model substantially larger can close the gap with Transformers.\nIn general, our experiments show that gMLP can scale as well as Transformers\nover increased data and compute.",
          "link": "http://arxiv.org/abs/2105.08050",
          "publishedOn": "2021-06-03T02:10:35.545Z",
          "wordCount": 587,
          "title": "Pay Attention to MLPs. (arXiv:2105.08050v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.14681",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Han_H/0/1/0/all/0/1\">Hyojung Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Indurthi_S/0/1/0/all/0/1\">Sathish Indurthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaidi_M/0/1/0/all/0/1\">Mohd Abbas Zaidi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakumarapu_N/0/1/0/all/0/1\">Nikhil Kumar Lakumarapu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1\">Beomseok Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sangha Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_C/0/1/0/all/0/1\">Chanwoo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_I/0/1/0/all/0/1\">Inchul Hwang</a>",
          "description": "Recently, simultaneous translation has gathered a lot of attention since it\nenables compelling applications such as subtitle translation for a live event\nor real-time video-call translation. Some of these translation applications\nallow editing of partial translation giving rise to re-translation approaches.\nThe current re-translation approaches are based on autoregressive sequence\ngeneration models (ReTA), which generate tar-get tokens in the (partial)\ntranslation sequentially. The multiple re-translations with sequential\ngeneration inReTAmodelslead to an increased inference time gap between the\nincoming source input and the corresponding target output as the source input\ngrows. Besides, due to the large number of inference operations involved, the\nReTA models are not favorable for resource-constrained devices. In this work,\nwe propose a faster re-translation system based on a non-autoregressive\nsequence generation model (FReTNA) to overcome the aforementioned limitations.\nWe evaluate the proposed model on multiple translation tasks and our model\nreduces the inference times by several orders and achieves a competitive\nBLEUscore compared to the ReTA and streaming (Wait-k) models.The proposed model\nreduces the average computation time by a factor of 20 when compared to the\nReTA model by incurring a small drop in the translation quality. It also\noutperforms the streaming-based Wait-k model both in terms of computation time\n(1.5 times lower) and translation quality.",
          "link": "http://arxiv.org/abs/2012.14681",
          "publishedOn": "2021-06-03T02:10:35.265Z",
          "wordCount": 678,
          "title": "Faster Re-translation Using Non-Autoregressive Model For Simultaneous Neural Machine Translation. (arXiv:2012.14681v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03654",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yong Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bach_N/0/1/0/all/0/1\">Nguyen Bach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhongqiang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1\">Kewei Tu</a>",
          "description": "Recent advances in Named Entity Recognition (NER) show that document-level\ncontexts can significantly improve model performance. In many application\nscenarios, however, such contexts are not available. In this paper, we propose\nto find external contexts of a sentence by retrieving and selecting a set of\nsemantically relevant texts through a search engine, with the original sentence\nas the query. We find empirically that the contextual representations computed\non the retrieval-based input view, constructed through the concatenation of a\nsentence and its external contexts, can achieve significantly improved\nperformance compared to the original input view based only on the sentence.\nFurthermore, we can improve the model performance of both input views by\nCooperative Learning, a training method that encourages the two input views to\nproduce similar contextual representations or output label distributions.\nExperiments show that our approach can achieve new state-of-the-art performance\non 8 NER data sets across 5 domains.",
          "link": "http://arxiv.org/abs/2105.03654",
          "publishedOn": "2021-06-03T02:10:35.258Z",
          "wordCount": 632,
          "title": "Improving Named Entity Recognition by External Context Retrieving and Cooperative Learning. (arXiv:2105.03654v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01186",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ginzburg_D/0/1/0/all/0/1\">Dvir Ginzburg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malkiel_I/0/1/0/all/0/1\">Itzik Malkiel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barkan_O/0/1/0/all/0/1\">Oren Barkan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caciularu_A/0/1/0/all/0/1\">Avi Caciularu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koenigstein_N/0/1/0/all/0/1\">Noam Koenigstein</a>",
          "description": "We present a novel model for the problem of ranking a collection of documents\naccording to their semantic similarity to a source (query) document. While the\nproblem of document-to-document similarity ranking has been studied, most\nmodern methods are limited to relatively short documents or rely on the\nexistence of \"ground-truth\" similarity labels. Yet, in most common real-world\ncases, similarity ranking is an unsupervised problem as similarity labels are\nunavailable. Moreover, an ideal model should not be restricted by documents'\nlength. Hence, we introduce SDR, a self-supervised method for document\nsimilarity that can be applied to documents of arbitrary length. Importantly,\nSDR can be effectively applied to extremely long documents, exceeding the 4,096\nmaximal token limits of Longformer. Extensive evaluations on large document\ndatasets show that SDR significantly outperforms its alternatives across all\nmetrics. To accelerate future research on unlabeled long document similarity\nranking, and as an additional contribution to the community, we herein publish\ntwo human-annotated test sets of long documents similarity evaluation. The SDR\ncode and datasets are publicly available.",
          "link": "http://arxiv.org/abs/2106.01186",
          "publishedOn": "2021-06-03T02:10:35.191Z",
          "wordCount": 605,
          "title": "Self-Supervised Document Similarity Ranking via Contextualized Language Models and Hierarchical Inference. (arXiv:2106.01186v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2005.01795",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Krishna_K/0/1/0/all/0/1\">Kundan Krishna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khosla_S/0/1/0/all/0/1\">Sopan Khosla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bigham_J/0/1/0/all/0/1\">Jeffrey P. Bigham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1\">Zachary C. Lipton</a>",
          "description": "Following each patient visit, physicians draft long semi-structured clinical\nsummaries called SOAP notes. While invaluable to clinicians and researchers,\ncreating digital SOAP notes is burdensome, contributing to physician burnout.\nIn this paper, we introduce the first complete pipelines to leverage deep\nsummarization models to generate these notes based on transcripts of\nconversations between physicians and patients. After exploring a spectrum of\nmethods across the extractive-abstractive spectrum, we propose Cluster2Sent, an\nalgorithm that (i) extracts important utterances relevant to each summary\nsection; (ii) clusters together related utterances; and then (iii) generates\none summary sentence per cluster. Cluster2Sent outperforms its purely\nabstractive counterpart by 8 ROUGE-1 points, and produces significantly more\nfactual and coherent sentences as assessed by expert human evaluators. For\nreproducibility, we demonstrate similar benefits on the publicly available AMI\ndataset. Our results speak to the benefits of structuring summaries into\nsections and annotating supporting evidence when constructing summarization\ncorpora.",
          "link": "http://arxiv.org/abs/2005.01795",
          "publishedOn": "2021-06-03T02:10:35.109Z",
          "wordCount": 642,
          "title": "Generating SOAP Notes from Doctor-Patient Conversations Using Modular Summarization Techniques. (arXiv:2005.01795v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01074",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thorne_J/0/1/0/all/0/1\">James Thorne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yazdani_M/0/1/0/all/0/1\">Majid Yazdani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saeidi_M/0/1/0/all/0/1\">Marzieh Saeidi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silvestri_F/0/1/0/all/0/1\">Fabrizio Silvestri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riedel_S/0/1/0/all/0/1\">Sebastian Riedel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Halevy_A/0/1/0/all/0/1\">Alon Halevy</a>",
          "description": "Neural models have shown impressive performance gains in answering queries\nfrom natural language text. However, existing works are unable to support\ndatabase queries, such as \"List/Count all female athletes who were born in 20th\ncentury\", which require reasoning over sets of relevant facts with operations\nsuch as join, filtering and aggregation. We show that while state-of-the-art\ntransformer models perform very well for small databases, they exhibit\nlimitations in processing noisy data, numerical operations, and queries that\naggregate facts. We propose a modular architecture to answer these\ndatabase-style queries over multiple spans from text and aggregating these at\nscale. We evaluate the architecture using WikiNLDB, a novel dataset for\nexploring such queries. Our architecture scales to databases containing\nthousands of facts whereas contemporary models are limited by how many facts\ncan be encoded. In direct comparison on small databases, our approach increases\noverall answer accuracy from 85% to 90%. On larger databases, our approach\nretains its accuracy whereas transformer baselines could not encode the\ncontext.",
          "link": "http://arxiv.org/abs/2106.01074",
          "publishedOn": "2021-06-03T02:10:35.041Z",
          "wordCount": 598,
          "title": "Database Reasoning Over Text. (arXiv:2106.01074v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01317",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yichen Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celikyilmaz_A/0/1/0/all/0/1\">Asli Celikyilmaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smolensky_P/0/1/0/all/0/1\">Paul Smolensky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soulos_P/0/1/0/all/0/1\">Paul Soulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_S/0/1/0/all/0/1\">Sudha Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palangi_H/0/1/0/all/0/1\">Hamid Palangi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fernandez_R/0/1/0/all/0/1\">Roland Fernandez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_C/0/1/0/all/0/1\">Caitlin Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>",
          "description": "Abstractive summarization, the task of generating a concise summary of input\ndocuments, requires: (1) reasoning over the source document to determine the\nsalient pieces of information scattered across the long document, and (2)\ncomposing a cohesive text by reconstructing these salient facts into a shorter\nsummary that faithfully reflects the complex relations connecting these facts.\nIn this paper, we adapt TP-TRANSFORMER (Schlag et al., 2019), an architecture\nthat enriches the original Transformer (Vaswani et al., 2017) with the\nexplicitly compositional Tensor Product Representation (TPR), for the task of\nabstractive summarization. The key feature of our model is a structural bias\nthat we introduce by encoding two separate representations for each token to\nrepresent the syntactic structure (with role vectors) and semantic content\n(with filler vectors) separately. The model then binds the role and filler\nvectors into the TPR as the layer output. We argue that the structured\nintermediate representations enable the model to take better control of the\ncontents (salient facts) and structures (the syntax that connects the facts)\nwhen generating the summary. Empirically, we show that our TP-TRANSFORMER\noutperforms the Transformer and the original TP-TRANSFORMER significantly on\nseveral abstractive summarization datasets based on both automatic and human\nevaluations. On several syntactic and semantic probing tasks, we demonstrate\nthe emergent structural information in the role vectors and improved syntactic\ninterpretability in the TPR layer outputs. Code and models are available at\nhttps://github.com/jiangycTarheel/TPT-Summ.",
          "link": "http://arxiv.org/abs/2106.01317",
          "publishedOn": "2021-06-03T02:10:35.036Z",
          "wordCount": 687,
          "title": "Enriching Transformers with Structured Tensor-Product Representations for Abstractive Summarization. (arXiv:2106.01317v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2010.16046",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_F/0/1/0/all/0/1\">Fuli Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiahao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yijia Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_B/0/1/0/all/0/1\">Bin Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Songfang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_L/0/1/0/all/0/1\">Luo Si</a>",
          "description": "Existing work in multilingual pretraining has demonstrated the potential of\ncross-lingual transferability by training a unified Transformer encoder for\nmultiple languages. However, much of this work only relies on the shared\nvocabulary and bilingual contexts to encourage the correlation across\nlanguages, which is loose and implicit for aligning the contextual\nrepresentations between languages. In this paper, we plug a cross-attention\nmodule into the Transformer encoder to explicitly build the interdependence\nbetween languages. It can effectively avoid the degeneration of predicting\nmasked words only conditioned on the context in its own language. More\nimportantly, when fine-tuning on downstream tasks, the cross-attention module\ncan be plugged in or out on-demand, thus naturally benefiting a wider range of\ncross-lingual tasks, from language understanding to generation.\n\nAs a result, the proposed cross-lingual model delivers new state-of-the-art\nresults on various cross-lingual understanding tasks of the XTREME benchmark,\ncovering text classification, sequence labeling, question answering, and\nsentence retrieval. For cross-lingual generation tasks, it also outperforms all\nexisting cross-lingual models and state-of-the-art Transformer variants on\nWMT14 English-to-German and English-to-French translation datasets, with gains\nof up to 1~2 BLEU.",
          "link": "http://arxiv.org/abs/2010.16046",
          "publishedOn": "2021-06-03T02:10:35.011Z",
          "wordCount": 659,
          "title": "VECO: Variable and Flexible Cross-lingual Pre-training for Language Understanding and Generation. (arXiv:2010.16046v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00872",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kaushik_D/0/1/0/all/0/1\">Divyansh Kaushik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiela_D/0/1/0/all/0/1\">Douwe Kiela</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1\">Zachary C. Lipton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yih_W/0/1/0/all/0/1\">Wen-tau Yih</a>",
          "description": "In adversarial data collection (ADC), a human workforce interacts with a\nmodel in real time, attempting to produce examples that elicit incorrect\npredictions. Researchers hope that models trained on these more challenging\ndatasets will rely less on superficial patterns, and thus be less brittle.\nHowever, despite ADC's intuitive appeal, it remains unclear when training on\nadversarial datasets produces more robust models. In this paper, we conduct a\nlarge-scale controlled study focused on question answering, assigning workers\nat random to compose questions either (i) adversarially (with a model in the\nloop); or (ii) in the standard fashion (without a model). Across a variety of\nmodels and datasets, we find that models trained on adversarial data usually\nperform better on other adversarial datasets but worse on a diverse collection\nof out-of-domain evaluation sets. Finally, we provide a qualitative analysis of\nadversarial (vs standard) data, identifying key differences and offering\nguidance for future research.",
          "link": "http://arxiv.org/abs/2106.00872",
          "publishedOn": "2021-06-03T02:10:35.006Z",
          "wordCount": 607,
          "title": "On the Efficacy of Adversarial Data Collection for Question Answering: Results from a Large-Scale Randomized Study. (arXiv:2106.00872v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01065",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gan_Y/0/1/0/all/0/1\">Yujian Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xinyun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Qiuping Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Purver_M/0/1/0/all/0/1\">Matthew Purver</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodward_J/0/1/0/all/0/1\">John R. Woodward</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1\">Jinxia Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_P/0/1/0/all/0/1\">Pengsheng Huang</a>",
          "description": "Recently, there has been significant progress in studying neural networks to\ntranslate text descriptions into SQL queries. Despite achieving good\nperformance on some public benchmarks, existing text-to-SQL models typically\nrely on the lexical matching between words in natural language (NL) questions\nand tokens in table schemas, which may render the models vulnerable to attacks\nthat break the schema linking mechanism. In this work, we investigate the\nrobustness of text-to-SQL models to synonym substitution. In particular, we\nintroduce Spider-Syn, a human-curated dataset based on the Spider benchmark for\ntext-to-SQL translation. NL questions in Spider-Syn are modified from Spider,\nby replacing their schema-related words with manually selected synonyms that\nreflect real-world question paraphrases. We observe that the accuracy\ndramatically drops by eliminating such explicit correspondence between NL\nquestions and table schemas, even if the synonyms are not adversarially\nselected to conduct worst-case adversarial attacks. Finally, we present two\ncategories of approaches to improve the model robustness. The first category of\napproaches utilizes additional synonym annotations for table schemas by\nmodifying the model input, while the second category is based on adversarial\ntraining. We demonstrate that both categories of approaches significantly\noutperform their counterparts without the defense, and the first category of\napproaches are more effective.",
          "link": "http://arxiv.org/abs/2106.01065",
          "publishedOn": "2021-06-03T02:10:34.996Z",
          "wordCount": 642,
          "title": "Towards Robustness of Text-to-SQL Models against Synonym Substitution. (arXiv:2106.01065v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00941",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiao_W/0/1/0/all/0/1\">Wenxiang Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhaopeng Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuming Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1\">Michael R. Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1\">Irwin King</a>",
          "description": "Self-training has proven effective for improving NMT performance by\naugmenting model training with synthetic parallel data. The common practice is\nto construct synthetic data based on a randomly sampled subset of large-scale\nmonolingual data, which we empirically show is sub-optimal. In this work, we\npropose to improve the sampling procedure by selecting the most informative\nmonolingual sentences to complement the parallel data. To this end, we compute\nthe uncertainty of monolingual sentences using the bilingual dictionary\nextracted from the parallel data. Intuitively, monolingual sentences with lower\nuncertainty generally correspond to easy-to-translate patterns which may not\nprovide additional gains. Accordingly, we design an uncertainty-based sampling\nstrategy to efficiently exploit the monolingual data for self-training, in\nwhich monolingual sentences with higher uncertainty would be sampled with\nhigher probability. Experimental results on large-scale WMT\nEnglish$\\Rightarrow$German and English$\\Rightarrow$Chinese datasets demonstrate\nthe effectiveness of the proposed approach. Extensive analyses suggest that\nemphasizing the learning on uncertain monolingual sentences by our approach\ndoes improve the translation quality of high-uncertainty sentences and also\nbenefits the prediction of low-frequency words at the target side.",
          "link": "http://arxiv.org/abs/2106.00941",
          "publishedOn": "2021-06-03T02:10:34.976Z",
          "wordCount": 626,
          "title": "Self-Training Sampling with Monolingual Data Uncertainty for Neural Machine Translation. (arXiv:2106.00941v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2012.15723",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1\">Tianyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fisch_A/0/1/0/all/0/1\">Adam Fisch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Danqi Chen</a>",
          "description": "The recent GPT-3 model (Brown et al., 2020) achieves remarkable few-shot\nperformance solely by leveraging a natural-language prompt and a few task\ndemonstrations as input context. Inspired by their findings, we study few-shot\nlearning in a more practical scenario, where we use smaller language models for\nwhich fine-tuning is computationally efficient. We present LM-BFF--better\nfew-shot fine-tuning of language models--a suite of simple and complementary\ntechniques for fine-tuning language models on a small number of annotated\nexamples. Our approach includes (1) prompt-based fine-tuning together with a\nnovel pipeline for automating prompt generation; and (2) a refined strategy for\ndynamically and selectively incorporating demonstrations into each context.\nFinally, we present a systematic evaluation for analyzing few-shot performance\non a range of NLP tasks, including classification and regression. Our\nexperiments demonstrate that our methods combine to dramatically outperform\nstandard fine-tuning procedures in this low resource setting, achieving up to\n30% absolute improvement, and 11% on average across all tasks. Our approach\nmakes minimal assumptions on task resources and domain expertise, and hence\nconstitutes a strong task-agnostic method for few-shot learning.",
          "link": "http://arxiv.org/abs/2012.15723",
          "publishedOn": "2021-06-03T02:10:34.953Z",
          "wordCount": 645,
          "title": "Making Pre-trained Language Models Better Few-shot Learners. (arXiv:2012.15723v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00891",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zhiwen Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_H/0/1/0/all/0/1\">Hrishikesh Kulkarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Grace Hui Yang</a>",
          "description": "Many task-oriented dialogue systems use deep reinforcement learning (DRL) to\nlearn policies that respond to the user appropriately and complete the tasks\nsuccessfully. Training DRL agents with diverse dialogue trajectories prepare\nthem well for rare user requests and unseen situations. One effective\ndiversification method is to let the agent interact with a diverse set of\nlearned user models. However, trajectories created by these artificial user\nmodels may contain generation errors, which can quickly propagate into the\nagent's policy. It is thus important to control the quality of the\ndiversification and resist the noise. In this paper, we propose a novel\ndialogue diversification method for task-oriented dialogue systems trained in\nsimulators. Our method, Intermittent Short Extension Ensemble (I-SEE),\nconstrains the intensity to interact with an ensemble of diverse user models\nand effectively controls the quality of the diversification. Evaluations on the\nMultiwoz dataset show that I-SEE successfully boosts the performance of several\nstate-of-the-art DRL dialogue agents.",
          "link": "http://arxiv.org/abs/2106.00891",
          "publishedOn": "2021-06-03T02:10:34.937Z",
          "wordCount": 588,
          "title": "High-Quality Diversification for Task-Oriented Dialogue Systems. (arXiv:2106.00891v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01044",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+White_J/0/1/0/all/0/1\">Jennifer C. White</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>",
          "description": "Since language models are used to model a wide variety of languages, it is\nnatural to ask whether the neural architectures used for the task have\ninductive biases towards modeling particular types of languages. Investigation\nof these biases has proved complicated due to the many variables that appear in\nthe experimental setup. Languages vary in many typological dimensions, and it\nis difficult to single out one or two to investigate without the others acting\nas confounders. We propose a novel method for investigating the inductive\nbiases of language models using artificial languages. These languages are\nconstructed to allow us to create parallel corpora across languages that differ\nonly in the typological feature being investigated, such as word order. We then\nuse them to train and test language models. This constitutes a fully controlled\ncausal framework, and demonstrates how grammar engineering can serve as a\nuseful tool for analyzing neural models. Using this method, we find that\ncommonly used neural architectures exhibit different inductive biases: LSTMs\ndisplay little preference with respect to word ordering, while transformers\ndisplay a clear preference for some orderings over others. Further, we find\nthat neither the inductive bias of the LSTM nor that of the transformer appears\nto reflect any tendencies that we see in attested natural languages.",
          "link": "http://arxiv.org/abs/2106.01044",
          "publishedOn": "2021-06-03T02:10:34.923Z",
          "wordCount": 647,
          "title": "Examining the Inductive Bias of Neural Language Models with Artificial Languages. (arXiv:2106.01044v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01195",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chakrabarty_T/0/1/0/all/0/1\">Tuhin Chakrabarty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_D/0/1/0/all/0/1\">Debanjan Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poliak_A/0/1/0/all/0/1\">Adam Poliak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muresan_S/0/1/0/all/0/1\">Smaranda Muresan</a>",
          "description": "We introduce a collection of recognizing textual entailment (RTE) datasets\nfocused on figurative language. We leverage five existing datasets annotated\nfor a variety of figurative language -- simile, metaphor, and irony -- and\nframe them into over 12,500 RTE examples.We evaluate how well state-of-the-art\nmodels trained on popular RTE datasets capture different aspects of figurative\nlanguage. Our results and analyses indicate that these models might not\nsufficiently capture figurative language, struggling to perform pragmatic\ninference and reasoning about world knowledge. Ultimately, our datasets provide\na challenging testbed for evaluating RTE models.",
          "link": "http://arxiv.org/abs/2106.01195",
          "publishedOn": "2021-06-03T02:10:34.917Z",
          "wordCount": 522,
          "title": "Figurative Language in Recognizing Textual Entailment. (arXiv:2106.01195v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00893",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Griffith_K/0/1/0/all/0/1\">Kaden Griffith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalita_J/0/1/0/all/0/1\">Jugal Kalita</a>",
          "description": "This paper outlines the use of Transformer networks trained to translate math\nword problems to equivalent arithmetic expressions in infix, prefix, and\npostfix notations. We compare results produced by many neural configurations\nand find that most configurations outperform previously reported approaches on\nthree of four datasets with significant increases in accuracy of over 20\npercentage points. The best neural approaches boost accuracy by 30% when\ncompared to the previous state-of-the-art on some datasets.",
          "link": "http://arxiv.org/abs/2106.00893",
          "publishedOn": "2021-06-03T02:10:34.891Z",
          "wordCount": 511,
          "title": "Solving Arithmetic Word Problems with Transformers and Preprocessing of Problem Text. (arXiv:2106.00893v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2006.01414",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yong Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1\">Kewei Tu</a>",
          "description": "This paper presents the system used in our submission to the \\textit{IWPT\n2020 Shared Task}. Our system is a graph-based parser with second-order\ninference. For the low-resource Tamil corpus, we specially mixed the training\ndata of Tamil with other languages and significantly improved the performance\nof Tamil. Due to our misunderstanding of the submission requirements, we\nsubmitted graphs that are not connected, which makes our system only rank\n\\textbf{6th} over 10 teams. However, after we fixed this problem, our system is\n0.6 ELAS higher than the team that ranked \\textbf{1st} in the official results.",
          "link": "http://arxiv.org/abs/2006.01414",
          "publishedOn": "2021-06-03T02:10:34.741Z",
          "wordCount": 590,
          "title": "Enhanced Universal Dependency Parsing with Second-Order Inference and Mixture of Training Data. (arXiv:2006.01414v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.05395",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhaofeng Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1\">Hao Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>",
          "description": "For natural language processing systems, two kinds of evidence support the\nuse of text representations from neural language models \"pretrained\" on large\nunannotated corpora: performance on application-inspired benchmarks (Peters et\nal., 2018, inter alia), and the emergence of syntactic abstractions in those\nrepresentations (Tenney et al., 2019, inter alia). On the other hand, the lack\nof grounded supervision calls into question how well these representations can\never capture meaning (Bender and Koller, 2020). We apply novel probes to recent\nlanguage models -- specifically focusing on predicate-argument structure as\noperationalized by semantic dependencies (Ivanova et al., 2012) -- and find\nthat, unlike syntax, semantics is not brought to the surface by today's\npretrained models. We then use convolutional graph encoders to explicitly\nincorporate semantic parses into task-specific finetuning, yielding benefits to\nnatural language understanding (NLU) tasks in the GLUE benchmark. This approach\ndemonstrates the potential for general-purpose (rather than task-specific)\nlinguistic supervision, above and beyond conventional pretraining and\nfinetuning. Several diagnostics help to localize the benefits of our approach.",
          "link": "http://arxiv.org/abs/2012.05395",
          "publishedOn": "2021-06-03T02:10:34.736Z",
          "wordCount": 638,
          "title": "Infusing Finetuning with Semantic Dependencies. (arXiv:2012.05395v4 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10747",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hinsvark_A/0/1/0/all/0/1\">Arthur Hinsvark</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Delworth_N/0/1/0/all/0/1\">Natalie Delworth</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Rio_M/0/1/0/all/0/1\">Miguel Del Rio</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+McNamara_Q/0/1/0/all/0/1\">Quinten McNamara</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1\">Joshua Dong</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Westerman_R/0/1/0/all/0/1\">Ryan Westerman</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Michelle Huang</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Palakapilly_J/0/1/0/all/0/1\">Joseph Palakapilly</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Drexler_J/0/1/0/all/0/1\">Jennifer Drexler</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Pirkin_I/0/1/0/all/0/1\">Ilya Pirkin</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Bhandari_N/0/1/0/all/0/1\">Nishchal Bhandari</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Jette_M/0/1/0/all/0/1\">Miguel Jette</a> (1) ((1) Rev.com)",
          "description": "Automatic Speech Recognition (ASR) systems generalize poorly on accented\nspeech. The phonetic and linguistic variability of accents present hard\nchallenges for ASR systems today in both data collection and modeling\nstrategies. The resulting bias in ASR performance across accents comes at a\ncost to both users and providers of ASR.\n\nWe present a survey of current promising approaches to accented speech\nrecognition and highlight the key challenges in the space. Approaches mostly\nfocus on single model generalization and accent feature engineering. Among the\nchallenges, lack of a standard benchmark makes research and comparison\nespecially difficult.",
          "link": "http://arxiv.org/abs/2104.10747",
          "publishedOn": "2021-06-03T02:10:34.730Z",
          "wordCount": 583,
          "title": "Accented Speech Recognition: A Survey. (arXiv:2104.10747v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1911.01542",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Heimerl_F/0/1/0/all/0/1\">Florian Heimerl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kralj_C/0/1/0/all/0/1\">Christoph Kralj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moller_T/0/1/0/all/0/1\">Torsten M&#xf6;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gleicher_M/0/1/0/all/0/1\">Michael Gleicher</a>",
          "description": "This paper introduces embComp, a novel approach for comparing two embeddings\nthat capture the similarity between objects, such as word and document\nembeddings. We survey scenarios where comparing these embedding spaces is\nuseful. From those scenarios, we derive common tasks, introduce visual analysis\nmethods that support these tasks, and combine them into a comprehensive system.\nOne of embComp's central features are overview visualizations that are based on\nmetrics for measuring differences in the local structure around objects.\nSummarizing these local metrics over the embeddings provides global overviews\nof similarities and differences. Detail views allow comparison of the local\nstructure around selected objects and relating this local information to the\nglobal views. Integrating and connecting all of these components, embComp\nsupports a range of analysis workflows that help understand similarities and\ndifferences between embedding spaces. We assess our approach by applying it in\nseveral use cases, including understanding corpora differences via word vector\nembeddings, and understanding algorithmic differences in generating embeddings.",
          "link": "http://arxiv.org/abs/1911.01542",
          "publishedOn": "2021-06-03T02:10:34.703Z",
          "wordCount": 628,
          "title": "embComp: Visual Interactive Comparison of Vector Embeddings. (arXiv:1911.01542v2 [cs.HC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.15045",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_S/0/1/0/all/0/1\">Sheng Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baevski_A/0/1/0/all/0/1\">Alexei Baevski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morcos_A/0/1/0/all/0/1\">Ari S. Morcos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keutzer_K/0/1/0/all/0/1\">Kurt Keutzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Auli_M/0/1/0/all/0/1\">Michael Auli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiela_D/0/1/0/all/0/1\">Douwe Kiela</a>",
          "description": "We demonstrate that transformers obtain impressive performance even when some\nof the layers are randomly initialized and never updated. Inspired by old and\nwell-established ideas in machine learning, we explore a variety of non-linear\n\"reservoir\" layers interspersed with regular transformer layers, and show\nimprovements in wall-clock compute time until convergence, as well as overall\nperformance, on various machine translation and (masked) language modelling\ntasks.",
          "link": "http://arxiv.org/abs/2012.15045",
          "publishedOn": "2021-06-03T02:10:34.692Z",
          "wordCount": 518,
          "title": "Reservoir Transformers. (arXiv:2012.15045v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.09696",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mhamdi_M/0/1/0/all/0/1\">Meryem M&#x27;hamdi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Doo Soon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dernoncourt_F/0/1/0/all/0/1\">Franck Dernoncourt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1\">Trung Bui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+May_J/0/1/0/all/0/1\">Jonathan May</a>",
          "description": "Multilingual models, such as M-BERT and XLM-R, have gained increasing\npopularity, due to their zero-shot cross-lingual transfer learning\ncapabilities. However, their generalization ability is still inconsistent for\ntypologically diverse languages and across different benchmarks. Recently,\nmeta-learning has garnered attention as a promising technique for enhancing\ntransfer learning under low-resource scenarios: particularly for cross-lingual\ntransfer in Natural Language Understanding (NLU). In this work, we propose\nX-METRA-ADA, a cross-lingual MEta-TRAnsfer learning ADAptation approach for\nNLU. Our approach adapts MAML, an optimization-based meta-learning approach, to\nlearn to adapt to new languages. We extensively evaluate our framework on two\nchallenging cross-lingual NLU tasks: multilingual task-oriented dialog and\ntypologically diverse question answering. We show that our approach outperforms\nnaive fine-tuning, reaching competitive performance on both tasks for most\nlanguages. Our analysis reveals that X-METRA-ADA can leverage limited data for\nfaster adaptation.",
          "link": "http://arxiv.org/abs/2104.09696",
          "publishedOn": "2021-06-03T02:10:34.687Z",
          "wordCount": 611,
          "title": "X-METRA-ADA: Cross-lingual Meta-Transfer Learning Adaptation to Natural Language Understanding and Question Answering. (arXiv:2104.09696v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.01785",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdul_Mageed_M/0/1/0/all/0/1\">Muhammad Abdul-Mageed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elmadany_A/0/1/0/all/0/1\">AbdelRahim Elmadany</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagoudi_E/0/1/0/all/0/1\">El Moatez Billah Nagoudi</a>",
          "description": "Pre-trained language models (LMs) are currently integral to many natural\nlanguage processing systems. Although multilingual LMs were also introduced to\nserve many languages, these have limitations such as being costly at inference\ntime and the size and diversity of non-English data involved in their\npre-training. We remedy these issues for a collection of diverse Arabic\nvarieties by introducing two powerful deep bidirectional transformer-based\nmodels, ARBERT and MARBERT. To evaluate our models, we also introduce ARLUE, a\nnew benchmark for multi-dialectal Arabic language understanding evaluation.\nARLUE is built using $42$ datasets targeting six different task clusters,\nallowing us to offer a series of standardized experiments under rich\nconditions. When fine-tuned on ARLUE, our models collectively achieve new\nstate-of-the-art results across the majority of tasks (37 out of 48\nclassification tasks, on the 42 datasets). Our best model acquires the highest\nARLUE score (77.40) across all six task clusters, outperforming all other\nmodels including XLM-R Large (~ 3.4 x larger size). Our models are publicly\navailable at https://github.com/UBC-NLP/marbert and ARLUE will be released\nthrough the same repository.",
          "link": "http://arxiv.org/abs/2101.01785",
          "publishedOn": "2021-06-03T02:10:34.671Z",
          "wordCount": 645,
          "title": "ARBERT & MARBERT: Deep Bidirectional Transformers for Arabic. (arXiv:2101.01785v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.01378",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Junbo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiwen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yongqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1\">Zhiyong Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1\">Qiong Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yukai Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Ke Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Povey_D/0/1/0/all/0/1\">Daniel Povey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yujun Wang</a>",
          "description": "This paper introduces a new open-source speech corpus named \"speechocean762\"\ndesigned for pronunciation assessment use, consisting of 5000 English\nutterances from 250 non-native speakers, where half of the speakers are\nchildren. Five experts annotated each of the utterances at sentence-level,\nword-level and phoneme-level. A baseline system is released in open source to\nillustrate the phoneme-level pronunciation assessment workflow on this corpus.\nThis corpus is allowed to be used freely for commercial and non-commercial\npurposes. It is available for free download from OpenSLR, and the corresponding\nbaseline system is published in the Kaldi speech recognition toolkit.",
          "link": "http://arxiv.org/abs/2104.01378",
          "publishedOn": "2021-06-03T02:10:34.665Z",
          "wordCount": 580,
          "title": "speechocean762: An Open-Source Non-native English Speech Corpus For Pronunciation Assessment. (arXiv:2104.01378v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.02172",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pimentel_T/0/1/0/all/0/1\">Tiago Pimentel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maudslay_R/0/1/0/all/0/1\">Rowan Hall Maudslay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blasi_D/0/1/0/all/0/1\">Dami&#xe1;n Blasi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>",
          "description": "Lexical ambiguity is widespread in language, allowing for the reuse of\neconomical word forms and therefore making language more efficient. If\nambiguous words cannot be disambiguated from context, however, this gain in\nefficiency might make language less clear -- resulting in frequent\nmiscommunication. For a language to be clear and efficiently encoded, we posit\nthat the lexical ambiguity of a word type should correlate with how much\ninformation context provides about it, on average. To investigate whether this\nis the case, we operationalise the lexical ambiguity of a word as the entropy\nof meanings it can take, and provide two ways to estimate this -- one which\nrequires human annotation (using WordNet), and one which does not (using BERT),\nmaking it readily applicable to a large number of languages. We validate these\nmeasures by showing that, on six high-resource languages, there are significant\nPearson correlations between our BERT-based estimate of ambiguity and the\nnumber of synonyms a word has in WordNet (e.g. $\\rho = 0.40$ in English). We\nthen test our main hypothesis -- that a word's lexical ambiguity should\nnegatively correlate with its contextual uncertainty -- and find significant\ncorrelations on all 18 typologically diverse languages we analyse. This\nsuggests that, in the presence of ambiguity, speakers compensate by making\ncontexts more informative.",
          "link": "http://arxiv.org/abs/2010.02172",
          "publishedOn": "2021-06-03T02:10:34.659Z",
          "wordCount": 692,
          "title": "Speakers Fill Lexical Semantic Gaps with Context. (arXiv:2010.02172v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.08330",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yong Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bach_N/0/1/0/all/0/1\">Nguyen Bach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhongqiang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1\">Kewei Tu</a>",
          "description": "Recent work proposes a family of contextual embeddings that significantly\nimproves the accuracy of sequence labelers over non-contextual embeddings.\nHowever, there is no definite conclusion on whether we can build better\nsequence labelers by combining different kinds of embeddings in various\nsettings. In this paper, we conduct extensive experiments on 3 tasks over 18\ndatasets and 8 languages to study the accuracy of sequence labeling with\nvarious embedding concatenations and make three observations: (1) concatenating\nmore embedding variants leads to better accuracy in rich-resource and\ncross-domain settings and some conditions of low-resource settings; (2)\nconcatenating additional contextual sub-word embeddings with contextual\ncharacter embeddings hurts the accuracy in extremely low-resource settings; (3)\nbased on the conclusion of (1), concatenating additional similar contextual\nembeddings cannot lead to further improvements. We hope these conclusions can\nhelp people build stronger sequence labelers in various settings.",
          "link": "http://arxiv.org/abs/2009.08330",
          "publishedOn": "2021-06-03T02:10:34.650Z",
          "wordCount": 620,
          "title": "More Embeddings, Better Sequence Labelers?. (arXiv:2009.08330v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.00262",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nishikawa_S/0/1/0/all/0/1\">Sosuke Nishikawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ri_R/0/1/0/all/0/1\">Ryokan Ri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsuruoka_Y/0/1/0/all/0/1\">Yoshimasa Tsuruoka</a>",
          "description": "Unsupervised cross-lingual word embedding (CLWE) methods learn a linear\ntransformation matrix that maps two monolingual embedding spaces that are\nseparately trained with monolingual corpora. This method relies on the\nassumption that the two embedding spaces are structurally similar, which does\nnot necessarily hold true in general. In this paper, we argue that using a\npseudo-parallel corpus generated by an unsupervised machine translation model\nfacilitates the structural similarity of the two embedding spaces and improves\nthe quality of CLWEs in the unsupervised mapping method. We show that our\napproach outperforms other alternative approaches given the same amount of\ndata, and, through detailed analysis, we show that data augmentation with the\npseudo data from unsupervised machine translation is especially effective for\nmapping-based CLWEs because (1) the pseudo data makes the source and target\ncorpora (partially) parallel; (2) the pseudo data contains information on the\noriginal language that helps to learn similar embedding spaces between the\nsource and target languages.",
          "link": "http://arxiv.org/abs/2006.00262",
          "publishedOn": "2021-06-03T02:10:34.629Z",
          "wordCount": 623,
          "title": "Data Augmentation with Unsupervised Machine Translation Improvesthe Structural Similarity of Cross-lingual Word Embeddings. (arXiv:2006.00262v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.14862",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Si Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1\">Yingzhuo Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhenghao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Chenyan Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaitao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_J/0/1/0/all/0/1\">Jie Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bennett_P/0/1/0/all/0/1\">Paul Bennett</a>",
          "description": "The effectiveness of Neural Information Retrieval (Neu-IR) often depends on a\nlarge scale of in-domain relevance training signals, which are not always\navailable in real-world ranking scenarios. To democratize the benefits of\nNeu-IR, this paper presents MetaAdaptRank, a domain adaptive learning method\nthat generalizes Neu-IR models from label-rich source domains to few-shot\ntarget domains. Drawing on source-domain massive relevance supervision,\nMetaAdaptRank contrastively synthesizes a large number of weak supervision\nsignals for target domains and meta-learns to reweight these synthetic \"weak\"\ndata based on their benefits to the target-domain ranking accuracy of Neu-IR\nmodels. Experiments on three TREC benchmarks in the web, news, and biomedical\ndomains show that MetaAdaptRank significantly improves the few-shot ranking\naccuracy of Neu-IR models. Further analyses indicate that MetaAdaptRank thrives\nfrom both its contrastive weak data synthesis and meta-reweighted data\nselection. The code and data of this paper can be obtained from\nhttps://github.com/thunlp/MetaAdaptRank.",
          "link": "http://arxiv.org/abs/2012.14862",
          "publishedOn": "2021-06-03T02:10:34.623Z",
          "wordCount": 625,
          "title": "Few-Shot Text Ranking with Meta Adapted Synthetic Weak Supervision. (arXiv:2012.14862v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.00121",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hambardzumyan_K/0/1/0/all/0/1\">Karen Hambardzumyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khachatrian_H/0/1/0/all/0/1\">Hrant Khachatrian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+May_J/0/1/0/all/0/1\">Jonathan May</a>",
          "description": "Transfer learning from pretrained language models recently became the\ndominant approach for solving many NLP tasks. A common approach to transfer\nlearning for multiple tasks that maximize parameter sharing trains one or more\ntask-specific layers on top of the language model. In this paper, we present an\nalternative approach based on adversarial reprogramming, which extends earlier\nwork on automatic prompt generation. Adversarial reprogramming attempts to\nlearn task-specific word embeddings that, when concatenated to the input text,\ninstruct the language model to solve the specified task. Using up to 25K\ntrainable parameters per task, this approach outperforms all existing methods\nwith up to 25M trainable parameters on the public leaderboard of the GLUE\nbenchmark. Our method, initialized with task-specific human-readable prompts,\nalso works in a few-shot setting, outperforming GPT-3 on two SuperGLUE tasks\nwith just 32 training samples.",
          "link": "http://arxiv.org/abs/2101.00121",
          "publishedOn": "2021-06-03T02:10:34.618Z",
          "wordCount": 587,
          "title": "WARP: Word-level Adversarial ReProgramming. (arXiv:2101.00121v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.07767",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoon_W/0/1/0/all/0/1\">Wonjin Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeo_Y/0/1/0/all/0/1\">Yoon Sun Yeo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_M/0/1/0/all/0/1\">Minbyul Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_B/0/1/0/all/0/1\">Bong-Jun Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1\">Jaewoo Kang</a>",
          "description": "By harnessing pre-trained language models, summarization models had rapid\nprogress recently. However, the models are mainly assessed by automatic\nevaluation metrics such as ROUGE. Although ROUGE is known for having a positive\ncorrelation with human evaluation scores, it has been criticized for its\nvulnerability and the gap between actual qualities. In this paper, we compare\nthe generated summaries from recent LM, BART, and the reference summaries from\na benchmark dataset, CNN/DM, using a crowd-sourced human evaluation metric.\nInterestingly, model-generated summaries receive higher scores relative to\nreference summaries. Stemming from our experimental results, we first argue the\nintrinsic characteristics of the CNN/DM dataset, the progress of pre-trained\nlanguage models, and their ability to generalize on the training data. Finally,\nwe share our insights into the model-generated summaries and presents our\nthought on learning methods for abstractive summarization.",
          "link": "http://arxiv.org/abs/2002.07767",
          "publishedOn": "2021-06-03T02:10:34.612Z",
          "wordCount": 657,
          "title": "Learning by Semantic Similarity Makes Abstractive Summarization Better. (arXiv:2002.07767v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01223",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1\">Hang Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_T/0/1/0/all/0/1\">Tao Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1\">Junqi Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1\">Qipeng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>",
          "description": "Named Entity Recognition (NER) is the task of identifying spans that\nrepresent entities in sentences. Whether the entity spans are nested or\ndiscontinuous, the NER task can be categorized into the flat NER, nested NER,\nand discontinuous NER subtasks. These subtasks have been mainly solved by the\ntoken-level sequence labelling or span-level classification. However, these\nsolutions can hardly tackle the three kinds of NER subtasks concurrently. To\nthat end, we propose to formulate the NER subtasks as an entity span sequence\ngeneration task, which can be solved by a unified sequence-to-sequence\n(Seq2Seq) framework. Based on our unified framework, we can leverage the\npre-trained Seq2Seq model to solve all three kinds of NER subtasks without the\nspecial design of the tagging schema or ways to enumerate spans. We exploit\nthree types of entity representations to linearize entities into a sequence.\nOur proposed framework is easy-to-implement and achieves state-of-the-art\n(SoTA) or near SoTA performance on eight English NER datasets, including two\nflat NER datasets, three nested NER datasets, and three discontinuous NER\ndatasets.",
          "link": "http://arxiv.org/abs/2106.01223",
          "publishedOn": "2021-06-03T02:10:34.607Z",
          "wordCount": 610,
          "title": "A Unified Generative Framework for Various NER Subtasks. (arXiv:2106.01223v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2012.15682",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1\">Mengjie Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shareghi_E/0/1/0/all/0/1\">Ehsan Shareghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1\">Ivan Vuli&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reichart_R/0/1/0/all/0/1\">Roi Reichart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korhonen_A/0/1/0/all/0/1\">Anna Korhonen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1\">Hinrich Sch&#xfc;tze</a>",
          "description": "Few-shot crosslingual transfer has been shown to outperform its zero-shot\ncounterpart with pretrained encoders like multilingual BERT. Despite its\ngrowing popularity, little to no attention has been paid to standardizing and\nanalyzing the design of few-shot experiments. In this work, we highlight a\nfundamental risk posed by this shortcoming, illustrating that the model\nexhibits a high degree of sensitivity to the selection of few shots. We conduct\na large-scale experimental study on 40 sets of sampled few shots for six\ndiverse NLP tasks across up to 40 languages. We provide an analysis of success\nand failure cases of few-shot transfer, which highlights the role of lexical\nfeatures. Additionally, we show that a straightforward full model finetuning\napproach is quite effective for few-shot transfer, outperforming several\nstate-of-the-art few-shot approaches. As a step towards standardizing few-shot\ncrosslingual experimental designs, we make our sampled few shots publicly\navailable.",
          "link": "http://arxiv.org/abs/2012.15682",
          "publishedOn": "2021-06-03T02:10:34.591Z",
          "wordCount": 617,
          "title": "A Closer Look at Few-Shot Crosslingual Transfer: The Choice of Shots Matters. (arXiv:2012.15682v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01087",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meister_C/0/1/0/all/0/1\">Clara Meister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lazov_S/0/1/0/all/0/1\">Stefan Lazov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Augenstein_I/0/1/0/all/0/1\">Isabelle Augenstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>",
          "description": "Sparse attention has been claimed to increase model interpretability under\nthe assumption that it highlights influential inputs. Yet the attention\ndistribution is typically over representations internal to the model rather\nthan the inputs themselves, suggesting this assumption may not have merit. We\nbuild on the recent work exploring the interpretability of attention; we design\na set of experiments to help us understand how sparsity affects our ability to\nuse attention as an explainability tool. On three text classification tasks, we\nverify that only a weak relationship between inputs and co-indexed intermediate\nrepresentations exists -- under sparse attention and otherwise. Further, we do\nnot find any plausible mappings from sparse attention distributions to a sparse\nset of influential inputs through other avenues. Rather, we observe in this\nsetting that inducing sparsity may make it less plausible that attention can be\nused as a tool for understanding model behavior.",
          "link": "http://arxiv.org/abs/2106.01087",
          "publishedOn": "2021-06-03T02:10:34.550Z",
          "wordCount": 573,
          "title": "Is Sparse Attention more Interpretable?. (arXiv:2106.01087v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2101.00403",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hofmann_V/0/1/0/all/0/1\">Valentin Hofmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pierrehumbert_J/0/1/0/all/0/1\">Janet B. Pierrehumbert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1\">Hinrich Sch&#xfc;tze</a>",
          "description": "How does the input segmentation of pretrained language models (PLMs) affect\ntheir interpretations of complex words? We present the first study\ninvestigating this question, taking BERT as the example PLM and focusing on its\nsemantic representations of English derivatives. We show that PLMs can be\ninterpreted as serial dual-route models, i.e., the meanings of complex words\nare either stored or else need to be computed from the subwords, which implies\nthat maximally meaningful input tokens should allow for the best generalization\non new words. This hypothesis is confirmed by a series of semantic probing\ntasks on which DelBERT (Derivation leveraging BERT), a model with derivational\ninput segmentation, substantially outperforms BERT with WordPiece segmentation.\nOur results suggest that the generalization capabilities of PLMs could be\nfurther improved if a morphologically-informed vocabulary of input tokens were\nused.",
          "link": "http://arxiv.org/abs/2101.00403",
          "publishedOn": "2021-06-03T02:10:34.544Z",
          "wordCount": 608,
          "title": "Superbizarre Is Not Superb: Derivational Morphology Improves BERT's Interpretation of Complex Words. (arXiv:2101.00403v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03142",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Awasthi_A/0/1/0/all/0/1\">Abhijeet Awasthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kansal_A/0/1/0/all/0/1\">Aman Kansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarawagi_S/0/1/0/all/0/1\">Sunita Sarawagi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jyothi_P/0/1/0/all/0/1\">Preethi Jyothi</a>",
          "description": "We consider the task of personalizing ASR models while being constrained by a\nfixed budget on recording speaker-specific utterances. Given a speaker and an\nASR model, we propose a method of identifying sentences for which the speaker's\nutterances are likely to be harder for the given ASR model to recognize. We\nassume a tiny amount of speaker-specific data to learn phoneme-level error\nmodels which help us select such sentences. We show that speaker's utterances\non the sentences selected using our error model indeed have larger error rates\nwhen compared to speaker's utterances on randomly selected sentences. We find\nthat fine-tuning the ASR model on the sentence utterances selected with the\nhelp of error models yield higher WER improvements in comparison to fine-tuning\non an equal number of randomly selected sentence utterances. Thus, our method\nprovides an efficient way of collecting speaker utterances under budget\nconstraints for personalizing ASR models.",
          "link": "http://arxiv.org/abs/2103.03142",
          "publishedOn": "2021-06-03T02:10:34.538Z",
          "wordCount": 613,
          "title": "Error-driven Fixed-Budget ASR Personalization for Accented Speakers. (arXiv:2103.03142v2 [cs.SD] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01263",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1\">Chiyu Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">Hongliang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_H/0/1/0/all/0/1\">Huachuan Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Haofei Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Z/0/1/0/all/0/1\">Zhenzhong Lan</a>",
          "description": "As an essential component of dialogue systems, multi-turn response selection\naims to pick out the optimal response among a set of candidates to improve the\ndialogue fluency. In this paper, we investigate three problems of current\nresponse selection approaches, especially for generation-based conversational\nagents: (i) Existing approaches are often formulated as a sentence scoring\nproblem, which does not consider relationships between responses. (ii) Existing\nmodels tend to select undesirable candidates that have large overlaps with the\ndialogue history. (iii) Negative instances in training are mainly constructed\nby random sampling from the corpus, whereas generated candidates in practice\ntypically have a closer distribution. To address the above problems, we create\na new dataset called ConvAI2+ and propose a new response selector called\nGlobal-Selector. Experimental results show that Global-Selector trained on\nConvAI2+ have noticeable improvements in both accuracy and inference speed.",
          "link": "http://arxiv.org/abs/2106.01263",
          "publishedOn": "2021-06-03T02:10:34.517Z",
          "wordCount": 579,
          "title": "Global-Selector: A New Benchmark Dataset and Model Architecture for Multi-turn Response Selection. (arXiv:2106.01263v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/1911.03663",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kang_D/0/1/0/all/0/1\">Dongyeop Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hovy_E/0/1/0/all/0/1\">Eduard Hovy</a>",
          "description": "Every natural text is written in some style. Style is formed by a complex\ncombination of different stylistic factors, including formality markers,\nemotions, metaphors, etc. One cannot form a complete understanding of a text\nwithout considering these factors. The factors combine and co-vary in complex\nways to form styles. Studying the nature of the co-varying combinations sheds\nlight on stylistic language in general, sometimes called cross-style language\nunderstanding. This paper provides the benchmark corpus (xSLUE) that combines\nexisting datasets and collects a new one for sentence-level cross-style\nlanguage understanding and evaluation. The benchmark contains text in 15\ndifferent styles under the proposed four theoretical groupings: figurative,\npersonal, affective, and interpersonal groups. For valid evaluation, we collect\nan additional diagnostic set by annotating all 15 styles on the same text.\nUsing xSLUE, we propose three interesting cross-style applications in\nclassification, correlation, and generation. First, our proposed cross-style\nclassifier trained with multiple styles together helps improve overall\nclassification performance against individually-trained style classifiers.\nSecond, our study shows that some styles are highly dependent on each other in\nhuman-written text. Finally, we find that combinations of some contradictive\nstyles likely generate stylistically less appropriate text. We believe our\nbenchmark and case studies help explore interesting future directions for\ncross-style research. The preprocessed datasets and code are publicly\navailable.",
          "link": "http://arxiv.org/abs/1911.03663",
          "publishedOn": "2021-06-03T02:10:34.497Z",
          "wordCount": 686,
          "title": "Style is NOT a single variable: Case Studies for Cross-Style Language Understanding. (arXiv:1911.03663v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01221",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yue_X/0/1/0/all/0/1\">Xiang Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_M/0/1/0/all/0/1\">Minxin Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tianhao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yaliang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Huan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chow_S/0/1/0/all/0/1\">Sherman S. M. Chow</a>",
          "description": "Texts convey sophisticated knowledge. However, texts also convey sensitive\ninformation. Despite the success of general-purpose language models and\ndomain-specific mechanisms with differential privacy (DP), existing text\nsanitization mechanisms still provide low utility, as cursed by the\nhigh-dimensional text representation. The companion issue of utilizing\nsanitized texts for downstream analytics is also under-explored. This paper\ntakes a direct approach to text sanitization. Our insight is to consider both\nsensitivity and similarity via our new local DP notion. The sanitized texts\nalso contribute to our sanitization-aware pretraining and fine-tuning, enabling\nprivacy-preserving natural language processing over the BERT language model\nwith promising utility. Surprisingly, the high utility does not boost up the\nsuccess rate of inference attacks.",
          "link": "http://arxiv.org/abs/2106.01221",
          "publishedOn": "2021-06-03T02:10:34.478Z",
          "wordCount": 562,
          "title": "Differential Privacy for Text Analytics via Natural Text Sanitization. (arXiv:2106.01221v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2010.12725",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shaw_P/0/1/0/all/0/1\">Peter Shaw</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_M/0/1/0/all/0/1\">Ming-Wei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pasupat_P/0/1/0/all/0/1\">Panupong Pasupat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toutanova_K/0/1/0/all/0/1\">Kristina Toutanova</a>",
          "description": "Sequence-to-sequence models excel at handling natural language variation, but\nhave been shown to struggle with out-of-distribution compositional\ngeneralization. This has motivated new specialized architectures with stronger\ncompositional biases, but most of these approaches have only been evaluated on\nsynthetically-generated datasets, which are not representative of natural\nlanguage variation. In this work we ask: can we develop a semantic parsing\napproach that handles both natural language variation and compositional\ngeneralization? To better assess this capability, we propose new train and test\nsplits of non-synthetic datasets. We demonstrate that strong existing\napproaches do not perform well across a broad set of evaluations. We also\npropose NQG-T5, a hybrid model that combines a high-precision grammar-based\napproach with a pre-trained sequence-to-sequence model. It outperforms existing\napproaches across several compositional generalization challenges on\nnon-synthetic data, while also being competitive with the state-of-the-art on\nstandard evaluations. While still far from solving this problem, our study\nhighlights the importance of diverse evaluations and the open challenge of\nhandling both compositional generalization and natural language variation in\nsemantic parsing.",
          "link": "http://arxiv.org/abs/2010.12725",
          "publishedOn": "2021-06-03T02:10:34.421Z",
          "wordCount": 639,
          "title": "Compositional Generalization and Natural Language Variation: Can a Semantic Parsing Approach Handle Both?. (arXiv:2010.12725v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1909.03396",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Levinboim_T/0/1/0/all/0/1\">Tomer Levinboim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thapliyal_A/0/1/0/all/0/1\">Ashish V. Thapliyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_P/0/1/0/all/0/1\">Piyush Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soricut_R/0/1/0/all/0/1\">Radu Soricut</a>",
          "description": "Automatic image captioning has improved significantly over the last few\nyears, but the problem is far from being solved, with state of the art models\nstill often producing low quality captions when used in the wild. In this\npaper, we focus on the task of Quality Estimation (QE) for image captions,\nwhich attempts to model the caption quality from a human perspective and\nwithout access to ground-truth references, so that it can be applied at\nprediction time to detect low-quality captions produced on previously unseen\nimages. For this task, we develop a human evaluation process that collects\ncoarse-grained caption annotations from crowdsourced users, which is then used\nto collect a large scale dataset spanning more than 600k caption quality\nratings. We then carefully validate the quality of the collected ratings and\nestablish baseline models for this new QE task. Finally, we further collect\nfine-grained caption quality annotations from trained raters, and use them to\ndemonstrate that QE models trained over the coarse ratings can effectively\ndetect and filter out low-quality image captions, thereby improving the user\nexperience from captioning systems.",
          "link": "http://arxiv.org/abs/1909.03396",
          "publishedOn": "2021-06-03T02:10:34.414Z",
          "wordCount": 659,
          "title": "Quality Estimation for Image Captions Based on Large-scale Human Evaluations. (arXiv:1909.03396v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01229",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kuribayashi_T/0/1/0/all/0/1\">Tatsuki Kuribayashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oseki_Y/0/1/0/all/0/1\">Yohei Oseki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ito_T/0/1/0/all/0/1\">Takumi Ito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoshida_R/0/1/0/all/0/1\">Ryo Yoshida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asahara_M/0/1/0/all/0/1\">Masayuki Asahara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Inui_K/0/1/0/all/0/1\">Kentaro Inui</a>",
          "description": "In computational psycholinguistics, various language models have been\nevaluated against human reading behavior (e.g., eye movement) to build\nhuman-like computational models. However, most previous efforts have focused\nalmost exclusively on English, despite the recent trend towards linguistic\nuniversal within the general community. In order to fill the gap, this paper\ninvestigates whether the established results in computational psycholinguistics\ncan be generalized across languages. Specifically, we re-examine an established\ngeneralization -- the lower perplexity a language model has, the more\nhuman-like the language model is -- in Japanese with typologically different\nstructures from English. Our experiments demonstrate that this established\ngeneralization exhibits a surprising lack of universality; namely, lower\nperplexity is not always human-like. Moreover, this discrepancy between English\nand Japanese is further explored from the perspective of (non-)uniform\ninformation density. Overall, our results suggest that a cross-lingual\nevaluation will be necessary to construct human-like computational models.",
          "link": "http://arxiv.org/abs/2106.01229",
          "publishedOn": "2021-06-03T02:10:34.405Z",
          "wordCount": 576,
          "title": "Lower Perplexity is Not Always Human-Like. (arXiv:2106.01229v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2012.15243",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haoyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1\">Dan Roth</a>",
          "description": "Identifying events and mapping them to pre-defined event types has long been\nan important natural language processing problem. Most previous work has been\nheavily relying on labor-intensive and domain-specific annotations while\nignoring the semantic meaning contained in the labels of the event types. As a\nresult, the learned models cannot effectively generalize to new domains, where\nnew event types could be introduced. In this paper, we propose an unsupervised\nevent extraction pipeline, which first identifies events with available tools\n(e.g., SRL) and then automatically maps them to pre-defined event types with\nour proposed unsupervised classification model. Rather than relying on\nannotated data, our model matches the semantics of identified events with those\nof event type labels. Specifically, we leverage pre-trained language models to\ncontextually represent pre-defined types for both event triggers and arguments.\nAfter we map identified events to the target types via representation\nsimilarity, we use the event ontology (e.g., argument type \"Victim\" can only\nappear as the argument of event type \"Attack\") as global constraints to\nregularize the prediction. The proposed approach is shown to be very effective\nwhen tested on the ACE-2005 dataset, which has 33 trigger and 22 argument\ntypes. Without using any annotation, we successfully map 83% of the triggers\nand 54% of the arguments to the correct types, almost doubling the performance\nof previous zero-shot approaches.",
          "link": "http://arxiv.org/abs/2012.15243",
          "publishedOn": "2021-06-03T02:10:34.391Z",
          "wordCount": 675,
          "title": "Unsupervised Label-aware Event Trigger and Argument Classification. (arXiv:2012.15243v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01228",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stowe_K/0/1/0/all/0/1\">Kevin Stowe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakrabarty_T/0/1/0/all/0/1\">Tuhin Chakrabarty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1\">Nanyun Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muresan_S/0/1/0/all/0/1\">Smaranda Muresan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>",
          "description": "Generating metaphors is a difficult task as it requires understanding nuanced\nrelationships between abstract concepts. In this paper, we aim to generate a\nmetaphoric sentence given a literal expression by replacing relevant verbs.\nGuided by conceptual metaphor theory, we propose to control the generation\nprocess by encoding conceptual mappings between cognitive domains to generate\nmeaningful metaphoric expressions. To achieve this, we develop two methods: 1)\nusing FrameNet-based embeddings to learn mappings between domains and applying\nthem at the lexical level (CM-Lex), and 2) deriving source/target pairs to\ntrain a controlled seq-to-seq generation model (CM-BART). We assess our methods\nthrough automatic and human evaluation for basic metaphoricity and conceptual\nmetaphor presence. We show that the unsupervised CM-Lex model is competitive\nwith recent deep learning metaphor generation systems, and CM-BART outperforms\nall other models both in automatic and human evaluations.",
          "link": "http://arxiv.org/abs/2106.01228",
          "publishedOn": "2021-06-03T02:10:34.385Z",
          "wordCount": 597,
          "title": "Metaphor Generation with Conceptual Mappings. (arXiv:2106.01228v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01072",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thorne_J/0/1/0/all/0/1\">James Thorne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vlachos_A/0/1/0/all/0/1\">Andreas Vlachos</a>",
          "description": "This paper introduces the task of factual error correction: performing edits\nto a claim so that the generated rewrite is better supported by evidence. This\nextends the well-studied task of fact verification by providing a mechanism to\ncorrect written texts that are refuted or only partially supported by evidence.\nWe demonstrate that it is feasible to train factual error correction systems\nfrom existing fact checking datasets which only contain labeled claims\naccompanied by evidence, but not the correction. We achieve this by employing a\ntwo-stage distant supervision approach that incorporates evidence into masked\nclaims when generating corrections. Our approach, based on the T5 transformer\nand using retrieved evidence, achieved better results than existing work which\nused a pointer copy network and gold evidence, producing accurate factual error\ncorrections for 5x more instances in human evaluation and a .125 increase in\nSARI score. The evaluation is conducted on a dataset of 65,000 instances based\non a recent fact verification shared task and we release it to enable further\nwork on the task.",
          "link": "http://arxiv.org/abs/2106.01072",
          "publishedOn": "2021-06-03T02:10:34.380Z",
          "wordCount": 605,
          "title": "Evidence-based Factual Error Correction. (arXiv:2106.01072v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01093",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_R/0/1/0/all/0/1\">Ruisheng Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Su Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1\">Kai Yu</a>",
          "description": "This work aims to tackle the challenging heterogeneous graph encoding problem\nin the text-to-SQL task. Previous methods are typically node-centric and merely\nutilize different weight matrices to parameterize edge types, which 1) ignore\nthe rich semantics embedded in the topological structure of edges, and 2) fail\nto distinguish local and non-local relations for each node. To this end, we\npropose a Line Graph Enhanced Text-to-SQL (LGESQL) model to mine the underlying\nrelational features without constructing meta-paths. By virtue of the line\ngraph, messages propagate more efficiently through not only connections between\nnodes, but also the topology of directed edges. Furthermore, both local and\nnon-local relations are integrated distinctively during the graph iteration. We\nalso design an auxiliary task called graph pruning to improve the\ndiscriminative capability of the encoder. Our framework achieves\nstate-of-the-art results (62.8% with Glove, 72.0% with Electra) on the\ncross-domain text-to-SQL benchmark Spider at the time of writing.",
          "link": "http://arxiv.org/abs/2106.01093",
          "publishedOn": "2021-06-03T02:10:34.369Z",
          "wordCount": 598,
          "title": "LGESQL: Line Graph Enhanced Text-to-SQL Model with Mixed Local and Non-Local Relations. (arXiv:2106.01093v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01251",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vinod_V/0/1/0/all/0/1\">Vishal Vinod</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_S/0/1/0/all/0/1\">Susmit Agrawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaurav_V/0/1/0/all/0/1\">Vipul Gaurav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+R_P/0/1/0/all/0/1\">Pallavi R</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choudhary_S/0/1/0/all/0/1\">Savita Choudhary</a>",
          "description": "In rural regions of several developing countries, access to quality\nhealthcare, medical infrastructure, and professional diagnosis is largely\nunavailable. Many of these regions are gradually gaining access to internet\ninfrastructure, although not with a strong enough connection to allow for\nsustained communication with a medical practitioner. Several deaths resulting\nfrom this lack of medical access, absence of patient's previous health records,\nand the unavailability of information in indigenous languages can be easily\nprevented. In this paper, we describe an approach leveraging the phenomenal\nprogress in Machine Learning and NLP (Natural Language Processing) techniques\nto design a model that is low-resource, multilingual, and a preliminary\nfirst-point-of-contact medical assistant. Our contribution includes defining\nthe NLP pipeline required for named-entity-recognition, language-agnostic\nsentence embedding, natural language translation, information retrieval,\nquestion answering, and generative pre-training for final query processing. We\nobtain promising results for this pipeline and preliminary results for EHR\n(Electronic Health Record) analysis with text summarization for medical\npractitioners to peruse for their diagnosis. Through this NLP pipeline, we aim\nto provide preliminary medical information to the user and do not claim to\nsupplant diagnosis from qualified medical practitioners. Using the input from\nsubject matter experts, we have compiled a large corpus to pre-train and\nfine-tune our BioBERT based NLP model for the specific tasks. We expect recent\nadvances in NLP architectures, several of which are efficient and\nprivacy-preserving models, to further the impact of our solution and improve on\nindividual task performance.",
          "link": "http://arxiv.org/abs/2106.01251",
          "publishedOn": "2021-06-03T02:10:34.363Z",
          "wordCount": 684,
          "title": "Multilingual Medical Question Answering and Information Retrieval for Rural Health Intelligence Access. (arXiv:2106.01251v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00984",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yunfeng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_G/0/1/0/all/0/1\">Guoxian Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1\">Zhongmin Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1\">Lizhen Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Domeniconi_C/0/1/0/all/0/1\">Carlotta Domeniconi</a>",
          "description": "Partial-label learning (PLL) generally focuses on inducing a noise-tolerant\nmulti-class classifier by training on overly-annotated samples, each of which\nis annotated with a set of labels, but only one is the valid label. A basic\npromise of existing PLL solutions is that there are sufficient partial-label\n(PL) samples for training. However, it is more common than not to have just few\nPL samples at hand when dealing with new tasks. Furthermore, existing few-shot\nlearning algorithms assume precise labels of the support set; as such,\nirrelevant labels may seriously mislead the meta-learner and thus lead to a\ncompromised performance. How to enable PLL under a few-shot learning setting is\nan important problem, but not yet well studied. In this paper, we introduce an\napproach called FsPLL (Few-shot PLL). FsPLL first performs adaptive distance\nmetric learning by an embedding network and rectifying prototypes on the tasks\npreviously encountered. Next, it calculates the prototype of each class of a\nnew task in the embedding network. An unseen example can then be classified via\nits distance to each prototype. Experimental results on widely-used few-shot\ndatasets (Omniglot and miniImageNet) demonstrate that our FsPLL can achieve a\nsuperior performance than the state-of-the-art methods across different\nsettings, and it needs fewer samples for quickly adapting to new tasks.",
          "link": "http://arxiv.org/abs/2106.00984",
          "publishedOn": "2021-06-03T02:10:34.349Z",
          "wordCount": 649,
          "title": "Few-Shot Partial-Label Learning. (arXiv:2106.00984v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01033",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_K/0/1/0/all/0/1\">Kunwoo Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_Z/0/1/0/all/0/1\">Zhufeng Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joo_J/0/1/0/all/0/1\">Jungseock Joo</a>",
          "description": "Understanding who blames or supports whom in news text is a critical research\nquestion in computational social science. Traditional methods and datasets for\nsentiment analysis are, however, not suitable for the domain of political text\nas they do not consider the direction of sentiments expressed between entities.\nIn this paper, we propose a novel NLP task of identifying directed sentiment\nrelationship between political entities from a given news document, which we\ncall directed sentiment extraction. From a million-scale news corpus, we\nconstruct a dataset of news sentences where sentiment relations of political\nentities are manually annotated. We present a simple but effective approach for\nutilizing a pretrained transformer, which infers the target class by predicting\nmultiple question-answering tasks and combining the outcomes. We demonstrate\nthe utility of our proposed method for social science research questions by\nanalyzing positive and negative opinions between political entities in two\nmajor events: 2016 U.S. presidential election and COVID-19. The newly proposed\nproblem, data, and method will facilitate future studies on interdisciplinary\nNLP methods and applications.",
          "link": "http://arxiv.org/abs/2106.01033",
          "publishedOn": "2021-06-03T02:10:34.336Z",
          "wordCount": 665,
          "title": "Who Blames or Endorses Whom? Entity-to-Entity Directed Sentiment Extraction in News Text. (arXiv:2106.01033v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01091",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wouts_J/0/1/0/all/0/1\">Joppe Wouts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boer_J/0/1/0/all/0/1\">Janna de Boer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Voppel_A/0/1/0/all/0/1\">Alban Voppel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brederoo_S/0/1/0/all/0/1\">Sanne Brederoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Splunter_S/0/1/0/all/0/1\">Sander van Splunter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sommer_I/0/1/0/all/0/1\">Iris Sommer</a>",
          "description": "Natural language processing (NLP) is becoming an important means for\nautomatic recognition of human traits and states, such as intoxication,\npresence of psychiatric disorders, presence of airway disorders and states of\nstress. Such applications have the potential to be an important pillar for\nonline help lines, and may gradually be introduced into eHealth modules.\nHowever, NLP is language specific and for languages such as Dutch, NLP models\nare scarce. As a result, recent Dutch NLP models have a low capture of long\nrange semantic dependencies over sentences. To overcome this, here we present\nbelabBERT, a new Dutch language model extending the RoBERTa architecture.\nbelabBERT is trained on a large Dutch corpus (+32 GB) of web crawled texts. We\napplied belabBERT to the classification of psychiatric illnesses. First, we\nevaluated the strength of text-based classification using belabBERT, and\ncompared the results to the existing RobBERT model. Then, we compared the\nperformance of belabBERT to audio classification for psychiatric disorders.\nFinally, a brief exploration was performed, extending the framework to a hybrid\ntext- and audio-based classification. Our results show that belabBERT\noutperformed the current best text classification network for Dutch, RobBERT.\nbelabBERT also outperformed classification based on audio alone.",
          "link": "http://arxiv.org/abs/2106.01091",
          "publishedOn": "2021-06-03T02:10:34.331Z",
          "wordCount": 641,
          "title": "belabBERT: a Dutch RoBERTa-based language model applied to psychiatric classification. (arXiv:2106.01091v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01227",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Billa_J/0/1/0/all/0/1\">Jayadev Billa</a>",
          "description": "Semi-supervised training (SST) is a common approach to leverage\nuntranscribed/unlabeled speech data to improve automatic speech recognition\nperformance in low-resource languages. However, if the available unlabeled\nspeech is mismatched to the target domain, SST is not as effective, and in many\ncases performs worse than the original system. In this paper, we address the\nissue of low-resource ASR when only untranscribed out-of-domain speech data is\nreadily available in the target language. Specifically, we look to improve\nperformance on conversational/telephony speech (target domain) using web\nresources, in particular YouTube data, which more closely resembles\nnews/topical broadcast data. Leveraging SST, we show that while in some cases\nsimply pooling the out-of-domain data with the training data lowers word error\nrate (WER), in all cases, we see improvements if we train first with the\nout-of-domain data and then fine-tune the resulting model with the original\ntraining data. Using 2000 hours of speed perturbed YouTube audio in each target\nlanguage, with semi-supervised transcripts, we show improvements on multiple\nlanguages/data sets, of up to 16.3% relative improvement in WER over the\nbaseline systems and up to 7.4% relative improvement in WER over a system that\nsimply pools the out-of-domain data with the training data.",
          "link": "http://arxiv.org/abs/2106.01227",
          "publishedOn": "2021-06-03T02:10:34.316Z",
          "wordCount": 629,
          "title": "Improving low-resource ASR performance with untranscribed out-of-domain data. (arXiv:2106.01227v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01199",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_Q/0/1/0/all/0/1\">Qingqing Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lal_Y/0/1/0/all/0/1\">Yash Kumar Lal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trivedi_H/0/1/0/all/0/1\">Harsh Trivedi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balasubramanian_A/0/1/0/all/0/1\">Aruna Balasubramanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balasubramanian_N/0/1/0/all/0/1\">Niranjan Balasubramanian</a>",
          "description": "Existing software-based energy measurements of NLP models are not accurate\nbecause they do not consider the complex interactions between energy\nconsumption and model execution. We present IrEne, an interpretable and\nextensible energy prediction system that accurately predicts the inference\nenergy consumption of a wide range of Transformer-based NLP models. IrEne\nconstructs a model tree graph that breaks down the NLP model into modules that\nare further broken down into low-level machine learning (ML) primitives. IrEne\npredicts the inference energy consumption of the ML primitives as a function of\ngeneralizable features and fine-grained runtime resource usage. IrEne then\naggregates these low-level predictions recursively to predict the energy of\neach module and finally of the entire model. Experiments across multiple\nTransformer models show IrEne predicts inference energy consumption of\ntransformer models with an error of under 7% compared to the ground truth. In\ncontrast, existing energy models see an error of over 50%. We also show how\nIrEne can be used to conduct energy bottleneck analysis and to easily evaluate\nthe energy impact of different architectural choices. We release the code and\ndata at https://github.com/StonyBrookNLP/irene.",
          "link": "http://arxiv.org/abs/2106.01199",
          "publishedOn": "2021-06-03T02:10:34.308Z",
          "wordCount": 614,
          "title": "IrEne: Interpretable Energy Prediction for Transformers. (arXiv:2106.01199v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01040",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chuhan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fangzhao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_T/0/1/0/all/0/1\">Tao Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yongfeng Huang</a>",
          "description": "Transformer is important for text modeling. However, it has difficulty in\nhandling long documents due to the quadratic complexity with input text length.\nIn order to handle this problem, we propose a hierarchical interactive\nTransformer (Hi-Transformer) for efficient and effective long document\nmodeling. Hi-Transformer models documents in a hierarchical way, i.e., first\nlearns sentence representations and then learns document representations. It\ncan effectively reduce the complexity and meanwhile capture global document\ncontext in the modeling of each sentence. More specifically, we first use a\nsentence Transformer to learn the representations of each sentence. Then we use\na document Transformer to model the global document context from these sentence\nrepresentations. Next, we use another sentence Transformer to enhance sentence\nmodeling using the global document context. Finally, we use hierarchical\npooling method to obtain document embedding. Extensive experiments on three\nbenchmark datasets validate the efficiency and effectiveness of Hi-Transformer\nin long document modeling.",
          "link": "http://arxiv.org/abs/2106.01040",
          "publishedOn": "2021-06-03T02:10:34.302Z",
          "wordCount": 585,
          "title": "Hi-Transformer: Hierarchical Interactive Transformer for Efficient and Effective Long Document Modeling. (arXiv:2106.01040v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01112",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yiming Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DHaro_L/0/1/0/all/0/1\">Luis Fernando D&#x27;Haro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Friedrichs_T/0/1/0/all/0/1\">Thomas Friedrichs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1\">Grandee Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haizhou Li</a>",
          "description": "A dialogue is essentially a multi-turn interaction among interlocutors.\nEffective evaluation metrics should reflect the dynamics of such interaction.\nExisting automatic metrics are focused very much on the turn-level quality,\nwhile ignoring such dynamics. To this end, we propose DynaEval, a unified\nautomatic evaluation framework which is not only capable of performing\nturn-level evaluation, but also holistically considers the quality of the\nentire dialogue. In DynaEval, the graph convolutional network (GCN) is adopted\nto model a dialogue in totality, where the graph nodes denote each individual\nutterance and the edges represent the dependency between pairs of utterances. A\ncontrastive loss is then applied to distinguish well-formed dialogues from\ncarefully constructed negative samples. Experiments show that DynaEval\nsignificantly outperforms the state-of-the-art dialogue coherence model, and\ncorrelates strongly with human judgements across multiple dialogue evaluation\naspects at both turn and dialogue level.",
          "link": "http://arxiv.org/abs/2106.01112",
          "publishedOn": "2021-06-03T02:10:34.276Z",
          "wordCount": 578,
          "title": "DynaEval: Unifying Turn and Dialogue Level Evaluation. (arXiv:2106.01112v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01105",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Santy_S/0/1/0/all/0/1\">Sebastin Santy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rani_A/0/1/0/all/0/1\">Anku Rani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choudhury_M/0/1/0/all/0/1\">Monojit Choudhury</a>",
          "description": "Ethical aspects of research in language technologies have received much\nattention recently. It is a standard practice to get a study involving human\nsubjects reviewed and approved by a professional ethics committee/board of the\ninstitution. How commonly do we see mention of ethical approvals in NLP\nresearch? What types of research or aspects of studies are usually subject to\nsuch reviews? With the rising concerns and discourse around the ethics of NLP,\ndo we also observe a rise in formal ethical reviews of NLP studies? And, if so,\nwould this imply that there is a heightened awareness of ethical issues that\nwas previously lacking? We aim to address these questions by conducting a\ndetailed quantitative and qualitative analysis of the ACL Anthology, as well as\ncomparing the trends in our field to those of other related disciplines, such\nas cognitive science, machine learning, data mining, and systems.",
          "link": "http://arxiv.org/abs/2106.01105",
          "publishedOn": "2021-06-03T02:10:34.259Z",
          "wordCount": 589,
          "title": "Use of Formal Ethical Reviews in NLP Literature: Historical Trends and Current Practices. (arXiv:2106.01105v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01170",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhatt_P/0/1/0/all/0/1\">Paras Bhatt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rios_A/0/1/0/all/0/1\">Anthony Rios</a>",
          "description": "Language generation models' democratization benefits many domains, from\nanswering health-related questions to enhancing education by providing\nAI-driven tutoring services. However, language generation models'\ndemocratization also makes it easier to generate human-like text at-scale for\nnefarious activities, from spreading misinformation to targeting specific\ngroups with hate speech. Thus, it is essential to understand how people\ninteract with bots and develop methods to detect bot-generated text. This paper\nshows that bot-generated text detection methods are more robust across datasets\nand models if we use information about how people respond to it rather than\nusing the bot's text directly. We also analyze linguistic alignment, providing\ninsight into differences between human-human and human-bot conversations.",
          "link": "http://arxiv.org/abs/2106.01170",
          "publishedOn": "2021-06-03T02:10:34.231Z",
          "wordCount": 546,
          "title": "Detecting Bot-Generated Text by Characterizing Linguistic Accommodation in Human-Bot Interactions. (arXiv:2106.01170v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00920",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Joshi_R/0/1/0/all/0/1\">Rishabh Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balachandran_V/0/1/0/all/0/1\">Vidhisha Balachandran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vashishth_S/0/1/0/all/0/1\">Shikhar Vashishth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Black_A/0/1/0/all/0/1\">Alan Black</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsvetkov_Y/0/1/0/all/0/1\">Yulia Tsvetkov</a>",
          "description": "To successfully negotiate a deal, it is not enough to communicate fluently:\npragmatic planning of persuasive negotiation strategies is essential. While\nmodern dialogue agents excel at generating fluent sentences, they still lack\npragmatic grounding and cannot reason strategically. We present DialoGraph, a\nnegotiation system that incorporates pragmatic strategies in a negotiation\ndialogue using graph neural networks. DialoGraph explicitly incorporates\ndependencies between sequences of strategies to enable improved and\ninterpretable prediction of next optimal strategies, given the dialogue\ncontext. Our graph-based method outperforms prior state-of-the-art negotiation\nmodels both in the accuracy of strategy/dialogue act prediction and in the\nquality of downstream dialogue response generation. We qualitatively show\nfurther benefits of learned strategy-graphs in providing explicit associations\nbetween effective negotiation strategies over the course of the dialogue,\nleading to interpretable and strategic dialogues.",
          "link": "http://arxiv.org/abs/2106.00920",
          "publishedOn": "2021-06-03T02:10:34.212Z",
          "wordCount": 575,
          "title": "DialoGraph: Incorporating Interpretable Strategy-Graph Networks into Negotiation Dialogues. (arXiv:2106.00920v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01023",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chuhan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fangzhao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yongfeng Huang</a>",
          "description": "Pre-trained language models (PLMs) achieve great success in NLP. However,\ntheir huge model sizes hinder their applications in many practical systems.\nKnowledge distillation is a popular technique to compress PLMs, which learns a\nsmall student model from a large teacher PLM. However, the knowledge learned\nfrom a single teacher may be limited and even biased, resulting in low-quality\nstudent model. In this paper, we propose a multi-teacher knowledge distillation\nframework named MT-BERT for pre-trained language model compression, which can\ntrain high-quality student model from multiple teacher PLMs. In MT-BERT we\ndesign a multi-teacher co-finetuning method to jointly finetune multiple\nteacher PLMs in downstream tasks with shared pooling and prediction layers to\nalign their output space for better collaborative teaching. In addition, we\npropose a multi-teacher hidden loss and a multi-teacher distillation loss to\ntransfer the useful knowledge in both hidden states and soft labels from\nmultiple teacher PLMs to the student model. Experiments on three benchmark\ndatasets validate the effectiveness of MT-BERT in compressing PLMs.",
          "link": "http://arxiv.org/abs/2106.01023",
          "publishedOn": "2021-06-03T02:10:34.199Z",
          "wordCount": 599,
          "title": "One Teacher is Enough? Pre-trained Language Model Distillation from Multiple Teachers. (arXiv:2106.01023v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01024",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lai_Y/0/1/0/all/0/1\">Yuxuan Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yansong Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Quzhe Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Dongyan Zhao</a>",
          "description": "Recent studies report that many machine reading comprehension (MRC) models\ncan perform closely to or even better than humans on benchmark datasets.\nHowever, existing works indicate that many MRC models may learn shortcuts to\noutwit these benchmarks, but the performance is unsatisfactory in real-world\napplications. In this work, we attempt to explore, instead of the expected\ncomprehension skills, why these models learn the shortcuts. Based on the\nobservation that a large portion of questions in current datasets have shortcut\nsolutions, we argue that larger proportion of shortcut questions in training\ndata make models rely on shortcut tricks excessively. To investigate this\nhypothesis, we carefully design two synthetic datasets with annotations that\nindicate whether a question can be answered using shortcut solutions. We\nfurther propose two new methods to quantitatively analyze the learning\ndifficulty regarding shortcut and challenging questions, and revealing the\ninherent learning mechanism behind the different performance between the two\nkinds of questions. A thorough empirical analysis shows that MRC models tend to\nlearn shortcut questions earlier than challenging questions, and the high\nproportions of shortcut questions in training sets hinder models from exploring\nthe sophisticated reasoning skills in the later stage of training.",
          "link": "http://arxiv.org/abs/2106.01024",
          "publishedOn": "2021-06-03T02:10:34.194Z",
          "wordCount": 629,
          "title": "Why Machine Reading Comprehension Models Learn Shortcuts?. (arXiv:2106.01024v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00948",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Keyang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_T/0/1/0/all/0/1\">Tongzheng Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shikun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yihao Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a>",
          "description": "Deployed real-world machine learning applications are often subject to\nuncontrolled and even potentially malicious inputs. Those out-of-domain inputs\ncan lead to unpredictable outputs and sometimes catastrophic safety issues.\nPrior studies on out-of-domain detection require in-domain task labels and are\nlimited to supervised classification scenarios. Our work tackles the problem of\ndetecting out-of-domain samples with only unsupervised in-domain data. We\nutilize the latent representations of pre-trained transformers and propose a\nsimple yet effective method to transform features across all layers to\nconstruct out-of-domain detectors efficiently. Two domain-specific fine-tuning\napproaches are further proposed to boost detection accuracy. Our empirical\nevaluations of related methods on two datasets validate that our method greatly\nimproves out-of-domain detection ability in a more general scenario.",
          "link": "http://arxiv.org/abs/2106.00948",
          "publishedOn": "2021-06-03T02:10:34.189Z",
          "wordCount": 558,
          "title": "Unsupervised Out-of-Domain Detection via Pre-trained Transformers. (arXiv:2106.00948v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01051",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ponti_E/0/1/0/all/0/1\">Edoardo Maria Ponti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aralikatte_R/0/1/0/all/0/1\">Rahul Aralikatte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shrivastava_D/0/1/0/all/0/1\">Disha Shrivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1\">Siva Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sogaard_A/0/1/0/all/0/1\">Anders S&#xf8;gaard</a>",
          "description": "Model-agnostic meta-learning (MAML) has been recently put forth as a strategy\nto learn resource-poor languages in a sample-efficient fashion. Nevertheless,\nthe properties of these languages are often not well represented by those\navailable during training. Hence, we argue that the i.i.d. assumption ingrained\nin MAML makes it ill-suited for cross-lingual NLP. In fact, under a\ndecision-theoretic framework, MAML can be interpreted as minimising the\nexpected risk across training languages (with a uniform prior), which is known\nas Bayes criterion. To increase its robustness to outlier languages, we create\ntwo variants of MAML based on alternative criteria: Minimax MAML reduces the\nmaximum risk across languages, while Neyman-Pearson MAML constrains the risk in\neach language to a maximum threshold. Both criteria constitute fully\ndifferentiable two-player games. In light of this, we propose a new adaptive\noptimiser solving for a local approximation to their Nash equilibrium. We\nevaluate both model variants on two popular NLP tasks, part-of-speech tagging\nand question answering. We report gains for their average and minimum\nperformance across low-resource languages in zero- and few-shot settings,\ncompared to joint multi-source transfer and vanilla MAML.",
          "link": "http://arxiv.org/abs/2106.01051",
          "publishedOn": "2021-06-03T02:10:34.176Z",
          "wordCount": 615,
          "title": "Minimax and Neyman-Pearson Meta-Learning for Outlier Languages. (arXiv:2106.01051v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00840",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vania_C/0/1/0/all/0/1\">Clara Vania</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Htut_P/0/1/0/all/0/1\">Phu Mon Htut</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">William Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mungra_D/0/1/0/all/0/1\">Dhara Mungra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_R/0/1/0/all/0/1\">Richard Yuanzhe Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phang_J/0/1/0/all/0/1\">Jason Phang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haokun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bowman_S/0/1/0/all/0/1\">Samuel R. Bowman</a>",
          "description": "Recent years have seen numerous NLP datasets introduced to evaluate the\nperformance of fine-tuned models on natural language understanding tasks.\nRecent results from large pretrained models, though, show that many of these\ndatasets are largely saturated and unlikely to be able to detect further\nprogress. What kind of datasets are still effective at discriminating among\nstrong models, and what kind of datasets should we expect to be able to detect\nfuture improvements? To measure this uniformly across datasets, we draw on Item\nResponse Theory and evaluate 29 datasets using predictions from 18 pretrained\nTransformer models on individual test examples. We find that Quoref, HellaSwag,\nand MC-TACO are best suited for distinguishing among state-of-the-art models,\nwhile SNLI, MNLI, and CommitmentBank seem to be saturated for current strong\nmodels. We also observe span selection task format, which is used for QA\ndatasets like QAMR or SQuAD2.0, is effective in differentiating between strong\nand weak models.",
          "link": "http://arxiv.org/abs/2106.00840",
          "publishedOn": "2021-06-03T02:10:34.146Z",
          "wordCount": 592,
          "title": "Comparing Test Sets with Item Response Theory. (arXiv:2106.00840v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00955",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hsu_C/0/1/0/all/0/1\">Chao-Chun Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lind_E/0/1/0/all/0/1\">Eric Lind</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soldaini_L/0/1/0/all/0/1\">Luca Soldaini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moschitti_A/0/1/0/all/0/1\">Alessandro Moschitti</a>",
          "description": "Recent advancements in transformer-based models have greatly improved the\nability of Question Answering (QA) systems to provide correct answers; in\nparticular, answer sentence selection (AS2) models, core components of\nretrieval-based systems, have achieved impressive results. While generally\neffective, these models fail to provide a satisfying answer when all retrieved\ncandidates are of poor quality, even if they contain correct information. In\nAS2, models are trained to select the best answer sentence among a set of\ncandidates retrieved for a given question. In this work, we propose to generate\nanswers from a set of AS2 top candidates. Rather than selecting the best\ncandidate, we train a sequence to sequence transformer model to generate an\nanswer from a candidate set. Our tests on three English AS2 datasets show\nimprovement up to 32 absolute points in accuracy over the state of the art.",
          "link": "http://arxiv.org/abs/2106.00955",
          "publishedOn": "2021-06-03T02:10:34.104Z",
          "wordCount": 574,
          "title": "Answer Generation for Retrieval-based Question Answering Systems. (arXiv:2106.00955v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00794",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nangia_N/0/1/0/all/0/1\">Nikita Nangia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugawara_S/0/1/0/all/0/1\">Saku Sugawara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trivedi_H/0/1/0/all/0/1\">Harsh Trivedi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Warstadt_A/0/1/0/all/0/1\">Alex Warstadt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vania_C/0/1/0/all/0/1\">Clara Vania</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bowman_S/0/1/0/all/0/1\">Samuel R. Bowman</a>",
          "description": "Crowdsourcing is widely used to create data for common natural language\nunderstanding tasks. Despite the importance of these datasets for measuring and\nrefining model understanding of language, there has been little focus on the\ncrowdsourcing methods used for collecting the datasets. In this paper, we\ncompare the efficacy of interventions that have been proposed in prior work as\nways of improving data quality. We use multiple-choice question answering as a\ntestbed and run a randomized trial by assigning crowdworkers to write questions\nunder one of four different data collection protocols. We find that asking\nworkers to write explanations for their examples is an ineffective stand-alone\nstrategy for boosting NLU example difficulty. However, we find that training\ncrowdworkers, and then using an iterative process of collecting data, sending\nfeedback, and qualifying workers based on expert judgments is an effective\nmeans of collecting challenging data. But using crowdsourced, instead of expert\njudgments, to qualify workers and send feedback does not prove to be effective.\nWe observe that the data from the iterative protocol with expert assessments is\nmore challenging by several measures. Notably, the human--model gap on the\nunanimous agreement portion of this data is, on average, twice as large as the\ngap for the baseline protocol data.",
          "link": "http://arxiv.org/abs/2106.00794",
          "publishedOn": "2021-06-03T02:10:34.059Z",
          "wordCount": 660,
          "title": "What Ingredients Make for an Effective Crowdsourcing Protocol for Difficult NLU Data Collection Tasks?. (arXiv:2106.00794v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00829",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fabbri_A/0/1/0/all/0/1\">Alexander R. Fabbri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahman_F/0/1/0/all/0/1\">Faiaz Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rizvi_I/0/1/0/all/0/1\">Imad Rizvi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Borui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haoran Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehdad_Y/0/1/0/all/0/1\">Yashar Mehdad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radev_D/0/1/0/all/0/1\">Dragomir Radev</a>",
          "description": "While online conversations can cover a vast amount of information in many\ndifferent formats, abstractive text summarization has primarily focused on\nmodeling solely news articles. This research gap is due, in part, to the lack\nof standardized datasets for summarizing online discussions. To address this\ngap, we design annotation protocols motivated by an\nissues--viewpoints--assertions framework to crowdsource four new datasets on\ndiverse online conversation forms of news comments, discussion forums,\ncommunity question answering forums, and email threads. We benchmark\nstate-of-the-art models on our datasets and analyze characteristics associated\nwith the data. To create a comprehensive benchmark, we also evaluate these\nmodels on widely-used conversation summarization datasets to establish strong\nbaselines in this domain. Furthermore, we incorporate argument mining through\ngraph construction to directly model the issues, viewpoints, and assertions\npresent in a conversation and filter noisy input, showing comparable or\nimproved results according to automatic and human evaluations.",
          "link": "http://arxiv.org/abs/2106.00829",
          "publishedOn": "2021-06-03T02:10:34.054Z",
          "wordCount": 589,
          "title": "ConvoSumm: Conversation Summarization Benchmark and Improved Abstractive Summarization with Argument Mining. (arXiv:2106.00829v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00957",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_J/0/1/0/all/0/1\">Junwei Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yan Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zichen Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1\">Shuguang Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Youzheng Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiaodong He</a>",
          "description": "Existing conversational recommendation (CR) systems usually suffer from\ninsufficient item information when conducted on short dialogue history and\nunfamiliar items. Incorporating external information (e.g., reviews) is a\npotential solution to alleviate this problem. Given that reviews often provide\na rich and detailed user experience on different interests, they are potential\nideal resources for providing high-quality recommendations within an\ninformative conversation. In this paper, we design a novel end-to-end\nframework, namely, Review-augmented Conversational Recommender (RevCore), where\nreviews are seamlessly incorporated to enrich item information and assist in\ngenerating both coherent and informative responses. In detail, we extract\nsentiment-consistent reviews, perform review-enriched and entity-based\nrecommendations for item suggestions, as well as use a review-attentive\nencoder-decoder for response generation. Experimental results demonstrate the\nsuperiority of our approach in yielding better performance on both\nrecommendation and conversation responding.",
          "link": "http://arxiv.org/abs/2106.00957",
          "publishedOn": "2021-06-03T02:10:34.040Z",
          "wordCount": 570,
          "title": "RevCore: Review-augmented Conversational Recommendation. (arXiv:2106.00957v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00950",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kruengkrai_C/0/1/0/all/0/1\">Canasai Kruengkrai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamagishi_J/0/1/0/all/0/1\">Junichi Yamagishi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>",
          "description": "Evidence-based fact checking aims to verify the truthfulness of a claim\nagainst evidence extracted from textual sources. Learning a representation that\neffectively captures relations between a claim and evidence can be challenging.\nRecent state-of-the-art approaches have developed increasingly sophisticated\nmodels based on graph structures. We present a simple model that can be trained\non sequence structures. Our model enables inter-sentence attentions at\ndifferent levels and can benefit from joint training. Results on a large-scale\ndataset for Fact Extraction and VERification (FEVER) show that our model\noutperforms the graph-based approaches and yields 1.09% and 1.42% improvements\nin label accuracy and FEVER score, respectively, over the best published model.",
          "link": "http://arxiv.org/abs/2106.00950",
          "publishedOn": "2021-06-03T02:10:34.035Z",
          "wordCount": 536,
          "title": "A Multi-Level Attention Model for Evidence-Based Fact Checking. (arXiv:2106.00950v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00853",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kazemi_A/0/1/0/all/0/1\">Ashkan Kazemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garimella_K/0/1/0/all/0/1\">Kiran Garimella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaffney_D/0/1/0/all/0/1\">Devin Gaffney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hale_S/0/1/0/all/0/1\">Scott A. Hale</a>",
          "description": "Manual fact-checking does not scale well to serve the needs of the internet.\nThis issue is further compounded in non-English contexts. In this paper, we\ndiscuss claim matching as a possible solution to scale fact-checking. We define\nclaim matching as the task of identifying pairs of textual messages containing\nclaims that can be served with one fact-check. We construct a novel dataset of\nWhatsApp tipline and public group messages alongside fact-checked claims that\nare first annotated for containing \"claim-like statements\" and then matched\nwith potentially similar items and annotated for claim matching. Our dataset\ncontains content in high-resource (English, Hindi) and lower-resource (Bengali,\nMalayalam, Tamil) languages. We train our own embedding model using knowledge\ndistillation and a high-quality \"teacher\" model in order to address the\nimbalance in embedding quality between the low- and high-resource languages in\nour dataset. We provide evaluations on the performance of our solution and\ncompare with baselines and existing state-of-the-art multilingual embedding\nmodels, namely LASER and LaBSE. We demonstrate that our performance exceeds\nLASER and LaBSE in all settings. We release our annotated datasets, codebooks,\nand trained embedding model to allow for further research.",
          "link": "http://arxiv.org/abs/2106.00853",
          "publishedOn": "2021-06-03T02:10:34.025Z",
          "wordCount": 625,
          "title": "Claim Matching Beyond English to Scale Global Fact-Checking. (arXiv:2106.00853v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00882",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yamada_I/0/1/0/all/0/1\">Ikuya Yamada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asai_A/0/1/0/all/0/1\">Akari Asai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>",
          "description": "Most state-of-the-art open-domain question answering systems use a neural\nretrieval model to encode passages into continuous vectors and extract them\nfrom a knowledge source. However, such retrieval models often require large\nmemory to run because of the massive size of their passage index. In this\npaper, we introduce Binary Passage Retriever (BPR), a memory-efficient neural\nretrieval model that integrates a learning-to-hash technique into the\nstate-of-the-art Dense Passage Retriever (DPR) to represent the passage index\nusing compact binary codes rather than continuous vectors. BPR is trained with\na multi-task objective over two tasks: efficient candidate generation based on\nbinary codes and accurate reranking based on continuous vectors. Compared with\nDPR, BPR substantially reduces the memory cost from 65GB to 2GB without a loss\nof accuracy on two standard open-domain question answering benchmarks: Natural\nQuestions and TriviaQA. Our code and trained models are available at\nhttps://github.com/studio-ousia/bpr.",
          "link": "http://arxiv.org/abs/2106.00882",
          "publishedOn": "2021-06-03T02:10:33.980Z",
          "wordCount": 579,
          "title": "Efficient Passage Retrieval with Hashing for Open-domain Question Answering. (arXiv:2106.00882v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00934",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Almarwani_N/0/1/0/all/0/1\">Nada Almarwani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diab_M/0/1/0/all/0/1\">Mona Diab</a>",
          "description": "Modern sentence encoders are used to generate dense vector representations\nthat capture the underlying linguistic characteristics for a sequence of words,\nincluding phrases, sentences, or paragraphs. These kinds of representations are\nideal for training a classifier for an end task such as sentiment analysis,\nquestion answering and text classification. Different models have been proposed\nto efficiently generate general purpose sentence representations to be used in\npretraining protocols. While averaging is the most commonly used efficient\nsentence encoder, Discrete Cosine Transform (DCT) was recently proposed as an\nalternative that captures the underlying syntactic characteristics of a given\ntext without compromising practical efficiency compared to averaging. However,\nas with most other sentence encoders, the DCT sentence encoder was only\nevaluated in English. To this end, we utilize DCT encoder to generate universal\nsentence representation for different languages such as German, French, Spanish\nand Russian. The experimental results clearly show the superior effectiveness\nof DCT encoding in which consistent performance improvements are achieved over\nstrong baselines on multiple standardized datasets.",
          "link": "http://arxiv.org/abs/2106.00934",
          "publishedOn": "2021-06-03T02:10:33.960Z",
          "wordCount": 594,
          "title": "Discrete Cosine Transform as Universal Sentence Encoder. (arXiv:2106.00934v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00737",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Belinda Z. Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nye_M/0/1/0/all/0/1\">Maxwell Nye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1\">Jacob Andreas</a>",
          "description": "Does the effectiveness of neural language models derive entirely from\naccurate modeling of surface word co-occurrence statistics, or do these models\nrepresent and reason about the world they describe? In BART and T5 transformer\nlanguage models, we identify contextual word representations that function as\nmodels of entities and situations as they evolve throughout a discourse. These\nneural representations have functional similarities to linguistic models of\ndynamic semantics: they support a linear readout of each entity's current\nproperties and relations, and can be manipulated with predictable effects on\nlanguage generation. Our results indicate that prediction in pretrained neural\nlanguage models is supported, at least in part, by dynamic representations of\nmeaning and implicit simulation of entity state, and that this behavior can be\nlearned with only text as training data. Code and data are available at\nhttps://github.com/belindal/state-probes .",
          "link": "http://arxiv.org/abs/2106.00737",
          "publishedOn": "2021-06-03T02:10:33.879Z",
          "wordCount": 574,
          "title": "Implicit Representations of Meaning in Neural Language Models. (arXiv:2106.00737v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00745",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abend_O/0/1/0/all/0/1\">Omri Abend</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choshen_L/0/1/0/all/0/1\">Leshem Choshen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikolaev_D/0/1/0/all/0/1\">Dmitry Nikolaev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rafaeli_O/0/1/0/all/0/1\">Ofek Rafaeli</a>",
          "description": "In this research paper, I will elaborate on a method to evaluate machine\ntranslation models based on their performance on underlying syntactical\nphenomena between English and Arabic languages. This method is especially\nimportant as such \"neural\" and \"machine learning\" are hard to fine-tune and\nchange. Thus, finding a way to evaluate them easily and diversely would greatly\nhelp the task of bettering them.",
          "link": "http://arxiv.org/abs/2106.00745",
          "publishedOn": "2021-06-03T02:10:33.815Z",
          "wordCount": 506,
          "title": "Part of Speech and Universal Dependency effects on English Arabic Machine Translation. (arXiv:2106.00745v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00874",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zaib_M/0/1/0/all/0/1\">Munazza Zaib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei Emma Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheng_Q/0/1/0/all/0/1\">Quan Z. Sheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmood_A/0/1/0/all/0/1\">Adnan Mahmood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>",
          "description": "Question answering (QA) systems provide a way of querying the information\navailable in various formats including, but not limited to, unstructured and\nstructured data in natural languages. It constitutes a considerable part of\nconversational artificial intelligence (AI) which has led to the introduction\nof a special research topic on Conversational Question Answering (CQA), wherein\na system is required to understand the given context and then engages in\nmulti-turn QA to satisfy the user's information needs. Whilst the focus of most\nof the existing research work is subjected to single-turn QA, the field of\nmulti-turn QA has recently grasped attention and prominence owing to the\navailability of large-scale, multi-turn QA datasets and the development of\npre-trained language models. With a good amount of models and research papers\nadding to the literature every year recently, there is a dire need of arranging\nand presenting the related work in a unified manner to streamline future\nresearch. This survey, therefore, is an effort to present a comprehensive\nreview of the state-of-the-art research trends of CQA primarily based on\nreviewed papers from 2016-2021. Our findings show that there has been a trend\nshift from single-turn to multi-turn QA which empowers the field of\nConversational AI from different perspectives. This survey is intended to\nprovide an epitome for the research community with the hope of laying a strong\nfoundation for the field of CQA.",
          "link": "http://arxiv.org/abs/2106.00874",
          "publishedOn": "2021-06-03T02:10:33.808Z",
          "wordCount": 660,
          "title": "Conversational Question Answering: A Survey. (arXiv:2106.00874v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00786",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hase_P/0/1/0/all/0/1\">Peter Hase</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_H/0/1/0/all/0/1\">Harry Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>",
          "description": "Feature importance (FI) estimates are a popular form of explanation, and they\nare commonly created and evaluated by computing the change in model confidence\ncaused by removing certain input features at test time. For example, in the\nstandard Sufficiency metric, only the top-k most important tokens are kept. In\nthis paper, we study several under-explored dimensions of FI-based\nexplanations, providing conceptual and empirical improvements for this form of\nexplanation. First, we advance a new argument for why it can be problematic to\nremove features from an input when creating or evaluating explanations: the\nfact that these counterfactual inputs are out-of-distribution (OOD) to models\nimplies that the resulting explanations are socially misaligned. The crux of\nthe problem is that the model prior and random weight initialization influence\nthe explanations (and explanation metrics) in unintended ways. To resolve this\nissue, we propose a simple alteration to the model training process, which\nresults in more socially aligned explanations and metrics. Second, we compare\namong five approaches for removing features from model inputs. We find that\nsome methods produce more OOD counterfactuals than others, and we make\nrecommendations for selecting a feature-replacement function. Finally, we\nintroduce four search-based methods for identifying FI explanations and compare\nthem to strong baselines, including LIME, Integrated Gradients, and random\nsearch. On experiments with six diverse text classification datasets, we find\nthat the only method that consistently outperforms random search is a Parallel\nLocal Search that we introduce. Improvements over the second-best method are as\nlarge as 5.4 points for Sufficiency and 17 points for Comprehensiveness. All\nsupporting code is publicly available at\nhttps://github.com/peterbhase/ExplanationSearch.",
          "link": "http://arxiv.org/abs/2106.00786",
          "publishedOn": "2021-06-03T02:10:33.779Z",
          "wordCount": 711,
          "title": "Search Methods for Sufficient, Socially-Aligned Feature Importance Explanations with In-Distribution Counterfactuals. (arXiv:2106.00786v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00851",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Castricato_L/0/1/0/all/0/1\">Louis Castricato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fitz_S/0/1/0/all/0/1\">Stephen Fitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_W/0/1/0/all/0/1\">Won Young Shin</a>",
          "description": "As the computational footprint of modern NLP systems grows, it becomes\nincreasingly important to arrive at more efficient models. We show that by\nemploying graph convolutional document representation, we can arrive at a\nquestion answering system that performs comparably to, and in some cases\nexceeds the SOTA solutions, while using less than 5\\% of their resources in\nterms of trainable parameters. As it currently stands, a major issue in\napplying GCNs to NLP is document representation. In this paper, we show that a\nGCN enriched document representation greatly improves the results seen in\nHotPotQA, even when using a trivial topology. Our model (gQA), performs\nadmirably when compared to the current SOTA, and requires little to no\npreprocessing. In Shao et al. 2020, the authors suggest that graph networks are\nnot necessary for good performance in multi-hop QA. In this paper, we suggest\nthat large language models are not necessary for good performance by showing a\nna\\\"{i}ve implementation of a GCN performs comparably to SoTA models based on\npretrained language models.",
          "link": "http://arxiv.org/abs/2106.00851",
          "publishedOn": "2021-06-03T02:10:33.723Z",
          "wordCount": 596,
          "title": "Parameter-Efficient Neural Question Answering Models via Graph-Enriched Document Representations. (arXiv:2106.00851v1 [cs.CL])"
        }
      ]
    },
    {
      "title": "cs.IR updates on arXiv.org",
      "feedUrl": "http://export.arxiv.org/rss/cs.IR",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2105.13868",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1\">Shuhuai Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Junyang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1\">Guangxiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Men_R/0/1/0/all/0/1\">Rui Men</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1\">An Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hongxia Yang</a>",
          "description": "Despite the achievements of large-scale multimodal pre-training approaches,\ncross-modal retrieval, e.g., image-text retrieval, remains a challenging task.\nTo bridge the semantic gap between the two modalities, previous studies mainly\nfocus on word-region alignment at the object level, lacking the matching\nbetween the linguistic relation among the words and the visual relation among\nthe regions. The neglect of such relation consistency impairs the\ncontextualized representation of image-text pairs and hinders the model\nperformance and the interpretability. In this paper, we first propose a novel\nmetric, Intra-modal Self-attention Distance (ISD), to quantify the relation\nconsistency by measuring the semantic distance between linguistic and visual\nrelations. In response, we present Inter-modal Alignment on Intra-modal\nSelf-attentions (IAIS), a regularized training method to optimize the ISD and\ncalibrate intra-modal self-attentions from the two modalities mutually via\ninter-modal alignment. The IAIS regularizer boosts the performance of\nprevailing models on Flickr30k and MS COCO datasets by a considerable margin,\nwhich demonstrates the superiority of our approach.",
          "link": "http://arxiv.org/abs/2105.13868",
          "publishedOn": "2021-06-08T02:20:22.677Z",
          "wordCount": 642,
          "title": "Learning Relation Alignment for Calibrated Cross-modal Retrieval. (arXiv:2105.13868v2 [cs.CL] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.11601",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Li Chen</a>",
          "description": "Personalization of natural language generation plays a vital role in a large\nspectrum of tasks, such as explainable recommendation, review summarization and\ndialog systems. In these tasks, user and item IDs are important identifiers for\npersonalization. Transformer, which is demonstrated with strong language\nmodeling capability, however, is not personalized and fails to make use of the\nuser and item IDs since the ID tokens are not even in the same semantic space\nas the words. To address this problem, we present a PErsonalized Transformer\nfor Explainable Recommendation (PETER), on which we design a simple and\neffective learning objective that utilizes the IDs to predict the words in the\ntarget explanation, so as to endow the IDs with linguistic meanings and to\nachieve personalized Transformer. Besides generating explanations, PETER can\nalso make recommendations, which makes it a unified model for the whole\nrecommendation-explanation pipeline. Extensive experiments show that our small\nunpretrained model outperforms fine-tuned BERT on the generation task, in terms\nof both effectiveness and efficiency, which highlights the importance and the\nnice utility of our design.",
          "link": "http://arxiv.org/abs/2105.11601",
          "publishedOn": "2021-06-08T02:20:22.530Z",
          "wordCount": 632,
          "title": "Personalized Transformer for Explainable Recommendation. (arXiv:2105.11601v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.02507",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1\">Damai Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1\">Jing Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_S/0/1/0/all/0/1\">Shuang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1\">Baobao Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_Z/0/1/0/all/0/1\">Zhifang Sui</a>",
          "description": "Document-level Relation Extraction (RE) requires extracting relations\nexpressed within and across sentences. Recent works show that graph-based\nmethods, usually constructing a document-level graph that captures\ndocument-aware interactions, can obtain useful entity representations thus\nhelping tackle document-level RE. These methods either focus more on the entire\ngraph, or pay more attention to a part of the graph, e.g., paths between the\ntarget entity pair. However, we find that document-level RE may benefit from\nfocusing on both of them simultaneously. Therefore, to obtain more\ncomprehensive entity representations, we propose the Coarse-to-Fine Entity\nRepresentation model (CFER) that adopts a coarse-to-fine strategy involving two\nphases. First, CFER uses graph neural networks to integrate global information\nin the entire graph at a coarse level. Next, CFER utilizes the global\ninformation as a guidance to selectively aggregate path information between the\ntarget entity pair at a fine level. In classification, we combine the entity\nrepresentations from both two levels into more comprehensive representations\nfor relation extraction. Experimental results on two document-level RE\ndatasets, DocRED and CDR, show that CFER outperforms existing models and is\nrobust to the uneven label distribution.",
          "link": "http://arxiv.org/abs/2012.02507",
          "publishedOn": "2021-06-08T02:20:20.962Z",
          "wordCount": 647,
          "title": "Coarse-to-Fine Entity Representations for Document-level Relation Extraction. (arXiv:2012.02507v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02831",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Soltaninejad_F/0/1/0/all/0/1\">Fahimeh Soltaninejad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bidgoly_A/0/1/0/all/0/1\">Amir Jalaly Bidgoly</a>",
          "description": "One of the popular approaches in recommendation systems is Collaborative\nFiltering (CF). The most significant step in CF is choosing the appropriate set\nof users. For this purpose, similarity measures are usually used for computing\nthe similarity between a specific user and the other users. This paper proposes\na new invasive weed optimization (IWO) based CF approach that uses users'\ncontext to identify important and effective users set. By using a newly defined\nsimilarity measure based on both rating values and a measure values called\nconfidence, the proposed approach calculates the similarity between users and\nthus identifies and filters the most similar users to a specific user. It then\nuses IWO to calculate the importance degree of users and finally, by using the\nidentified important users and their importance degrees it predicts unknown\nratings. To evaluate the proposed method, several experiments have been\nperformed on two known real world datasets and the results show that the\nproposed method improves the state of the art results up to 15% in terms of\nRoot Mean Square Error (RMSE) and Mean Absolute Error (MAE).",
          "link": "http://arxiv.org/abs/2106.02831",
          "publishedOn": "2021-06-08T02:20:20.805Z",
          "wordCount": 605,
          "title": "A novel method for recommendation systems using invasive weed optimization. (arXiv:2106.02831v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02771",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Pan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Que_M/0/1/0/all/0/1\">Maofei Que</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhichao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yao Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuzhilin_A/0/1/0/all/0/1\">Alexander Tuzhilin</a>",
          "description": "Classical recommender system methods typically face the filter bubble problem\nwhen users only receive recommendations of their familiar items, making them\nbored and dissatisfied. To address the filter bubble problem, unexpected\nrecommendations have been proposed to recommend items significantly deviating\nfrom user's prior expectations and thus surprising them by presenting \"fresh\"\nand previously unexplored items to the users. In this paper, we describe a\nnovel Personalized Unexpected Recommender System (PURS) model that incorporates\nunexpectedness into the recommendation process by providing multi-cluster\nmodeling of user interests in the latent space and personalized unexpectedness\nvia the self-attention mechanism and via selection of an appropriate unexpected\nactivation function. Extensive offline experiments on three real-world datasets\nillustrate that the proposed PURS model significantly outperforms the\nstate-of-the-art baseline approaches in terms of both accuracy and\nunexpectedness measures. In addition, we conduct an online A/B test at a major\nvideo platform Alibaba-Youku, where our model achieves over 3\\% increase in the\naverage video view per user metric. The proposed model is in the process of\nbeing deployed by the company.",
          "link": "http://arxiv.org/abs/2106.02771",
          "publishedOn": "2021-06-08T02:20:20.759Z",
          "wordCount": 609,
          "title": "PURS: Personalized Unexpected Recommender System for Improving User Satisfaction. (arXiv:2106.02771v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2101.05993",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guangtao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1\">Qinbao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaoyan Zhu</a>",
          "description": "Recommending appropriate algorithms to a classification problem is one of the\nmost challenging issues in the field of data mining. The existing algorithm\nrecommendation models are generally constructed on only one kind of\nmeta-features by single learners. Considering that i) ensemble learners usually\nshow better performance and ii) different kinds of meta-features characterize\nthe classification problems in different viewpoints independently, and further\nthe models constructed with different sets of meta-features will be\ncomplementary with each other and applicable for ensemble. This paper proposes\nan ensemble learning-based algorithm recommendation method. To evaluate the\nproposed recommendation method, extensive experiments with 13 well-known\ncandidate classification algorithms and five different kinds of meta-features\nare conducted on 1090 benchmark classification problems. The results show the\neffectiveness of the proposed ensemble learning based recommendation method.",
          "link": "http://arxiv.org/abs/2101.05993",
          "publishedOn": "2021-06-08T02:20:20.580Z",
          "wordCount": 566,
          "title": "Ensemble Learning Based Classification Algorithm Recommendation. (arXiv:2101.05993v1 [cs.IR] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02870",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kweon_W/0/1/0/all/0/1\">Wonbin Kweon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_S/0/1/0/all/0/1\">SeongKu Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hwanjo Yu</a>",
          "description": "Recommender systems (RS) have started to employ knowledge distillation, which\nis a model compression technique training a compact model (student) with the\nknowledge transferred from a cumbersome model (teacher). The state-of-the-art\nmethods rely on unidirectional distillation transferring the knowledge only\nfrom the teacher to the student, with an underlying assumption that the teacher\nis always superior to the student. However, we demonstrate that the student\nperforms better than the teacher on a significant proportion of the test set,\nespecially for RS. Based on this observation, we propose Bidirectional\nDistillation (BD) framework whereby both the teacher and the student\ncollaboratively improve with each other. Specifically, each model is trained\nwith the distillation loss that makes to follow the other's prediction along\nwith its original loss function. For effective bidirectional distillation, we\npropose rank discrepancy-aware sampling scheme to distill only the informative\nknowledge that can fully enhance each other. The proposed scheme is designed to\neffectively cope with a large performance gap between the teacher and the\nstudent. Trained in the bidirectional way, it turns out that both the teacher\nand the student are significantly improved compared to when being trained\nseparately. Our extensive experiments on real-world datasets show that our\nproposed framework consistently outperforms the state-of-the-art competitors.\nWe also provide analyses for an in-depth understanding of BD and ablation\nstudies to verify the effectiveness of each proposed component.",
          "link": "http://arxiv.org/abs/2106.02870",
          "publishedOn": "2021-06-08T02:20:20.569Z",
          "wordCount": 649,
          "title": "Bidirectional Distillation for Top-K Recommender System. (arXiv:2106.02870v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02768",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Pan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhichao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Que_M/0/1/0/all/0/1\">Maofei Que</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yao Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuzhilin_A/0/1/0/all/0/1\">Alexander Tuzhilin</a>",
          "description": "Cross domain recommender system constitutes a powerful method to tackle the\ncold-start and sparsity problem by aggregating and transferring user\npreferences across multiple category domains. Therefore, it has great potential\nto improve click-through-rate prediction performance in online commerce\nplatforms having many domains of products. While several cross domain\nsequential recommendation models have been proposed to leverage information\nfrom a source domain to improve CTR predictions in a target domain, they did\nnot take into account bidirectional latent relations of user preferences across\nsource-target domain pairs. As such, they cannot provide enhanced cross-domain\nCTR predictions for both domains simultaneously. In this paper, we propose a\nnovel approach to cross-domain sequential recommendations based on the dual\nlearning mechanism that simultaneously transfers information between two\nrelated domains in an iterative manner until the learning process stabilizes.\nIn particular, the proposed Dual Attentive Sequential Learning (DASL) model\nconsists of two novel components Dual Embedding and Dual Attention, which\njointly establish the two-stage learning process: we first construct dual\nlatent embeddings that extract user preferences in both domains simultaneously,\nand subsequently provide cross-domain recommendations by matching the extracted\nlatent embeddings with candidate items through dual-attention learning\nmechanism. We conduct extensive offline experiments on three real-world\ndatasets to demonstrate the superiority of our proposed model, which\nsignificantly and consistently outperforms several state-of-the-art baselines\nacross all experimental settings. We also conduct an online A/B test at a major\nvideo streaming platform Alibaba-Youku, where our proposed model significantly\nimproves business performance over the latest production system in the company.",
          "link": "http://arxiv.org/abs/2106.02768",
          "publishedOn": "2021-06-08T02:20:20.522Z",
          "wordCount": 686,
          "title": "Dual Attentive Sequential Learning for Cross-Domain Click-Through Rate Prediction. (arXiv:2106.02768v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02715",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Urman_A/0/1/0/all/0/1\">Aleksandra Urman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makhortykh_M/0/1/0/all/0/1\">Mykola Makhortykh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ulloa_R/0/1/0/all/0/1\">Roberto Ulloa</a>",
          "description": "We audit the presence of domain-level source diversity bias in video search\nresults. Using a virtual agent-based approach, we compare outputs of four\nWestern and one non-Western search engines for English and Russian queries. Our\nfindings highlight that source diversity varies substantially depending on the\nlanguage with English queries returning more diverse outputs. We also find\ndisproportionately high presence of a single platform, YouTube, in top search\noutputs for all Western search engines except Google. At the same time, we\nobserve that Youtube's major competitors such as Vimeo or Dailymotion do not\nappear in the sampled Google's video search results. This finding suggests that\nGoogle might be downgrading the results from the main competitors of\nGoogle-owned Youtube and highlights the necessity for further studies focusing\non the presence of own-content bias in Google's search results.",
          "link": "http://arxiv.org/abs/2106.02715",
          "publishedOn": "2021-06-08T02:20:20.489Z",
          "wordCount": 579,
          "title": "Auditing Source Diversity Bias in Video Search Results Using Virtual Agents. (arXiv:2106.02715v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2010.15363",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_T/0/1/0/all/0/1\">Tianxin Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1\">Fuli Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiawei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Ziwei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_J/0/1/0/all/0/1\">Jinfeng Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiangnan He</a>",
          "description": "The general aim of the recommender system is to provide personalized\nsuggestions to users, which is opposed to suggesting popular items. However,\nthe normal training paradigm, i.e., fitting a recommender model to recover the\nuser behavior data with pointwise or pairwise loss, makes the model biased\ntowards popular items. This results in the terrible Matthew effect, making\npopular items be more frequently recommended and become even more popular.\nExisting work addresses this issue with Inverse Propensity Weighting (IPW),\nwhich decreases the impact of popular items on the training and increases the\nimpact of long-tail items. Although theoretically sound, IPW methods are highly\nsensitive to the weighting strategy, which is notoriously difficult to tune. In\nthis work, we explore the popularity bias issue from a novel and fundamental\nperspective -- cause-effect. We identify that popularity bias lies in the\ndirect effect from the item node to the ranking score, such that an item's\nintrinsic property is the cause of mistakenly assigning it a higher ranking\nscore. To eliminate popularity bias, it is essential to answer the\ncounterfactual question that what the ranking score would be if the model only\nuses item property. To this end, we formulate a causal graph to describe the\nimportant cause-effect relations in the recommendation process. During\ntraining, we perform multi-task learning to achieve the contribution of each\ncause; during testing, we perform counterfactual inference to remove the effect\nof item popularity. Remarkably, our solution amends the learning process of\nrecommendation which is agnostic to a wide range of models -- it can be easily\nimplemented in existing methods. We demonstrate it on Matrix Factorization (MF)\nand LightGCN [20]. Experiments on five real-world datasets demonstrate the\neffectiveness of our method.",
          "link": "http://arxiv.org/abs/2010.15363",
          "publishedOn": "2021-06-08T02:20:20.471Z",
          "wordCount": 752,
          "title": "Model-Agnostic Counterfactual Reasoning for Eliminating Popularity Bias in Recommender System. (arXiv:2010.15363v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.04373",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qiaosheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suh_G/0/1/0/all/0/1\">Geewon Suh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suh_C/0/1/0/all/0/1\">Changho Suh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_V/0/1/0/all/0/1\">Vincent Y. F. Tan</a>",
          "description": "In this paper, we design and analyze MC2G (Matrix Completion with 2 Graphs),\nan algorithm that performs matrix completion in the presence of social and item\nsimilarity graphs. MC2G runs in quasilinear time and is parameter free. It is\nbased on spectral clustering and local refinement steps. The expected number of\nsampled entries required for MC2G to succeed (i.e., recover the clusters in the\ngraphs and complete the matrix) matches an information-theoretic lower bound up\nto a constant factor for a wide range of parameters. We show via extensive\nexperiments on both synthetic and real datasets that MC2G outperforms other\nstate-of-the-art matrix completion algorithms that leverage graph side\ninformation.",
          "link": "http://arxiv.org/abs/2006.04373",
          "publishedOn": "2021-06-08T02:20:20.446Z",
          "wordCount": 594,
          "title": "MC2G: An Efficient Algorithm for Matrix Completion with Social and Item Similarity Graphs. (arXiv:2006.04373v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.10784",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kang_W/0/1/0/all/0/1\">Wang-Cheng Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_D/0/1/0/all/0/1\">Derek Zhiyuan Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_T/0/1/0/all/0/1\">Tiansheng Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1\">Xinyang Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Ting Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_L/0/1/0/all/0/1\">Lichan Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chi_E/0/1/0/all/0/1\">Ed H. Chi</a>",
          "description": "Embedding learning of categorical features (e.g. user/item IDs) is at the\ncore of various recommendation models including matrix factorization and neural\ncollaborative filtering. The standard approach creates an embedding table where\neach row represents a dedicated embedding vector for every unique feature\nvalue. However, this method fails to efficiently handle high-cardinality\nfeatures and unseen feature values (e.g. new video ID) that are prevalent in\nreal-world recommendation systems. In this paper, we propose an alternative\nembedding framework Deep Hash Embedding (DHE), replacing embedding tables by a\ndeep embedding network to compute embeddings on the fly. DHE first encodes the\nfeature value to a unique identifier vector with multiple hashing functions and\ntransformations, and then applies a DNN to convert the identifier vector to an\nembedding. The encoding module is deterministic, non-learnable, and free of\nstorage, while the embedding network is updated during the training time to\nlearn embedding generation. Empirical results show that DHE achieves comparable\nAUC against the standard one-hot full embedding, with smaller model sizes. Our\nwork sheds light on the design of DNN-based alternative embedding schemes for\ncategorical features without using embedding table lookup.",
          "link": "http://arxiv.org/abs/2010.10784",
          "publishedOn": "2021-06-08T02:20:20.433Z",
          "wordCount": 663,
          "title": "Learning to Embed Categorical Features without Embedding Tables for Recommendation. (arXiv:2010.10784v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.11804",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mazzeo_V/0/1/0/all/0/1\">V. Mazzeo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rapisarda_A/0/1/0/all/0/1\">A. Rapisarda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giuffrida_G/0/1/0/all/0/1\">G. Giuffrida</a>",
          "description": "In early January 2020, after China reported the first cases of the new\ncoronavirus (SARS-CoV-2) in the city of Wuhan, unreliable and not fully\naccurate information has started spreading faster than the virus itself.\nAlongside this pandemic, people have experienced a parallel infodemic, i.e., an\noverabundance of information, some of which misleading or even harmful, that\nhas widely spread around the globe. Although Social Media are increasingly\nbeing used as information source, Web Search Engines, like Google or Yahoo!,\nstill represent a powerful and trustworthy resource for finding information on\nthe Web. This is due to their capability to capture the largest amount of\ninformation, helping users quickly identify the most relevant, useful, although\nnot always the most reliable, results for their search queries. This study aims\nto detect potential misleading and fake contents by capturing and analysing\ntextual information, which flow through Search Engines. By using a real-world\ndataset associated with recent CoViD-19 pandemic, we first apply re-sampling\ntechniques for class imbalance, then we use existing Machine Learning\nalgorithms for classification of not reliable news. By extracting lexical and\nhost-based features of associated Uniform Resource Locators (URLs) for news\narticles, we show that the proposed methods, so common in phishing and\nmalicious URLs detection, can improve the efficiency and performance of\nclassifiers. Based on these findings, we suggest that the use of both textual\nand URLs features can improve the effectiveness of fake news detection methods.",
          "link": "http://arxiv.org/abs/2103.11804",
          "publishedOn": "2021-06-08T02:20:20.418Z",
          "wordCount": 740,
          "title": "Detection of fake news on CoViD-19 on Web Search Engines. (arXiv:2103.11804v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.12964",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jianxin Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jianwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hongxia Yang</a>",
          "description": "Deep candidate generation (DCG) that narrows down the collection of relevant\nitems from billions to hundreds via representation learning has become\nprevalent in industrial recommender systems. Standard approaches approximate\nmaximum likelihood estimation (MLE) through sampling for better scalability and\naddress the problem of DCG in a way similar to language modeling. However, live\nrecommender systems face severe exposure bias and have a vocabulary several\norders of magnitude larger than that of natural language, implying that MLE\nwill preserve and even exacerbate the exposure bias in the long run in order to\nfaithfully fit the observed samples. In this paper, we theoretically prove that\na popular choice of contrastive loss is equivalent to reducing the exposure\nbias via inverse propensity weighting, which provides a new perspective for\nunderstanding the effectiveness of contrastive learning. Based on the\ntheoretical discovery, we design CLRec, a contrastive learning method to\nimprove DCG in terms of fairness, effectiveness and efficiency in recommender\nsystems with extremely large candidate size. We further improve upon CLRec and\npropose Multi-CLRec, for accurate multi-intention aware bias reduction. Our\nmethods have been successfully deployed in Taobao, where at least four-month\nonline A/B tests and offline analyses demonstrate its substantial improvements,\nincluding a dramatic reduction in the Matthew effect.",
          "link": "http://arxiv.org/abs/2005.12964",
          "publishedOn": "2021-06-07T03:06:11.174Z",
          "wordCount": 759,
          "title": "Contrastive Learning for Debiased Candidate Generation in Large-Scale Recommender Systems. (arXiv:2005.12964v9 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02400",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1\">Manh-Duy Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_B/0/1/0/all/0/1\">Binh T. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurrin_C/0/1/0/all/0/1\">Cathal Gurrin</a>",
          "description": "Conventional approaches to image-text retrieval mainly focus on indexing\nvisual objects appearing in pictures but ignore the interactions between these\nobjects. Such objects occurrences and interactions are equivalently useful and\nimportant in this field as they are usually mentioned in the text. Scene graph\npresentation is a suitable method for the image-text matching challenge and\nobtained good results due to its ability to capture the inter-relationship\ninformation. Both images and text are represented in scene graph levels and\nformulate the retrieval challenge as a scene graph matching challenge. In this\npaper, we introduce the Local and Global Scene Graph Matching (LGSGM) model\nthat enhances the state-of-the-art method by integrating an extra graph\nconvolution network to capture the general information of a graph.\nSpecifically, for a pair of scene graphs of an image and its caption, two\nseparate models are used to learn the features of each graph's nodes and edges.\nThen a Siamese-structure graph convolution model is employed to embed graphs\ninto vector forms. We finally combine the graph-level and the vector-level to\ncalculate the similarity of this image-text pair. The empirical experiments\nshow that our enhancement with the combination of levels can improve the\nperformance of the baseline method by increasing the recall by more than 10% on\nthe Flickr30k dataset.",
          "link": "http://arxiv.org/abs/2106.02400",
          "publishedOn": "2021-06-07T03:06:10.740Z",
          "wordCount": 652,
          "title": "A Deep Local and Global Scene-Graph Matching for Image-Text Retrieval. (arXiv:2106.02400v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02545",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Roger Zhe Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Urbano_J/0/1/0/all/0/1\">Juli&#xe1;n Urbano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanjalic_A/0/1/0/all/0/1\">Alan Hanjalic</a>",
          "description": "Direct optimization of IR metrics has often been adopted as an approach to\ndevise and develop ranking-based recommender systems. Most methods following\nthis approach aim at optimizing the same metric being used for evaluation,\nunder the assumption that this will lead to the best performance. A number of\nstudies of this practice bring this assumption, however, into question. In this\npaper, we dig deeper into this issue in order to learn more about the effects\nof the choice of the metric to optimize on the performance of a ranking-based\nrecommender system. We present an extensive experimental study conducted on\ndifferent datasets in both pairwise and listwise learning-to-rank scenarios, to\ncompare the relative merit of four popular IR metrics, namely RR, AP, nDCG and\nRBP, when used for optimization and assessment of recommender systems in\nvarious combinations. For the first three, we follow the practice of loss\nfunction formulation available in literature. For the fourth one, we propose\nnovel loss functions inspired by RBP for both the pairwise and listwise\nscenario. Our results confirm that the best performance is indeed not\nnecessarily achieved when optimizing the same metric being used for evaluation.\nIn fact, we find that RBP-inspired losses perform at least as well as other\nmetrics in a consistent way, and offer clear benefits in several cases.\nInteresting to see is that RBP-inspired losses, while improving the\nrecommendation performance for all uses, may lead to an individual performance\ngain that is correlated with the activity level of a user in interacting with\nitems. The more active the users, the more they benefit. Overall, our results\nchallenge the assumption behind the current research practice of optimizing and\nevaluating the same metric, and point to RBP-based optimization instead as a\npromising alternative when learning to rank in the recommendation context.",
          "link": "http://arxiv.org/abs/2106.02545",
          "publishedOn": "2021-06-07T03:06:10.712Z",
          "wordCount": 732,
          "title": "New Insights into Metric Optimization for Ranking-based Recommendation. (arXiv:2106.02545v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2004.09424",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bi_K/0/1/0/all/0/1\">Keping Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ai_Q/0/1/0/all/0/1\">Qingyao Ai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Croft_W/0/1/0/all/0/1\">W. Bruce Croft</a>",
          "description": "Product search has been a crucial entry point to serve people shopping\nonline. Most existing personalized product models follow the paradigm of\nrepresenting and matching user intents and items in the semantic space, where\nfiner-grained matching is totally discarded and the ranking of an item cannot\nbe explained further than just user/item level similarity. In addition, while\nsome models in existing studies have created dynamic user representations based\non search context, their representations for items are static across all search\nsessions. This makes every piece of information about the item always equally\nimportant in representing the item during matching with various user intents.\nAware of the above limitations, we propose a review-based transformer model\n(RTM) for personalized product search, which encodes the sequence of query,\nuser reviews, and item reviews with a transformer architecture. RTM conducts\nreview-level matching between the user and item, where each review has a\ndynamic effect according to the context in the sequence. This makes it possible\nto identify useful reviews to explain the scoring. Experimental results show\nthat RTM significantly outperforms state-of-the-art personalized product search\nbaselines.",
          "link": "http://arxiv.org/abs/2004.09424",
          "publishedOn": "2021-06-07T03:06:10.697Z",
          "wordCount": 660,
          "title": "Learning a Fine-Grained Review-based Transformer Model for Personalized Product Search. (arXiv:2004.09424v3 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02223",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1\">Hongzhi Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yujia Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zi Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Meng Wang</a>",
          "description": "In today's context, deploying data-driven services like recommendation on\nedge devices instead of cloud servers becomes increasingly attractive due to\nprivacy and network latency concerns. A common practice in building compact\non-device recommender systems is to compress their embeddings which are\nnormally the cause of excessive parameterization. However, despite the vast\nvariety of devices and their associated memory constraints, existing\nmemory-efficient recommender systems are only specialized for a fixed memory\nbudget in every design and training life cycle, where a new model has to be\nretrained to obtain the optimal performance while adapting to a smaller/larger\nmemory budget. In this paper, we present a novel lightweight recommendation\nparadigm that allows a well-trained recommender to be customized for arbitrary\ndevice-specific memory constraints without retraining. The core idea is to\ncompose elastic embeddings for each item, where an elastic embedding is the\nconcatenation of a set of embedding blocks that are carefully chosen by an\nautomated search function. Correspondingly, we propose an innovative approach,\nnamely recommendation with universally learned elastic embeddings (RULE). To\nensure the expressiveness of all candidate embedding blocks, RULE enforces a\ndiversity-driven regularization when learning different embedding blocks. Then,\na performance estimator-based evolutionary search function is designed,\nallowing for efficient specialization of elastic embeddings under any memory\nconstraint for on-device recommendation. Extensive experiments on real-world\ndatasets reveal the superior performance of RULE under tight memory budgets.",
          "link": "http://arxiv.org/abs/2106.02223",
          "publishedOn": "2021-06-07T03:06:10.644Z",
          "wordCount": 658,
          "title": "Learning Elastic Embeddings for Customizing On-Device Recommenders. (arXiv:2106.02223v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02256",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yihong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maekawa_T/0/1/0/all/0/1\">Takuya Maekawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hara_T/0/1/0/all/0/1\">Takahiro Hara</a>",
          "description": "In recommender systems, a cold-start problem occurs when there is no past\ninteraction record associated with the user or item. Typical solutions to the\ncold-start problem make use of contextual information, such as user demographic\nattributes or product descriptions. A group of works have shown that social\nmedia background can help predicting temporal phenomenons such as product sales\nand stock price movements. In this work, our goal is to investigate whether\nsocial media background can be used as extra contextual information to improve\nrecommendation models. Based on an existing deep neural network model, we\nproposed a method to represent temporal social media background as embeddings\nand fuse them as an extra component in the model. We conduct experimental\nevaluations on a real-world e-commerce dataset and a Twitter dataset. The\nresults show that our method of fusing social media background with the\nexisting model does generally improve recommendation performance. In some cases\nthe recommendation accuracy measured by hit-rate@K doubles after fusing with\nsocial media background. Our findings can be beneficial for future recommender\nsystem designs that consider complex temporal information representing social\ninterests.",
          "link": "http://arxiv.org/abs/2106.02256",
          "publishedOn": "2021-06-07T03:06:10.401Z",
          "wordCount": 618,
          "title": "Using Social Media Background to Improve Cold-start Recommendation Deep Models. (arXiv:2106.02256v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02361",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Daga_E/0/1/0/all/0/1\">Enrico Daga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asprino_L/0/1/0/all/0/1\">Luigi Asprino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mulholland_P/0/1/0/all/0/1\">Paul Mulholland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gangemi_A/0/1/0/all/0/1\">Aldo Gangemi</a>",
          "description": "The Semantic Web research community understood since its beginning how\ncrucial it is to equip practitioners with methods to transform non-RDF\nresources into RDF. Proposals focus on either engineering content\ntransformations or accessing non-RDF resources with SPARQL. Existing solutions\nrequire users to learn specific mapping languages (e.g. RML), to know how to\nquery and manipulate a variety of source formats (e.g. XPATH, JSON-Path), or to\ncombine multiple languages (e.g. SPARQL Generate). In this paper, we explore an\nalternative solution and contribute a general-purpose meta-model for converting\nnon-RDF resources into RDF: Facade-X. Our approach can be implemented by\noverriding the SERVICE operator and does not require to extend the SPARQL\nsyntax. We compare our approach with the state of art methods RML and SPARQL\nGenerate and show how our solution has lower learning demands and cognitive\ncomplexity, and it is cheaper to implement and maintain, while having\ncomparable extensibility and efficiency.",
          "link": "http://arxiv.org/abs/2106.02361",
          "publishedOn": "2021-06-07T03:06:10.383Z",
          "wordCount": 585,
          "title": "Facade-X: an opinionated approach to SPARQL anything. (arXiv:2106.02361v1 [cs.DB])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02250",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yihong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shirakawa_M/0/1/0/all/0/1\">Masumi Shirakawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hara_T/0/1/0/all/0/1\">Takahiro Hara</a>",
          "description": "Event detection on social media has attracted a number of researches, given\nthe recent availability of large volumes of social media discussions. Previous\nworks on social media event detection either assume a specific type of event,\nor assume certain behavior of observed variables. In this paper, we propose a\ngeneral method for event detection on social media that makes few assumptions.\nThe main assumption we make is that when an event occurs, affected semantic\naspects will behave differently from its usual behavior. We generalize the\nrepresentation of time units based on word embeddings of social media text, and\npropose an algorithm to detect events in time series in a general sense. In the\nexperimental evaluation, we use a novel setting to test if our method and\nbaseline methods can exhaustively catch all real-world news in the test period.\nThe evaluation results show that when the event is quite unusual with regard to\nthe base social media discussion, it can be captured more effectively with our\nmethod. Our method can be easily implemented and can be treated as a starting\npoint for more specific applications.",
          "link": "http://arxiv.org/abs/2106.02250",
          "publishedOn": "2021-06-07T03:06:10.358Z",
          "wordCount": 625,
          "title": "A General Method for Event Detection on Social Media. (arXiv:2106.02250v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02293",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yanda Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kedzie_C/0/1/0/all/0/1\">Chris Kedzie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nair_S/0/1/0/all/0/1\">Suraj Nair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galuscakova_P/0/1/0/all/0/1\">Petra Galu&#x161;&#x10d;&#xe1;kov&#xe1;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oard_D/0/1/0/all/0/1\">Douglas W. Oard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McKeown_K/0/1/0/all/0/1\">Kathleen McKeown</a>",
          "description": "This paper proposes an approach to cross-language sentence selection in a\nlow-resource setting. It uses data augmentation and negative sampling\ntechniques on noisy parallel sentence data to directly learn a cross-lingual\nembedding-based query relevance model. Results show that this approach performs\nas well as or better than multiple state-of-the-art machine translation +\nmonolingual retrieval systems trained on the same parallel data. Moreover, when\na rationale training secondary objective is applied to encourage the model to\nmatch word alignment hints from a phrase-based statistical machine translation\nmodel, consistent improvements are seen across three language pairs\n(English-Somali, English-Swahili and English-Tagalog) over a variety of\nstate-of-the-art baselines.",
          "link": "http://arxiv.org/abs/2106.02293",
          "publishedOn": "2021-06-07T03:06:10.316Z",
          "wordCount": 548,
          "title": "Cross-language Sentence Selection via Data Augmentation and Rationale Training. (arXiv:2106.02293v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01941",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yi Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bayoumi_M/0/1/0/all/0/1\">Magd Bayoumi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joachims_T/0/1/0/all/0/1\">Thorsten Joachims</a>",
          "description": "Based on the success of recommender systems in e-commerce, there is growing\ninterest in their use in matching markets (e.g., labor). While this holds\npotential for improving market fluidity and fairness, we show in this paper\nthat naively applying existing recommender systems to matching markets is\nsub-optimal. Considering the standard process where candidates apply and then\nget evaluated by employers, we present a new recommendation framework to model\nthis interaction mechanism and propose efficient algorithms for computing\npersonalized rankings in this setting. We show that the optimal rankings need\nto not only account for the potentially divergent preferences of candidates and\nemployers, but they also need to account for capacity constraints. This makes\nconventional ranking systems that merely rank by some local score (e.g.,\none-sided or reciprocal relevance) highly sub-optimal -- not only for an\nindividual user, but also for societal goals (e.g., low unemployment). To\naddress this shortcoming, we propose the first method for jointly optimizing\nthe rankings for all candidates in the market to explicitly maximize social\nwelfare. In addition to the theoretical derivation, we evaluate the method both\non simulated environments and on data from a real-world\nnetworking-recommendation system that we built and fielded at a large computer\nscience conference.",
          "link": "http://arxiv.org/abs/2106.01941",
          "publishedOn": "2021-06-04T01:12:26.481Z",
          "wordCount": 623,
          "title": "Optimizing Rankings for Recommendation in Matching Markets. (arXiv:2106.01941v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01706",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kamran_S/0/1/0/all/0/1\">Sara Kamran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zall_R/0/1/0/all/0/1\">Raziyeh Zall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kangavari_M/0/1/0/all/0/1\">Mohammad Reza Kangavari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hosseini_S/0/1/0/all/0/1\">Saeid Hosseini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahmani_S/0/1/0/all/0/1\">Sana Rahmani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1\">Wen Hua</a>",
          "description": "The latent knowledge in the emotions and the opinions of the individuals that\nare manifested via social networks are crucial to numerous applications\nincluding social management, dynamical processes, and public security.\nAffective computing, as an interdisciplinary research field, linking artificial\nintelligence to cognitive inference, is capable to exploit emotion-oriented\nknowledge from brief contents. The textual contents convey hidden information\nsuch as personality and cognition about corresponding authors that can\ndetermine both correlations and variations between users. Emotion recognition\nfrom brief contents should embrace the contrast between authors where the\ndifferences in personality and cognition can be traced within emotional\nexpressions. To tackle this challenge, we devise a framework that, on the one\nhand, infers latent individual aspects, from brief contents and, on the other\nhand, presents a novel ensemble classifier equipped with dynamic dropout\nconvnets to extract emotions from textual context. To categorize short text\ncontents, our proposed method conjointly leverages cognitive factors and\nexploits hidden information. We utilize the outcome vectors in a novel\nembedding model to foster emotion-pertinent features that are collectively\nassembled by lexicon inductions. Experimental results show that compared to\nother competitors, our proposed model can achieve a higher performance in\nrecognizing emotion from noisy contents.",
          "link": "http://arxiv.org/abs/2106.01706",
          "publishedOn": "2021-06-04T01:12:26.470Z",
          "wordCount": 651,
          "title": "EmoDNN: Understanding emotions from short texts through a deep neural network ensemble. (arXiv:2106.01706v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2004.02023",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Biega_A/0/1/0/all/0/1\">Asia J. Biega</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_J/0/1/0/all/0/1\">Jana Schmidt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_R/0/1/0/all/0/1\">Rishiraj Saha Roy</a>",
          "description": "Translating verbose information needs into crisp search queries is a\nphenomenon that is ubiquitous but hardly understood. Insights into this process\ncould be valuable in several applications, including synthesizing large\nprivacy-friendly query logs from public Web sources which are readily available\nto the academic research community. In this work, we take a step towards\nunderstanding query formulation by tapping into the rich potential of community\nquestion answering (CQA) forums. Specifically, we sample natural language (NL)\nquestions spanning diverse themes from the Stack Exchange platform, and conduct\na large-scale conversion experiment where crowdworkers submit search queries\nthey would use when looking for equivalent information. We provide a careful\nanalysis of this data, accounting for possible sources of bias during\nconversion, along with insights into user-specific linguistic patterns and\nsearch behaviors. We release a dataset of 7,000 question-query pairs from this\nstudy to facilitate further research on query understanding.",
          "link": "http://arxiv.org/abs/2004.02023",
          "publishedOn": "2021-06-04T01:12:26.458Z",
          "wordCount": 625,
          "title": "Towards Query Logs for Privacy Studies: On Deriving Search Queries from Questions. (arXiv:2004.02023v3 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01674",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1\">Qian Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_X/0/1/0/all/0/1\">Xiaochao Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1\">Hao Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Guangxing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenlin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Guobao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zha_Z/0/1/0/all/0/1\">Zhiwei Zha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_D/0/1/0/all/0/1\">Daxiang Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_D/0/1/0/all/0/1\">Dejing Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1\">Haoyi Xiong</a>",
          "description": "In modern internet industries, deep learning based recommender systems have\nbecame an indispensable building block for a wide spectrum of applications,\nsuch as search engine, news feed, and short video clips. However, it remains\nchallenging to carry the well-trained deep models for online real-time\ninference serving, with respect to the time-varying web-scale traffics from\nbillions of users, in a cost-effective manner. In this work, we present JIZHI -\na Model-as-a-Service system - that per second handles hundreds of millions of\nonline inference requests to huge deep models with more than trillions of\nsparse parameters, for over twenty real-time recommendation services at Baidu,\nInc. In JIZHI, the inference workflow of every recommendation request is\ntransformed to a Staged Event-Driven Pipeline (SEDP), where each node in the\npipeline refers to a staged computation or I/O intensive task processor. With\ntraffics of real-time inference requests arrived, each modularized processor\ncan be run in a fully asynchronized way and managed separately. Besides, JIZHI\nintroduces heterogeneous and hierarchical storage to further accelerate the\nonline inference process by reducing unnecessary computations and potential\ndata access latency induced by ultra-sparse model parameters. Moreover, an\nintelligent resource manager has been deployed to maximize the throughput of\nJIZHI over the shared infrastructure by searching the optimal resource\nallocation plan from historical logs and fine-tuning the load shedding policies\nover intermediate system feedback. Extensive experiments have been done to\ndemonstrate the advantages of JIZHI from the perspectives of end-to-end service\nlatency, system-wide throughput, and resource consumption. JIZHI has helped\nBaidu saved more than ten million US dollars in hardware and utility costs\nwhile handling 200% more traffics without sacrificing inference efficiency.",
          "link": "http://arxiv.org/abs/2106.01674",
          "publishedOn": "2021-06-04T01:12:26.119Z",
          "wordCount": 740,
          "title": "JIZHI: A Fast and Cost-Effective Model-As-A-Service System for Web-Scale Online Inference at Baidu. (arXiv:2106.01674v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01490",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuan Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1\">Ke Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pelleg_D/0/1/0/all/0/1\">Dan Pelleg</a>",
          "description": "User engagement is crucial to the long-term success of a mobile app. Several\nmetrics, such as dwell time, have been used for measuring user engagement.\nHowever, how to effectively predict user engagement in the context of mobile\napps is still an open research question. For example, do the mobile usage\ncontexts (e.g.,~time of day) in which users access mobile apps impact their\ndwell time? Answers to such questions could help mobile operating system and\npublishers to optimize advertising and service placement. In this paper, we\nfirst conduct an empirical study for assessing how user characteristics,\ntemporal features, and the short/long-term contexts contribute to gains in\npredicting users' app dwell time on the population level. The comprehensive\nanalysis is conducted on large app usage logs collected through a mobile\nadvertising company. The dataset covers more than 12K anonymous users and 1.3\nmillion log events. Based on the analysis, we further investigate a novel\nmobile app engagement prediction problem -- can we predict simultaneously what\napp the user will use next and how long he/she will stay on that app? We\npropose several strategies for this joint prediction problem and demonstrate\nthat our model can improve the performance significantly when compared with the\nstate-of-the-art baselines. Our work can help mobile system developers in\ndesigning a better and more engagement-aware mobile app user experience.",
          "link": "http://arxiv.org/abs/2106.01490",
          "publishedOn": "2021-06-04T01:12:26.099Z",
          "wordCount": 660,
          "title": "What and How long: Prediction of Mobile App Engagement. (arXiv:2106.01490v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2103.00368",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1\">Yiling Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huazheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Stephen Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongning Wang</a>",
          "description": "Online Learning to Rank (OL2R) eliminates the need of explicit relevance\nannotation by directly optimizing the rankers from their interactions with\nusers. However, the required exploration drives it away from successful\npractices in offline learning to rank, which limits OL2R's empirical\nperformance and practical applicability. In this work, we propose to estimate a\npairwise learning to rank model online. In each round, candidate documents are\npartitioned and ranked according to the model's confidence on the estimated\npairwise rank order, and exploration is only performed on the uncertain pairs\nof documents, i.e., \\emph{divide-and-conquer}. Regret directly defined on the\nnumber of mis-ordered pairs is proven, which connects the online solution's\ntheoretical convergence with its expected ranking performance. Comparisons\nagainst an extensive list of OL2R baselines on two public learning to rank\nbenchmark datasets demonstrate the effectiveness of the proposed solution.",
          "link": "http://arxiv.org/abs/2103.00368",
          "publishedOn": "2021-06-03T02:10:33.258Z",
          "wordCount": 611,
          "title": "PairRank: Online Pairwise Learning to Rank by Divide-and-Conquer. (arXiv:2103.00368v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14201",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Q/0/1/0/all/0/1\">Qianren Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1\">Hao Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hongdong Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianxin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zheng Wang</a>",
          "description": "By producing summaries for long-running events, timeline summarization (TLS)\nunderpins many information retrieval tasks. Successful TLS requires identifying\nan appropriate set of key dates (the timeline length) to cover. However, doing\nso is challenging as the right length can change from one topic to another.\nExisting TLS solutions either rely on an event-agnostic fixed length or an\nexpert-supplied setting. Neither of the strategies is desired for real-life TLS\nscenarios. A fixed, event-agnostic setting ignores the diversity of events and\ntheir development and hence can lead to low-quality TLS. Relying on\nexpert-crafted settings is neither scalable nor sustainable for processing many\ndynamically changing events. This paper presents a better TLS approach for\nautomatically and dynamically determining the TLS timeline length. We achieve\nthis by employing the established elbow method from the machine learning\ncommunity to automatically find the minimum number of dates within the time\nseries to generate concise and informative summaries. We applied our approach\nto four TLS datasets of English and Chinese and compared them against three\nprior methods. Experimental results show that our approach delivers comparable\nor even better summaries over state-of-art TLS methods, but it achieves this\nwithout expert involvement.",
          "link": "http://arxiv.org/abs/2105.14201",
          "publishedOn": "2021-06-03T02:10:33.063Z",
          "wordCount": 629,
          "title": "Automated Timeline Length Selection for Flexible Timeline Summarization. (arXiv:2105.14201v1 [cs.AI] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.14862",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Si Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1\">Yingzhuo Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhenghao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Chenyan Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaitao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_J/0/1/0/all/0/1\">Jie Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bennett_P/0/1/0/all/0/1\">Paul Bennett</a>",
          "description": "The effectiveness of Neural Information Retrieval (Neu-IR) often depends on a\nlarge scale of in-domain relevance training signals, which are not always\navailable in real-world ranking scenarios. To democratize the benefits of\nNeu-IR, this paper presents MetaAdaptRank, a domain adaptive learning method\nthat generalizes Neu-IR models from label-rich source domains to few-shot\ntarget domains. Drawing on source-domain massive relevance supervision,\nMetaAdaptRank contrastively synthesizes a large number of weak supervision\nsignals for target domains and meta-learns to reweight these synthetic \"weak\"\ndata based on their benefits to the target-domain ranking accuracy of Neu-IR\nmodels. Experiments on three TREC benchmarks in the web, news, and biomedical\ndomains show that MetaAdaptRank significantly improves the few-shot ranking\naccuracy of Neu-IR models. Further analyses indicate that MetaAdaptRank thrives\nfrom both its contrastive weak data synthesis and meta-reweighted data\nselection. The code and data of this paper can be obtained from\nhttps://github.com/thunlp/MetaAdaptRank.",
          "link": "http://arxiv.org/abs/2012.14862",
          "publishedOn": "2021-06-03T02:10:33.055Z",
          "wordCount": 625,
          "title": "Few-Shot Text Ranking with Meta Adapted Synthetic Weak Supervision. (arXiv:2012.14862v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01251",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vinod_V/0/1/0/all/0/1\">Vishal Vinod</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_S/0/1/0/all/0/1\">Susmit Agrawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaurav_V/0/1/0/all/0/1\">Vipul Gaurav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+R_P/0/1/0/all/0/1\">Pallavi R</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choudhary_S/0/1/0/all/0/1\">Savita Choudhary</a>",
          "description": "In rural regions of several developing countries, access to quality\nhealthcare, medical infrastructure, and professional diagnosis is largely\nunavailable. Many of these regions are gradually gaining access to internet\ninfrastructure, although not with a strong enough connection to allow for\nsustained communication with a medical practitioner. Several deaths resulting\nfrom this lack of medical access, absence of patient's previous health records,\nand the unavailability of information in indigenous languages can be easily\nprevented. In this paper, we describe an approach leveraging the phenomenal\nprogress in Machine Learning and NLP (Natural Language Processing) techniques\nto design a model that is low-resource, multilingual, and a preliminary\nfirst-point-of-contact medical assistant. Our contribution includes defining\nthe NLP pipeline required for named-entity-recognition, language-agnostic\nsentence embedding, natural language translation, information retrieval,\nquestion answering, and generative pre-training for final query processing. We\nobtain promising results for this pipeline and preliminary results for EHR\n(Electronic Health Record) analysis with text summarization for medical\npractitioners to peruse for their diagnosis. Through this NLP pipeline, we aim\nto provide preliminary medical information to the user and do not claim to\nsupplant diagnosis from qualified medical practitioners. Using the input from\nsubject matter experts, we have compiled a large corpus to pre-train and\nfine-tune our BioBERT based NLP model for the specific tasks. We expect recent\nadvances in NLP architectures, several of which are efficient and\nprivacy-preserving models, to further the impact of our solution and improve on\nindividual task performance.",
          "link": "http://arxiv.org/abs/2106.01251",
          "publishedOn": "2021-06-03T02:10:32.851Z",
          "wordCount": 684,
          "title": "Multilingual Medical Question Answering and Information Retrieval for Rural Health Intelligence Access. (arXiv:2106.01251v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01300",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_T/0/1/0/all/0/1\">Tao Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fangzhao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chuhan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yongfeng Huang</a>",
          "description": "Personalized news recommendation methods are widely used in online news\nservices. These methods usually recommend news based on the matching between\nnews content and user interest inferred from historical behaviors. However,\nthese methods usually have difficulties in making accurate recommendations to\ncold-start users, and tend to recommend similar news with those users have\nread. In general, popular news usually contain important information and can\nattract users with different interests. Besides, they are usually diverse in\ncontent and topic. Thus, in this paper we propose to incorporate news\npopularity information to alleviate the cold-start and diversity problems for\npersonalized news recommendation. In our method, the ranking score for\nrecommending a candidate news to a target user is the combination of a\npersonalized matching score and a news popularity score. The former is used to\ncapture the personalized user interest in news. The latter is used to measure\ntime-aware popularity of candidate news, which is predicted based on news\ncontent, recency, and real-time CTR using a unified framework. Besides, we\npropose a popularity-aware user encoder to eliminate the popularity bias in\nuser behaviors for accurate interest modeling. Experiments on two real-world\ndatasets show our method can effectively improve the accuracy and diversity for\nnews recommendation.",
          "link": "http://arxiv.org/abs/2106.01300",
          "publishedOn": "2021-06-03T02:10:32.808Z",
          "wordCount": 636,
          "title": "PP-Rec: News Recommendation with Personalized User Interest and Time-aware News Popularity. (arXiv:2106.01300v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01232",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khurana_P/0/1/0/all/0/1\">Parul Khurana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganesan_G/0/1/0/all/0/1\">Geetha Ganesan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_G/0/1/0/all/0/1\">Gulshan Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_K/0/1/0/all/0/1\">Kiran Sharma</a>",
          "description": "Numerous indexing databases keep track of the number of publications,\ncitations, etc. in order to maintain the progress of science and individual.\nHowever, the choice of journals and articles varies among these indexing\ndatabases, hence the number of citations and h-index varies. There is no common\nplatform exists that can provide a single count for the number of publications,\ncitations, h-index, etc. To overcome this limitation, we have proposed a\nweighted unified informetrics, named \"conflate\". The proposed system takes into\naccount the input from multiple indexing databases and generates a single\noutput. Here, we have used the data from Scopus and WoS to generate a conflate\ndataset. Further, a comparative analysis of conflate has been performed with\nScopus and WoS at three levels: author, organization, and journal. Finally, a\nmapping is proposed between research publications and distributed ledger\ntechnology in order to provide a transparent and distributed view to its\nstakeholders.",
          "link": "http://arxiv.org/abs/2106.01232",
          "publishedOn": "2021-06-03T02:10:32.787Z",
          "wordCount": 586,
          "title": "A weighted unified informetrics based on Scopus and WoS. (arXiv:2106.01232v1 [cs.DL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01033",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_K/0/1/0/all/0/1\">Kunwoo Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_Z/0/1/0/all/0/1\">Zhufeng Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joo_J/0/1/0/all/0/1\">Jungseock Joo</a>",
          "description": "Understanding who blames or supports whom in news text is a critical research\nquestion in computational social science. Traditional methods and datasets for\nsentiment analysis are, however, not suitable for the domain of political text\nas they do not consider the direction of sentiments expressed between entities.\nIn this paper, we propose a novel NLP task of identifying directed sentiment\nrelationship between political entities from a given news document, which we\ncall directed sentiment extraction. From a million-scale news corpus, we\nconstruct a dataset of news sentences where sentiment relations of political\nentities are manually annotated. We present a simple but effective approach for\nutilizing a pretrained transformer, which infers the target class by predicting\nmultiple question-answering tasks and combining the outcomes. We demonstrate\nthe utility of our proposed method for social science research questions by\nanalyzing positive and negative opinions between political entities in two\nmajor events: 2016 U.S. presidential election and COVID-19. The newly proposed\nproblem, data, and method will facilitate future studies on interdisciplinary\nNLP methods and applications.",
          "link": "http://arxiv.org/abs/2106.01033",
          "publishedOn": "2021-06-03T02:10:32.732Z",
          "wordCount": 665,
          "title": "Who Blames or Endorses Whom? Entity-to-Entity Directed Sentiment Extraction in News Text. (arXiv:2106.01033v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00882",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yamada_I/0/1/0/all/0/1\">Ikuya Yamada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asai_A/0/1/0/all/0/1\">Akari Asai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>",
          "description": "Most state-of-the-art open-domain question answering systems use a neural\nretrieval model to encode passages into continuous vectors and extract them\nfrom a knowledge source. However, such retrieval models often require large\nmemory to run because of the massive size of their passage index. In this\npaper, we introduce Binary Passage Retriever (BPR), a memory-efficient neural\nretrieval model that integrates a learning-to-hash technique into the\nstate-of-the-art Dense Passage Retriever (DPR) to represent the passage index\nusing compact binary codes rather than continuous vectors. BPR is trained with\na multi-task objective over two tasks: efficient candidate generation based on\nbinary codes and accurate reranking based on continuous vectors. Compared with\nDPR, BPR substantially reduces the memory cost from 65GB to 2GB without a loss\nof accuracy on two standard open-domain question answering benchmarks: Natural\nQuestions and TriviaQA. Our code and trained models are available at\nhttps://github.com/studio-ousia/bpr.",
          "link": "http://arxiv.org/abs/2106.00882",
          "publishedOn": "2021-06-03T02:10:32.722Z",
          "wordCount": 579,
          "title": "Efficient Passage Retrieval with Hashing for Open-domain Question Answering. (arXiv:2106.00882v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00874",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zaib_M/0/1/0/all/0/1\">Munazza Zaib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei Emma Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheng_Q/0/1/0/all/0/1\">Quan Z. Sheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmood_A/0/1/0/all/0/1\">Adnan Mahmood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>",
          "description": "Question answering (QA) systems provide a way of querying the information\navailable in various formats including, but not limited to, unstructured and\nstructured data in natural languages. It constitutes a considerable part of\nconversational artificial intelligence (AI) which has led to the introduction\nof a special research topic on Conversational Question Answering (CQA), wherein\na system is required to understand the given context and then engages in\nmulti-turn QA to satisfy the user's information needs. Whilst the focus of most\nof the existing research work is subjected to single-turn QA, the field of\nmulti-turn QA has recently grasped attention and prominence owing to the\navailability of large-scale, multi-turn QA datasets and the development of\npre-trained language models. With a good amount of models and research papers\nadding to the literature every year recently, there is a dire need of arranging\nand presenting the related work in a unified manner to streamline future\nresearch. This survey, therefore, is an effort to present a comprehensive\nreview of the state-of-the-art research trends of CQA primarily based on\nreviewed papers from 2016-2021. Our findings show that there has been a trend\nshift from single-turn to multi-turn QA which empowers the field of\nConversational AI from different perspectives. This survey is intended to\nprovide an epitome for the research community with the hope of laying a strong\nfoundation for the field of CQA.",
          "link": "http://arxiv.org/abs/2106.00874",
          "publishedOn": "2021-06-03T02:10:32.692Z",
          "wordCount": 660,
          "title": "Conversational Question Answering: A Survey. (arXiv:2106.00874v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2006.06963",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Marchant_N/0/1/0/all/0/1\">Neil G. Marchant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubinstein_B/0/1/0/all/0/1\">Benjamin I. P. Rubinstein</a>",
          "description": "Important tasks like record linkage and extreme classification demonstrate\nextreme class imbalance, with 1 minority instance to every 1 million or more\nmajority instances. Obtaining a sufficient sample of all classes, even just to\nachieve statistically-significant evaluation, is so challenging that most\ncurrent approaches yield poor estimates or incur impractical cost. Where\nimportance sampling has been levied against this challenge, restrictive\nconstraints are placed on performance metrics, estimates do not come with\nappropriate guarantees, or evaluations cannot adapt to incoming labels. This\npaper develops a framework for online evaluation based on adaptive importance\nsampling. Given a target performance metric and model for $p(y|x)$, the\nframework adapts a distribution over items to label in order to maximize\nstatistical precision. We establish strong consistency and a central limit\ntheorem for the resulting performance estimates, and instantiate our framework\nwith worked examples that leverage Dirichlet-tree models. Experiments\ndemonstrate an average MSE superior to state-of-the-art on fixed label budgets.",
          "link": "http://arxiv.org/abs/2006.06963",
          "publishedOn": "2021-06-03T02:10:32.537Z",
          "wordCount": 640,
          "title": "Needle in a Haystack: Label-Efficient Evaluation under Extreme Class Imbalance. (arXiv:2006.06963v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01149",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Ho-Hsiang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fuentes_M/0/1/0/all/0/1\">Magdalena Fuentes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bello_J/0/1/0/all/0/1\">Juan P. Bello</a>",
          "description": "Music information is often conveyed or recorded across multiple data\nmodalities including but not limited to audio, images, text and scores.\nHowever, music information retrieval research has almost exclusively focused on\nsingle modality recognition, requiring development of separate models for each\nmodality. Some multi-modal works require multiple coexisting modalities given\nto the model as inputs, constraining the use of these models to the few cases\nwhere data from all modalities are available. To the best of our knowledge, no\nexisting model has the ability to take inputs from varying modalities, e.g.\nimages or sounds, and classify them into unified music categories. We explore\nthe use of cross-modal retrieval as a pretext task to learn modality-agnostic\nrepresentations, which can then be used as inputs to classifiers that are\nindependent of modality. We select instrument classification as an example task\nfor our study as both visual and audio components provide relevant semantic\ninformation. We train music instrument classifiers that can take both images or\nsounds as input, and perform comparably to sound-only or image-only\nclassifiers. Furthermore, we explore the case when there is limited labeled\ndata for a given modality, and the impact in performance by using labeled data\nfrom other modalities. We are able to achieve almost 70% of best performing\nsystem in a zero-shot setting. We provide a detailed analysis of experimental\nresults to understand the potential and limitations of the approach, and\ndiscuss future steps towards modality-agnostic classifiers.",
          "link": "http://arxiv.org/abs/2106.01149",
          "publishedOn": "2021-06-03T02:10:32.499Z",
          "wordCount": 667,
          "title": "Exploring modality-agnostic representations for music classification. (arXiv:2106.01149v1 [cs.SD])"
        }
      ]
    },
    {
      "title": "cs.MM updates on arXiv.org",
      "feedUrl": "http://export.arxiv.org/rss/cs.MM",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2010.10637",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaofeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1\">Linghao Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_J/0/1/0/all/0/1\">Jane You</a>",
          "description": "How to extract effective expression representations that invariant to the\nidentity-specific attributes is a long-lasting problem for facial expression\nrecognition (FER). Most of the previous methods process the RGB images of a\nsequence, while we argue that the off-the-shelf and valuable expression-related\nmuscle movement is already embedded in the compression format. In this paper,\nwe target to explore the inter-subject variations eliminated facial expression\nrepresentation in the compressed video domain. In the up to two orders of\nmagnitude compressed domain, we can explicitly infer the expression from the\nresidual frames and possibly extract identity factors from the I frame with a\npre-trained face recognition network. By enforcing the marginal independence of\nthem, the expression feature is expected to be purer for the expression and be\nrobust to identity shifts. Specifically, we propose a novel collaborative\nmin-min game for mutual information (MI) minimization in latent space. We do\nnot need the identity label or multiple expression samples from the same person\nfor identity elimination. Moreover, when the apex frame is annotated in the\ndataset, the complementary constraint can be further added to regularize the\nfeature-level game. In testing, only the compressed residual frames are\nrequired to achieve expression prediction. Our solution can achieve comparable\nor better performance than the recent decoded image-based methods on the\ntypical FER benchmarks with about 3 times faster inference.",
          "link": "http://arxiv.org/abs/2010.10637",
          "publishedOn": "2021-06-08T02:20:20.501Z",
          "wordCount": 695,
          "title": "Mutual Information Regularized Identity-aware Facial ExpressionRecognition in Compressed Video. (arXiv:2010.10637v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.13125",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Li_T/0/1/0/all/0/1\">Tianyi Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_M/0/1/0/all/0/1\">Mai Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tang_R/0/1/0/all/0/1\">Runzhi Tang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1\">Ying Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xing_Q/0/1/0/all/0/1\">Qunliang Xing</a>",
          "description": "Versatile Video Coding (VVC), as the latest standard, significantly improves\nthe coding efficiency over its ancestor standard High Efficiency Video Coding\n(HEVC), but at the expense of sharply increased complexity. In VVC, the\nquad-tree plus multi-type tree (QTMT) structure of coding unit (CU) partition\naccounts for over 97% of the encoding time, due to the brute-force search for\nrecursive rate-distortion (RD) optimization. Instead of the brute-force QTMT\nsearch, this paper proposes a deep learning approach to predict the QTMT-based\nCU partition, for drastically accelerating the encoding process of intra-mode\nVVC. First, we establish a large-scale database containing sufficient CU\npartition patterns with diverse video content, which can facilitate the\ndata-driven VVC complexity reduction. Next, we propose a multi-stage exit CNN\n(MSE-CNN) model with an early-exit mechanism to determine the CU partition, in\naccord with the flexible QTMT structure at multiple stages. Then, we design an\nadaptive loss function for training the MSE-CNN model, synthesizing both the\nuncertain number of split modes and the target on minimized RD cost. Finally, a\nmulti-threshold decision scheme is developed, achieving desirable trade-off\nbetween complexity and RD performance. Experimental results demonstrate that\nour approach can reduce the encoding time of VVC by 44.65%-66.88% with the\nnegligible Bj{\\o}ntegaard delta bit-rate (BD-BR) of 1.322%-3.188%, which\nsignificantly outperforms other state-of-the-art approaches.",
          "link": "http://arxiv.org/abs/2006.13125",
          "publishedOn": "2021-06-08T02:20:20.377Z",
          "wordCount": 718,
          "title": "DeepQTMT: A Deep Learning Approach for Fast QTMT-based CU Partition of Intra-mode VVC. (arXiv:2006.13125v3 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02864",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tripathi_S/0/1/0/all/0/1\">Suvidha Tripathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Satish Kumar Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hwee Kuan Lee</a>",
          "description": "Researchers working on computational analysis of Whole Slide Images (WSIs) in\nhistopathology have primarily resorted to patch-based modelling due to large\nresolution of each WSI. The large resolution makes WSIs infeasible to be fed\ndirectly into the machine learning models due to computational constraints.\nHowever, due to patch-based analysis, most of the current methods fail to\nexploit the underlying spatial relationship among the patches. In our work, we\nhave tried to integrate this relationship along with feature-based correlation\namong the extracted patches from the particular tumorous region. For the given\ntask of classification, we have used BiLSTMs to model both forward and backward\ncontextual relationship. RNN based models eliminate the limitation of sequence\nsize by allowing the modelling of variable size images within a deep learning\nmodel. We have also incorporated the effect of spatial continuity by exploring\ndifferent scanning techniques used to sample patches. To establish the\nefficiency of our approach, we trained and tested our model on two datasets,\nmicroscopy images and WSI tumour regions. After comparing with contemporary\nliterature we achieved the better performance with accuracy of 90% for\nmicroscopy image dataset. For WSI tumour region dataset, we compared the\nclassification results with deep learning networks such as ResNet, DenseNet,\nand InceptionV3 using maximum voting technique. We achieved the highest\nperformance accuracy of 84%. We found out that BiLSTMs with CNN features have\nperformed much better in modelling patches into an end-to-end Image\nclassification network. Additionally, the variable dimensions of WSI tumour\nregions were used for classification without the need for resizing. This\nsuggests that our method is independent of tumour image size and can process\nlarge dimensional images without losing the resolution details.",
          "link": "http://arxiv.org/abs/2106.02864",
          "publishedOn": "2021-06-08T02:20:20.291Z",
          "wordCount": 757,
          "title": "An End-to-End Breast Tumour Classification Model Using Context-Based Patch Modelling- A BiLSTM Approach for Image Classification. (arXiv:2106.02864v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02738",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mo_T/0/1/0/all/0/1\">Tong Mo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bang Liu</a>",
          "description": "Keyword spotting aims to identify specific keyword audio utterances. In\nrecent years, deep convolutional neural networks have been widely utilized in\nkeyword spotting systems. However, their model architectures are mainly based\non off-the shelfbackbones such as VGG-Net or ResNet, instead of specially\ndesigned for the task. In this paper, we utilize neural architecture search to\ndesign convolutional neural network models that can boost the performance of\nkeyword spotting while maintaining an acceptable memory footprint.\nSpecifically, we search the model operators and their connections in a specific\nsearch space with Encoder-Decoder neural architecture optimization. Extensive\nevaluations on Google's Speech Commands Dataset show that the model\narchitecture searched by our approach achieves a state-of-the-art accuracy of\nover 97%.",
          "link": "http://arxiv.org/abs/2106.02738",
          "publishedOn": "2021-06-08T02:20:20.207Z",
          "wordCount": 540,
          "title": "Encoder-Decoder Neural Architecture Optimization for Keyword Spotting. (arXiv:2106.02738v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02634",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sitzmann_V/0/1/0/all/0/1\">Vincent Sitzmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rezchikov_S/0/1/0/all/0/1\">Semon Rezchikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freeman_W/0/1/0/all/0/1\">William T. Freeman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua B. Tenenbaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durand_F/0/1/0/all/0/1\">Fredo Durand</a>",
          "description": "Inferring representations of 3D scenes from 2D observations is a fundamental\nproblem of computer graphics, computer vision, and artificial intelligence.\nEmerging 3D-structured neural scene representations are a promising approach to\n3D scene understanding. In this work, we propose a novel neural scene\nrepresentation, Light Field Networks or LFNs, which represent both geometry and\nappearance of the underlying 3D scene in a 360-degree, four-dimensional light\nfield parameterized via a neural implicit representation. Rendering a ray from\nan LFN requires only a *single* network evaluation, as opposed to hundreds of\nevaluations per ray for ray-marching or volumetric based renderers in\n3D-structured neural scene representations. In the setting of simple scenes, we\nleverage meta-learning to learn a prior over LFNs that enables multi-view\nconsistent light field reconstruction from as little as a single image\nobservation. This results in dramatic reductions in time and memory complexity,\nand enables real-time rendering. The cost of storing a 360-degree light field\nvia an LFN is two orders of magnitude lower than conventional methods such as\nthe Lumigraph. Utilizing the analytical differentiability of neural implicit\nrepresentations and a novel parameterization of light space, we further\ndemonstrate the extraction of sparse depth maps from LFNs.",
          "link": "http://arxiv.org/abs/2106.02634",
          "publishedOn": "2021-06-07T03:06:10.657Z",
          "wordCount": 657,
          "title": "Light Field Networks: Neural Scene Representations with Single-Evaluation Rendering. (arXiv:2106.02634v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baccour_E/0/1/0/all/0/1\">Emna Baccour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haouari_F/0/1/0/all/0/1\">Fatima Haouari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erbad_A/0/1/0/all/0/1\">Aiman Erbad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohamed_A/0/1/0/all/0/1\">Amr Mohamed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilal_K/0/1/0/all/0/1\">Kashif Bilal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guizani_M/0/1/0/all/0/1\">Mohsen Guizani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamdi_M/0/1/0/all/0/1\">Mounir Hamdi</a>",
          "description": "Crowdsourced live video streaming (livecast) services such as Facebook Live,\nYouNow, Douyu and Twitch are gaining more momentum recently. Allocating the\nlimited resources in a cost-effective manner while maximizing the Quality of\nService (QoS) through real-time delivery and the provision of the appropriate\nrepresentations for all viewers is a challenging problem. In our paper, we\nintroduce a machine-learning based predictive resource allocation framework for\ngeo-distributed cloud sites, considering the delay and quality constraints to\nguarantee the maximum QoS for viewers and the minimum cost for content\nproviders. First, we present an offline optimization that decides the required\ntranscoding resources in distributed regions near the viewers with a trade-off\nbetween the QoS and the overall cost. Second, we use machine learning to build\nforecasting models that proactively predict the approximate transcoding\nresources to be reserved at each cloud site ahead of time. Finally, we develop\na Greedy Nearest and Cheapest algorithm (GNCA) to perform the resource\nallocation of real-time broadcasted videos on the rented resources. Extensive\nsimulations have shown that GNCA outperforms the state-of-the art resource\nallocation approaches for crowdsourced live streaming by achieving more than\n20% gain in terms of system cost while serving the viewers with relatively\nlower latency.",
          "link": "http://arxiv.org/abs/2106.02420",
          "publishedOn": "2021-06-07T03:06:10.260Z",
          "wordCount": 667,
          "title": "An Intelligent Resource Reservation for Crowdsourced Live Video Streaming Applications in Geo-Distributed Cloud Environment. (arXiv:2106.02420v1 [cs.NI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01861",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kinoshita_Y/0/1/0/all/0/1\">Yuma Kinoshita</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kiya_H/0/1/0/all/0/1\">Hitoshi Kiya</a>",
          "description": "In this paper, we propose a novel method for separately estimating spectral\ndistributions from images captured by a typical RGB camera. The proposed method\nallows us to separately estimate a spectral distribution of illumination,\nreflectance, or camera sensitivity, while recent hyperspectral cameras are\nlimited to capturing a joint spectral distribution from a scene. In addition,\nthe use of Bayesian inference makes it possible to take into account prior\ninformation of both spectral distributions and image noise as probability\ndistributions. As a result, the proposed method can estimate spectral\ndistributions in a unified way, and it can enhance the robustness of the\nestimation against noise, which conventional spectral-distribution estimation\nmethods cannot. The use of Bayesian inference also enables us to obtain the\nconfidence of estimation results. In an experiment, the proposed method is\nshown not only to outperform conventional estimation methods in terms of RMSE\nbut also to be robust against noise.",
          "link": "http://arxiv.org/abs/2106.01861",
          "publishedOn": "2021-06-04T01:12:26.067Z",
          "wordCount": 599,
          "title": "Separated-Spectral-Distribution Estimation Based on Bayesian Inference with Single RGB Camera. (arXiv:2106.01861v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02036",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Girdhar_R/0/1/0/all/0/1\">Rohit Girdhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grauman_K/0/1/0/all/0/1\">Kristen Grauman</a>",
          "description": "We propose Anticipative Video Transformer (AVT), an end-to-end\nattention-based video modeling architecture that attends to the previously\nobserved video in order to anticipate future actions. We train the model\njointly to predict the next action in a video sequence, while also learning\nframe feature encoders that are predictive of successive future frames'\nfeatures. Compared to existing temporal aggregation strategies, AVT has the\nadvantage of both maintaining the sequential progression of observed actions\nwhile still capturing long-range dependencies--both critical for the\nanticipation task. Through extensive experiments, we show that AVT obtains the\nbest reported performance on four popular action anticipation benchmarks:\nEpicKitchens-55, EpicKitchens-100, EGTEA Gaze+, and 50-Salads, including\noutperforming all submissions to the EpicKitchens-100 CVPR'21 challenge.",
          "link": "http://arxiv.org/abs/2106.02036",
          "publishedOn": "2021-06-04T01:12:26.034Z",
          "wordCount": 557,
          "title": "Anticipative Video Transformer. (arXiv:2106.02036v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01266",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fanzeres_L/0/1/0/all/0/1\">Leonardo A. Fanzeres</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nadeu_C/0/1/0/all/0/1\">Climent Nadeu</a>",
          "description": "The motivation of our research is to develop a sound-to-image (S2I)\ntranslation system for enabling a human receiver to visually infer the\noccurrence of sound related events. We expect the computer to 'imagine' the\nscene from the captured sound, generating original images that picture the\nsound emitting source. Previous studies on similar topics opted for simplified\napproaches using data with low content diversity and/or strong supervision.\nDifferently, we propose to perform unsupervised S2I translation using thousands\nof distinct and unknown scenes, with slightly pre-cleaned data, just enough to\nguarantee aural-visual semantic coherence. To that end, we employ conditional\ngenerative adversarial networks (GANs) with a deep densely connected generator.\nBesides, we implemented a moving-average adversarial loss to address GANs\ntraining instability. Though the specified S2I translation problem is quite\nchallenging, we were able to generalize the translator model enough to obtain\nmore than 14%, in average, of interpretable and semantically coherent images\ntranslated from unknown sounds. Additionally, we present a solution using\ninformativity classifiers to perform quantitative evaluation of S2I\ntranslation.",
          "link": "http://arxiv.org/abs/2106.01266",
          "publishedOn": "2021-06-03T02:10:32.822Z",
          "wordCount": 618,
          "title": "Sound-to-Imagination: Unsupervised Crossmodal Translation Using Deep Dense Network Architecture. (arXiv:2106.01266v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00828",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kaya_E/0/1/0/all/0/1\">Emre Can Kaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwarz_S/0/1/0/all/0/1\">Sebastian Schwarz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tabus_I/0/1/0/all/0/1\">Ioan Tabus</a>",
          "description": "This paper describes a novel lossless compression method for point cloud\ngeometry, building on a recent lossy compression method that aimed at\nreconstructing only the bounding volume of a point cloud. The proposed scheme\nstarts by partially reconstructing the geometry from the two depthmaps\nassociated to a single projection direction. The partial reconstruction\nobtained from the depthmaps is completed to a full reconstruction of the point\ncloud by sweeping section by section along one direction and encoding the\npoints which were not contained in the two depthmaps. The main ingredient is a\nlist-based encoding of the inner points (situated inside the feasible regions)\nby a novel arithmetic three dimensional context coding procedure that\nefficiently utilizes rotational invariances present in the input data.\nState-of-the-art bits-per-voxel results are obtained on benchmark datasets.",
          "link": "http://arxiv.org/abs/2106.00828",
          "publishedOn": "2021-06-03T02:10:32.776Z",
          "wordCount": 632,
          "title": "Refining the bounding volumes for lossless compression of voxelized point clouds geometry. (arXiv:2106.00828v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2011.05049",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zongheng Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1\">Yue Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Si Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Guanbin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1\">Xiaojie Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Hongxu Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Q/0/1/0/all/0/1\">Qian Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1\">Dong Xu</a>",
          "description": "In this work, we introduce a novel task - Humancentric Spatio-Temporal Video\nGrounding (HC-STVG). Unlike the existing referring expression tasks in images\nor videos, by focusing on humans, HC-STVG aims to localize a spatiotemporal\ntube of the target person from an untrimmed video based on a given textural\ndescription. This task is useful, especially for healthcare and\nsecurity-related applications, where the surveillance videos can be extremely\nlong but only a specific person during a specific period of time is concerned.\nHC-STVG is a video grounding task that requires both spatial (where) and\ntemporal (when) localization. Unfortunately, the existing grounding methods\ncannot handle this task well. We tackle this task by proposing an effective\nbaseline method named Spatio-Temporal Grounding with Visual Transformers\n(STGVT), which utilizes Visual Transformers to extract cross-modal\nrepresentations for video-sentence matching and temporal localization. To\nfacilitate this task, we also contribute an HC-STVG dataset consisting of 5,660\nvideo-sentence pairs on complex multi-person scenes. Specifically, each video\nlasts for 20 seconds, pairing with a natural query sentence with an average of\n17.25 words. Extensive experiments are conducted on this dataset, demonstrating\nthe newly-proposed method outperforms the existing baseline methods.",
          "link": "http://arxiv.org/abs/2011.05049",
          "publishedOn": "2021-06-03T02:10:32.553Z",
          "wordCount": 667,
          "title": "Human-centric Spatio-Temporal Video Grounding With Visual Transformers. (arXiv:2011.05049v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01111",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sun_W/0/1/0/all/0/1\">Wei Sun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_T/0/1/0/all/0/1\">Tao Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Min_X/0/1/0/all/0/1\">Xiongkuo Min</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yi_F/0/1/0/all/0/1\">Fuwang Yi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhai_G/0/1/0/all/0/1\">Guangtao Zhai</a>",
          "description": "In this paper, we propose a deep learning based video quality assessment\n(VQA) framework to evaluate the quality of the compressed user's generated\ncontent (UGC) videos. The proposed VQA framework consists of three modules, the\nfeature extraction module, the quality regression module, and the quality\npooling module. For the feature extraction module, we fuse the features from\nintermediate layers of the convolutional neural network (CNN) network into\nfinal quality-aware feature representation, which enables the model to make\nfull use of visual information from low-level to high-level. Specifically, the\nstructure and texture similarities of feature maps extracted from all\nintermediate layers are calculated as the feature representation for the full\nreference (FR) VQA model, and the global mean and standard deviation of the\nfinal feature maps fused by intermediate feature maps are calculated as the\nfeature representation for the no reference (NR) VQA model. For the quality\nregression module, we use the fully connected (FC) layer to regress the\nquality-aware features into frame-level scores. Finally, a\nsubjectively-inspired temporal pooling strategy is adopted to pool frame-level\nscores into the video-level score. The proposed model achieves the best\nperformance among the state-of-the-art FR and NR VQA models on the Compressed\nUGC VQA database and also achieves pretty good performance on the in-the-wild\nUGC VQA databases.",
          "link": "http://arxiv.org/abs/2106.01111",
          "publishedOn": "2021-06-03T02:10:32.522Z",
          "wordCount": 666,
          "title": "Deep Learning based Full-reference and No-reference Quality Assessment Models for Compressed UGC Videos. (arXiv:2106.01111v1 [eess.IV])"
        }
      ]
    },
    {
      "title": "cs.CV updates on arXiv.org",
      "feedUrl": "http://export.arxiv.org/rss/cs.CV",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2012.03515",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bukchin_G/0/1/0/all/0/1\">Guy Bukchin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwartz_E/0/1/0/all/0/1\">Eli Schwartz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1\">Kate Saenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shahar_O/0/1/0/all/0/1\">Ori Shahar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feris_R/0/1/0/all/0/1\">Rogerio Feris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giryes_R/0/1/0/all/0/1\">Raja Giryes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karlinsky_L/0/1/0/all/0/1\">Leonid Karlinsky</a>",
          "description": "Few-shot learning methods offer pre-training techniques optimized for easier\nlater adaptation of the model to new classes (unseen during training) using one\nor a few examples. This adaptivity to unseen classes is especially important\nfor many practical applications where the pre-trained label space cannot remain\nfixed for effective use and the model needs to be \"specialized\" to support new\ncategories on the fly. One particularly interesting scenario, essentially\noverlooked by the few-shot literature, is Coarse-to-Fine Few-Shot (C2FS), where\nthe training classes (e.g. animals) are of much `coarser granularity' than the\ntarget (test) classes (e.g. breeds). A very practical example of C2FS is when\nthe target classes are sub-classes of the training classes. Intuitively, it is\nespecially challenging as (both regular and few-shot) supervised pre-training\ntends to learn to ignore intra-class variability which is essential for\nseparating sub-classes. In this paper, we introduce a novel 'Angular\nnormalization' module that allows to effectively combine supervised and\nself-supervised contrastive pre-training to approach the proposed C2FS task,\ndemonstrating significant gains in a broad study over multiple baselines and\ndatasets. We hope that this work will help to pave the way for future research\non this new, challenging, and very practical topic of C2FS classification.",
          "link": "http://arxiv.org/abs/2012.03515",
          "publishedOn": "2021-06-08T02:20:28.134Z",
          "wordCount": 663,
          "title": "Fine-grained Angular Contrastive Learning with Coarse Labels. (arXiv:2012.03515v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.09667",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shumailov_I/0/1/0/all/0/1\">Ilia Shumailov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shumaylov_Z/0/1/0/all/0/1\">Zakhar Shumaylov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kazhdan_D/0/1/0/all/0/1\">Dmitry Kazhdan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yiren Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papernot_N/0/1/0/all/0/1\">Nicolas Papernot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erdogdu_M/0/1/0/all/0/1\">Murat A. Erdogdu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anderson_R/0/1/0/all/0/1\">Ross Anderson</a>",
          "description": "Machine learning is vulnerable to a wide variety of attacks. It is now well\nunderstood that by changing the underlying data distribution, an adversary can\npoison the model trained with it or introduce backdoors. In this paper we\npresent a novel class of training-time attacks that require no changes to the\nunderlying dataset or model architecture, but instead only change the order in\nwhich data are supplied to the model. In particular, we find that the attacker\ncan either prevent the model from learning, or poison it to learn behaviours\nspecified by the attacker. Furthermore, we find that even a single\nadversarially-ordered epoch can be enough to slow down model learning, or even\nto reset all of the learning progress. Indeed, the attacks presented here are\nnot specific to the model or dataset, but rather target the stochastic nature\nof modern learning procedures. We extensively evaluate our attacks on computer\nvision and natural language benchmarks to find that the adversary can disrupt\nmodel training and even introduce backdoors.",
          "link": "http://arxiv.org/abs/2104.09667",
          "publishedOn": "2021-06-08T02:20:28.089Z",
          "wordCount": 642,
          "title": "Manipulating SGD with Data Ordering Attacks. (arXiv:2104.09667v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02804",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1\">Kuai Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_H/0/1/0/all/0/1\">Hakeem Frank</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilson_D/0/1/0/all/0/1\">Daniel Wilson</a>",
          "description": "In applied image segmentation tasks, the ability to provide numerous and\nprecise labels for training is paramount to the accuracy of the model at\ninference time. However, this overhead is often neglected, and recently\nproposed segmentation architectures rely heavily on the availability and\nfidelity of ground truth labels to achieve state-of-the-art accuracies. Failure\nto acknowledge the difficulty in creating adequate ground truths can lead to an\nover-reliance on pre-trained models or a lack of adoption in real-world\napplications. We introduce Points2Polygons (P2P), a model which makes use of\ncontextual metric learning techniques that directly addresses this problem.\nPoints2Polygons performs well against existing fully-supervised segmentation\nbaselines with limited training data, despite using lightweight segmentation\nmodels (U-Net with a ResNet18 backbone) and having access to only weak labels\nin the form of object centroids and no pre-training. We demonstrate this on\nseveral different small but non-trivial datasets. We show that metric learning\nusing contextual data provides key insights for self-supervised tasks in\ngeneral, and allow segmentation models to easily generalize across\ntraditionally label-intensive domains in computer vision.",
          "link": "http://arxiv.org/abs/2106.02804",
          "publishedOn": "2021-06-08T02:20:28.082Z",
          "wordCount": 609,
          "title": "Points2Polygons: Context-Based Segmentation from Weak Labels Using Adversarial Networks. (arXiv:2106.02804v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02694",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kong_F/0/1/0/all/0/1\">Fanjie Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henao_R/0/1/0/all/0/1\">Ricardo Henao</a>",
          "description": "An increasing number of applications in the computer vision domain,\nspecially, in medical imaging and remote sensing, are challenging when the goal\nis to classify very large images with tiny objects. More specifically, these\ntype of classification tasks face two key challenges: $i$) the size of the\ninput image in the target dataset is usually in the order of megapixels,\nhowever, existing deep architectures do not easily operate on such big images\ndue to memory constraints, consequently, we seek a memory-efficient method to\nprocess these images; and $ii$) only a small fraction of the input images are\ninformative of the label of interest, resulting in low region of interest (ROI)\nto image ratio. However, most of the current convolutional neural networks\n(CNNs) are designed for image classification datasets that have relatively\nlarge ROIs and small image size (sub-megapixel). Existing approaches have\naddressed these two challenges in isolation. We present an end-to-end CNN model\ntermed Zoom-In network that leverages hierarchical attention sampling for\nclassification of large images with tiny objects using a single GPU. We\nevaluate our method on two large-image datasets and one gigapixel dataset.\nExperimental results show that our model achieves higher accuracy than existing\nmethods while requiring less computing resources.",
          "link": "http://arxiv.org/abs/2106.02694",
          "publishedOn": "2021-06-08T02:20:28.051Z",
          "wordCount": 634,
          "title": "Efficient Classification of Very Large Images with Tiny Objects. (arXiv:2106.02694v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2011.12454",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiu_Z/0/1/0/all/0/1\">Zidi Xiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Junya Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henao_R/0/1/0/all/0/1\">Ricardo Henao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldstein_B/0/1/0/all/0/1\">Benjamin Goldstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carin_L/0/1/0/all/0/1\">Lawrence Carin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_C/0/1/0/all/0/1\">Chenyang Tao</a>",
          "description": "Dealing with severe class imbalance poses a major challenge for real-world\napplications, especially when the accurate classification and generalization of\nminority classes is of primary interest. In computer vision, learning from long\ntailed datasets is a recurring theme, especially for natural image datasets.\nWhile existing solutions mostly appeal to sampling or weighting adjustments to\nalleviate the pathological imbalance, or imposing inductive bias to prioritize\nnon-spurious associations, we take novel perspectives to promote sample\nefficiency and model generalization based on the invariance principles of\ncausality. Our proposal posits a meta-distributional scenario, where the data\ngenerating mechanism is invariant across the label-conditional feature\ndistributions. Such causal assumption enables efficient knowledge transfer from\nthe dominant classes to their under-represented counterparts, even if the\nrespective feature distributions show apparent disparities. This allows us to\nleverage a causal data inflation procedure to enlarge the representation of\nminority classes. Our development is orthogonal to the existing extreme\nclassification techniques thus can be seamlessly integrated. The utility of our\nproposal is validated with an extensive set of synthetic and real-world\ncomputer vision tasks against SOTA solutions.",
          "link": "http://arxiv.org/abs/2011.12454",
          "publishedOn": "2021-06-08T02:20:28.044Z",
          "wordCount": 652,
          "title": "Supercharging Imbalanced Data Learning With Energy-based Contrastive Representation Transfer. (arXiv:2011.12454v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02800",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhang_Q/0/1/0/all/0/1\">Qian Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sampani_K/0/1/0/all/0/1\">Konstantina Sampani</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_M/0/1/0/all/0/1\">Mengjia Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cai_S/0/1/0/all/0/1\">Shengze Cai</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Deng_Y/0/1/0/all/0/1\">Yixiang Deng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_H/0/1/0/all/0/1\">He Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sun_J/0/1/0/all/0/1\">Jennifer K. Sun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Karniadakis_G/0/1/0/all/0/1\">George Em Karniadakis</a>",
          "description": "Adaptive optics scanning laser ophthalmoscopy (AOSLO) provides real-time\nretinal images with high resolution down to 2 $\\mu m$. This technique enables\ndetection of the morphologies of individual microaneurysms (MAs), which are one\nof the earliest signs of diabetic retinopathy (DR), a frequent complication of\ndiabetes that can lead to visual impairment and blindness. In contrast to\nprevious automatic models developed for MA detection on standard fundus\nphotographs, currently there is no high throughput image protocol available for\nautomatic analysis of AOSLO photographs. To address this urgency, we introduce\nAOSLO-net, a deep neural network framework with customized training policy,\nincluding preprocessing, data augmentation and transfer learning, to\nautomatically segment MAs from AOSLO images. We evaluate the performance of\nAOSLO-net using 87 DR AOSLO images demonstrating very accurate MA detection and\nsegmentation, leading to correct MA morphological classification, while\noutperforming the state-of-the-art both in accuracy and cost.",
          "link": "http://arxiv.org/abs/2106.02800",
          "publishedOn": "2021-06-08T02:20:28.038Z",
          "wordCount": 617,
          "title": "AOSLO-net: A deep learning-based method for automatic segmentation of retinal microaneurysms from adaptive optics scanning laser ophthalmoscope images. (arXiv:2106.02800v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2007.11622",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1\">Han Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1\">Chuang Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1\">Ligeng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Song Han</a>",
          "description": "On-device learning enables edge devices to continually adapt the AI models to\nnew data, which requires a small memory footprint to fit the tight memory\nconstraint of edge devices. Existing work solves this problem by reducing the\nnumber of trainable parameters. However, this doesn't directly translate to\nmemory saving since the major bottleneck is the activations, not parameters. In\nthis work, we present Tiny-Transfer-Learning (TinyTL) for memory-efficient\non-device learning. TinyTL freezes the weights while only learns the bias\nmodules, thus no need to store the intermediate activations. To maintain the\nadaptation capacity, we introduce a new memory-efficient bias module, the lite\nresidual module, to refine the feature extractor by learning small residual\nfeature maps adding only 3.8% memory overhead. Extensive experiments show that\nTinyTL significantly saves the memory (up to 6.5x) with little accuracy loss\ncompared to fine-tuning the full network. Compared to fine-tuning the last\nlayer, TinyTL provides significant accuracy improvements (up to 34.1%) with\nlittle memory overhead. Furthermore, combined with feature extractor\nadaptation, TinyTL provides 7.3-12.9x memory saving without sacrificing\naccuracy compared to fine-tuning the full Inception-V3.",
          "link": "http://arxiv.org/abs/2007.11622",
          "publishedOn": "2021-06-08T02:20:28.025Z",
          "wordCount": 675,
          "title": "TinyTL: Reduce Activations, Not Trainable Parameters for Efficient On-Device Learning. (arXiv:2007.11622v5 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.09435",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_H/0/1/0/all/0/1\">Hyoungjun Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Na_M/0/1/0/all/0/1\">Myeongsu Na</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1\">Bumju Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Soohyun Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1\">Ki Hean Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Sunghoe Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jong Chul Ye</a>",
          "description": "Volumetric imaging by fluorescence microscopy is often limited by anisotropic\nspatial resolution from inferior axial resolution compared to the lateral\nresolution. To address this problem, here we present a deep-learning-enabled\nunsupervised super-resolution technique that enhances anisotropic images in\nvolumetric fluorescence microscopy. In contrast to the existing deep learning\napproaches that require matched high-resolution target volume images, our\nmethod greatly reduces the effort to put into practice as the training of a\nnetwork requires as little as a single 3D image stack, without a priori\nknowledge of the image formation process, registration of training data, or\nseparate acquisition of target data. This is achieved based on the optimal\ntransport driven cycle-consistent generative adversarial network that learns\nfrom an unpaired matching between high-resolution 2D images in lateral image\nplane and low-resolution 2D images in the other planes. Using fluorescence\nconfocal microscopy and light-sheet microscopy, we demonstrate that the trained\nnetwork not only enhances axial resolution, but also restores suppressed visual\ndetails between the imaging planes and removes imaging artifacts.",
          "link": "http://arxiv.org/abs/2104.09435",
          "publishedOn": "2021-06-08T02:20:28.005Z",
          "wordCount": 651,
          "title": "Deep learning enables reference-free isotropic super-resolution for volumetric fluorescence microscopy. (arXiv:2104.09435v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1812.00426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kasten_Y/0/1/0/all/0/1\">Yoni Kasten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geifman_A/0/1/0/all/0/1\">Amnon Geifman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galun_M/0/1/0/all/0/1\">Meirav Galun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basri_R/0/1/0/all/0/1\">Ronen Basri</a>",
          "description": "This paper addresses the problem of recovering projective camera matrices\nfrom collections of fundamental matrices in multiview settings. We make two\nmain contributions. First, given ${n \\choose 2}$ fundamental matrices computed\nfor $n$ images, we provide a complete algebraic characterization in the form of\nconditions that are both necessary and sufficient to enabling the recovery of\ncamera matrices. These conditions are based on arranging the fundamental\nmatrices as blocks in a single matrix, called the $n$-view fundamental matrix,\nand characterizing this matrix in terms of the signs of its eigenvalues and\nrank structures. Secondly, we propose a concrete algorithm for projective\nstructure-from-motion that utilizes this characterization. Given a complete or\npartial collection of measured fundamental matrices, our method seeks camera\nmatrices that minimize a global algebraic error for the measured fundamental\nmatrices. In contrast to existing methods, our optimization, without any\ninitialization, produces a consistent set of fundamental matrices that\ncorresponds to a unique set of cameras (up to a choice of projective frame).\nOur experiments indicate that our method achieves state of the art performance\nin both accuracy and running time.",
          "link": "http://arxiv.org/abs/1812.00426",
          "publishedOn": "2021-06-08T02:20:27.993Z",
          "wordCount": 665,
          "title": "GPSfM: Global Projective SFM Using Algebraic Constraints on Multi-View Fundamental Matrices. (arXiv:1812.00426v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02781",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huanan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhiwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Lei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1\">Shuyue Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yongqiang Deng</a>",
          "description": "Due to the high complexity and occlusion, insufficient perception in the\ncrowded urban intersection can be a serious safety risk for both human drivers\nand autonomous algorithms, whereas CVIS (Cooperative Vehicle Infrastructure\nSystem) is a proposed solution for full-participants perception in this\nscenario. However, the research on roadside multimodal perception is still in\nits infancy, and there is no open-source dataset for such scenario.\nAccordingly, this paper fills the gap. Through an IPS (Intersection Perception\nSystem) installed at the diagonal of the intersection, this paper proposes a\nhigh-quality multimodal dataset for the intersection perception task. The\ncenter of the experimental intersection covers an area of 3000m2, and the\nextended distance reaches 300m, which is typical for CVIS. The first batch of\nopen-source data includes 14198 frames, and each frame has an average of 319.84\nlabels, which is 9.6 times larger than the most crowded dataset (H3D dataset in\n2019) by now. In order to facilitate further study, this dataset tries to keep\nthe label documents consistent with the KITTI dataset, and a standardized\nbenchmark is created for algorithm evaluation. Our dataset is available at:\nthis http URL",
          "link": "http://arxiv.org/abs/2106.02781",
          "publishedOn": "2021-06-08T02:20:27.980Z",
          "wordCount": 623,
          "title": "IPS300+: a Challenging Multimodal Dataset for Intersection Perception System. (arXiv:2106.02781v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2002.11169",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Paul_W/0/1/0/all/0/1\">William Paul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_I/0/1/0/all/0/1\">I-Jeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alajaji_F/0/1/0/all/0/1\">Fady Alajaji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burlina_P/0/1/0/all/0/1\">Philippe Burlina</a>",
          "description": "Our work focuses on unsupervised and generative methods that address the\nfollowing goals: (a) learning unsupervised generative representations that\ndiscover latent factors controlling image semantic attributes, (b) studying how\nthis ability to control attributes formally relates to the issue of latent\nfactor disentanglement, clarifying related but dissimilar concepts that had\nbeen confounded in the past, and (c) developing anomaly detection methods that\nleverage representations learned in (a). For (a), we propose a network\narchitecture that exploits the combination of multiscale generative models with\nmutual information (MI) maximization. For (b), we derive an analytical result\n(Lemma 1) that brings clarity to two related but distinct concepts: the ability\nof generative networks to control semantic attributes of images they generate,\nresulting from MI maximization, and the ability to disentangle latent space\nrepresentations, obtained via total correlation minimization. More\nspecifically, we demonstrate that maximizing semantic attribute control\nencourages disentanglement of latent factors. Using Lemma 1 and adopting MI in\nour loss function, we then show empirically that, for image generation tasks,\nthe proposed approach exhibits superior performance as measured in the quality\nand disentanglement trade space, when compared to other state of the art\nmethods, with quality assessed via the Frechet Inception Distance (FID), and\ndisentanglement via mutual information gap. For (c), we design several systems\nfor anomaly detection exploiting representations learned in (a), and\ndemonstrate their performance benefits when compared to state-of-the-art\ngenerative and discriminative algorithms. The above contributions in\nrepresentation learning have potential applications in addressing other\nimportant problems in computer vision, such as bias and privacy in AI.",
          "link": "http://arxiv.org/abs/2002.11169",
          "publishedOn": "2021-06-08T02:20:27.950Z",
          "wordCount": 755,
          "title": "Unsupervised Discovery, Control, and Disentanglement of Semantic Attributes with Applications to Anomaly Detection. (arXiv:2002.11169v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02775",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Justin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1\">Judith E. Fan</a>",
          "description": "People can produce drawings of specific entities (e.g., Garfield), as well as\ngeneral categories (e.g., \"cat\"). What explains this ability to produce such\nvaried drawings of even highly familiar object concepts? We hypothesized that\ndrawing objects at different levels of abstraction depends on both sensory\ninformation and representational goals, such that drawings intended to portray\na recently seen object preserve more detail than those intended to represent a\ncategory. Participants drew objects cued either with a photo or a category\nlabel. For each cue type, half the participants aimed to draw a specific\nexemplar; the other half aimed to draw the category. We found that label-cued\ncategory drawings were the most recognizable at the basic level, whereas\nphoto-cued exemplar drawings were the least recognizable. Together, these\nfindings highlight the importance of task context for explaining how people use\ndrawings to communicate visual concepts in different ways.",
          "link": "http://arxiv.org/abs/2106.02775",
          "publishedOn": "2021-06-08T02:20:27.943Z",
          "wordCount": 595,
          "title": "Visual communication of object concepts at different levels of abstraction. (arXiv:2106.02775v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2101.08894",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gautam_C/0/1/0/all/0/1\">Chandan Gautam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parameswaran_S/0/1/0/all/0/1\">Sethupathy Parameswaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_A/0/1/0/all/0/1\">Ashish Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sundaram_S/0/1/0/all/0/1\">Suresh Sundaram</a>",
          "description": "Zero-shot learning is a new paradigm to classify objects from classes that\nare not available at training time. Zero-shot learning (ZSL) methods have\nattracted considerable attention in recent years because of their ability to\nclassify unseen/novel class examples. Most of the existing approaches on ZSL\nworks when all the samples from seen classes are available to train the model,\nwhich does not suit real life. In this paper, we tackle this hindrance by\ndeveloping a generative replay-based continual ZSL (GRCZSL). The proposed\nmethod endows traditional ZSL to learn from streaming data and acquire new\nknowledge without forgetting the previous tasks' gained experience. We handle\ncatastrophic forgetting in GRCZSL by replaying the synthetic samples of seen\nclasses, which have appeared in the earlier tasks. These synthetic samples are\nsynthesized using the trained conditional variational autoencoder (VAE) over\nthe immediate past task. Moreover, we only require the current and immediate\nprevious VAE at any time for training and testing. The proposed GRZSL method is\ndeveloped for a single-head setting of continual learning, simulating a\nreal-world problem setting. In this setting, task identity is given during\ntraining but unavailable during testing. GRCZSL performance is evaluated on\nfive benchmark datasets for the generalized setup of ZSL with fixed and dynamic\n(incremental class) settings of continual learning. The existing class setting\npresented recently in the literature is not suitable for a class-incremental\nsetting. Therefore, this paper proposes a new setting to address this issue.\nExperimental results show that the proposed method significantly outperforms\nthe baseline and the state-of-the-art method and makes it more suitable for\nreal-world applications.",
          "link": "http://arxiv.org/abs/2101.08894",
          "publishedOn": "2021-06-08T02:20:27.934Z",
          "wordCount": 718,
          "title": "Generative Replay-based Continual Zero-Shot Learning. (arXiv:2101.08894v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2001.10980",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jing Jiang</a>",
          "description": "Traditionally, text generation models take in a sequence of text as input,\nand iteratively generate the next most probable word using pre-trained\nparameters. In this work, we propose the architecture to use images instead of\ntext as the input of the text generation model, called StoryGen. In the\narchitecture, we design a Relational Text Data Generator algorithm that relates\ndifferent features from multiple images. The output samples from the model\ndemonstrate the ability to generate meaningful paragraphs of text containing\nthe extracted features from the input images. This is an undergraduate project\nreport. Completed Dec. 2019 at the Cooper Union.",
          "link": "http://arxiv.org/abs/2001.10980",
          "publishedOn": "2021-06-08T02:20:27.927Z",
          "wordCount": 572,
          "title": "Multimodal Story Generation on Plural Images. (arXiv:2001.10980v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02914",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yue Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1\">Yuan Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Luchan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1\">Yang Xiang</a>",
          "description": "Pruning is a model compression method that removes redundant parameters in\ndeep neural networks (DNNs) while maintaining accuracy. Most available filter\npruning methods require complex treatments such as iterative pruning, features\nstatistics/ranking, or additional optimization designs in the training process.\nIn this paper, we propose a simple and effective regularization strategy from a\nnew perspective of evolution of features, which we call feature flow\nregularization (FFR), for improving structured sparsity and filter pruning in\nDNNs. Specifically, FFR imposes controls on the gradient and curvature of\nfeature flow along the neural network, which implicitly increases the sparsity\nof the parameters. The principle behind FFR is that coherent and smooth\nevolution of features will lead to an efficient network that avoids redundant\nparameters. The high structured sparsity obtained from FFR enables us to prune\nfilters effectively. Experiments with VGGNets, ResNets on CIFAR-10/100, and\nTiny ImageNet datasets demonstrate that FFR can significantly improve both\nunstructured and structured sparsity. Our pruning results in terms of reduction\nof parameters and FLOPs are comparable to or even better than those of\nstate-of-the-art pruning methods.",
          "link": "http://arxiv.org/abs/2106.02914",
          "publishedOn": "2021-06-08T02:20:27.909Z",
          "wordCount": 616,
          "title": "Feature Flow Regularization: Improving Structured Sparsity in Deep Neural Networks. (arXiv:2106.02914v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.12883",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yin_P/0/1/0/all/0/1\">Peng Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Lingyun Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Ji Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choset_H/0/1/0/all/0/1\">Howie Choset</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scherer_S/0/1/0/all/0/1\">Sebastian Scherer</a>",
          "description": "We present a method for localizing a single camera with respect to a point\ncloud map in indoor and outdoor scenes. The problem is challenging because\ncorrespondences of local invariant features are inconsistent across the domains\nbetween image and 3D. The problem is even more challenging as the method must\nhandle various environmental conditions such as illumination, weather, and\nseasonal changes. Our method can match equirectangular images to the 3D range\nprojections by extracting cross-domain symmetric place descriptors. Our key\ninsight is to retain condition-invariant 3D geometry features from limited data\nsamples while eliminating the condition-related features by a designed\nGenerative Adversarial Network. Based on such features, we further design a\nspherical convolution network to learn viewpoint-invariant symmetric place\ndescriptors. We evaluate our method on extensive self-collected datasets, which\ninvolve \\textit{Long-term} (variant appearance conditions),\n\\textit{Large-scale} (up to $2km$ structure/unstructured environment), and\n\\textit{Multistory} (four-floor confined space). Our method surpasses other\ncurrent state-of-the-arts by achieving around $3$ times higher place retrievals\nto inconsistent environments, and above $3$ times accuracy on online\nlocalization. To highlight our method's generalization capabilities, we also\nevaluate the recognition across different datasets. With a single trained\nmodel, i3dLoc can demonstrate reliable visual localization in random\nconditions.",
          "link": "http://arxiv.org/abs/2105.12883",
          "publishedOn": "2021-06-08T02:20:27.903Z",
          "wordCount": 681,
          "title": "i3dLoc: Image-to-range Cross-domain Localization Robust to Inconsistent Environmental Conditions. (arXiv:2105.12883v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03358",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Datta_S/0/1/0/all/0/1\">Soumyya Kanti Datta</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shaikh_M/0/1/0/all/0/1\">Mohammad Abuzar Shaikh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Srihari_S/0/1/0/all/0/1\">Sargur N. Srihari</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gao_M/0/1/0/all/0/1\">Mingchen Gao</a>",
          "description": "In clinical applications, neural networks must focus on and highlight the\nmost important parts of an input image. Soft-Attention mechanism enables a\nneural network toachieve this goal. This paper investigates the effectiveness\nof Soft-Attention in deep neural architectures. The central aim of\nSoft-Attention is to boost the value of important features and suppress the\nnoise-inducing features. We compare the performance of VGG, ResNet,\nInceptionResNetv2 and DenseNet architectures with and without the\nSoft-Attention mechanism, while classifying skin lesions. The original network\nwhen coupled with Soft-Attention outperforms the baseline[16] by 4.7% while\nachieving a precision of 93.7% on HAM10000 dataset [25]. Additionally,\nSoft-Attention coupling improves the sensitivity score by 3.8% compared to\nbaseline[31] and achieves 91.6% on ISIC-2017 dataset [2]. The code is publicly\navailable at github.",
          "link": "http://arxiv.org/abs/2105.03358",
          "publishedOn": "2021-06-08T02:20:27.890Z",
          "wordCount": 600,
          "title": "Soft-Attention Improves Skin Cancer Classification Performance. (arXiv:2105.03358v3 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02884",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1\">Hui Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yue_Z/0/1/0/all/0/1\">Zongsheng Yue</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhao_Q/0/1/0/all/0/1\">Qian Zhao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Meng_D/0/1/0/all/0/1\">Deyu Meng</a>",
          "description": "Blind image deblurring is an important yet very challenging problem in\nlow-level vision. Traditional optimization based methods generally formulate\nthis task as a maximum-a-posteriori estimation or variational inference\nproblem, whose performance highly relies on the handcraft priors for both the\nlatent image and the blur kernel. In contrast, recent deep learning methods\ngenerally learn, from a large collection of training images, deep neural\nnetworks (DNNs) directly mapping the blurry image to the clean one or to the\nblur kernel, paying less attention to the physical degradation process of the\nblurry image. In this paper, we present a deep variational Bayesian framework\nfor blind image deblurring. Under this framework, the posterior of the latent\nclean image and blur kernel can be jointly estimated in an amortized inference\nfashion with DNNs, and the involved inference DNNs can be trained by fully\nconsidering the physical blur model, together with the supervision of data\ndriven priors for the clean image and blur kernel, which is naturally led to by\nthe evidence lower bound objective. Comprehensive experiments are conducted to\nsubstantiate the effectiveness of the proposed framework. The results show that\nit can not only achieve a promising performance with relatively simple\nnetworks, but also enhance the performance of existing DNNs for deblurring.",
          "link": "http://arxiv.org/abs/2106.02884",
          "publishedOn": "2021-06-08T02:20:27.839Z",
          "wordCount": 648,
          "title": "A Deep Variational Bayesian Framework for Blind Image Deblurring. (arXiv:2106.02884v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2009.07536",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Guoqing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Junchuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yuhui Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shengyong Chen</a>",
          "description": "Extracting effective and discriminative features is very important for\naddressing the challenging person re-identification (re-ID) task. Prevailing\ndeep convolutional neural networks (CNNs) usually use high-level features for\nidentifying pedestrian. However, some essential spatial information resided in\nlow-level features such as shape, texture and color will be lost when learning\nthe high-level features, due to extensive padding and pooling operations in the\ntraining stage. In addition, most existing person re-ID methods are mainly\nbased on hand-craft bounding boxes where images are precisely aligned. It is\nunrealistic in practical applications, since the exploited object detection\nalgorithms often produce inaccurate bounding boxes. This will inevitably\ndegrade the performance of existing algorithms. To address these problems, we\nput forward a novel person re-ID model that fuses high- and low-level\nembeddings to reduce the information loss caused in learning high-level\nfeatures. Then we divide the fused embedding into several parts and reconnect\nthem to obtain the global feature and more significant local features, so as to\nalleviate the affect caused by the inaccurate bounding boxes. In addition, we\nalso introduce the spatial and channel attention mechanisms in our model, which\naims to mine more discriminative features related to the target. Finally, we\nreconstruct the feature extractor to ensure that our model can obtain more\nricher and robust features. Extensive experiments display the superiority of\nour approach compared with existing approaches. Our code is available at\nhttps://github.com/libraflower/MutipleFeature-for-PRID.",
          "link": "http://arxiv.org/abs/2009.07536",
          "publishedOn": "2021-06-08T02:20:26.017Z",
          "wordCount": 705,
          "title": "Hybrid-Attention Guided Network with Multiple Resolution Features for Person Re-Identification. (arXiv:2009.07536v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02813",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rajora_H/0/1/0/all/0/1\">Harish Rajora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Punn_N/0/1/0/all/0/1\">Narinder Singh Punn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sonbhadra_S/0/1/0/all/0/1\">Sanjay Kumar Sonbhadra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1\">Sonali Agarwal</a>",
          "description": "Worldwide, several cases go undiagnosed due to poor healthcare support in\nremote areas. In this context, a centralized system is needed for effective\nmonitoring and analysis of the medical records. A web-based patient diagnostic\nsystem is a central platform to store the medical history and predict the\npossible disease based on the current symptoms experienced by a patient to\nensure faster and accurate diagnosis. Early disease prediction can help the\nusers determine the severity of the disease and take quick action. The proposed\nweb-based disease prediction system utilizes machine learning based\nclassification techniques on a data set acquired from the National Centre of\nDisease Control (NCDC). $K$-nearest neighbor (K-NN), random forest and naive\nbayes classification approaches are utilized and an ensemble voting algorithm\nis also proposed where each classifier is assigned weights dynamically based on\nthe prediction confidence. The proposed system is also equipped with a\nrecommendation scheme to recommend the type of tests based on the existing\nsymptoms of the patient, so that necessary precautions can be taken. A\ncentralized database ensures that the medical data is preserved and there is\ntransparency in the system. The tampering into the system is prevented by\ngiving the no \"updation\" rights once the diagnosis is created.",
          "link": "http://arxiv.org/abs/2106.02813",
          "publishedOn": "2021-06-08T02:20:25.285Z",
          "wordCount": null,
          "title": "Web based disease prediction and recommender system. (arXiv:2106.02813v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02749",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choksi_B/0/1/0/all/0/1\">Bhavin Choksi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mozafari_M/0/1/0/all/0/1\">Milad Mozafari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+OMay_C/0/1/0/all/0/1\">Callum Biggs O&#x27;May</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ador_B/0/1/0/all/0/1\">Benjamin Ador</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alamia_A/0/1/0/all/0/1\">Andrea Alamia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+VanRullen_R/0/1/0/all/0/1\">Rufin VanRullen</a>",
          "description": "Deep neural networks excel at image classification, but their performance is\nfar less robust to input perturbations than human perception. In this work we\nexplore whether this shortcoming may be partly addressed by incorporating\nbrain-inspired recurrent dynamics in deep convolutional networks. We take\ninspiration from a popular framework in neuroscience: 'predictive coding'. At\neach layer of the hierarchical model, generative feedback 'predicts' (i.e.,\nreconstructs) the pattern of activity in the previous layer. The reconstruction\nerrors are used to iteratively update the network's representations across\ntimesteps, and to optimize the network's feedback weights over the natural\nimage dataset-a form of unsupervised training. We show that implementing this\nstrategy into two popular networks, VGG16 and EfficientNetB0, improves their\nrobustness against various corruptions. We hypothesize that other feedforward\nnetworks could similarly benefit from the proposed framework. To promote\nresearch in this direction, we provide an open-sourced PyTorch-based package\ncalled Predify, which can be used to implement and investigate the impacts of\nthe predictive coding dynamics in any convolutional neural network.",
          "link": "http://arxiv.org/abs/2106.02749",
          "publishedOn": "2021-06-08T02:20:25.284Z",
          "wordCount": null,
          "title": "Predify: Augmenting deep neural networks with brain-inspired predictive coding dynamics. (arXiv:2106.02749v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2010.02036",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Patashnik_O/0/1/0/all/0/1\">Or Patashnik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Danon_D/0/1/0/all/0/1\">Dov Danon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_Or_D/0/1/0/all/0/1\">Daniel Cohen-Or</a>",
          "description": "State-of-the-art image-to-image translation methods tend to struggle in an\nimbalanced domain setting, where one image domain lacks richness and diversity.\nWe introduce a new unsupervised translation network, BalaGAN, specifically\ndesigned to tackle the domain imbalance problem. We leverage the latent\nmodalities of the richer domain to turn the image-to-image translation problem,\nbetween two imbalanced domains, into a balanced, multi-class, and conditional\ntranslation problem, more resembling the style transfer setting. Specifically,\nwe analyze the source domain and learn a decomposition of it into a set of\nlatent modes or classes, without any supervision. This leaves us with a\nmultitude of balanced cross-domain translation tasks, between all pairs of\nclasses, including the target domain. During inference, the trained network\ntakes as input a source image, as well as a reference or style image from one\nof the modes as a condition, and produces an image which resembles the source\non the pixel-wise level, but shares the same mode as the reference. We show\nthat employing modalities within the dataset improves the quality of the\ntranslated images, and that BalaGAN outperforms strong baselines of both\nunconditioned and style-transfer-based image-to-image translation methods, in\nterms of image quality and diversity.",
          "link": "http://arxiv.org/abs/2010.02036",
          "publishedOn": "2021-06-08T02:20:25.271Z",
          "wordCount": null,
          "title": "BalaGAN: Image Translation Between Imbalanced Domains via Cross-Modal Transfer. (arXiv:2010.02036v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.10637",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaofeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1\">Linghao Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_J/0/1/0/all/0/1\">Jane You</a>",
          "description": "How to extract effective expression representations that invariant to the\nidentity-specific attributes is a long-lasting problem for facial expression\nrecognition (FER). Most of the previous methods process the RGB images of a\nsequence, while we argue that the off-the-shelf and valuable expression-related\nmuscle movement is already embedded in the compression format. In this paper,\nwe target to explore the inter-subject variations eliminated facial expression\nrepresentation in the compressed video domain. In the up to two orders of\nmagnitude compressed domain, we can explicitly infer the expression from the\nresidual frames and possibly extract identity factors from the I frame with a\npre-trained face recognition network. By enforcing the marginal independence of\nthem, the expression feature is expected to be purer for the expression and be\nrobust to identity shifts. Specifically, we propose a novel collaborative\nmin-min game for mutual information (MI) minimization in latent space. We do\nnot need the identity label or multiple expression samples from the same person\nfor identity elimination. Moreover, when the apex frame is annotated in the\ndataset, the complementary constraint can be further added to regularize the\nfeature-level game. In testing, only the compressed residual frames are\nrequired to achieve expression prediction. Our solution can achieve comparable\nor better performance than the recent decoded image-based methods on the\ntypical FER benchmarks with about 3 times faster inference.",
          "link": "http://arxiv.org/abs/2010.10637",
          "publishedOn": "2021-06-08T02:20:25.174Z",
          "wordCount": null,
          "title": "Mutual Information Regularized Identity-aware Facial ExpressionRecognition in Compressed Video. (arXiv:2010.10637v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02994",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1\">Alex Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cicek_S/0/1/0/all/0/1\">Safa Cicek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1\">Stefano Soatto</a>",
          "description": "We present a method for inferring dense depth maps from images and sparse\ndepth measurements by leveraging synthetic data to learn the association of\nsparse point clouds with dense natural shapes, and using the image as evidence\nto validate the predicted depth map. Our learned prior for natural shapes uses\nonly sparse depth as input, not images, so the method is not affected by the\ncovariate shift when attempting to transfer learned models from synthetic data\nto real ones. This allows us to use abundant synthetic data with ground truth\nto learn the most difficult component of the reconstruction process, which is\ntopology estimation, and use the image to refine the prediction based on\nphotometric evidence. Our approach uses fewer parameters than previous methods,\nyet, achieves the state of the art on both indoor and outdoor benchmark\ndatasets. Code available at:\nhttps://github.com/alexklwong/learning-topology-synthetic-data.",
          "link": "http://arxiv.org/abs/2106.02994",
          "publishedOn": "2021-06-08T02:20:25.139Z",
          "wordCount": null,
          "title": "Learning Topology from Synthetic Data for Unsupervised Depth Completion. (arXiv:2106.02994v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02809",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Lirong Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yanshan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaihao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_W/0/1/0/all/0/1\">Wenhan Luo</a>",
          "description": "Hazy images reduce the visibility of the image content, and haze will lead to\nfailure in handling subsequent computer vision tasks. In this paper, we address\nthe problem of image dehazing by proposing a dehazing network named T-Net,\nwhich consists of a backbone network based on the U-Net architecture and a dual\nattention module. And it can achieve multi-scale feature fusion by using skip\nconnections with a new fusion strategy. Furthermore, by repeatedly unfolding\nthe plain T-Net, Stack T-Net is proposed to take advantage of the dependence of\ndeep features across stages via a recursive strategy. In order to reduce\nnetwork parameters, the intra-stage recursive computation of ResNet is adopted\nin our Stack T-Net. And we take both the stage-wise result and the original\nhazy image as input to each T-Net and finally output the prediction of clean\nimage. Experimental results on both synthetic and real-world images demonstrate\nthat our plain T-Net and the advanced Stack T-Net perform favorably against the\nstate-of-the-art dehazing algorithms, and show that our Stack T-Net could\nfurther improve the dehazing effect, demonstrating the effectiveness of the\nrecursive strategy.",
          "link": "http://arxiv.org/abs/2106.02809",
          "publishedOn": "2021-06-08T02:20:25.132Z",
          "wordCount": null,
          "title": "T-Net: Deep Stacked Scale-Iteration Network for Image Dehazing. (arXiv:2106.02809v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/1912.01756",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fuyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nauata_N/0/1/0/all/0/1\">Nelson Nauata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Furukawa_Y/0/1/0/all/0/1\">Yasutaka Furukawa</a>",
          "description": "This paper proposes a novel message passing neural (MPN) architecture\nConv-MPN, which reconstructs an outdoor building as a planar graph from a\nsingle RGB image. Conv-MPN is specifically designed for cases where nodes of a\ngraph have explicit spatial embedding. In our problem, nodes correspond to\nbuilding edges in an image. Conv-MPN is different from MPN in that 1) the\nfeature associated with a node is represented as a feature volume instead of a\n1D vector; and 2) convolutions encode messages instead of fully connected\nlayers. Conv-MPN learns to select a true subset of nodes (i.e., building edges)\nto reconstruct a building planar graph. Our qualitative and quantitative\nevaluations over 2,000 buildings show that Conv-MPN makes significant\nimprovements over the existing fully neural solutions. We believe that the\npaper has a potential to open a new line of graph neural network research for\nstructured geometry reconstruction.",
          "link": "http://arxiv.org/abs/1912.01756",
          "publishedOn": "2021-06-08T02:20:24.637Z",
          "wordCount": null,
          "title": "Conv-MPN: Convolutional Message Passing Neural Network for Structured Outdoor Architecture Reconstruction. (arXiv:1912.01756v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.13868",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1\">Shuhuai Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Junyang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1\">Guangxiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Men_R/0/1/0/all/0/1\">Rui Men</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1\">An Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hongxia Yang</a>",
          "description": "Despite the achievements of large-scale multimodal pre-training approaches,\ncross-modal retrieval, e.g., image-text retrieval, remains a challenging task.\nTo bridge the semantic gap between the two modalities, previous studies mainly\nfocus on word-region alignment at the object level, lacking the matching\nbetween the linguistic relation among the words and the visual relation among\nthe regions. The neglect of such relation consistency impairs the\ncontextualized representation of image-text pairs and hinders the model\nperformance and the interpretability. In this paper, we first propose a novel\nmetric, Intra-modal Self-attention Distance (ISD), to quantify the relation\nconsistency by measuring the semantic distance between linguistic and visual\nrelations. In response, we present Inter-modal Alignment on Intra-modal\nSelf-attentions (IAIS), a regularized training method to optimize the ISD and\ncalibrate intra-modal self-attentions from the two modalities mutually via\ninter-modal alignment. The IAIS regularizer boosts the performance of\nprevailing models on Flickr30k and MS COCO datasets by a considerable margin,\nwhich demonstrates the superiority of our approach.",
          "link": "http://arxiv.org/abs/2105.13868",
          "publishedOn": "2021-06-08T02:20:23.738Z",
          "wordCount": 642,
          "title": "Learning Relation Alignment for Calibrated Cross-modal Retrieval. (arXiv:2105.13868v2 [cs.CL] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.07085",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_H/0/1/0/all/0/1\">Hongyi Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dabawi_D/0/1/0/all/0/1\">Diaa Dabawi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cetin_A/0/1/0/all/0/1\">Ahmet Enis Cetin</a>",
          "description": "In this paper, we propose a novel layer based on fast Walsh-Hadamard\ntransform (WHT) and smooth-thresholding to replace $1\\times 1$ convolution\nlayers in deep neural networks. In the WHT domain, we denoise the transform\ndomain coefficients using the new smooth-thresholding non-linearity, a smoothed\nversion of the well-known soft-thresholding operator. We also introduce a\nfamily of multiplication-free operators from the basic 2$\\times$2 Hadamard\ntransform to implement $3\\times 3$ depthwise separable convolution layers.\nUsing these two types of layers, we replace the bottleneck layers in\nMobileNet-V2 to reduce the network's number of parameters with a slight loss in\naccuracy. For example, by replacing the final third bottleneck layers, we\nreduce the number of parameters from 2.270M to 540K. This reduces the accuracy\nfrom 95.21\\% to 92.98\\% on the CIFAR-10 dataset. Our approach significantly\nimproves the speed of data processing. The fast Walsh-Hadamard transform has a\ncomputational complexity of $O(m\\log_2 m)$. As a result, it is computationally\nmore efficient than the $1\\times1$ convolution layer. The fast Walsh-Hadamard\nlayer processes a tensor in $\\mathbb{R}^{10\\times32\\times32\\times1024}$ about 2\ntimes faster than $1\\times1$ convolution layer on NVIDIA Jetson Nano computer\nboard.",
          "link": "http://arxiv.org/abs/2104.07085",
          "publishedOn": "2021-06-08T02:20:23.677Z",
          "wordCount": 686,
          "title": "Fast Walsh-Hadamard Transform and Smooth-Thresholding Based Binary Layers in Deep Neural Networks. (arXiv:2104.07085v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.10702",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1\">Chen Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yawei Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi Yang</a>",
          "description": "Text-based video segmentation is a challenging task that segments out the\nnatural language referred objects in videos. It essentially requires semantic\ncomprehension and fine-grained video understanding. Existing methods introduce\nlanguage representation into segmentation models in a bottom-up manner, which\nmerely conducts vision-language interaction within local receptive fields of\nConvNets. We argue that such interaction is not fulfilled since the model can\nbarely construct region-level relationships given partial observations, which\nis contrary to the description logic of natural language/referring expressions.\nIn fact, people usually describe a target object using relations with other\nobjects, which may not be easily understood without seeing the whole video. To\naddress the issue, we introduce a novel top-down approach by imitating how we\nhuman segment an object with the language guidance. We first figure out all\ncandidate objects in videos and then choose the refereed one by parsing\nrelations among those high-level objects. Three kinds of object-level relations\nare investigated for precise relationship understanding, i.e., positional\nrelation, text-guided semantic relation, and temporal relation. Extensive\nexperiments on A2D Sentences and J-HMDB Sentences show our method outperforms\nstate-of-the-art methods by a large margin. Qualitative results also show our\nresults are more explainable. Besides, based on the inspiration, we win the\nfirst place in CVPR2021 Referring Youtube-VOS challenge.",
          "link": "http://arxiv.org/abs/2103.10702",
          "publishedOn": "2021-06-08T02:20:23.579Z",
          "wordCount": 668,
          "title": "ClawCraneNet: Leveraging Object-level Relation for Text-based Video Segmentation. (arXiv:2103.10702v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.09943",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Lantao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Dehong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansour_H/0/1/0/all/0/1\">Hassan Mansour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boufounos_P/0/1/0/all/0/1\">Petros T. Boufounos</a>",
          "description": "Blind pansharpening addresses the problem of generating a high\nspatial-resolution multi-spectral (HRMS) image given a low spatial-resolution\nmulti-spectral (LRMS) image with the guidance of its associated spatially\nmisaligned high spatial-resolution panchromatic (PAN) image without parametric\nside information. In this paper, we propose a fast approach to blind\npansharpening and achieve state-of-the-art image reconstruction quality.\nTypical blind pansharpening algorithms are often computationally intensive\nsince the blur kernel and the target HRMS image are often computed using\niterative solvers and in an alternating fashion. To achieve fast blind\npansharpening, we decouple the solution of the blur kernel and of the HRMS\nimage. First, we estimate the blur kernel by computing the kernel coefficients\nwith minimum total generalized variation that blur a downsampled version of the\nPAN image to approximate a linear combination of the LRMS image channels. Then,\nwe estimate each channel of the HRMS image using local Laplacian prior to\nregularize the relationship between each HRMS channel and the PAN image.\nSolving the HRMS image is accelerated by both parallelizing across the channels\nand by fast numerical algorithms for each channel. Due to the fast scheme and\nthe powerful priors we used on the blur kernel coefficients (total generalized\nvariation) and on the cross-channel relationship (local Laplacian prior),\nnumerical experiments demonstrate that our algorithm outperforms\nstate-of-the-art model-based counterparts in terms of both computational time\nand reconstruction quality of the HRMS images.",
          "link": "http://arxiv.org/abs/2103.09943",
          "publishedOn": "2021-06-08T02:20:23.556Z",
          "wordCount": 704,
          "title": "Fast and High-Quality Blind Multi-Spectral Image Pansharpening. (arXiv:2103.09943v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10972",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ridnik_T/0/1/0/all/0/1\">Tal Ridnik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ben_Baruch_E/0/1/0/all/0/1\">Emanuel Ben-Baruch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noy_A/0/1/0/all/0/1\">Asaf Noy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zelnik_Manor_L/0/1/0/all/0/1\">Lihi Zelnik-Manor</a>",
          "description": "ImageNet-1K serves as the primary dataset for pretraining deep learning\nmodels for computer vision tasks. ImageNet-21K dataset, which is bigger and\nmore diverse, is used less frequently for pretraining, mainly due to its\ncomplexity, low accessibility, and underestimation of its added value. This\npaper aims to close this gap, and make high-quality efficient pretraining on\nImageNet-21K available for everyone. Via a dedicated preprocessing stage,\nutilization of WordNet hierarchical structure, and a novel training scheme\ncalled semantic softmax, we show that various models significantly benefit from\nImageNet-21K pretraining on numerous datasets and tasks, including small\nmobile-oriented models. We also show that we outperform previous ImageNet-21K\npretraining schemes for prominent new models like ViT and Mixer. Our proposed\npretraining pipeline is efficient, accessible, and leads to SoTA reproducible\nresults, from a publicly available dataset. The training code and pretrained\nmodels are available at: https://github.com/Alibaba-MIIL/ImageNet21K",
          "link": "http://arxiv.org/abs/2104.10972",
          "publishedOn": "2021-06-08T02:20:23.495Z",
          "wordCount": 609,
          "title": "ImageNet-21K Pretraining for the Masses. (arXiv:2104.10972v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.00825",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hou_A/0/1/0/all/0/1\">Andrew Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ze Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarkis_M/0/1/0/all/0/1\">Michel Sarkis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_N/0/1/0/all/0/1\">Ning Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_Y/0/1/0/all/0/1\">Yiying Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaoming Liu</a>",
          "description": "Existing face relighting methods often struggle with two problems:\nmaintaining the local facial details of the subject and accurately removing and\nsynthesizing shadows in the relit image, especially hard shadows. We propose a\nnovel deep face relighting method that addresses both problems. Our method\nlearns to predict the ratio (quotient) image between a source image and the\ntarget image with the desired lighting, allowing us to relight the image while\nmaintaining the local facial details. During training, our model also learns to\naccurately modify shadows by using estimated shadow masks to emphasize on the\nhigh-contrast shadow borders. Furthermore, we introduce a method to use the\nshadow mask to estimate the ambient light intensity in an image, and are thus\nable to leverage multiple datasets during training with different global\nlighting intensities. With quantitative and qualitative evaluations on the\nMulti-PIE and FFHQ datasets, we demonstrate that our proposed method faithfully\nmaintains the local facial details of the subject and can accurately handle\nhard shadows while achieving state-of-the-art face relighting performance.",
          "link": "http://arxiv.org/abs/2104.00825",
          "publishedOn": "2021-06-08T02:20:22.685Z",
          "wordCount": 642,
          "title": "Towards High Fidelity Face Relighting with Realistic Shadows. (arXiv:2104.00825v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.07954",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kassel_L/0/1/0/all/0/1\">Levi Kassel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Werman_M/0/1/0/all/0/1\">Michael Werman</a>",
          "description": "Neural networks are a powerful framework for foreground segmentation in video\nacquired by static cameras, segmenting moving objects from the background in a\nrobust way in various challenging scenarios. The premier methods are those\nbased on supervision requiring a final training stage on a database of tens to\nhundreds of manually segmented images from the specific static camera. In this\nwork, we propose a method to automatically create an \"artificial\" database that\nis sufficient for training the supervised methods so that it performs better\nthan current unsupervised methods. It is based on combining a weak foreground\nsegmenter, compared to the supervised method, to extract suitable objects from\nthe training images and randomly inserting these objects back into a background\nimage. Test results are shown on the test sequences in CDnet.",
          "link": "http://arxiv.org/abs/2011.07954",
          "publishedOn": "2021-06-08T02:20:22.640Z",
          "wordCount": 593,
          "title": "Using a Supervised Method without supervision for foreground segmentation. (arXiv:2011.07954v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.03176",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1\">Zhihao Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1\">Yuheng Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_J/0/1/0/all/0/1\">Junhui Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qingfu Zhang</a>",
          "description": "Deep subspace clustering networks have attracted much attention in subspace\nclustering, in which an auto-encoder non-linearly maps the input data into a\nlatent space, and a fully connected layer named self-expressiveness module is\nintroduced to learn the affinity matrix via a typical regularization term\n(e.g., sparse or low-rank). However, the adopted regularization terms ignore\nthe connectivity within each subspace, limiting their clustering performance.\nIn addition, the adopted framework suffers from the coupling issue between the\nauto-encoder module and the self-expressiveness module, making the network\ntraining non-trivial. To tackle these two issues, we propose a novel deep\nsubspace clustering method named Maximum Entropy Subspace Clustering Network\n(MESC-Net). Specifically, MESC-Net maximizes the entropy of the affinity matrix\nto promote the connectivity within each subspace, in which its elements\ncorresponding to the same subspace are uniformly and densely distributed.\nFurthermore, we design a novel framework to explicitly decouple the\nauto-encoder module and the self-expressiveness module. We also theoretically\nprove that the learned affinity matrix satisfies the block-diagonal property\nunder the independent subspaces. Extensive quantitative and qualitative results\non commonly used benchmark datasets validate MESC-Net significantly outperforms\nstate-of-the-art methods.",
          "link": "http://arxiv.org/abs/2012.03176",
          "publishedOn": "2021-06-08T02:20:22.443Z",
          "wordCount": 648,
          "title": "Maximum Entropy Subspace Clustering Network. (arXiv:2012.03176v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.13771",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alatalo_J/0/1/0/all/0/1\">Janne Alatalo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korpihalkola_J/0/1/0/all/0/1\">Joni Korpihalkola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sipola_T/0/1/0/all/0/1\">Tuomo Sipola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kokkonen_T/0/1/0/all/0/1\">Tero Kokkonen</a>",
          "description": "One-pixel attack is a curious way of deceiving neural network classifier by\nchanging only one pixel in the input image. The full potential and boundaries\nof this attack method are not yet fully understood. In this research, the\nsuccessful and unsuccessful attacks are studied in more detail to illustrate\nthe working mechanisms of a one-pixel attack created using differential\nevolution. The data comes from our earlier studies where we applied the attack\nagainst medical imaging. We used a real breast cancer tissue dataset and a real\nclassifier as the attack target. This research presents ways to analyze\nchromatic and spatial distributions of one-pixel attacks. In addition, we\npresent one-pixel attack confidence maps to illustrate the behavior of the\ntarget classifier. We show that the more effective attacks change the color of\nthe pixel more, and that the successful attacks are situated at the center of\nthe images. This kind of analysis is not only useful for understanding the\nbehavior of the attack but also the qualities of the classifying neural\nnetwork.",
          "link": "http://arxiv.org/abs/2105.13771",
          "publishedOn": "2021-06-08T02:20:22.436Z",
          "wordCount": 636,
          "title": "Chromatic and spatial analysis of one-pixel attacks against an image classifier. (arXiv:2105.13771v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14217",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_Z/0/1/0/all/0/1\">Zizheng Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_B/0/1/0/all/0/1\">Bohan Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">Haoyu He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1\">Jianfei Cai</a>",
          "description": "Transformers have become one of the dominant architectures in deep learning,\nparticularly as a powerful alternative to convolutional neural networks (CNNs)\nin computer vision. However, Transformer training and inference in previous\nworks can be prohibitively expensive due to the quadratic complexity of\nself-attention over a long sequence of representations, especially for\nhigh-resolution dense prediction tasks. To this end, we present a novel Less\nattention vIsion Transformer (LIT), building upon the fact that convolutions,\nfully-connected (FC) layers, and self-attentions have almost equivalent\nmathematical expressions for processing image patch sequences. Specifically, we\npropose a hierarchical Transformer where we use pure multi-layer perceptrons\n(MLPs) to encode rich local patterns in the early stages while applying\nself-attention modules to capture longer dependencies in deeper layers.\nMoreover, we further propose a learned deformable token merging module to\nadaptively fuse informative patches in a non-uniform manner. The proposed LIT\nachieves promising performance on image recognition tasks, including image\nclassification, object detection and instance segmentation, serving as a strong\nbackbone for many vision tasks. Code is available at:\nhttps://github.com/MonashAI/LIT",
          "link": "http://arxiv.org/abs/2105.14217",
          "publishedOn": "2021-06-08T02:20:22.415Z",
          "wordCount": 629,
          "title": "Less is More: Pay Less Attention in Vision Transformers. (arXiv:2105.14217v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.15203",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_E/0/1/0/all/0/1\">Enze Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenhai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhiding Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alvarez_J/0/1/0/all/0/1\">Jose M. Alvarez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1\">Ping Luo</a>",
          "description": "We present SegFormer, a simple, efficient yet powerful semantic segmentation\nframework which unifies Transformers with lightweight multilayer perception\n(MLP) decoders. SegFormer has two appealing features: 1) SegFormer comprises a\nnovel hierarchically structured Transformer encoder which outputs multiscale\nfeatures. It does not need positional encoding, thereby avoiding the\ninterpolation of positional codes which leads to decreased performance when the\ntesting resolution differs from training. 2) SegFormer avoids complex decoders.\nThe proposed MLP decoder aggregates information from different layers, and thus\ncombining both local attention and global attention to render powerful\nrepresentations. We show that this simple and lightweight design is the key to\nefficient segmentation on Transformers. We scale our approach up to obtain a\nseries of models from SegFormer-B0 to SegFormer-B5, reaching significantly\nbetter performance and efficiency than previous counterparts. For example,\nSegFormer-B4 achieves 50.3% mIoU on ADE20K with 64M parameters, being 5x\nsmaller and 2.2% better than the previous best method. Our best model,\nSegFormer-B5, achieves 84.0% mIoU on Cityscapes validation set and shows\nexcellent zero-shot robustness on Cityscapes-C. Code will be released at:\ngithub.com/NVlabs/SegFormer.",
          "link": "http://arxiv.org/abs/2105.15203",
          "publishedOn": "2021-06-08T02:20:22.389Z",
          "wordCount": 641,
          "title": "SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers. (arXiv:2105.15203v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.03736",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Su Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Han-Jia Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_L/0/1/0/all/0/1\">Le Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_D/0/1/0/all/0/1\">De-Chuan Zhan</a>",
          "description": "Meta-learning can extract an inductive bias from previous learning experience\nand assist the training processes of new tasks. It is often realized through\noptimizing a meta-model with the evaluation loss of a series of task-specific\nsolvers. Most existing algorithms sample non-overlapping $\\mathit{support}$\nsets and $\\mathit{query}$ sets to train and evaluate the solvers respectively\ndue to simplicity ($\\mathcal{S}/\\mathcal{Q}$ protocol). However, another\nevaluation method that assesses the discrepancy between the solver and a target\nmodel is short of research ($\\mathcal{S}/\\mathcal{T}$ protocol).\n$\\mathcal{S}/\\mathcal{T}$ protocol has unique advantages such as offering more\ninformative supervision, but it is computationally expensive. This paper looks\ninto this special evaluation method and takes a step towards putting it into\npractice. We find that with a small ratio of tasks armed with target models,\nclassic meta-learning algorithms can be improved a lot without consuming many\nresources. Furthermore, we empirically verify the effectiveness of\n$\\mathcal{S}/\\mathcal{T}$ protocol in a typical application of meta-learning,\n$\\mathit{i.e.}$, few-shot learning. In detail, after constructing target models\nby fine-tuning the pre-trained network on those hard tasks, we match the\ntask-specific solvers to target models via knowledge distillation. Experiments\ndemonstrate the superiority of our proposal.",
          "link": "http://arxiv.org/abs/2104.03736",
          "publishedOn": "2021-06-08T02:20:22.234Z",
          "wordCount": 645,
          "title": "Towards Enabling Meta-Learning from Target Models. (arXiv:2104.03736v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.13677",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qinglong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yubin Yang</a>",
          "description": "This paper presents an efficient multi-scale vision Transformer, called ResT,\nthat capably served as a general-purpose backbone for image recognition. Unlike\nexisting Transformer methods, which employ standard Transformer blocks to\ntackle raw images with a fixed resolution, our ResT have several advantages:\n(1) A memory-efficient multi-head self-attention is built, which compresses the\nmemory by a simple depth-wise convolution, and projects the interaction across\nthe attention-heads dimension while keeping the diversity ability of\nmulti-heads; (2) Position encoding is constructed as spatial attention, which\nis more flexible and can tackle with input images of arbitrary size without\ninterpolation or fine-tune; (3) Instead of the straightforward tokenization at\nthe beginning of each stage, we design the patch embedding as a stack of\noverlapping convolution operation with stride on the 2D-reshaped token map. We\ncomprehensively validate ResT on image classification and downstream tasks.\nExperimental results show that the proposed ResT can outperform the recently\nstate-of-the-art backbones by a large margin, demonstrating the potential of\nResT as strong backbones. The code and models will be made publicly available\nat https://github.com/wofmanaf/ResT.",
          "link": "http://arxiv.org/abs/2105.13677",
          "publishedOn": "2021-06-08T02:20:22.202Z",
          "wordCount": 661,
          "title": "ResT: An Efficient Transformer for Visual Recognition. (arXiv:2105.13677v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.13016",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chiang_P/0/1/0/all/0/1\">Pei-Ze Chiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsai_M/0/1/0/all/0/1\">Meng-Shiun Tsai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tseng_H/0/1/0/all/0/1\">Hung-Yu Tseng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_W/0/1/0/all/0/1\">Wei-sheng Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiu_W/0/1/0/all/0/1\">Wei-Chen Chiu</a>",
          "description": "In this work, we aim to address the 3D scene stylization problem - generating\nstylized images of the scene at arbitrary novel view angles. A straightforward\nsolution is to combine existing novel view synthesis and image/video style\ntransfer approaches, which often leads to blurry results or inconsistent\nappearance. Inspired by the high quality results of the neural radiance fields\n(NeRF) method, we propose a joint framework to directly render novel views with\nthe desired style. Our framework consists of two components: an implicit\nrepresentation of the 3D scene with the neural radiance field model, and a\nhypernetwork to transfer the style information into the scene representation.\nIn particular, our implicit representation model disentangles the scene into\nthe geometry and appearance branches, and the hypernetwork learns to predict\nthe parameters of the appearance branch from the reference style image. To\nalleviate the training difficulties and memory burden, we propose a two-stage\ntraining procedure and a patch sub-sampling approach to optimize the style and\ncontent losses with the neural radiance field model. After optimization, our\nmodel is able to render consistent novel views at arbitrary view angles with\narbitrary style. Both quantitative evaluation and human subject study have\ndemonstrated that the proposed method generates faithful stylization results\nwith consistent appearance across different views.",
          "link": "http://arxiv.org/abs/2105.13016",
          "publishedOn": "2021-06-08T02:20:22.196Z",
          "wordCount": 682,
          "title": "Stylizing 3D Scene via Implicit Representation and HyperNetwork. (arXiv:2105.13016v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.06419",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1\">Jinke Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lv_P/0/1/0/all/0/1\">Peiqing Lv</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1\">Haiying Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_C/0/1/0/all/0/1\">Changfa Shi</a>",
          "description": "Background and objective: In this paper, a modified U-Net based framework is\npresented, which leverages techniques from Squeeze-and-Excitation (SE) block,\nAtrous Spatial Pyramid Pooling (ASPP) and residual learning for accurate and\nrobust liver CT segmentation, and the effectiveness of the proposed method was\ntested on two public datasets LiTS17 and SLiver07.\n\nMethods: A new network architecture called SAR-U-Net was designed. Firstly,\nthe SE block is introduced to adaptively extract image features after each\nconvolution in the U-Net encoder, while suppressing irrelevant regions, and\nhighlighting features of specific segmentation task; Secondly, ASPP was\nemployed to replace the transition layer and the output layer, and acquire\nmulti-scale image information via different receptive fields. Thirdly, to\nalleviate the degradation problem, the traditional convolution block was\nreplaced with the residual block and thus prompt the network to gain accuracy\nfrom considerably increased depth.\n\nResults: In the LiTS17 experiment, the mean values of Dice, VOE, RVD, ASD and\nMSD were 95.71, 9.52, -0.84, 1.54 and 29.14, respectively. Compared with other\nclosely related 2D-based models, the proposed method achieved the highest\naccuracy. In the experiment of the SLiver07, the mean values of Dice, VOE, RVD,\nASD and MSD were 97.31, 5.37, -1.08, 1.85 and 27.45, respectively. Compared\nwith other closely related models, the proposed method achieved the highest\nsegmentation accuracy except for the RVD.\n\nConclusion: The proposed model enables a great improvement on the accuracy\ncompared to 2D-based models, and its robustness in circumvent challenging\nproblems, such as small liver regions, discontinuous liver regions, and fuzzy\nliver boundaries, is also well demonstrated and validated.",
          "link": "http://arxiv.org/abs/2103.06419",
          "publishedOn": "2021-06-08T02:20:22.189Z",
          "wordCount": 744,
          "title": "SAR-U-Net: squeeze-and-excitation block and atrous spatial pyramid pooling based residual U-Net for automatic liver segmentation in Computed Tomography. (arXiv:2103.06419v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.02610",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahmood_K/0/1/0/all/0/1\">Kaleel Mahmood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmood_R/0/1/0/all/0/1\">Rigel Mahmood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dijk_M/0/1/0/all/0/1\">Marten van Dijk</a>",
          "description": "Recent advances in attention-based networks have shown that Vision\nTransformers can achieve state-of-the-art or near state-of-the-art results on\nmany image classification tasks. This puts transformers in the unique position\nof being a promising alternative to traditional convolutional neural networks\n(CNNs). While CNNs have been carefully studied with respect to adversarial\nattacks, the same cannot be said of Vision Transformers. In this paper, we\nstudy the robustness of Vision Transformers to adversarial examples. Our\nanalyses of transformer security is divided into three parts. First, we test\nthe transformer under standard white-box and black-box attacks. Second, we\nstudy the transferability of adversarial examples between CNNs and\ntransformers. We show that adversarial examples do not readily transfer between\nCNNs and transformers. Based on this finding, we analyze the security of a\nsimple ensemble defense of CNNs and transformers. By creating a new attack, the\nself-attention blended gradient attack, we show that such an ensemble is not\nsecure under a white-box adversary. However, under a black-box adversary, we\nshow that an ensemble can achieve unprecedented robustness without sacrificing\nclean accuracy. Our analysis for this work is done using six types of white-box\nattacks and two types of black-box attacks. Our study encompasses multiple\nVision Transformers, Big Transfer Models and CNN architectures trained on\nCIFAR-10, CIFAR-100 and ImageNet.",
          "link": "http://arxiv.org/abs/2104.02610",
          "publishedOn": "2021-06-08T02:20:22.163Z",
          "wordCount": 675,
          "title": "On the Robustness of Vision Transformers to Adversarial Examples. (arXiv:2104.02610v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.03640",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1\">Yingjie Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xuesong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1\">Kwan-Yee Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaogang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongsheng Li</a>",
          "description": "Semantic Scene Completion aims at reconstructing a complete 3D scene with\nprecise voxel-wise semantics from a single-view depth or RGBD image. It is a\ncrucial but challenging problem for indoor scene understanding. In this work,\nwe present a novel framework named Scene-Instance-Scene Network\n(\\textit{SISNet}), which takes advantages of both instance and scene level\nsemantic information. Our method is capable of inferring fine-grained shape\ndetails as well as nearby objects whose semantic categories are easily\nmixed-up. The key insight is that we decouple the instances from a coarsely\ncompleted semantic scene instead of a raw input image to guide the\nreconstruction of instances and the overall scene. SISNet conducts iterative\nscene-to-instance (SI) and instance-to-scene (IS) semantic completion.\nSpecifically, the SI is able to encode objects' surrounding context for\neffectively decoupling instances from the scene and each instance could be\nvoxelized into higher resolution to capture finer details. With IS,\nfine-grained instance information can be integrated back into the 3D scene and\nthus leads to more accurate semantic scene completion. Utilizing such an\niterative mechanism, the scene and instance completion benefits each other to\nachieve higher completion accuracy. Extensively experiments show that our\nproposed method consistently outperforms state-of-the-art methods on both real\nNYU, NYUCAD and synthetic SUNCG-RGBD datasets. The code and the supplementary\nmaterial will be available at \\url{https://github.com/yjcaimeow/SISNet}.",
          "link": "http://arxiv.org/abs/2104.03640",
          "publishedOn": "2021-06-08T02:20:22.154Z",
          "wordCount": 686,
          "title": "Semantic Scene Completion via Integrating Instances and Scene in-the-Loop. (arXiv:2104.03640v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.11646",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tingyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zhedong Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_C/0/1/0/all/0/1\">Chenggang Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiyong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yaoqi Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1\">Bolun Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi Yang</a>",
          "description": "Cross-view geo-localization is to spot images of the same geographic target\nfrom different platforms, e.g., drone-view cameras and satellites. It is\nchallenging in the large visual appearance changes caused by extreme viewpoint\nvariations. Existing methods usually concentrate on mining the fine-grained\nfeature of the geographic target in the image center, but underestimate the\ncontextual information in neighbor areas. In this work, we argue that neighbor\nareas can be leveraged as auxiliary information, enriching discriminative clues\nfor geolocalization. Specifically, we introduce a simple and effective deep\nneural network, called Local Pattern Network (LPN), to take advantage of\ncontextual information in an end-to-end manner. Without using extra part\nestimators, LPN adopts a square-ring feature partition strategy, which provides\nthe attention according to the distance to the image center. It eases the part\nmatching and enables the part-wise representation learning. Owing to the\nsquare-ring partition design, the proposed LPN has good scalability to rotation\nvariations and achieves competitive results on three prevailing benchmarks,\ni.e., University-1652, CVUSA and CVACT. Besides, we also show the proposed LPN\ncan be easily embedded into other frameworks to further boost performance.",
          "link": "http://arxiv.org/abs/2008.11646",
          "publishedOn": "2021-06-08T02:20:22.136Z",
          "wordCount": 666,
          "title": "Each Part Matters: Local Patterns Facilitate Cross-view Geo-localization. (arXiv:2008.11646v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.04522",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Englesson_E/0/1/0/all/0/1\">Erik Englesson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azizpour_H/0/1/0/all/0/1\">Hossein Azizpour</a>",
          "description": "Prior works have found it beneficial to combine provably noise-robust loss\nfunctions e.g., mean absolute error (MAE) with standard categorical loss\nfunction e.g. cross entropy (CE) to improve their learnability. Here, we\npropose to use Jensen-Shannon divergence as a noise-robust loss function and\nshow that it interestingly interpolate between CE and MAE with a controllable\nmixing parameter. Furthermore, we make a crucial observation that CE exhibit\nlower consistency around noisy data points. Based on this observation, we adopt\na generalized version of the Jensen-Shannon divergence for multiple\ndistributions to encourage consistency around data points. Using this loss\nfunction, we show state-of-the-art results on both synthetic (CIFAR), and\nreal-world (WebVision) noise with varying noise rates.",
          "link": "http://arxiv.org/abs/2105.04522",
          "publishedOn": "2021-06-08T02:20:22.114Z",
          "wordCount": 584,
          "title": "Generalized Jensen-Shannon Divergence Loss for Learning with Noisy Labels. (arXiv:2105.04522v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.05434",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Liu_X/0/1/0/all/0/1\">Xiaofeng Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xing_F/0/1/0/all/0/1\">Fangxu Xing</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fakhri_G/0/1/0/all/0/1\">Georges El Fakhri</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Woo_J/0/1/0/all/0/1\">Jonghye Woo</a>",
          "description": "Multimodal MRI provides complementary and clinically relevant information to\nprobe tissue condition and to characterize various diseases. However, it is\noften difficult to acquire sufficiently many modalities from the same subject\ndue to limitations in study plans, while quantitative analysis is still\ndemanded. In this work, we propose a unified conditional disentanglement\nframework to synthesize any arbitrary modality from an input modality. Our\nframework hinges on a cycle-constrained conditional adversarial training\napproach, where it can extract a modality-invariant anatomical feature with a\nmodality-agnostic encoder and generate a target modality with a conditioned\ndecoder. We validate our framework on four MRI modalities, including\nT1-weighted, T1 contrast enhanced, T2-weighted, and FLAIR MRI, from the\nBraTS'18 database, showing superior performance on synthesis quality over the\ncomparison methods. In addition, we report results from experiments on a tumor\nsegmentation task carried out with synthesized data.",
          "link": "http://arxiv.org/abs/2101.05434",
          "publishedOn": "2021-06-08T02:20:22.107Z",
          "wordCount": 617,
          "title": "A Unified Conditional Disentanglement Framework for Multimodal Brain MR Image Translation. (arXiv:2101.05434v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.11060",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lobachev_O/0/1/0/all/0/1\">Oleg Lobachev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Funatomi_T/0/1/0/all/0/1\">Takuya Funatomi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfaffenroth_A/0/1/0/all/0/1\">Alexander Pfaffenroth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forster_R/0/1/0/all/0/1\">Reinhold F&#xf6;rster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knudsen_L/0/1/0/all/0/1\">Lars Knudsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wrede_C/0/1/0/all/0/1\">Christoph Wrede</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guthe_M/0/1/0/all/0/1\">Michael Guthe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haberthur_D/0/1/0/all/0/1\">David Haberth&#xfc;r</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hlushchuk_R/0/1/0/all/0/1\">Ruslan Hlushchuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salaets_T/0/1/0/all/0/1\">Thomas Salaets</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toelen_J/0/1/0/all/0/1\">Jaan Toelen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaffling_S/0/1/0/all/0/1\">Simone Gaffling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muhlfeld_C/0/1/0/all/0/1\">Christian M&#xfc;hlfeld</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grothausmann_R/0/1/0/all/0/1\">Roman Grothausmann</a>",
          "description": "Registration of histological serial sections is a challenging task. Serial\nsections exhibit distortions and damage from sectioning. Missing information on\nhow the tissue looked before cutting makes a realistic validation of 2D\nregistrations extremely difficult.\n\nThis work proposes methods for ground-truth-based evaluation of\nregistrations. Firstly, we present a methodology to generate test data for\nregistrations. We distort an innately registered image stack in the manner\nsimilar to the cutting distortion of serial sections. Test cases are generated\nfrom existing 3D data sets, thus the ground truth is known. Secondly, our test\ncase generation premises evaluation of the registrations with known ground\ntruths. Our methodology for such an evaluation technique distinguishes this\nwork from other approaches. Both under- and over-registration become evident in\nour evaluations. We also survey existing validation efforts.\n\nWe present a full-series evaluation across six different registration methods\napplied to our distorted 3D data sets of animal lungs. Our distorted and ground\ntruth data sets are made publicly available.",
          "link": "http://arxiv.org/abs/2011.11060",
          "publishedOn": "2021-06-08T02:20:22.100Z",
          "wordCount": 656,
          "title": "Registration of serial sections: An evaluation method based on distortions of the ground truths. (arXiv:2011.11060v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.02468",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Petrini_L/0/1/0/all/0/1\">Leonardo Petrini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Favero_A/0/1/0/all/0/1\">Alessandro Favero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geiger_M/0/1/0/all/0/1\">Mario Geiger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wyart_M/0/1/0/all/0/1\">Matthieu Wyart</a>",
          "description": "Understanding why deep nets can classify data in large dimensions remains a\nchallenge. It has been proposed that they do so by becoming stable to\ndiffeomorphisms, yet existing empirical measurements support that it is often\nnot the case. We revisit this question by defining a maximum-entropy\ndistribution on diffeomorphisms, that allows to study typical diffeomorphisms\nof a given norm. We confirm that stability toward diffeomorphisms does not\nstrongly correlate to performance on benchmark data sets of images. By\ncontrast, we find that the stability toward diffeomorphisms relative to that of\ngeneric transformations $R_f$ correlates remarkably with the test error\n$\\epsilon_t$. It is of order unity at initialization but decreases by several\ndecades during training for state-of-the-art architectures. For CIFAR10 and 15\nknown architectures, we find $\\epsilon_t\\approx 0.2\\sqrt{R_f}$, suggesting that\nobtaining a small $R_f$ is important to achieve good performance. We study how\n$R_f$ depends on the size of the training set and compare it to a simple model\nof invariant learning.",
          "link": "http://arxiv.org/abs/2105.02468",
          "publishedOn": "2021-06-08T02:20:22.090Z",
          "wordCount": 621,
          "title": "Relative stability toward diffeomorphisms indicates performance in deep nets. (arXiv:2105.02468v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02923",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rhodes_T/0/1/0/all/0/1\">Travers Rhodes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Daniel D. Lee</a>",
          "description": "There have been many recent advances in representation learning; however,\nunsupervised representation learning can still struggle with model\nidentification issues. Variational Auto-Encoders (VAEs) and their extensions\nsuch as $\\beta$-VAEs have been shown to locally align latent variables with PCA\ndirections, which can help to improve model disentanglement under some\nconditions. Borrowing inspiration from Independent Component Analysis (ICA) and\nsparse coding, we propose applying an $L_1$ loss to the VAE's generative\nJacobian during training to encourage local latent variable alignment with\nindependent factors of variation in the data. We demonstrate our results on a\nvariety of datasets, giving qualitative and quantitative results using\ninformation theoretic and modularity measures that show our added $L_1$ cost\nencourages local axis alignment of the latent representation with individual\nfactors of variation.",
          "link": "http://arxiv.org/abs/2106.02923",
          "publishedOn": "2021-06-08T02:20:22.084Z",
          "wordCount": 560,
          "title": "Local Disentanglement in Variational Auto-Encoders Using Jacobian $L_1$ Regularization. (arXiv:2106.02923v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.04400",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baek_J/0/1/0/all/0/1\">Jeonghun Baek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matsui_Y/0/1/0/all/0/1\">Yusuke Matsui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aizawa_K/0/1/0/all/0/1\">Kiyoharu Aizawa</a>",
          "description": "Scene text recognition (STR) task has a common practice: All state-of-the-art\nSTR models are trained on large synthetic data. In contrast to this practice,\ntraining STR models only on fewer real labels (STR with fewer labels) is\nimportant when we have to train STR models without synthetic data: for\nhandwritten or artistic texts that are difficult to generate synthetically and\nfor languages other than English for which we do not always have synthetic\ndata. However, there has been implicit common knowledge that training STR\nmodels on real data is nearly impossible because real data is insufficient. We\nconsider that this common knowledge has obstructed the study of STR with fewer\nlabels. In this work, we would like to reactivate STR with fewer labels by\ndisproving the common knowledge. We consolidate recently accumulated public\nreal data and show that we can train STR models satisfactorily only with real\nlabeled data. Subsequently, we find simple data augmentation to fully exploit\nreal data. Furthermore, we improve the models by collecting unlabeled data and\nintroducing semi- and self-supervised methods. As a result, we obtain a\ncompetitive model to state-of-the-art methods. To the best of our knowledge,\nthis is the first study that 1) shows sufficient performance by only using real\nlabels and 2) introduces semi- and self-supervised methods into STR with fewer\nlabels. Our code and data are available:\nhttps://github.com/ku21fan/STR-Fewer-Labels",
          "link": "http://arxiv.org/abs/2103.04400",
          "publishedOn": "2021-06-08T02:20:22.061Z",
          "wordCount": 706,
          "title": "What If We Only Use Real Datasets for Scene Text Recognition? Toward Scene Text Recognition With Fewer Labels. (arXiv:2103.04400v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.12731",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vaswani_A/0/1/0/all/0/1\">Ashish Vaswani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramachandran_P/0/1/0/all/0/1\">Prajit Ramachandran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivas_A/0/1/0/all/0/1\">Aravind Srinivas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parmar_N/0/1/0/all/0/1\">Niki Parmar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hechtman_B/0/1/0/all/0/1\">Blake Hechtman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shlens_J/0/1/0/all/0/1\">Jonathon Shlens</a>",
          "description": "Self-attention has the promise of improving computer vision systems due to\nparameter-independent scaling of receptive fields and content-dependent\ninteractions, in contrast to parameter-dependent scaling and\ncontent-independent interactions of convolutions. Self-attention models have\nrecently been shown to have encouraging improvements on accuracy-parameter\ntrade-offs compared to baseline convolutional models such as ResNet-50. In this\nwork, we aim to develop self-attention models that can outperform not just the\ncanonical baseline models, but even the high-performing convolutional models.\nWe propose two extensions to self-attention that, in conjunction with a more\nefficient implementation of self-attention, improve the speed, memory usage,\nand accuracy of these models. We leverage these improvements to develop a new\nself-attention model family, HaloNets, which reach state-of-the-art accuracies\non the parameter-limited setting of the ImageNet classification benchmark. In\npreliminary transfer learning experiments, we find that HaloNet models\noutperform much larger models and have better inference performance. On harder\ntasks such as object detection and instance segmentation, our simple local\nself-attention and convolutional hybrids show improvements over very strong\nbaselines. These results mark another step in demonstrating the efficacy of\nself-attention models on settings traditionally dominated by convolutional\nmodels.",
          "link": "http://arxiv.org/abs/2103.12731",
          "publishedOn": "2021-06-08T02:20:22.054Z",
          "wordCount": 664,
          "title": "Scaling Local Self-Attention for Parameter Efficient Visual Backbones. (arXiv:2103.12731v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.06464",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lan_S/0/1/0/all/0/1\">Shiyi Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhiding Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choy_C/0/1/0/all/0/1\">Christopher Choy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radhakrishnan_S/0/1/0/all/0/1\">Subhashree Radhakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guilin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yuke Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davis_L/0/1/0/all/0/1\">Larry S. Davis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>",
          "description": "We introduce DiscoBox, a novel framework that jointly learns instance\nsegmentation and semantic correspondence using bounding box supervision.\nSpecifically, we propose a self-ensembling framework where instance\nsegmentation and semantic correspondence are jointly guided by a structured\nteacher in addition to the bounding box supervision. The teacher is a\nstructured energy model incorporating a pairwise potential and a cross-image\npotential to model the pairwise pixel relationships both within and across the\nboxes. Minimizing the teacher energy simultaneously yields refined object masks\nand dense correspondences between intra-class objects, which are taken as\npseudo-labels to supervise the task network and provide positive/negative\ncorrespondence pairs for dense constrastive learning. We show a symbiotic\nrelationship where the two tasks mutually benefit from each other. Our best\nmodel achieves 37.9% AP on COCO instance segmentation, surpassing prior weakly\nsupervised methods and is competitive to supervised methods. We also obtain\nstate of the art weakly supervised results on PASCAL VOC12 and PF-PASCAL with\nreal-time inference.",
          "link": "http://arxiv.org/abs/2105.06464",
          "publishedOn": "2021-06-08T02:20:22.044Z",
          "wordCount": 642,
          "title": "DiscoBox: Weakly Supervised Instance Segmentation and Semantic Correspondence from Box Supervision. (arXiv:2105.06464v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02898",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1\">Mingjian Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1\">Kai Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_E/0/1/0/all/0/1\">Enhua Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qiulin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_Y/0/1/0/all/0/1\">Ying Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Z/0/1/0/all/0/1\">Zhenzhong Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yunhe Wang</a>",
          "description": "Deep convolutional neural networks (CNNs) are often of sophisticated design\nwith numerous convolutional layers and learnable parameters for the accuracy\nreason. To alleviate the expensive costs of deploying them on mobile devices,\nrecent works have made huge efforts for excavating redundancy in pre-defined\narchitectures. Nevertheless, the redundancy on the input resolution of modern\nCNNs has not been fully investigated, i.e., the resolution of input image is\nfixed. In this paper, we observe that the smallest resolution for accurately\npredicting the given image is different using the same neural network. To this\nend, we propose a novel dynamic-resolution network (DRNet) in which the\nresolution is determined dynamically based on each input sample. Thus, a\nresolution predictor with negligible computational costs is explored and\noptimized jointly with the desired network. In practice, the predictor learns\nthe smallest resolution that can retain and even exceed the original\nrecognition accuracy for each image. During the inference, each input image\nwill be resized to its predicted resolution for minimizing the overall\ncomputation burden. We then conduct extensive experiments on several benchmark\nnetworks and datasets. The results show that our DRNet can be embedded in any\noff-the-shelf network architecture to obtain a considerable reduction in\ncomputational complexity. For instance, DRNet achieves similar performance with\nan about 34% computation reduction, while gains 1.4% accuracy increase with 10%\ncomputation reduction compared to the original ResNet-50 on ImageNet.",
          "link": "http://arxiv.org/abs/2106.02898",
          "publishedOn": "2021-06-08T02:20:22.029Z",
          "wordCount": 655,
          "title": "Dynamic Resolution Network. (arXiv:2106.02898v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/1911.07255",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Boyarski_A/0/1/0/all/0/1\">Amit Boyarski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vedula_S/0/1/0/all/0/1\">Sanketh Vedula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bronstein_A/0/1/0/all/0/1\">Alex Bronstein</a>",
          "description": "Deep Matrix Factorization (DMF) is an emerging approach to the problem of\nmatrix completion. Recent works have established that gradient descent applied\nto a DMF model induces an implicit regularization on the rank of the recovered\nmatrix. In this work we interpret the DMF model through the lens of spectral\ngeometry. This allows us to incorporate explicit regularization without\nbreaking the DMF structure, thus enjoying the best of both worlds. In\nparticular, we focus on matrix completion problems with underlying geometric or\ntopological relations between the rows and/or columns. Such relations are\nprevalent in matrix completion problems that arise in many applications, such\nas recommender systems and drug-target interaction. Our contributions enable\nDMF models to exploit these relations, and make them competitive on real\nbenchmarks, while exhibiting one of the first successful applications of deep\nlinear networks.",
          "link": "http://arxiv.org/abs/1911.07255",
          "publishedOn": "2021-06-08T02:20:22.003Z",
          "wordCount": 615,
          "title": "Spectral Geometric Matrix Completion. (arXiv:1911.07255v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.09688",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1\">Meng-Hao Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1\">Jun-Xiong Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zheng-Ning Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mu_T/0/1/0/all/0/1\">Tai-Jiang Mu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_R/0/1/0/all/0/1\">Ralph R. Martin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Shi-Min Hu</a>",
          "description": "The irregular domain and lack of ordering make it challenging to design deep\nneural networks for point cloud processing. This paper presents a novel\nframework named Point Cloud Transformer(PCT) for point cloud learning. PCT is\nbased on Transformer, which achieves huge success in natural language\nprocessing and displays great potential in image processing. It is inherently\npermutation invariant for processing a sequence of points, making it\nwell-suited for point cloud learning. To better capture local context within\nthe point cloud, we enhance input embedding with the support of farthest point\nsampling and nearest neighbor search. Extensive experiments demonstrate that\nthe PCT achieves the state-of-the-art performance on shape classification, part\nsegmentation and normal estimation tasks.",
          "link": "http://arxiv.org/abs/2012.09688",
          "publishedOn": "2021-06-08T02:20:21.995Z",
          "wordCount": 610,
          "title": "PCT: Point cloud transformer. (arXiv:2012.09688v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02953",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1\">Shashi Kant Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mengmi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chia-Chien Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolfe_J/0/1/0/all/0/1\">Jeremy M. Wolfe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kreiman_G/0/1/0/all/0/1\">Gabriel Kreiman</a>",
          "description": "Visual search is a ubiquitous and often challenging daily task, exemplified\nby looking for the car keys at home or a friend in a crowd. An intriguing\nproperty of some classical search tasks is an asymmetry such that finding a\ntarget A among distractors B can be easier than finding B among A. To elucidate\nthe mechanisms responsible for asymmetry in visual search, we propose a\ncomputational model that takes a target and a search image as inputs and\nproduces a sequence of eye movements until the target is found. The model\nintegrates eccentricity-dependent visual recognition with target-dependent\ntop-down cues. We compared the model against human behavior in six paradigmatic\nsearch tasks that show asymmetry in humans. Without prior exposure to the\nstimuli or task-specific training, the model provides a plausible mechanism for\nsearch asymmetry. We hypothesized that the polarity of search asymmetry arises\nfrom experience with the natural environment. We tested this hypothesis by\ntraining the model on an augmented version of ImageNet where the biases of\nnatural images were either removed or reversed. The polarity of search\nasymmetry disappeared or was altered depending on the training protocol. This\nstudy highlights how classical perceptual properties can emerge in neural\nnetwork models, without the need for task-specific training, but rather as a\nconsequence of the statistical properties of the developmental diet fed to the\nmodel. All source code and stimuli are publicly available\nhttps://github.com/kreimanlab/VisualSearchAsymmetry",
          "link": "http://arxiv.org/abs/2106.02953",
          "publishedOn": "2021-06-08T02:20:21.988Z",
          "wordCount": 683,
          "title": "Visual Search Asymmetry: Deep Nets and Humans Share Similar Inherent Biases. (arXiv:2106.02953v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02852",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1\">Yehui Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1\">Kai Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yunhe Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jianyuan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>",
          "description": "This paper studies the efficiency problem for visual transformers by\nexcavating redundant calculation in given networks. The recent transformer\narchitecture has demonstrated its effectiveness for achieving excellent\nperformance on a series of computer vision tasks. However, similar to that of\nconvolutional neural networks, the huge computational cost of vision\ntransformers is still a severe issue. Considering that the attention mechanism\naggregates different patches layer-by-layer, we present a novel patch slimming\napproach that discards useless patches in a top-down paradigm. We first\nidentify the effective patches in the last layer and then use them to guide the\npatch selection process of previous layers. For each layer, the impact of a\npatch on the final output feature is approximated and patches with less impact\nwill be removed. Experimental results on benchmark datasets demonstrate that\nthe proposed method can significantly reduce the computational costs of vision\ntransformers without affecting their performances. For example, over 45% FLOPs\nof the ViT-Ti model can be reduced with only 0.2% top-1 accuracy drop on the\nImageNet dataset.",
          "link": "http://arxiv.org/abs/2106.02852",
          "publishedOn": "2021-06-08T02:20:21.981Z",
          "wordCount": 606,
          "title": "Patch Slimming for Efficient Vision Transformers. (arXiv:2106.02852v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2007.04865",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Woo_J/0/1/0/all/0/1\">Jonghye Woo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_F/0/1/0/all/0/1\">Fangxu Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prince_J/0/1/0/all/0/1\">Jerry L. Prince</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stone_M/0/1/0/all/0/1\">Maureen Stone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_A/0/1/0/all/0/1\">Arnold Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reese_T/0/1/0/all/0/1\">Timothy G. Reese</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wedeen_V/0/1/0/all/0/1\">Van J. Wedeen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fakhri_G/0/1/0/all/0/1\">Georges El Fakhri</a>",
          "description": "Intelligible speech is produced by creating varying internal local muscle\ngroupings -- i.e., functional units -- that are generated in a systematic and\ncoordinated manner. There are two major challenges in characterizing and\nanalyzing functional units.~First, due to the complex and convoluted nature of\ntongue structure and function, it is of great importance to develop a method\nthat can accurately decode complex muscle coordination patterns during speech.\nSecond, it is challenging to keep identified functional units across subjects\ncomparable due to their substantial variability. In this work, to address these\nchallenges, we develop a new deep learning framework to identify common and\nsubject-specific functional units of tongue motion during speech.~Our framework\nhinges on joint deep graph-regularized sparse non-negative matrix factorization\n(NMF) using motion quantities derived from displacements by tagged Magnetic\nResonance Imaging. More specifically, we transform NMF with sparse and graph\nregularizations into modular architectures akin to deep neural networks by\nmeans of unfolding the Iterative Shrinkage-Thresholding Algorithm to learn\ninterpretable building blocks and associated weighting map. We then apply\nspectral clustering to common and subject-specific weighting maps from which we\njointly determine the common and subject-specific functional units. Experiments\ncarried out with simulated datasets show that the proposed method achieved on\npar or better clustering performance over the comparison methods. Experiments\ncarried out with in vivo tongue motion data show that the proposed method can\ndetermine the common and subject-specific functional units with increased\ninterpretability and decreased size variability.",
          "link": "http://arxiv.org/abs/2007.04865",
          "publishedOn": "2021-06-08T02:20:21.974Z",
          "wordCount": 754,
          "title": "A Deep Joint Sparse Non-negative Matrix Factorization Framework for Identifying the Common and Subject-specific Functional Units of Tongue Motion During Speech. (arXiv:2007.04865v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.06255",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1\">Changhong Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bowen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_F/0/1/0/all/0/1\">Fangqiang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1\">Fuling Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_G/0/1/0/all/0/1\">Geng Lu</a>",
          "description": "Aerial tracking, which has exhibited its omnipresent dedication and splendid\nperformance, is one of the most active applications in the remote sensing\nfield. Especially, unmanned aerial vehicle (UAV)-based remote sensing system,\nequipped with a visual tracking approach, has been widely used in aviation,\nnavigation, agriculture,transportation, and public security, etc. As is\nmentioned above, the UAV-based aerial tracking platform has been gradually\ndeveloped from research to practical application stage, reaching one of the\nmain aerial remote sensing technologies in the future. However, due to the\nreal-world onerous situations, e.g., harsh external challenges, the vibration\nof the UAV mechanical structure (especially under strong wind conditions), the\nmaneuvering flight in complex environment, and the limited computation\nresources onboard, accuracy, robustness, and high efficiency are all crucial\nfor the onboard tracking methods. Recently, the discriminative correlation\nfilter (DCF)-based trackers have stood out for their high computational\nefficiency and appealing robustness on a single CPU, and have flourished in the\nUAV visual tracking community. In this work, the basic framework of the\nDCF-based trackers is firstly generalized, based on which, 23 state-of-the-art\nDCF-based trackers are orderly summarized according to their innovations for\nsolving various issues. Besides, exhaustive and quantitative experiments have\nbeen extended on various prevailing UAV tracking benchmarks, i.e., UAV123,\nUAV123@10fps, UAV20L, UAVDT, DTB70, and VisDrone2019-SOT, which contain 371,903\nframes in total. The experiments show the performance, verify the feasibility,\nand demonstrate the current challenges of DCF-based trackers onboard UAV\ntracking.",
          "link": "http://arxiv.org/abs/2010.06255",
          "publishedOn": "2021-06-08T02:20:21.955Z",
          "wordCount": 754,
          "title": "Correlation Filters for Unmanned Aerial Vehicle-Based Aerial Tracking: A Review and Experimental Evaluation. (arXiv:2010.06255v5 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.00777",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hou_Y/0/1/0/all/0/1\">Yimin Hou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jia_S/0/1/0/all/0/1\">Shuyue Jia</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lun_X/0/1/0/all/0/1\">Xiangmin Lun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_Y/0/1/0/all/0/1\">Yan Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>",
          "description": "Recognition accuracy and response time are both critically essential ahead of\nbuilding practical electroencephalography (EEG) based brain-computer interface\n(BCI). Recent approaches, however, have either compromised in the\nclassification accuracy or responding time. This paper presents a novel deep\nlearning approach designed towards remarkably accurate and responsive motor\nimagery (MI) recognition based on scalp EEG. Bidirectional Long Short-term\nMemory (BiLSTM) with the Attention mechanism manages to derive relevant\nfeatures from raw EEG signals. The connected graph convolutional neural network\n(GCN) promotes the decoding performance by cooperating with the topological\nstructure of features, which are estimated from the overall data. The\n0.4-second detection framework has shown effective and efficient prediction\nbased on individual and group-wise training, with 98.81% and 94.64% accuracy,\nrespectively, which outperformed all the state-of-the-art studies. The\nintroduced deep feature mining approach can precisely recognize human motion\nintents from raw EEG signals, which paves the road to translate the EEG based\nMI recognition to practical BCI systems.",
          "link": "http://arxiv.org/abs/2005.00777",
          "publishedOn": "2021-06-08T02:20:21.917Z",
          "wordCount": 624,
          "title": "Deep Feature Mining via Attention-based BiLSTM-GCN for Human Motor Imagery Recognition. (arXiv:2005.00777v2 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02795",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_S/0/1/0/all/0/1\">Si Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Gang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1\">Cho-Jui Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_S/0/1/0/all/0/1\">Samy Bengio</a>",
          "description": "Attentional mechanisms are order-invariant. Positional encoding is a crucial\ncomponent to allow attention-based deep model architectures such as Transformer\nto address sequences or images where the position of information matters. In\nthis paper, we propose a novel positional encoding method based on learnable\nFourier features. Instead of hard-coding each position as a token or a vector,\nwe represent each position, which can be multi-dimensional, as a trainable\nencoding based on learnable Fourier feature mapping, modulated with a\nmulti-layer perceptron. The representation is particularly advantageous for a\nspatial multi-dimensional position, e.g., pixel positions on an image, where\n$L_2$ distances or more complex positional relationships need to be captured.\nOur experiments based on several public benchmark tasks show that our learnable\nFourier feature representation for multi-dimensional positional encoding\noutperforms existing methods by both improving the accuracy and allowing faster\nconvergence.",
          "link": "http://arxiv.org/abs/2106.02795",
          "publishedOn": "2021-06-08T02:20:21.870Z",
          "wordCount": 573,
          "title": "Learnable Fourier Features for Multi-DimensionalSpatial Positional Encoding. (arXiv:2106.02795v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02885",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jiaxing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_D/0/1/0/all/0/1\">Dayan Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_A/0/1/0/all/0/1\">Aoran Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Shijian Lu</a>",
          "description": "Instance contrast for unsupervised representation learning has achieved great\nsuccess in recent years. In this work, we explore the idea of instance\ncontrastive learning in unsupervised domain adaptation (UDA) and propose a\nnovel Category Contrast technique (CaCo) that introduces semantic priors on top\nof instance discrimination for visual UDA tasks. By considering instance\ncontrastive learning as a dictionary look-up operation, we construct a\nsemantics-aware dictionary with samples from both source and target domains\nwhere each target sample is assigned a (pseudo) category label based on the\ncategory priors of source samples. This allows category contrastive learning\n(between target queries and the category-level dictionary) for\ncategory-discriminative yet domain-invariant feature representations: samples\nof the same category (from either source or target domain) are pulled closer\nwhile those of different categories are pushed apart simultaneously. Extensive\nUDA experiments in multiple visual tasks ($e.g.$, segmentation, classification\nand detection) show that the simple implementation of CaCo achieves superior\nperformance as compared with the highly-optimized state-of-the-art methods.\nAnalytically and empirically, the experiments also demonstrate that CaCo is\ncomplementary to existing UDA methods and generalizable to other learning\nsetups such as semi-supervised learning, unsupervised model adaptation, etc.",
          "link": "http://arxiv.org/abs/2106.02885",
          "publishedOn": "2021-06-08T02:20:21.862Z",
          "wordCount": 622,
          "title": "Category Contrast for Unsupervised Domain Adaptation in Visual Tasks. (arXiv:2106.02885v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2009.08348",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roth_K/0/1/0/all/0/1\">Karsten Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milbich_T/0/1/0/all/0/1\">Timo Milbich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ommer_B/0/1/0/all/0/1\">Bj&#xf6;rn Ommer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_J/0/1/0/all/0/1\">Joseph Paul Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghassemi_M/0/1/0/all/0/1\">Marzyeh Ghassemi</a>",
          "description": "Deep Metric Learning (DML) provides a crucial tool for visual similarity and\nzero-shot applications by learning generalizing embedding spaces, although\nrecent work in DML has shown strong performance saturation across training\nobjectives. However, generalization capacity is known to scale with the\nembedding space dimensionality. Unfortunately, high dimensional embeddings also\ncreate higher retrieval cost for downstream applications. To remedy this, we\npropose \\emph{Simultaneous Similarity-based Self-distillation (S2SD). S2SD\nextends DML with knowledge distillation from auxiliary, high-dimensional\nembedding and feature spaces to leverage complementary context during training\nwhile retaining test-time cost and with negligible changes to the training\ntime. Experiments and ablations across different objectives and standard\nbenchmarks show S2SD offers notable improvements of up to 7% in Recall@1, while\nalso setting a new state-of-the-art. Code available at\nhttps://github.com/MLforHealth/S2SD.",
          "link": "http://arxiv.org/abs/2009.08348",
          "publishedOn": "2021-06-08T02:20:21.830Z",
          "wordCount": 605,
          "title": "S2SD: Simultaneous Similarity-based Self-Distillation for Deep Metric Learning. (arXiv:2009.08348v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02853",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ling_J/0/1/0/all/0/1\">Jun Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_H/0/1/0/all/0/1\">Han Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1\">Li Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_R/0/1/0/all/0/1\">Rong Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_X/0/1/0/all/0/1\">Xiao Gu</a>",
          "description": "Image composition plays a common but important role in photo editing. To\nacquire photo-realistic composite images, one must adjust the appearance and\nvisual style of the foreground to be compatible with the background. Existing\ndeep learning methods for harmonizing composite images directly learn an image\nmapping network from the composite to the real one, without explicit\nexploration on visual style consistency between the background and the\nforeground images. To ensure the visual style consistency between the\nforeground and the background, in this paper, we treat image harmonization as a\nstyle transfer problem. In particular, we propose a simple yet effective\nRegion-aware Adaptive Instance Normalization (RAIN) module, which explicitly\nformulates the visual style from the background and adaptively applies them to\nthe foreground. With our settings, our RAIN module can be used as a drop-in\nmodule for existing image harmonization networks and is able to bring\nsignificant improvements. Extensive experiments on the existing image\nharmonization benchmark datasets show the superior capability of the proposed\nmethod. Code is available at {https://github.com/junleen/RainNet}.",
          "link": "http://arxiv.org/abs/2106.02853",
          "publishedOn": "2021-06-08T02:20:21.794Z",
          "wordCount": 607,
          "title": "Region-aware Adaptive Instance Normalization for Image Harmonization. (arXiv:2106.02853v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02859",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianfeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xiaolin Hu</a>",
          "description": "The convolutional neural network (CNN) has become a basic model for solving\nmany computer vision problems. In recent years, a new class of CNNs, recurrent\nconvolution neural network (RCNN), inspired by abundant recurrent connections\nin the visual systems of animals, was proposed. The critical element of RCNN is\nthe recurrent convolutional layer (RCL), which incorporates recurrent\nconnections between neurons in the standard convolutional layer. With\nincreasing number of recurrent computations, the receptive fields (RFs) of\nneurons in RCL expand unboundedly, which is inconsistent with biological facts.\nWe propose to modulate the RFs of neurons by introducing gates to the recurrent\nconnections. The gates control the amount of context information inputting to\nthe neurons and the neurons' RFs therefore become adaptive. The resulting layer\nis called gated recurrent convolution layer (GRCL). Multiple GRCLs constitute a\ndeep model called gated RCNN (GRCNN). The GRCNN was evaluated on several\ncomputer vision tasks including object recognition, scene text recognition and\nobject detection, and obtained much better results than the RCNN. In addition,\nwhen combined with other adaptive RF techniques, the GRCNN demonstrated\ncompetitive performance to the state-of-the-art models on benchmark datasets\nfor these tasks. The codes are released at\n\\href{https://github.com/Jianf-Wang/GRCNN}{https://github.com/Jianf-Wang/GRCNN}.",
          "link": "http://arxiv.org/abs/2106.02859",
          "publishedOn": "2021-06-08T02:20:21.772Z",
          "wordCount": 664,
          "title": "Convolutional Neural Networks with Gated Recurrent Connections. (arXiv:2106.02859v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02796",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhadane_S/0/1/0/all/0/1\">Sourbh Bhadane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wagner_A/0/1/0/all/0/1\">Aaron B. Wagner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Acharya_J/0/1/0/all/0/1\">Jayadev Acharya</a>",
          "description": "We consider a linear autoencoder in which the latent variables are quantized,\nor corrupted by noise, and the constraint is Schur-concave in the set of latent\nvariances. Although finding the optimal encoder/decoder pair for this setup is\na nonconvex optimization problem, we show that decomposing the source into its\nprincipal components is optimal. If the constraint is strictly Schur-concave\nand the empirical covariance matrix has only simple eigenvalues, then any\noptimal encoder/decoder must decompose the source in this way. As one\napplication, we consider a strictly Schur-concave constraint that estimates the\nnumber of bits needed to represent the latent variables under fixed-rate\nencoding, a setup that we call \\emph{Principal Bit Analysis (PBA)}. This yields\na practical, general-purpose, fixed-rate compressor that outperforms existing\nalgorithms. As a second application, we show that a prototypical\nautoencoder-based variable-rate compressor is guaranteed to decompose the\nsource into its principal components.",
          "link": "http://arxiv.org/abs/2106.02796",
          "publishedOn": "2021-06-08T02:20:21.763Z",
          "wordCount": 581,
          "title": "Principle Bit Analysis: Autoencoding with Schur-Concave Loss. (arXiv:2106.02796v1 [cs.IT])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02719",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Castrejon_L/0/1/0/all/0/1\">Lluis Castrejon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ballas_N/0/1/0/all/0/1\">Nicolas Ballas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Courville_A/0/1/0/all/0/1\">Aaron Courville</a>",
          "description": "Videos can often be created by first outlining a global description of the\nscene and then adding local details. Inspired by this we propose a hierarchical\nmodel for video generation which follows a coarse to fine approach. First our\nmodel generates a low resolution video, establishing the global scene\nstructure, that is then refined by subsequent levels in the hierarchy. We train\neach level in our hierarchy sequentially on partial views of the videos. This\nreduces the computational complexity of our generative model, which scales to\nhigh-resolution videos beyond a few frames. We validate our approach on\nKinetics-600 and BDD100K, for which we train a three level model capable of\ngenerating 256x256 videos with 48 frames.",
          "link": "http://arxiv.org/abs/2106.02719",
          "publishedOn": "2021-06-08T02:20:21.755Z",
          "wordCount": 540,
          "title": "Hierarchical Video Generation for Complex Data. (arXiv:2106.02719v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2103.07230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chaorong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Malu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_F/0/1/0/all/0/1\">Fengqing Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_A/0/1/0/all/0/1\">Anping Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yuanyuan Huang</a>",
          "description": "Deep Convolutional Neural Network (DCNN) and Transformer have achieved\nremarkable successes in image recognition. However, their performance in\nfine-grained image recognition is still difficult to meet the requirements of\nactual needs. This paper proposes a Sequence Random Network (SRN) to enhance\nthe performance of DCNN. The output of DCNN is one-dimensional features. This\none-dimensional feature abstractly represents image information, but it does\nnot express well the detailed information of image. To address this issue, we\nuse the proposed SRN which composed of BiLSTM and several Tanh-Dropout blocks\n(called BiLSTM-TDN), to further process DCNN one-dimensional features for\nhighlighting the detail information of image. After the feature transform by\nBiLSTM-TDN, the recognition performance has been greatly improved. We conducted\nthe experiments on six fine-grained image datasets. Except for FGVC-Aircraft,\nthe accuracies of the proposed methods on the other datasets exceeded 99%.\nExperimental results show that BiLSTM-TDN is far superior to the existing\nstate-of-the-art methods. In addition to DCNN, BiLSTM-TDN can also be extended\nto other models, such as Transformer.",
          "link": "http://arxiv.org/abs/2103.07230",
          "publishedOn": "2021-06-08T02:20:21.716Z",
          "wordCount": 651,
          "title": "Sequential Random Network for Fine-grained Image Classification. (arXiv:2103.07230v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02990",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Ziyu Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianlong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mortazavi_B/0/1/0/all/0/1\">Bobak Mortazavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>",
          "description": "The recent breakthrough achieved by contrastive learning accelerates the pace\nfor deploying unsupervised training on real-world data applications. However,\nunlabeled data in reality is commonly imbalanced and shows a long-tail\ndistribution, and it is unclear how robustly the latest contrastive learning\nmethods could perform in the practical scenario. This paper proposes to\nexplicitly tackle this challenge, via a principled framework called\nSelf-Damaging Contrastive Learning (SDCLR), to automatically balance the\nrepresentation learning without knowing the classes. Our main inspiration is\ndrawn from the recent finding that deep models have difficult-to-memorize\nsamples, and those may be exposed through network pruning. It is further\nnatural to hypothesize that long-tail samples are also tougher for the model to\nlearn well due to insufficient examples. Hence, the key innovation in SDCLR is\nto create a dynamic self-competitor model to contrast with the target model,\nwhich is a pruned version of the latter. During training, contrasting the two\nmodels will lead to adaptive online mining of the most easily forgotten samples\nfor the current target model, and implicitly emphasize them more in the\ncontrastive loss. Extensive experiments across multiple datasets and imbalance\nsettings show that SDCLR significantly improves not only overall accuracies but\nalso balancedness, in terms of linear evaluation on the full-shot and few-shot\nsettings. Our code is available at: https://github.com/VITA-Group/SDCLR.",
          "link": "http://arxiv.org/abs/2106.02990",
          "publishedOn": "2021-06-08T02:20:21.693Z",
          "wordCount": 640,
          "title": "Self-Damaging Contrastive Learning. (arXiv:2106.02990v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02701",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Athey_T/0/1/0/all/0/1\">Thomas L. Athey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tward_D/0/1/0/all/0/1\">Daniel Tward</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mueller_U/0/1/0/all/0/1\">Ulrich Mueller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miller_M/0/1/0/all/0/1\">Michael I. Miller</a>",
          "description": "Recent advances in brain clearing and imaging have made it possible to image\nentire mammalian brains at sub-micron resolution. These images offer the\npotential to assemble brain-wide atlases of projection neuron morphology, but\nmanual neuron reconstruction remains a bottleneck. Here we present a method\ninspired by hidden Markov modeling and appearance modeling of fluorescent\nneuron images that can automatically trace neuronal processes. Our method\nleverages dynamic programming to scale to terabyte sized image data and can be\napplied to images with one or more neurons. We applied our algorithm to the\noutput of image segmentation models where false negatives severed neuronal\nprocesses, and showed that it can follow axons in the presence of noise or\nnearby neurons. Our method has the potential to be integrated into a semi or\nfully automated reconstruction pipeline. Additionally, it creates a framework\nthrough which users can intervene with hard constraints to, for example, rule\nout certain reconstructions, or assign axons to particular cell bodies.",
          "link": "http://arxiv.org/abs/2106.02701",
          "publishedOn": "2021-06-08T02:20:21.686Z",
          "wordCount": 604,
          "title": "Hidden Markov Modeling for Maximum Likelihood Neuron Reconstruction. (arXiv:2106.02701v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2010.00148",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Rashid_T/0/1/0/all/0/1\">Tanweer Rashid</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Abdulkadir_A/0/1/0/all/0/1\">Ahmed Abdulkadir</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nasrallah_I/0/1/0/all/0/1\">Ilya M. Nasrallah</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ware_J/0/1/0/all/0/1\">Jeffrey B. Ware</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_H/0/1/0/all/0/1\">Hangfan Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Spincemaille_P/0/1/0/all/0/1\">Pascal Spincemaille</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Romero_J/0/1/0/all/0/1\">J. Rafael Romero</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bryan_R/0/1/0/all/0/1\">R. Nick Bryan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Heckbert_S/0/1/0/all/0/1\">Susan R. Heckbert</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Habes_M/0/1/0/all/0/1\">Mohamad Habes</a>",
          "description": "Lobar cerebral microbleeds (CMBs) and localized non-hemorrhage iron deposits\nin the basal ganglia have been associated with brain aging, vascular disease\nand neurodegenerative disorders. Particularly, CMBs are small lesions and\nrequire multiple neuroimaging modalities for accurate detection. Quantitative\nsusceptibility mapping (QSM) derived from in vivo magnetic resonance imaging\n(MRI) is necessary to differentiate between iron content and mineralization. We\nset out to develop a deep learning-based segmentation method suitable for\nsegmenting both CMBs and iron deposits. We included a convenience sample of 24\nparticipants from the MESA cohort and used T2-weighted images, susceptibility\nweighted imaging (SWI), and QSM to segment the two types of lesions. We\ndeveloped a protocol for simultaneous manual annotation of CMBs and\nnon-hemorrhage iron deposits in the basal ganglia. This manual annotation was\nthen used to train a deep convolution neural network (CNN). Specifically, we\nadapted the U-Net model with a higher number of resolution layers to be able to\ndetect small lesions such as CMBs from standard resolution MRI. We tested\ndifferent combinations of the three modalities to determine the most\ninformative data sources for the detection tasks. In the detection of CMBs\nusing single class and multiclass models, we achieved an average sensitivity\nand precision of between 0.84-0.88 and 0.40-0.59, respectively. The same\nframework detected non-hemorrhage iron deposits with an average sensitivity and\nprecision of about 0.75-0.81 and 0.62-0.75, respectively. Our results showed\nthat deep learning could automate the detection of small vessel disease lesions\nand including multimodal MR data (particularly QSM) can improve the detection\nof CMB and non-hemorrhage iron deposits with sensitivity and precision that is\ncompatible with use in large-scale research studies.",
          "link": "http://arxiv.org/abs/2010.00148",
          "publishedOn": "2021-06-08T02:20:21.659Z",
          "wordCount": 768,
          "title": "DEEPMIR: A DEEP neural network for differential detection of cerebral Microbleeds and IRon deposits in MRI. (arXiv:2010.00148v3 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1811.11849",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Quach_K/0/1/0/all/0/1\">Kha Gia Quach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_N/0/1/0/all/0/1\">Ngan Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duong_C/0/1/0/all/0/1\">Chi Nhan Duong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jalata_I/0/1/0/all/0/1\">Ibsa Jalata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_K/0/1/0/all/0/1\">Kaushik Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luu_K/0/1/0/all/0/1\">Khoa Luu</a>",
          "description": "Group-level emotion recognition (ER) is a growing research area as the\ndemands for assessing crowds of all sizes are becoming an interest in both the\nsecurity arena as well as social media. This work extends the earlier ER\ninvestigations, which focused on either group-level ER on single images or\nwithin a video, by fully investigating group-level expression recognition on\ncrowd videos. In this paper, we propose an effective deep feature level fusion\nmechanism to model the spatial-temporal information in the crowd videos. In our\napproach, the fusing process is performed on the deep feature domain by a\ngenerative probabilistic model, Non-Volume Preserving Fusion (NVPF), that\nmodels spatial information relationships. Furthermore, we extend our proposed\nspatial NVPF approach to the spatial-temporal NVPF approach to learn the\ntemporal information between frames. To demonstrate the robustness and\neffectiveness of each component in the proposed approach, three experiments\nwere conducted: (i) evaluation on AffectNet database to benchmark the proposed\nEmoNet for recognizing facial expression; (ii) evaluation on EmotiW2018 to\nbenchmark the proposed deep feature level fusion mechanism NVPF; and, (iii)\nexamine the proposed TNVPF on an innovative Group-level Emotion on Crowd Videos\n(GECV) dataset composed of 627 videos collected from publicly available\nsources. GECV dataset is a collection of videos containing crowds of people.\nEach video is labeled with emotion categories at three levels: individual\nfaces, group of people, and the entire video frame.",
          "link": "http://arxiv.org/abs/1811.11849",
          "publishedOn": "2021-06-08T02:20:21.643Z",
          "wordCount": 719,
          "title": "Non-Volume Preserving-based Fusion to Group-Level Emotion Recognition on Crowd Videos. (arXiv:1811.11849v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.04690",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Weiyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_R/0/1/0/all/0/1\">Rongmei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rehg_J/0/1/0/all/0/1\">James M. Rehg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paull_L/0/1/0/all/0/1\">Liam Paull</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1\">Li Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1\">Le Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1\">Adrian Weller</a>",
          "description": "The inductive bias of a neural network is largely determined by the\narchitecture and the training algorithm. To achieve good generalization, how to\neffectively train a neural network is of great importance. We propose a novel\northogonal over-parameterized training (OPT) framework that can provably\nminimize the hyperspherical energy which characterizes the diversity of neurons\non a hypersphere. By maintaining the minimum hyperspherical energy during\ntraining, OPT can greatly improve the empirical generalization. Specifically,\nOPT fixes the randomly initialized weights of the neurons and learns an\northogonal transformation that applies to these neurons. We consider multiple\nways to learn such an orthogonal transformation, including unrolling\northogonalization algorithms, applying orthogonal parameterization, and\ndesigning orthogonality-preserving gradient descent. For better scalability, we\npropose the stochastic OPT which performs orthogonal transformation\nstochastically for partial dimensions of neurons. Interestingly, OPT reveals\nthat learning a proper coordinate system for neurons is crucial to\ngeneralization. We provide some insights on why OPT yields better\ngeneralization. Extensive experiments validate the superiority of OPT over the\nstandard training.",
          "link": "http://arxiv.org/abs/2004.04690",
          "publishedOn": "2021-06-08T02:20:21.636Z",
          "wordCount": 685,
          "title": "Orthogonal Over-Parameterized Training. (arXiv:2004.04690v6 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.05123",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pony_R/0/1/0/all/0/1\">Roi Pony</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naeh_I/0/1/0/all/0/1\">Itay Naeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mannor_S/0/1/0/all/0/1\">Shie Mannor</a>",
          "description": "Deep neural networks for video classification, just like image classification\nnetworks, may be subjected to adversarial manipulation. The main difference\nbetween image classifiers and video classifiers is that the latter usually use\ntemporal information contained within the video. In this work we present a\nmanipulation scheme for fooling video classifiers by introducing a flickering\ntemporal perturbation that in some cases may be unnoticeable by human observers\nand is implementable in the real world. After demonstrating the manipulation of\naction classification of single videos, we generalize the procedure to make\nuniversal adversarial perturbation, achieving high fooling ratio. In addition,\nwe generalize the universal perturbation and produce a temporal-invariant\nperturbation, which can be applied to the video without synchronizing the\nperturbation to the input. The attack was implemented on several target models\nand the transferability of the attack was demonstrated. These properties allow\nus to bridge the gap between simulated environment and real-world application,\nas will be demonstrated in this paper for the first time for an over-the-air\nflickering attack.",
          "link": "http://arxiv.org/abs/2002.05123",
          "publishedOn": "2021-06-08T02:20:21.618Z",
          "wordCount": 651,
          "title": "Over-the-Air Adversarial Flickering Attacks against Video Recognition Networks. (arXiv:2002.05123v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.02267",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chaabane_M/0/1/0/all/0/1\">Mohamed Chaabane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Peter Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beveridge_J/0/1/0/all/0/1\">J. Ross Beveridge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+OHara_S/0/1/0/all/0/1\">Stephen O&#x27;Hara</a>",
          "description": "Most modern multiple object tracking (MOT) systems follow the\ntracking-by-detection paradigm, consisting of a detector followed by a method\nfor associating detections into tracks. There is a long history in tracking of\ncombining motion and appearance features to provide robustness to occlusions\nand other challenges, but typically this comes with the trade-off of a more\ncomplex and slower implementation. Recent successes on popular 2D tracking\nbenchmarks indicate that top-scores can be achieved using a state-of-the-art\ndetector and relatively simple associations relying on single-frame spatial\noffsets -- notably outperforming contemporary methods that leverage learned\nappearance features to help re-identify lost tracks. In this paper, we propose\nan efficient joint detection and tracking model named DEFT, or \"Detection\nEmbeddings for Tracking.\" Our approach relies on an appearance-based object\nmatching network jointly-learned with an underlying object detection network.\nAn LSTM is also added to capture motion constraints. DEFT has comparable\naccuracy and speed to the top methods on 2D online tracking leaderboards while\nhaving significant advantages in robustness when applied to more challenging\ntracking data. DEFT raises the bar on the nuScenes monocular 3D tracking\nchallenge, more than doubling the performance of the previous top method. Code\nis publicly available.",
          "link": "http://arxiv.org/abs/2102.02267",
          "publishedOn": "2021-06-08T02:20:21.611Z",
          "wordCount": 665,
          "title": "DEFT: Detection Embeddings for Tracking. (arXiv:2102.02267v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.11543",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_N/0/1/0/all/0/1\">Nianchang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jungong Han</a>",
          "description": "Most existing lightweight RGB-D salient object detection (SOD) models are\nbased on two-stream structure or single-stream structure. The former one first\nuses two sub-networks to extract unimodal features from RGB and depth images,\nrespectively, and then fuses them for SOD. While, the latter one directly\nextracts multi-modal features from the input RGB-D images and then focuses on\nexploiting cross-level complementary information. However, two-stream structure\nbased models inevitably require more parameters and single-stream structure\nbased ones cannot well exploit the cross-modal complementary information since\nthey ignore the modality difference. To address these issues, we propose to\nemploy the middle-level fusion structure for designing lightweight RGB-D SOD\nmodel in this paper, which first employs two sub-networks to extract low- and\nmiddle-level unimodal features, respectively, and then fuses those extracted\nmiddle-level unimodal features for extracting corresponding high-level\nmulti-modal features in the subsequent sub-network. Different from existing\nmodels, this structure can effectively exploit the cross-modal complementary\ninformation and significantly reduce the network's parameters, simultaneously.\nTherefore, a novel lightweight SOD model is designed, which contains a\ninformation-aware multi-modal feature fusion (IMFF) module for effectively\ncapturing the cross-modal complementary information and a lightweight\nfeature-level and decision-level feature fusion (LFDF) module for aggregating\nthe feature-level and the decision-level saliency information in different\nstages with less parameters. Our proposed model has only 3.9M parameters and\nruns at 33 FPS. The experimental results on several benchmark datasets verify\nthe effectiveness and superiority of the proposed method over some\nstate-of-the-art methods.",
          "link": "http://arxiv.org/abs/2104.11543",
          "publishedOn": "2021-06-08T02:20:21.601Z",
          "wordCount": 709,
          "title": "Middle-level Fusion for Lightweight RGB-D Salient Object Detection. (arXiv:2104.11543v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02669",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Pourbemany_J/0/1/0/all/0/1\">Jafar Pourbemany</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Essa_A/0/1/0/all/0/1\">Almabrok Essa</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhu_Y/0/1/0/all/0/1\">Ye Zhu</a>",
          "description": "In recent years, research about monitoring vital signs by smartphones grows\nsignificantly. There are some special sensors like Electrocardiogram (ECG) and\nPhotoplethysmographic (PPG) to detect heart rate (HR) and respiration rate\n(RR). Smartphone cameras also can measure HR by detecting and processing\nimaging Photoplethysmographic (iPPG) signals from the video of a user's face.\nIndeed, the variation in the intensity of the green channel can be measured by\nthe iPPG signals of the video. This study aimed to provide a method to extract\nheart rate and respiration rate using the video of individuals' faces. The\nproposed method is based on measuring fluctuations in the Hue, and can\ntherefore extract both HR and RR from the video of a user's face. The proposed\nmethod is evaluated by performing on 25 healthy individuals. For each subject,\n20 seconds video of his/her face is recorded. Results show that the proposed\napproach of measuring iPPG using Hue gives more accurate rates than the Green\nchannel.",
          "link": "http://arxiv.org/abs/2106.02669",
          "publishedOn": "2021-06-08T02:20:21.593Z",
          "wordCount": 606,
          "title": "Real Time Video based Heart and Respiration Rate Monitoring. (arXiv:2106.02669v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02689",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chun-Fu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panda_R/0/1/0/all/0/1\">Rameswar Panda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Q/0/1/0/all/0/1\">Quanfu Fan</a>",
          "description": "Vision transformer (ViT) has recently showed its strong capability in\nachieving comparable results to convolutional neural networks (CNNs) on image\nclassification. However, vanilla ViT simply inherits the same architecture from\nthe natural language processing directly, which is often not optimized for\nvision applications. Motivated by this, in this paper, we propose a new\narchitecture that adopts the pyramid structure and employ a novel\nregional-to-local attention rather than global self-attention in vision\ntransformers. More specifically, our model first generates regional tokens and\nlocal tokens from an image with different patch sizes, where each regional\ntoken is associated with a set of local tokens based on the spatial location.\nThe regional-to-local attention includes two steps: first, the regional\nself-attention extract global information among all regional tokens and then\nthe local self-attention exchanges the information among one regional token and\nthe associated local tokens via self-attention. Therefore, even though local\nself-attention confines the scope in a local region but it can still receive\nglobal information. Extensive experiments on three vision tasks, including\nimage classification, object detection and action recognition, show that our\napproach outperforms or is on par with state-of-the-art ViT variants including\nmany concurrent works. Our source codes and models will be publicly available.",
          "link": "http://arxiv.org/abs/2106.02689",
          "publishedOn": "2021-06-08T02:20:21.580Z",
          "wordCount": 628,
          "title": "RegionViT: Regional-to-Local Attention for Vision Transformers. (arXiv:2106.02689v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.08868",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Faghri_F/0/1/0/all/0/1\">Fartash Faghri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gowal_S/0/1/0/all/0/1\">Sven Gowal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasconcelos_C/0/1/0/all/0/1\">Cristina Vasconcelos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fleet_D/0/1/0/all/0/1\">David J. Fleet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pedregosa_F/0/1/0/all/0/1\">Fabian Pedregosa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roux_N/0/1/0/all/0/1\">Nicolas Le Roux</a>",
          "description": "We demonstrate that the choice of optimizer, neural network architecture, and\nregularizer significantly affect the adversarial robustness of linear neural\nnetworks, providing guarantees without the need for adversarial training. To\nthis end, we revisit a known result linking maximally robust classifiers and\nminimum norm solutions, and combine it with recent results on the implicit bias\nof optimizers. First, we show that, under certain conditions, it is possible to\nachieve both perfect standard accuracy and a certain degree of robustness,\nsimply by training an overparametrized model using the implicit bias of the\noptimization. In that regime, there is a direct relationship between the type\nof the optimizer and the attack to which the model is robust. To the best of\nour knowledge, this work is the first to study the impact of optimization\nmethods such as sign gradient descent and proximal methods on adversarial\nrobustness. Second, we characterize the robustness of linear convolutional\nmodels, showing that they resist attacks subject to a constraint on the\nFourier-$\\ell_\\infty$ norm. To illustrate these findings we design a novel\nFourier-$\\ell_\\infty$ attack that finds adversarial examples with controllable\nfrequencies. We evaluate Fourier-$\\ell_\\infty$ robustness of\nadversarially-trained deep CIFAR-10 models from the standard RobustBench\nbenchmark and visualize adversarial perturbations.",
          "link": "http://arxiv.org/abs/2102.08868",
          "publishedOn": "2021-06-08T02:20:21.553Z",
          "wordCount": 685,
          "title": "Bridging the Gap Between Adversarial Robustness and Optimization Bias. (arXiv:2102.08868v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.08107",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wang_R/0/1/0/all/0/1\">Ruxin Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_S/0/1/0/all/0/1\">Shuyuan Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ji_C/0/1/0/all/0/1\">Chaojie Ji</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1\">Ye Li</a>",
          "description": "Skin lesion segmentation is an important step for automatic melanoma\ndiagnosis. Due to the non-negligible diversity of lesions from different\npatients, extracting powerful context for fine-grained semantic segmentation is\nstill challenging today. Although the deep convolutional neural network (CNNs)\nhave made significant improvements on skin lesion segmentation, they often fail\nto reserve the spatial details and long-range dependencies context due to\nconsecutive convolution striding and pooling operations inside CNNs. In this\npaper, we formulate a cascaded context enhancement neural network for automatic\nskin lesion segmentation. A new cascaded context aggregation (CCA) module with\na gate-based information integration approach is proposed to sequentially and\nselectively aggregate original image and multi-level features from the encoder\nsub-network. The generated context is further utilized to guide discriminative\nfeatures extraction by the designed context-guided local affinity (CGL) module.\nFurthermore, an auxiliary loss is added to the CCA module for refining the\nprediction. In our work, we evaluate our approach on four public skin\ndermoscopy image datasets. The proposed method achieves the Jaccard Index (JA)\nof 87.1%, 80.3%, 83.4%, and 86.6% on ISIC-2016, ISIC-2017, ISIC-2018, and PH2\ndatasets, which are higher than other state-of-the-art models respectively.",
          "link": "http://arxiv.org/abs/2004.08107",
          "publishedOn": "2021-06-08T02:20:21.547Z",
          "wordCount": 657,
          "title": "Cascaded Context Enhancement Network for Automatic Skin Lesion Segmentation. (arXiv:2004.08107v3 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.04337",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Hwanjun Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minseok Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1\">Dongmin Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_Y/0/1/0/all/0/1\">Yooju Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jae-Gil Lee</a>",
          "description": "Real-world data inevitably contains noisy labels, which induce the poor\ngeneralization of deep neural networks. It is known that the network typically\nbegins to rapidly memorize false-labeled samples after a certain point of\ntraining. Thus, to counter the label noise challenge, we propose a novel\nself-transitional learning method called MORPH, which automatically switches\nits learning phase at the transition point from seeding to evolution. In the\nseeding phase, the network is updated using all the samples to collect a seed\nof clean samples. Then, in the evolution phase, the network is updated using\nonly the set of arguably clean samples, which precisely keeps expanding by the\nupdated network. Thus, MORPH effectively avoids the overfitting to\nfalse-labeled samples throughout the entire training period. Extensive\nexperiments using five real-world or synthetic benchmark datasets demonstrate\nsubstantial improvements over state-of-the-art methods in terms of robustness\nand efficiency.",
          "link": "http://arxiv.org/abs/2012.04337",
          "publishedOn": "2021-06-08T02:20:21.531Z",
          "wordCount": 614,
          "title": "Robust Learning by Self-Transition for Handling Noisy Labels. (arXiv:2012.04337v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1910.13671",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1\">Chaoyue Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yugang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shulai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_B/0/1/0/all/0/1\">Bingbing Ni</a>",
          "description": "In this work, we use facial landmarks to make the deformation for facial\nimages more authentic. The deformation includes the expansion of eyes and the\nshrinking of noses, mouths, and cheeks. An advanced 106-point facial landmark\ndetector is utilized to provide control points for deformation. Bilinear\ninterpolation is used in the expansion and Moving Least Squares methods (MLS)\nincluding Affine Deformation, Similarity Deformation and Rigid Deformation are\nused in the shrinking. We compare the running time as well as the quality of\ndeformed images using different MLS methods. The experimental results show that\nthe Rigid Deformation which can keep other parts of the images unchanged\nperforms better even if it takes the longest time.",
          "link": "http://arxiv.org/abs/1910.13671",
          "publishedOn": "2021-06-08T02:20:21.524Z",
          "wordCount": 575,
          "title": "Facial Image Deformation Based on Landmark Detection. (arXiv:1910.13671v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.05734",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1\">Wang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1\">Wanli Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1\">Ping Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wentao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaogang Wang</a>",
          "description": "Estimating 3D mesh of the human body from a single 2D image is an important\ntask with many applications such as augmented reality and Human-Robot\ninteraction. However, prior works reconstructed 3D mesh from global image\nfeature extracted by using convolutional neural network (CNN), where the dense\ncorrespondences between the mesh surface and the image pixels are missing,\nleading to suboptimal solution. This paper proposes a model-free 3D human mesh\nestimation framework, named DecoMR, which explicitly establishes the dense\ncorrespondence between the mesh and the local image features in the UV space\n(i.e. a 2D space used for texture mapping of 3D mesh). DecoMR first predicts\npixel-to-surface dense correspondence map (i.e., IUV image), with which we\ntransfer local features from the image space to the UV space. Then the\ntransferred local image features are processed in the UV space to regress a\nlocation map, which is well aligned with transferred features. Finally we\nreconstruct 3D human mesh from the regressed location map with a predefined\nmapping function. We also observe that the existing discontinuous UV map are\nunfriendly to the learning of network. Therefore, we propose a novel UV map\nthat maintains most of the neighboring relations on the original mesh surface.\nExperiments demonstrate that our proposed local feature alignment and\ncontinuous UV map outperforms existing 3D mesh based methods on multiple public\nbenchmarks. Code will be made available at\nhttps://github.com/zengwang430521/DecoMR",
          "link": "http://arxiv.org/abs/2006.05734",
          "publishedOn": "2021-06-08T02:20:21.516Z",
          "wordCount": 697,
          "title": "3D Human Mesh Regression with Dense Correspondence. (arXiv:2006.05734v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02930",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_D/0/1/0/all/0/1\">Defu Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiachen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1\">Hengbo Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomizuka_M/0/1/0/all/0/1\">Masayoshi Tomizuka</a>",
          "description": "An effective understanding of the contextual environment and accurate motion\nforecasting of surrounding agents is crucial for the development of autonomous\nvehicles and social mobile robots. This task is challenging since the behavior\nof an autonomous agent is not only affected by its own intention, but also by\nthe static environment and surrounding dynamically interacting agents. Previous\nworks focused on utilizing the spatial and temporal information in time domain\nwhile not sufficiently taking advantage of the cues in frequency domain. To\nthis end, we propose a Spectral Temporal Graph Neural Network (SpecTGNN), which\ncan capture inter-agent correlations and temporal dependency simultaneously in\nfrequency domain in addition to time domain. SpecTGNN operates on both an agent\ngraph with dynamic state information and an environment graph with the features\nextracted from context images in two streams. The model integrates graph\nFourier transform, spectral graph convolution and temporal gated convolution to\nencode history information and forecast future trajectories. Moreover, we\nincorporate a multi-head spatio-temporal attention mechanism to mitigate the\neffect of error propagation in a long time horizon. We demonstrate the\nperformance of SpecTGNN on two public trajectory prediction benchmark datasets,\nwhich achieves state-of-the-art performance in terms of prediction accuracy.",
          "link": "http://arxiv.org/abs/2106.02930",
          "publishedOn": "2021-06-08T02:20:21.508Z",
          "wordCount": 641,
          "title": "Spectral Temporal Graph Neural Network for Trajectory Prediction. (arXiv:2106.02930v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2103.07054",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1\">Xi Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1\">Hyung Jin Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_J/0/1/0/all/0/1\">Jinming Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Linlin Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leonardis_A/0/1/0/all/0/1\">Ales Leonardis</a>",
          "description": "In this paper, we focus on category-level 6D pose and size estimation from\nmonocular RGB-D image. Previous methods suffer from inefficient category-level\npose feature extraction which leads to low accuracy and inference speed. To\ntackle this problem, we propose a fast shape-based network (FS-Net) with\nefficient category-level feature extraction for 6D pose estimation. First, we\ndesign an orientation aware autoencoder with 3D graph convolution for latent\nfeature extraction. The learned latent feature is insensitive to point shift\nand object size thanks to the shift and scale-invariance properties of the 3D\ngraph convolution. Then, to efficiently decode category-level rotation\ninformation from the latent feature, we propose a novel decoupled rotation\nmechanism that employs two decoders to complementarily access the rotation\ninformation. Meanwhile, we estimate translation and size by two residuals,\nwhich are the difference between the mean of object points and ground truth\ntranslation, and the difference between the mean size of the category and\nground truth size, respectively. Finally, to increase the generalization\nability of FS-Net, we propose an online box-cage based 3D deformation mechanism\nto augment the training data. Extensive experiments on two benchmark datasets\nshow that the proposed method achieves state-of-the-art performance in both\ncategory- and instance-level 6D object pose estimation. Especially in\ncategory-level pose estimation, without extra synthetic data, our method\noutperforms existing methods by 6.3% on the NOCS-REAL dataset.",
          "link": "http://arxiv.org/abs/2103.07054",
          "publishedOn": "2021-06-08T02:20:21.501Z",
          "wordCount": 707,
          "title": "FS-Net: Fast Shape-based Network for Category-Level 6D Object Pose Estimation with Decoupled Rotation Mechanism. (arXiv:2103.07054v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10110",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiao_Y/0/1/0/all/0/1\">Yingxia Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chou_Y/0/1/0/all/0/1\">Yu-Cheng Chou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shouyuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_G/0/1/0/all/0/1\">Ge-Peng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_R/0/1/0/all/0/1\">Rong Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_G/0/1/0/all/0/1\">Ge Gao</a>",
          "description": "Owing to the difficulties of mining spatial-temporal cues, the existing\napproaches for video salient object detection (VSOD) are limited in\nunderstanding complex and noisy scenarios, and often fail in inferring\nprominent objects. To alleviate such shortcomings, we propose a simple yet\nefficient architecture, termed Guidance and Teaching Network (GTNet), to\nindependently distil effective spatial and temporal cues with implicit guidance\nand explicit teaching at feature- and decision-level, respectively. To be\nspecific, we (a) introduce a temporal modulator to implicitly bridge features\nfrom motion into the appearance branch, which is capable of fusing cross-modal\nfeatures collaboratively, and (b) utilise motion-guided mask to propagate the\nexplicit cues during the feature aggregation. This novel learning strategy\nachieves satisfactory results via decoupling the complex spatial-temporal cues\nand mapping informative cues across different modalities. Extensive experiments\non three challenging benchmarks show that the proposed method can run at ~28\nfps on a single TITAN Xp GPU and perform competitively against 14 cutting-edge\nbaselines.",
          "link": "http://arxiv.org/abs/2105.10110",
          "publishedOn": "2021-06-08T02:20:21.494Z",
          "wordCount": 639,
          "title": "Guidance and Teaching Network for Video Salient Object Detection. (arXiv:2105.10110v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.03244",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Saha_A/0/1/0/all/0/1\">Anindo Saha</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hosseinzadeh_M/0/1/0/all/0/1\">Matin Hosseinzadeh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huisman_H/0/1/0/all/0/1\">Henkjan Huisman</a>",
          "description": "We present a multi-stage 3D computer-aided detection and diagnosis (CAD)\nmodel for automated localization of clinically significant prostate cancer\n(csPCa) in bi-parametric MR imaging (bpMRI). Deep attention mechanisms drive\nits detection network, targeting salient structures and highly discriminative\nfeature dimensions across multiple resolutions. Its goal is to accurately\nidentify csPCa lesions from indolent cancer and the wide range of benign\npathology that can afflict the prostate gland. Simultaneously, a decoupled\nresidual classifier is used to achieve consistent false positive reduction,\nwithout sacrificing high sensitivity or computational efficiency. In order to\nguide model generalization with domain-specific clinical knowledge, a\nprobabilistic anatomical prior is used to encode the spatial prevalence and\nzonal distinction of csPCa. Using a large dataset of 1950 prostate bpMRI paired\nwith radiologically-estimated annotations, we hypothesize that such CNN-based\nmodels can be trained to detect biopsy-confirmed malignancies in an independent\ncohort.\n\nFor 486 institutional testing scans, the 3D CAD system achieves\n83.69$\\pm$5.22% and 93.19$\\pm$2.96% detection sensitivity at 0.50 and 1.46\nfalse positive(s) per patient, respectively, with 0.882$\\pm$0.030 AUROC in\npatient-based diagnosis $-$significantly outperforming four state-of-the-art\nbaseline architectures (U-SEResNet, UNet++, nnU-Net, Attention U-Net) from\nrecent literature. For 296 external biopsy-confirmed testing scans, the\nensembled CAD system shares moderate agreement with a consensus of expert\nradiologists (76.69%; $kappa$ $=$ 0.51$\\pm$0.04) and independent pathologists\n(81.08%; $kappa$ $=$ 0.56$\\pm$0.06); demonstrating strong generalization to\nhistologically-confirmed csPCa diagnosis.",
          "link": "http://arxiv.org/abs/2101.03244",
          "publishedOn": "2021-06-08T02:20:21.487Z",
          "wordCount": 777,
          "title": "End-to-end Prostate Cancer Detection in bpMRI via 3D CNNs: Effects of Attention Mechanisms, Clinical Priori and Decoupled False Positive Reduction. (arXiv:2101.03244v8 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.12885",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yin_P/0/1/0/all/0/1\">Peng Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Lingyun Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_J/0/1/0/all/0/1\">Jianmin Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scherer_S/0/1/0/all/0/1\">Sebastian Scherer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choset_H/0/1/0/all/0/1\">Howie Choset</a>",
          "description": "One of the main obstacles to 3D semantic segmentation is the significant\namount of endeavor required to generate expensive point-wise annotations for\nfully supervised training. To alleviate manual efforts, we propose GIDSeg, a\nnovel approach that can simultaneously learn segmentation from sparse\nannotations via reasoning global-regional structures and individual-vicinal\nproperties. GIDSeg depicts global- and individual- relation via a dynamic edge\nconvolution network coupled with a kernelized identity descriptor. The ensemble\neffects are obtained by endowing a fine-grained receptive field to a\nlow-resolution voxelized map. In our GIDSeg, an adversarial learning module is\nalso designed to further enhance the conditional constraint of identity\ndescriptors within the joint feature distribution. Despite the apparent\nsimplicity, our proposed approach achieves superior performance over\nstate-of-the-art for inferencing 3D dense segmentation with only sparse\nannotations. Particularly, with $5\\%$ annotations of raw data, GIDSeg\noutperforms other 3D segmentation methods.",
          "link": "http://arxiv.org/abs/2105.12885",
          "publishedOn": "2021-06-08T02:20:21.471Z",
          "wordCount": 619,
          "title": "3D Segmentation Learning from Sparse Annotations and Hierarchical Descriptors. (arXiv:2105.12885v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.08115",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sonbhadra_S/0/1/0/all/0/1\">Sanjay Kumar Sonbhadra</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Agarwal_S/0/1/0/all/0/1\">Sonali Agarwal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nagabhushan_P/0/1/0/all/0/1\">P. Nagabhushan</a>",
          "description": "The infection of respiratory coronavirus disease 2019 (COVID-19) starts with\nthe upper respiratory tract and as the virus grows, the infection can progress\nto lungs and develop pneumonia. The conventional way of COVID-19 diagnosis is\nreverse transcription polymerase chain reaction (RT-PCR), which is less\nsensitive during early stages; especially if the patient is asymptomatic, which\nmay further cause more severe pneumonia. In this context, several deep learning\nmodels have been proposed to identify pulmonary infections using publicly\navailable chest X-ray (CXR) image datasets for early diagnosis, better\ntreatment and quick cure. In these datasets, presence of less number of\nCOVID-19 positive samples compared to other classes (normal, pneumonia and\nTuberculosis) raises the challenge for unbiased learning of deep learning\nmodels. All deep learning models opted class balancing techniques to solve this\nissue; which however should be avoided in any medical diagnosis process.\nMoreover, the deep learning models are also data hungry and need massive\ncomputation resources. Therefore for quicker diagnosis, this research proposes\na novel pinball loss function based one-class support vector machine\n(PB-OCSVM), that can work in presence of limited COVID-19 positive CXR samples\nwith objectives to maximize the learning efficiency and to minimize the false\npredictions. The performance of the proposed model is compared with\nconventional OCSVM and existing deep learning models, and the experimental\nresults prove that the proposed model outperformed over state-of-the-art\nmethods. To validate the robustness of the proposed model, experiments are also\nperformed with noisy CXR images and UCI benchmark datasets.",
          "link": "http://arxiv.org/abs/2010.08115",
          "publishedOn": "2021-06-08T02:20:21.444Z",
          "wordCount": 759,
          "title": "Pinball-OCSVM for early-stage COVID-19 diagnosis with limited posteroanterior chest X-ray images. (arXiv:2010.08115v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.06387",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Paul_W/0/1/0/all/0/1\">William Paul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hadzic_A/0/1/0/all/0/1\">Armin Hadzic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_N/0/1/0/all/0/1\">Neil Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alajaji_F/0/1/0/all/0/1\">Fady Alajaji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burlina_P/0/1/0/all/0/1\">Phil Burlina</a>",
          "description": "We propose a novel method for enforcing AI fairness with respect to protected\nor sensitive factors. This method uses a dual strategy performing training and\nrepresentation alteration (TARA) for the mitigation of prominent causes of AI\nbias by including: a) the use of representation learning alteration via\nadversarial independence to suppress the bias-inducing dependence of the data\nrepresentation from protected factors; and b) training set alteration via\nintelligent augmentation to address bias-causing data imbalance, by using\ngenerative models that allow the fine control of sensitive factors related to\nunderrepresented populations via domain adaptation and latent space\nmanipulation. When testing our methods on image analytics, experiments\ndemonstrate that TARA significantly or fully debiases baseline models while\noutperforming competing debiasing methods that have the same amount of\ninformation, e.g., with (% overall accuracy, % accuracy gap) = (78.8, 0.5) vs.\nthe baseline method's score of (71.8, 10.5) for EyePACS, and (73.7, 11.8) vs.\n(69.1, 21.7) for CelebA. Furthermore, recognizing certain limitations in\ncurrent metrics used for assessing debiasing performance, we propose novel\nconjunctive debiasing metrics. Our experiments also demonstrate the ability of\nthese novel metrics in assessing the Pareto efficiency of the proposed methods.",
          "link": "http://arxiv.org/abs/2012.06387",
          "publishedOn": "2021-06-08T02:20:21.419Z",
          "wordCount": 675,
          "title": "TARA: Training and Representation Alteration for AI Fairness and Domain Generalization. (arXiv:2012.06387v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02864",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tripathi_S/0/1/0/all/0/1\">Suvidha Tripathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Satish Kumar Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hwee Kuan Lee</a>",
          "description": "Researchers working on computational analysis of Whole Slide Images (WSIs) in\nhistopathology have primarily resorted to patch-based modelling due to large\nresolution of each WSI. The large resolution makes WSIs infeasible to be fed\ndirectly into the machine learning models due to computational constraints.\nHowever, due to patch-based analysis, most of the current methods fail to\nexploit the underlying spatial relationship among the patches. In our work, we\nhave tried to integrate this relationship along with feature-based correlation\namong the extracted patches from the particular tumorous region. For the given\ntask of classification, we have used BiLSTMs to model both forward and backward\ncontextual relationship. RNN based models eliminate the limitation of sequence\nsize by allowing the modelling of variable size images within a deep learning\nmodel. We have also incorporated the effect of spatial continuity by exploring\ndifferent scanning techniques used to sample patches. To establish the\nefficiency of our approach, we trained and tested our model on two datasets,\nmicroscopy images and WSI tumour regions. After comparing with contemporary\nliterature we achieved the better performance with accuracy of 90% for\nmicroscopy image dataset. For WSI tumour region dataset, we compared the\nclassification results with deep learning networks such as ResNet, DenseNet,\nand InceptionV3 using maximum voting technique. We achieved the highest\nperformance accuracy of 84%. We found out that BiLSTMs with CNN features have\nperformed much better in modelling patches into an end-to-end Image\nclassification network. Additionally, the variable dimensions of WSI tumour\nregions were used for classification without the need for resizing. This\nsuggests that our method is independent of tumour image size and can process\nlarge dimensional images without losing the resolution details.",
          "link": "http://arxiv.org/abs/2106.02864",
          "publishedOn": "2021-06-08T02:20:21.393Z",
          "wordCount": 757,
          "title": "An End-to-End Breast Tumour Classification Model Using Context-Based Patch Modelling- A BiLSTM Approach for Image Classification. (arXiv:2106.02864v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2103.03417",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aka_O/0/1/0/all/0/1\">Osman Aka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burke_K/0/1/0/all/0/1\">Ken Burke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bauerle_A/0/1/0/all/0/1\">Alex B&#xe4;uerle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greer_C/0/1/0/all/0/1\">Christina Greer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitchell_M/0/1/0/all/0/1\">Margaret Mitchell</a>",
          "description": "The measurement of bias in machine learning often focuses on model\nperformance across identity subgroups (such as man and woman) with respect to\ngroundtruth labels. However, these methods do not directly measure the\nassociations that a model may have learned, for example between labels and\nidentity subgroups. Further, measuring a model's bias requires a fully\nannotated evaluation dataset which may not be easily available in practice. We\npresent an elegant mathematical solution that tackles both issues\nsimultaneously, using image classification as a working example. By treating a\nclassification model's predictions for a given image as a set of labels\nanalogous to a bag of words, we rank the biases that a model has learned with\nrespect to different identity labels. We use (man, woman) as a concrete example\nof an identity label set (although this set need not be binary), and present\nrankings for the labels that are most biased towards one identity or the other.\nWe demonstrate how the statistical properties of different association metrics\ncan lead to different rankings of the most \"gender biased\" labels, and conclude\nthat normalized pointwise mutual information (nPMI) is most useful in practice.\nFinally, we announce an open-sourced nPMI visualization tool using TensorBoard.",
          "link": "http://arxiv.org/abs/2103.03417",
          "publishedOn": "2021-06-08T02:20:21.386Z",
          "wordCount": 675,
          "title": "Measuring Model Biases in the Absence of Ground Truth. (arXiv:2103.03417v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02740",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bashkirova_D/0/1/0/all/0/1\">Dina Bashkirova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Ziliang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akl_J/0/1/0/all/0/1\">James Akl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alladkani_F/0/1/0/all/0/1\">Fadi Alladkani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_P/0/1/0/all/0/1\">Ping Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ablavsky_V/0/1/0/all/0/1\">Vitaly Ablavsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calli_B/0/1/0/all/0/1\">Berk Calli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bargal_S/0/1/0/all/0/1\">Sarah Adel Bargal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1\">Kate Saenko</a>",
          "description": "Less than 35% of recyclable waste is being actually recycled in the US, which\nleads to increased soil and sea pollution and is one of the major concerns of\nenvironmental researchers as well as the common public. At the heart of the\nproblem is the inefficiencies of the waste sorting process (separating paper,\nplastic, metal, glass, etc.) due to the extremely complex and cluttered nature\nof the waste stream. Automated waste detection strategies have a great\npotential to enable more efficient, reliable and safer waste sorting practices,\nbut the literature lacks comprehensive datasets and methodology for the\nindustrial waste sorting solutions. In this paper, we take a step towards\ncomputer-aided waste detection and present the first in-the-wild\nindustrial-grade waste detection and segmentation dataset, ZeroWaste. This\ndataset contains over1800fully segmented video frames collected from a real\nwaste sorting plant along with waste material labels for training and\nevaluation of the segmentation methods, as well as over6000unlabeled frames\nthat can be further used for semi-supervised and self-supervised learning\ntechniques. ZeroWaste also provides frames of the conveyor belt before and\nafter the sorting process, comprising a novel setup that can be used for\nweakly-supervised segmentation. We present baselines for fully-, semi- and\nweakly-supervised segmentation methods. Our experimental results demonstrate\nthat state-of-the-art segmentation methods struggle to correctly detect and\nclassify target objects which suggests the challenging nature of our proposed\nin-the-wild dataset. We believe that ZeroWastewill catalyze research in object\ndetection and semantic segmentation in extreme clutter as well as applications\nin the recycling domain. Our project page can be found\natthis http URL",
          "link": "http://arxiv.org/abs/2106.02740",
          "publishedOn": "2021-06-08T02:20:21.296Z",
          "wordCount": 697,
          "title": "ZeroWaste Dataset: Towards Automated Waste Recycling. (arXiv:2106.02740v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02874",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jiaxing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_D/0/1/0/all/0/1\">Dayan Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_A/0/1/0/all/0/1\">Aoran Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Shijian Lu</a>",
          "description": "Unsupervised domain adaptation (UDA) involves a supervised loss in a labeled\nsource domain and an unsupervised loss in an unlabeled target domain, which\noften faces more severe overfitting (than classical supervised learning) as the\nsupervised source loss has clear domain gap and the unsupervised target loss is\noften noisy due to the lack of annotations. This paper presents RDA, a robust\ndomain adaptation technique that introduces adversarial attacking to mitigate\noverfitting in UDA. We achieve robust domain adaptation by a novel Fourier\nadversarial attacking (FAA) method that allows large magnitude of perturbation\nnoises but has minimal modification of image semantics, the former is critical\nto the effectiveness of its generated adversarial samples due to the existence\nof 'domain gaps'. Specifically, FAA decomposes images into multiple frequency\ncomponents (FCs) and generates adversarial samples by just perturbating certain\nFCs that capture little semantic information. With FAA-generated samples, the\ntraining can continue the 'random walk' and drift into an area with a flat loss\nlandscape, leading to more robust domain adaptation. Extensive experiments over\nmultiple domain adaptation tasks show that RDA can work with different computer\nvision tasks with superior performance.",
          "link": "http://arxiv.org/abs/2106.02874",
          "publishedOn": "2021-06-08T02:20:21.234Z",
          "wordCount": 618,
          "title": "RDA: Robust Domain Adaptation via Fourier Adversarial Attacking. (arXiv:2106.02874v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02778",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Long_Y/0/1/0/all/0/1\">Yunfei Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morris_D/0/1/0/all/0/1\">Daniel Morris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaoming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Castro_M/0/1/0/all/0/1\">Marcos Castro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakravarty_P/0/1/0/all/0/1\">Punarjay Chakravarty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narayanan_P/0/1/0/all/0/1\">Praveen Narayanan</a>",
          "description": "While radar and video data can be readily fused at the detection level,\nfusing them at the pixel level is potentially more beneficial. This is also\nmore challenging in part due to the sparsity of radar, but also because\nautomotive radar beams are much wider than a typical pixel combined with a\nlarge baseline between camera and radar, which results in poor association\nbetween radar pixels and color pixel. A consequence is that depth completion\nmethods designed for LiDAR and video fare poorly for radar and video. Here we\npropose a radar-to-pixel association stage which learns a mapping from radar\nreturns to pixels. This mapping also serves to densify radar returns. Using\nthis as a first stage, followed by a more traditional depth completion method,\nwe are able to achieve image-guided depth completion with radar and video. We\ndemonstrate performance superior to camera and radar alone on the nuScenes\ndataset. Our source code is available at https://github.com/longyunf/rc-pda.",
          "link": "http://arxiv.org/abs/2106.02778",
          "publishedOn": "2021-06-08T02:20:21.190Z",
          "wordCount": 601,
          "title": "Radar-Camera Pixel Depth Association for Depth Completion. (arXiv:2106.02778v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02845",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jiaxing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_D/0/1/0/all/0/1\">Dayan Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_A/0/1/0/all/0/1\">Aoran Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Shijian Lu</a>",
          "description": "Contemporary domain adaptive semantic segmentation aims to address data\nannotation challenges by assuming that target domains are completely\nunannotated. However, annotating a few target samples is usually very\nmanageable and worthwhile especially if it improves the adaptation performance\nsubstantially. This paper presents SSDAS, a Semi-Supervised Domain Adaptive\nimage Segmentation network that employs a few labeled target samples as anchors\nfor adaptive and progressive feature alignment between labeled source samples\nand unlabeled target samples. We position the few labeled target samples as\nreferences that gauge the similarity between source and target features and\nguide adaptive inter-domain alignment for learning more similar source\nfeatures. In addition, we replace the dissimilar source features by\nhigh-confidence target features continuously during the iterative training\nprocess, which achieves progressive intra-domain alignment between confident\nand unconfident target features. Extensive experiments show the proposed SSDAS\ngreatly outperforms a number of baselines, i.e., UDA-based semantic\nsegmentation and SSDA-based image classification. In addition, SSDAS is\ncomplementary and can be easily incorporated into UDA-based methods with\nconsistent improvements in domain adaptive semantic segmentation.",
          "link": "http://arxiv.org/abs/2106.02845",
          "publishedOn": "2021-06-08T02:20:21.174Z",
          "wordCount": 604,
          "title": "Semi-Supervised Domain Adaptation via Adaptive and Progressive Feature Alignment. (arXiv:2106.02845v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02824",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yilin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Shaozuo Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaokang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1\">Wei Shen</a>",
          "description": "In this paper, we propose a generic model transfer scheme to make\nConvlutional Neural Networks (CNNs) interpretable, while maintaining their high\nclassification accuracy. We achieve this by building a differentiable decision\nforest on top of CNNs, which enjoys two characteristics: 1) During training,\nthe tree hierarchies of the forest are learned in a top-down manner under the\nguidance from the category semantics embedded in the pre-trained CNN weights;\n2) During inference, a single decision tree is dynamically selected from the\nforest for each input sample, enabling the transferred model to make sequential\ndecisions corresponding to the attributes shared by semantically-similar\ncategories, rather than directly performing flat classification. We name the\ntransferred model deep Dynamic Sequential Decision Forest (dDSDF). Experimental\nresults show that dDSDF not only achieves higher classification accuracy than\nits conuterpart, i.e., the original CNN, but has much better interpretability,\nas qualitatively it has plausible hierarchies and quantitatively it leads to\nmore precise saliency maps.",
          "link": "http://arxiv.org/abs/2106.02824",
          "publishedOn": "2021-06-08T02:20:21.130Z",
          "wordCount": 596,
          "title": "Making CNNs Interpretable by Building Dynamic Sequential Decision Forests with Top-down Hierarchy Learning. (arXiv:2106.02824v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02711",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Para_W/0/1/0/all/0/1\">Wamiq Reyaz Para</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhat_S/0/1/0/all/0/1\">Shariq Farooq Bhat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guerrero_P/0/1/0/all/0/1\">Paul Guerrero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kelly_T/0/1/0/all/0/1\">Tom Kelly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitra_N/0/1/0/all/0/1\">Niloy Mitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guibas_L/0/1/0/all/0/1\">Leonidas Guibas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wonka_P/0/1/0/all/0/1\">Peter Wonka</a>",
          "description": "Computer-aided design (CAD) is the most widely used modeling approach for\ntechnical design. The typical starting point in these designs is 2D sketches\nwhich can later be extruded and combined to obtain complex three-dimensional\nassemblies. Such sketches are typically composed of parametric primitives, such\nas points, lines, and circular arcs, augmented with geometric constraints\nlinking the primitives, such as coincidence, parallelism, or orthogonality.\nSketches can be represented as graphs, with the primitives as nodes and the\nconstraints as edges. Training a model to automatically generate CAD sketches\ncan enable several novel workflows, but is challenging due to the complexity of\nthe graphs and the heterogeneity of the primitives and constraints. In\nparticular, each type of primitive and constraint may require a record of\ndifferent size and parameter types. We propose SketchGen as a generative model\nbased on a transformer architecture to address the heterogeneity problem by\ncarefully designing a sequential language for the primitives and constraints\nthat allows distinguishing between different primitive or constraint types and\ntheir parameters, while encouraging our model to re-use information across\nrelated parameters, encoding shared structure. A particular highlight of our\nwork is the ability to produce primitives linked via constraints that enables\nthe final output to be further regularized via a constraint solver. We evaluate\nour model by demonstrating constraint prediction for given sets of primitives\nand full sketch generation from scratch, showing that our approach\nsignificantly out performs the state-of-the-art in CAD sketch generation.",
          "link": "http://arxiv.org/abs/2106.02711",
          "publishedOn": "2021-06-08T02:20:21.086Z",
          "wordCount": 688,
          "title": "SketchGen: Generating Constrained CAD Sketches. (arXiv:2106.02711v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02842",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ciampi_L/0/1/0/all/0/1\">Luca Ciampi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gennaro_C/0/1/0/all/0/1\">Claudio Gennaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carrara_F/0/1/0/all/0/1\">Fabio Carrara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Falchi_F/0/1/0/all/0/1\">Fabrizio Falchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vairo_C/0/1/0/all/0/1\">Claudio Vairo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amato_G/0/1/0/all/0/1\">Giuseppe Amato</a>",
          "description": "This paper presents a novel solution to automatically count vehicles in a\nparking lot using images captured by smart cameras. Unlike most of the\nliterature on this task, which focuses on the analysis of single images, this\npaper proposes the use of multiple visual sources to monitor a wider parking\narea from different perspectives. The proposed multi-camera system is capable\nof automatically estimate the number of cars present in the entire parking lot\ndirectly on board the edge devices. It comprises an on-device deep\nlearning-based detector that locates and counts the vehicles from the captured\nimages and a decentralized geometric-based approach that can analyze the\ninter-camera shared areas and merge the data acquired by all the devices. We\nconduct the experimental evaluation on an extended version of the CNRPark-EXT\ndataset, a collection of images taken from the parking lot on the campus of the\nNational Research Council (CNR) in Pisa, Italy. We show that our system is\nrobust and takes advantage of the redundant information deriving from the\ndifferent cameras, improving the overall performance without requiring any\nextra geometrical information of the monitored scene.",
          "link": "http://arxiv.org/abs/2106.02842",
          "publishedOn": "2021-06-08T02:20:21.079Z",
          "wordCount": 618,
          "title": "Multi-Camera Vehicle Counting Using Edge-AI. (arXiv:2106.02842v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02733",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sosnovik_I/0/1/0/all/0/1\">Ivan Sosnovik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moskalev_A/0/1/0/all/0/1\">Artem Moskalev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smeulders_A/0/1/0/all/0/1\">Arnold Smeulders</a>",
          "description": "Scale is often seen as a given, disturbing factor in many vision tasks. When\ndoing so it is one of the factors why we need more data during learning. In\nrecent work scale equivariance was added to convolutional neural networks. It\nwas shown to be effective for a range of tasks. We aim for accurate\nscale-equivariant convolutional neural networks (SE-CNNs) applicable for\nproblems where high granularity of scale and small filter sizes are required.\nCurrent SE-CNNs rely on weight sharing and filter rescaling, the latter of\nwhich is accurate for integer scales only. To reach accurate scale\nequivariance, we derive general constraints under which scale-convolution\nremains equivariant to discrete rescaling. We find the exact solution for all\ncases where it exists, and compute the approximation for the rest. The discrete\nscale-convolution pays off, as demonstrated in a new state-of-the-art\nclassification on MNIST-scale and improving the results on STL-10. With the\nsame SE scheme, we also improve the computational effort of a scale-equivariant\nSiamese tracker on OTB-13.",
          "link": "http://arxiv.org/abs/2106.02733",
          "publishedOn": "2021-06-08T02:20:21.069Z",
          "wordCount": 588,
          "title": "DISCO: accurate Discrete Scale Convolutions. (arXiv:2106.02733v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02773",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1\">Zhenfeng Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiaming Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_L/0/1/0/all/0/1\">Lianbing Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xiao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_T/0/1/0/all/0/1\">Tao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruiqian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_X/0/1/0/all/0/1\">Xianwei Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Q/0/1/0/all/0/1\">Qing Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhiqiang Wang</a>",
          "description": "In this paper, we introduce a challenging global large-scale ship database\n(called GLSD), designed specifically for ship detection tasks. The designed\nGLSD database includes a total of 140,616 annotated instances from 100,729\nimages. Based on the collected images, we propose 13 categories that widely\nexists in international routes. These categories include sailing boat, fishing\nboat, passenger ship, war ship, general cargo ship, container ship, bulk cargo\ncarrier, barge, ore carrier, speed boat, canoe, oil carrier, and tug. The\nmotivations of developing GLSD include the following: 1) providing a refined\nship detection database; 2) providing the worldwide researchers of ship\ndetection and exhaustive label information (bounding box and ship class label)\nin one uniform global database; and 3) providing a large-scale ship database\nwith geographic information (port and country information) that benefits\nmulti-modal analysis. In addition, we discuss the evaluation protocols given\nimage characteristics in GLSD and analyze the performance of selected\nstate-of-the-art object detection algorithms on GSLD, providing baselines for\nfuture studies. More information regarding the designed GLSD can be found at\nhttps://github.com/jiaming-wang/GLSD.",
          "link": "http://arxiv.org/abs/2106.02773",
          "publishedOn": "2021-06-08T02:20:21.051Z",
          "wordCount": 621,
          "title": "GLSD: The Global Large-Scale Ship Database and Baseline Evaluations. (arXiv:2106.02773v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.14117",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shubin_D/0/1/0/all/0/1\">Dmitrii Shubin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eytan_D/0/1/0/all/0/1\">Danny Eytan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodfellow_S/0/1/0/all/0/1\">Sebastian D. Goodfellow</a>",
          "description": "Self-supervised learning methods for computer vision have demonstrated the\neffectiveness of pre-training feature representations, resulting in\nwell-generalizing Deep Neural Networks, even if the annotated data are limited.\nHowever, representation learning techniques require a significant amount of\ntime for model training, with most of it time spent on precise hyper-parameter\noptimization and selection of augmentation techniques. We hypothesized that if\nthe annotated dataset has enough morphological diversity to capture the general\npopulation's as is common in medical imaging, for example, due to conserved\nsimilarities of tissue mythologies, the variance error of the trained model is\nthe prevalent component of the Bias-Variance Trade-off. We propose the Variance\nAware Training (VAT) method that exploits this property by introducing the\nvariance error into the model loss function, i.e., enabling minimizing the\nvariance explicitly. Additionally, we provide the theoretical formulation and\nproof of the proposed method to aid in interpreting the approach. Our method\nrequires selecting only one hyper-parameter and was able to match or improve\nthe state-of-the-art performance of self-supervised methods while achieving an\norder of magnitude reduction in the GPU training time. We validated VAT on\nthree medical imaging datasets from diverse domains and various learning\nobjectives. These included a Magnetic Resonance Imaging (MRI) dataset for the\nheart semantic segmentation (MICCAI 2017 ACDC challenge), fundus photography\ndataset for ordinary regression of diabetic retinopathy progression (Kaggle\n2019 APTOS Blindness Detection challenge), and classification of\nhistopathologic scans of lymph node sections (PatchCamelyon dataset).",
          "link": "http://arxiv.org/abs/2105.14117",
          "publishedOn": "2021-06-07T23:29:40.150Z",
          "wordCount": 702,
          "title": "About Explicit Variance Minimization: Training Neural Networks for Medical Imaging With Limited Data Annotations. (arXiv:2105.14117v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14106",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pelosin_F/0/1/0/all/0/1\">Francesco Pelosin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torsello_A/0/1/0/all/0/1\">Andrea Torsello</a>",
          "description": "The design of machines and algorithms capable of learning in a dynamically\nchanging environment has become an increasingly topical problem with the\nincrease of the size and heterogeneity of data available to learning systems.\nAs a consequence, the key issue of Continual Learning has become that of\naddressing the stability-plasticity dilemma of connectionist systems, as they\nneed to adapt their model without forgetting previously acquired knowledge.\nWithin this context, rehearsal-based methods i.e., solutions in where the\nlearner exploits memory to revisit past data, has proven to be very effective,\nleading to performance at the state-of-the-art. In our study, we propose an\nanalysis of the memory quantity/quality trade-off adopting various data\nreduction approaches to increase the number of instances storable in memory. In\nparticular, we investigate complex instance compression techniques such as deep\nencoders, but also trivial approaches such as image resizing and linear\ndimensionality reduction. Our findings suggest that the optimal trade-off is\nseverely skewed toward instance quantity, where rehearsal approaches with\nseveral heavily compressed instances easily outperform state-of-the-art\napproaches with the same amount of memory at their disposal. Further, in high\nmemory configurations, deep approaches extracting spatial structure combined\nwith extreme resizing (of the order of $8\\times8$ images) yield the best\nresults, while in memory-constrained configurations where deep approaches\ncannot be used due to their memory requirement in training, Extreme Learning\nMachines (ELM) offer a clear advantage.",
          "link": "http://arxiv.org/abs/2105.14106",
          "publishedOn": "2021-06-07T23:29:40.127Z",
          "wordCount": 680,
          "title": "More Is Better: An Analysis of Instance Quantity/Quality Trade-off in Rehearsal-based Continual Learning. (arXiv:2105.14106v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10375",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhipeng Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaobo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1\">Xiaojiang Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_B/0/1/0/all/0/1\">Baigui Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1\">Yang You</a>",
          "description": "Face recognition has achieved significant progress in deep-learning era due\nto the ultra-large-scale and well-labeled datasets.\n\nHowever, training on ultra-large-scale datasets is time-consuming and takes\nup a lot of hardware resource.\n\nTherefore, designing an efficient training approach is crucial and\nindispensable.\n\nThe heavy computational and memory costs mainly result from the high\ndimensionality of the Fully-Connected (FC) layer.\n\nSpecifically, the dimensionality is determined by the number of face\nidentities, which can be million-level or even more.\n\nTo this end, we propose a novel training approach for ultra-large-scale face\ndatasets, termed Faster Face Classification (F$^2$C).\n\nIn F$^2$C, we first define a Gallery Net and a Probe Net that are used to\ngenerate identities' centers and extract faces' features for face recognition,\nrespectively.\n\nGallery Net has the same structure as Probe Net and inherits the parameters\nfrom Probe Net with a moving average paradigm.\n\nAfter that, to reduce the training time and hardware costs of the FC layer,\nwe propose a Dynamic Class Pool (DCP) that stores the features from Gallery Net\nand calculates the inner product (logits) with positive samples (whose\nidentities are in the DCP) in each mini-batch.\n\nDCP can be regarded as a substitute for the FC layer but it is far smaller,\nthus greatly reducing the computational and memory costs.\n\nFor negative samples (whose identities are not in DCP), we minimize the\ncosine similarities between negative samples and those in DCP.\n\nThen, to improve the update efficiency of DCP's parameters, we design a dual\ndata-loader including identity-based and instance-based loaders to generate a\ncertain of identities and samples in mini-batches.",
          "link": "http://arxiv.org/abs/2105.10375",
          "publishedOn": "2021-06-07T22:33:05.238Z",
          "wordCount": 776,
          "title": "An Efficient Training Approach for Very Large Scale Face Recognition. (arXiv:2105.10375v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.11237",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1\">Jinlong Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhengkai Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yueyang Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yabiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tai_Y/0/1/0/all/0/1\">Ying Tai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chengjie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1\">Weiyao Lin</a>",
          "description": "Recently, most siamese network based trackers locate targets via object\nclassification and bounding-box regression. Generally, they select the\nbounding-box with maximum classification confidence as the final prediction.\nThis strategy may miss the right result due to the accuracy misalignment\nbetween classification and regression. In this paper, we propose a novel\nsiamese tracking algorithm called SiamRCR, addressing this problem with a\nsimple, light and effective solution. It builds reciprocal links between\nclassification and regression branches, which can dynamically re-weight their\nlosses for each positive sample. In addition, we add a localization branch to\npredict the localization accuracy, so that it can work as the replacement of\nthe regression assistance link during inference. This branch makes the training\nand inference more consistent. Extensive experimental results demonstrate the\neffectiveness of SiamRCR and its superiority over the state-of-the-art\ncompetitors on GOT-10k, LaSOT, TrackingNet, OTB-2015, VOT-2018 and VOT-2019.\nMoreover, our SiamRCR runs at 65 FPS, far above the real-time requirement.",
          "link": "http://arxiv.org/abs/2105.11237",
          "publishedOn": "2021-06-07T22:33:05.218Z",
          "wordCount": 646,
          "title": "SiamRCR: Reciprocal Classification and Regression for Visual Object Tracking. (arXiv:2105.11237v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.11578",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamidouche_W/0/1/0/all/0/1\">Wassim Hamidouche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deforges_O/0/1/0/all/0/1\">Olivier Deforges</a>",
          "description": "Salient human detection (SHD) in dynamic 360{\\deg} immersive videos is of\ngreat importance for various applications such as robotics, inter-human and\nhuman-object interaction in augmented reality. However, 360{\\deg} video SHD has\nbeen seldom discussed in the computer vision community due to a lack of\ndatasets with large-scale omnidirectional videos and rich annotations. To this\nend, we propose SHD360, the first 360{\\deg} video SHD dataset containing\nvarious real-life daily scenes borrowed from this http URL, with\nhierarchical annotations for 6,268 key frames uniformly sampled from 37,403\nomnidirectional video frames at 4K resolution. Since so far there is no method\nproposed for 360{\\deg} image/video SHD, we systematically benchmark 11\nrepresentative state-of-the-art salient object detection approaches on our\nSHD360. We hope our proposed dataset and benchmark could serve as a good\nstarting point for advancing human-centric researches towards 360{\\deg}\npanoramic data. Our dataset and benchmark will be publicly available at\nhttps://github.com/PanoAsh/SHD360.",
          "link": "http://arxiv.org/abs/2105.11578",
          "publishedOn": "2021-06-07T22:33:05.198Z",
          "wordCount": 623,
          "title": "SHD360: A Benchmark Dataset for Salient Human Detection in 360{\\deg} Videos. (arXiv:2105.11578v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10762",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Murphy_R/0/1/0/all/0/1\">Robert A. Murphy</a>",
          "description": "Random field and random cluster theory is used to prove certain mathematical\nresults concerning the probability distribution of images characterized as\ngeneric $2D$ integer arrays during simultaneous learning. Example models in\nimage classification and object segmentation illustrate the mathematical\nresults.",
          "link": "http://arxiv.org/abs/2104.10762",
          "publishedOn": "2021-06-07T22:33:05.164Z",
          "wordCount": 525,
          "title": "Image Distribution Estimation with Random Field and Random Cluster Theories. (arXiv:2104.10762v5 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.10426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chai_L/0/1/0/all/0/1\">Lucy Chai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wulff_J/0/1/0/all/0/1\">Jonas Wulff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isola_P/0/1/0/all/0/1\">Phillip Isola</a>",
          "description": "In recent years, Generative Adversarial Networks have become ubiquitous in\nboth research and public perception, but how GANs convert an unstructured\nlatent code to a high quality output is still an open question. In this work,\nwe investigate regression into the latent space as a probe to understand the\ncompositional properties of GANs. We find that combining the regressor and a\npretrained generator provides a strong image prior, allowing us to create\ncomposite images from a collage of random image parts at inference time while\nmaintaining global consistency. To compare compositional properties across\ndifferent generators, we measure the trade-offs between reconstruction of the\nunrealistic input and image quality of the regenerated samples. We find that\nthe regression approach enables more localized editing of individual image\nparts compared to direct editing in the latent space, and we conduct\nexperiments to quantify this independence effect. Our method is agnostic to the\nsemantics of edits, and does not require labels or predefined concepts during\ntraining. Beyond image composition, our method extends to a number of related\napplications, such as image inpainting or example-based image editing, which we\ndemonstrate on several GANs and datasets, and because it uses only a single\nforward pass, it can operate in real-time. Code is available on our project\npage: https://chail.github.io/latent-composition/.",
          "link": "http://arxiv.org/abs/2103.10426",
          "publishedOn": "2021-06-07T03:06:13.443Z",
          "wordCount": 687,
          "title": "Using latent space regression to analyze and leverage compositionality in GANs. (arXiv:2103.10426v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.08360",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_E/0/1/0/all/0/1\">Ella Y. Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Som_A/0/1/0/all/0/1\">Anirudh Som</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shukla_A/0/1/0/all/0/1\">Ankita Shukla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_H/0/1/0/all/0/1\">Hongjun Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turaga_P/0/1/0/all/0/1\">Pavan Turaga</a>",
          "description": "Deep neural networks have increasingly been used as an auxiliary tool in\nhealthcare applications, due to their ability to improve performance of several\ndiagnosis tasks. However, these methods are not widely adopted in clinical\nsettings due to the practical limitations in the reliability, generalizability,\nand interpretability of deep learning based systems. As a result, methods have\nbeen developed that impose additional constraints during network training to\ngain more control as well as improve interpretabilty, facilitating their\nacceptance in healthcare community. In this work, we investigate the benefit of\nusing Orthogonal Spheres (OS) constraint for classification of COVID-19 cases\nfrom chest X-ray images. The OS constraint can be written as a simple\northonormality term which is used in conjunction with the standard\ncross-entropy loss during classification network training. Previous studies\nhave demonstrated significant benefits in applying such constraints to deep\nlearning models. Our findings corroborate these observations, indicating that\nthe orthonormality loss function effectively produces improved semantic\nlocalization via GradCAM visualizations, enhanced classification performance,\nand reduced model calibration error. Our approach achieves an improvement in\naccuracy of 1.6% and 4.8% for two- and three-class classification,\nrespectively; similar results are found for models with data augmentation\napplied. In addition to these findings, our work also presents a new\napplication of the OS regularizer in healthcare, increasing the post-hoc\ninterpretability and performance of deep learning models for COVID-19\nclassification to facilitate adoption of these methods in clinical settings. We\nalso identify the limitations of our strategy that can be explored for further\nresearch in future.",
          "link": "http://arxiv.org/abs/2102.08360",
          "publishedOn": "2021-06-07T03:06:13.428Z",
          "wordCount": 769,
          "title": "Interpretable COVID-19 Chest X-Ray Classification via Orthogonality Constraint. (arXiv:2102.08360v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.14862",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1\">Wei Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_F/0/1/0/all/0/1\">Fang Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xingjia Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1\">Zhiliang Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1\">Qi Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1\">Zhenjun Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1\">Bolei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1\">Qixiang Ye</a>",
          "description": "Weakly supervised object localization (WSOL) is a challenging problem when\ngiven image category labels but requires to learn object localization models.\nOptimizing a convolutional neural network (CNN) for classification tends to\nactivate local discriminative regions while ignoring complete object extent,\ncausing the partial activation issue. In this paper, we argue that partial\nactivation is caused by the intrinsic characteristics of CNN, where the\nconvolution operations produce local receptive fields and experience difficulty\nto capture long-range feature dependency among pixels. We introduce the token\nsemantic coupled attention map (TS-CAM) to take full advantage of the\nself-attention mechanism in visual transformer for long-range dependency\nextraction. TS-CAM first splits an image into a sequence of patch tokens for\nspatial embedding, which produce attention maps of long-range visual dependency\nto avoid partial activation. TS-CAM then re-allocates category-related\nsemantics for patch tokens, enabling each of them to be aware of object\ncategories. TS-CAM finally couples the patch tokens with the semantic-agnostic\nattention map to achieve semantic-aware localization. Experiments on the\nILSVRC/CUB-200-2011 datasets show that TS-CAM outperforms its CNN-CAM\ncounterparts by 7.1%/27.1% for WSOL, achieving state-of-the-art performance.",
          "link": "http://arxiv.org/abs/2103.14862",
          "publishedOn": "2021-06-07T03:06:13.409Z",
          "wordCount": 674,
          "title": "TS-CAM: Token Semantic Coupled Attention Map for Weakly Supervised Object Localization. (arXiv:2103.14862v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03827",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yuxiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wenhao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yue He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yingying Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xiao Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shifeng Chen</a>",
          "description": "The detection of traffic anomalies is a critical component of the intelligent\ncity transportation management system. Previous works have proposed a variety\nof notable insights and taken a step forward in this field, however, dealing\nwith the complex traffic environment remains a challenge. Moreover, the lack of\nhigh-quality data and the complexity of the traffic scene, motivate us to study\nthis problem from a hand-crafted perspective. In this paper, we propose a\nstraightforward and efficient framework that includes pre-processing, a dynamic\ntrack module, and post-processing. With video stabilization, background\nmodeling, and vehicle detection, the pro-processing phase aims to generate\ncandidate anomalies. The dynamic tracking module seeks and locates the start\ntime of anomalies by utilizing vehicle motion patterns and spatiotemporal\nstatus. Finally, we use post-processing to fine-tune the temporal boundary of\nanomalies. Not surprisingly, our proposed framework was ranked $1^{st}$ in the\nNVIDIA AI CITY 2021 leaderboard for traffic anomaly detection. The code is\navailable at: https://github.com/Endeavour10020/AICity2021-Anomaly-Detection .",
          "link": "http://arxiv.org/abs/2105.03827",
          "publishedOn": "2021-06-07T03:06:13.374Z",
          "wordCount": 642,
          "title": "Good Practices and A Strong Baseline for Traffic Anomaly Detection. (arXiv:2105.03827v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.00573",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_F/0/1/0/all/0/1\">Fei Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hongxin Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krovi_V/0/1/0/all/0/1\">Venkat Krovi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_F/0/1/0/all/0/1\">Feng Luo</a>",
          "description": "Knowledge distillation (KD) has become an important technique for model\ncompression and knowledge transfer. In this work, we first perform a\ncomprehensive analysis of the knowledge transferred by different KD methods. We\ndemonstrate that traditional KD methods, which minimize the KL divergence of\nsoftmax outputs between networks, are related to the knowledge alignment of an\nindividual sample only. Meanwhile, recent contrastive learning-based KD methods\nmainly transfer relational knowledge between different samples, namely,\nknowledge correlation. While it is important to transfer the full knowledge\nfrom teacher to student, we introduce the Multi-level Knowledge Distillation\n(MLKD) by effectively considering both knowledge alignment and correlation.\nMLKD is task-agnostic and model-agnostic, and can easily transfer knowledge\nfrom supervised or self-supervised pretrained teachers. We show that MLKD can\nimprove the reliability and transferability of learned representations.\nExperiments demonstrate that MLKD outperforms other state-of-the-art methods on\na large number of experimental settings including different (a) pretraining\nstrategies (b) network architectures (c) datasets (d) tasks.",
          "link": "http://arxiv.org/abs/2012.00573",
          "publishedOn": "2021-06-07T03:06:13.351Z",
          "wordCount": 625,
          "title": "Multi-level Knowledge Distillation via Knowledge Alignment and Correlation. (arXiv:2012.00573v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.06466",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Steven Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiuming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhoutong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Richard Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun-Yan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Russell_B/0/1/0/all/0/1\">Bryan Russell</a>",
          "description": "A neural radiance field (NeRF) is a scene model supporting high-quality view\nsynthesis, optimized per scene. In this paper, we explore enabling user editing\nof a category-level NeRF - also known as a conditional radiance field - trained\non a shape category. Specifically, we introduce a method for propagating coarse\n2D user scribbles to the 3D space, to modify the color or shape of a local\nregion. First, we propose a conditional radiance field that incorporates new\nmodular network components, including a shape branch that is shared across\nobject instances. Observing multiple instances of the same category, our model\nlearns underlying part semantics without any supervision, thereby allowing the\npropagation of coarse 2D user scribbles to the entire 3D region (e.g., chair\nseat). Next, we propose a hybrid network update strategy that targets specific\nnetwork components, which balances efficiency and accuracy. During user\ninteraction, we formulate an optimization problem that both satisfies the\nuser's constraints and preserves the original object structure. We demonstrate\nour approach on various editing tasks over three shape datasets and show that\nit outperforms prior neural editing approaches. Finally, we edit the appearance\nand shape of a real photograph and show that the edit propagates to\nextrapolated novel views.",
          "link": "http://arxiv.org/abs/2105.06466",
          "publishedOn": "2021-06-07T03:06:13.345Z",
          "wordCount": 682,
          "title": "Editing Conditional Radiance Fields. (arXiv:2105.06466v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.10538",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yulin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1\">Gao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1\">Shiji Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xuran Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yitong Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Cheng Wu</a>",
          "description": "Data augmentation is widely known as a simple yet surprisingly effective\ntechnique for regularizing deep networks. Conventional data augmentation\nschemes, e.g., flipping, translation or rotation, are low-level,\ndata-independent and class-agnostic operations, leading to limited diversity\nfor augmented samples. To this end, we propose a novel semantic data\naugmentation algorithm to complement traditional approaches. The proposed\nmethod is inspired by the intriguing property that deep networks are effective\nin learning linearized features, i.e., certain directions in the deep feature\nspace correspond to meaningful semantic transformations, e.g., changing the\nbackground or view angle of an object. Based on this observation, translating\ntraining samples along many such directions in the feature space can\neffectively augment the dataset for more diversity. To implement this idea, we\nfirst introduce a sampling based method to obtain semantically meaningful\ndirections efficiently. Then, an upper bound of the expected cross-entropy (CE)\nloss on the augmented training set is derived by assuming the number of\naugmented samples goes to infinity, yielding a highly efficient algorithm. In\nfact, we show that the proposed implicit semantic data augmentation (ISDA)\nalgorithm amounts to minimizing a novel robust CE loss, which adds minimal\nextra computational cost to a normal training procedure. In addition to\nsupervised learning, ISDA can be applied to semi-supervised learning tasks\nunder the consistency regularization framework, where ISDA amounts to\nminimizing the upper bound of the expected KL-divergence between the augmented\nfeatures and the original features. Although being simple, ISDA consistently\nimproves the generalization performance of popular deep models (e.g., ResNets\nand DenseNets) on a variety of datasets, i.e., CIFAR-10, CIFAR-100, SVHN,\nImageNet, and Cityscapes.",
          "link": "http://arxiv.org/abs/2007.10538",
          "publishedOn": "2021-06-07T03:06:13.323Z",
          "wordCount": 781,
          "title": "Regularizing Deep Networks with Semantic Data Augmentation. (arXiv:2007.10538v5 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2003.10130",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1\">Bo Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziyan Zhang</a>",
          "description": "Graph Neural Networks (GNNs) are gaining increasing attention on graph data\nlearning tasks in recent years. However, in many applications, graph may be\ncoming in an incomplete form where attributes of graph nodes are partially\nunknown/missing. Existing GNNs are generally designed on complete graphs which\ncan not deal with attribute-incomplete graph data directly. To address this\nproblem, we develop a novel partial aggregation based GNNs, named Partial Graph\nNeural Networks (PaGNNs), for attribute-incomplete graph representation and\nlearning. Our work is motivated by the observation that the neighborhood\naggregation function in standard GNNs can be equivalently viewed as the\nneighborhood reconstruction formulation. Based on it, we define two novel\npartial aggregation (reconstruction) functions on incomplete graph and derive\nPaGNNs for incomplete graph data learning. Extensive experiments on several\ndatasets demonstrate the effectiveness and efficiency of the proposed PaGNNs.",
          "link": "http://arxiv.org/abs/2003.10130",
          "publishedOn": "2021-06-07T03:06:13.317Z",
          "wordCount": 600,
          "title": "Incomplete Graph Representation and Learning via Partial Graph Neural Networks. (arXiv:2003.10130v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.02164",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rahman_T/0/1/0/all/0/1\">Tanzila Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chou_S/0/1/0/all/0/1\">Shih-Han Chou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sigal_L/0/1/0/all/0/1\">Leonid Sigal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carenini_G/0/1/0/all/0/1\">Giuseppe Carenini</a>",
          "description": "We consider the problem of Visual Question Answering (VQA). Given an image\nand a free-form, open-ended, question, expressed in natural language, the goal\nof VQA system is to provide accurate answer to this question with respect to\nthe image. The task is challenging because it requires simultaneous and\nintricate understanding of both visual and textual information. Attention,\nwhich captures intra- and inter-modal dependencies, has emerged as perhaps the\nmost widely used mechanism for addressing these challenges. In this paper, we\npropose an improved attention-based architecture to solve VQA. We incorporate\nan Attention on Attention (AoA) module within encoder-decoder framework, which\nis able to determine the relation between attention results and queries.\nAttention module generates weighted average for each query. On the other hand,\nAoA module first generates an information vector and an attention gate using\nattention results and current context; and then adds another attention to\ngenerate final attended information by multiplying the two. We also propose\nmultimodal fusion module to combine both visual and textual information. The\ngoal of this fusion module is to dynamically decide how much information should\nbe considered from each modality. Extensive experiments on VQA-v2 benchmark\ndataset show that our method achieves the state-of-the-art performance.",
          "link": "http://arxiv.org/abs/2011.02164",
          "publishedOn": "2021-06-07T03:06:13.310Z",
          "wordCount": 674,
          "title": "An Improved Attention for Visual Question Answering. (arXiv:2011.02164v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.12056",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Shi_C/0/1/0/all/0/1\">Changfa Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xian_M/0/1/0/all/0/1\">Min Xian</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_X/0/1/0/all/0/1\">Xiancheng Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1\">Haotian Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheng_H/0/1/0/all/0/1\">Heng-Da Cheng</a>",
          "description": "Liver segmentation from abdominal CT images is an essential step for liver\ncancer computer-aided diagnosis and surgical planning. However, both the\naccuracy and robustness of existing liver segmentation methods cannot meet the\nrequirements of clinical applications. In particular, for the common clinical\ncases where the liver tissue contains major pathology, current segmentation\nmethods show poor performance. In this paper, we propose a novel low-rank\ntensor decomposition (LRTD) based multi-atlas segmentation (MAS) framework that\nachieves accurate and robust pathological liver segmentation of CT images.\nFirstly, we propose a multi-slice LRTD scheme to recover the underlying\nlow-rank structure embedded in 3D medical images. It performs the LRTD on small\nimage segments consisting of multiple consecutive image slices. Then, we\npresent an LRTD-based atlas construction method to generate tumor-free liver\natlases that mitigates the performance degradation of liver segmentation due to\nthe presence of tumors. Finally, we introduce an LRTD-based MAS algorithm to\nderive patient-specific liver atlases for each test image, and to achieve\naccurate pairwise image registration and label propagation. Extensive\nexperiments on three public databases of pathological liver cases validate the\neffectiveness of the proposed method. Both qualitative and quantitative results\ndemonstrate that, in the presence of major pathology, the proposed method is\nmore accurate and robust than state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2102.12056",
          "publishedOn": "2021-06-07T03:06:13.303Z",
          "wordCount": 695,
          "title": "Multi-Slice Low-Rank Tensor Decomposition Based Multi-Atlas Segmentation: Application to Automatic Pathological Liver CT Segmentation. (arXiv:2102.12056v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.02315",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhengzheng Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chenglong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lang_Y/0/1/0/all/0/1\">Yang Lang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jin Tang</a>",
          "description": "RGB-thermal salient object detection (SOD) aims to segment the common\nprominent regions of visible image and corresponding thermal infrared image\nthat we call it RGBT SOD. Existing methods don't fully explore and exploit the\npotentials of complementarity of different modalities and multi-type cues of\nimage contents, which play a vital role in achieving accurate results. In this\npaper, we propose a multi-interactive dual-decoder to mine and model the\nmulti-type interactions for accurate RGBT SOD. In specific, we first encode two\nmodalities into multi-level multi-modal feature representations. Then, we\ndesign a novel dual-decoder to conduct the interactions of multi-level\nfeatures, two modalities and global contexts. With these interactions, our\nmethod works well in diversely challenging scenarios even in the presence of\ninvalid modality. Finally, we carry out extensive experiments on public RGBT\nand RGBD SOD datasets, and the results show that the proposed method achieves\nthe outstanding performance against state-of-the-art algorithms. The source\ncode has been released\nat:https://github.com/lz118/Multi-interactive-Dual-decoder.",
          "link": "http://arxiv.org/abs/2005.02315",
          "publishedOn": "2021-06-07T03:06:13.294Z",
          "wordCount": 631,
          "title": "Multi-interactive Dual-decoder for RGB-thermal Salient Object Detection. (arXiv:2005.02315v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.01678",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Yamashita_R/0/1/0/all/0/1\">Rikiya Yamashita</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Long_J/0/1/0/all/0/1\">Jin Long</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Banda_S/0/1/0/all/0/1\">Snikitha Banda</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shen_J/0/1/0/all/0/1\">Jeanne Shen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rubin_D/0/1/0/all/0/1\">Daniel L. Rubin</a>",
          "description": "Suboptimal generalization of machine learning models on unseen data is a key\nchallenge which hampers the clinical applicability of such models to medical\nimaging. Although various methods such as domain adaptation and domain\ngeneralization have evolved to combat this challenge, learning robust and\ngeneralizable representations is core to medical image understanding, and\ncontinues to be a problem. Here, we propose STRAP (Style TRansfer Augmentation\nfor histoPathology), a form of data augmentation based on random style transfer\nfrom non-medical style source such as artistic paintings, for learning\ndomain-agnostic visual representations in computational pathology. Style\ntransfer replaces the low-level texture content of an image with the\nuninformative style of randomly selected style source image, while preserving\nthe original high-level semantic content. This improves robustness to domain\nshift and can be used as a simple yet powerful tool for learning\ndomain-agnostic representations. We demonstrate that STRAP leads to\nstate-of-the-art performance, particularly in the presence of domain shifts, on\ntwo particular classification tasks in computational pathology.",
          "link": "http://arxiv.org/abs/2102.01678",
          "publishedOn": "2021-06-07T03:06:13.277Z",
          "wordCount": 633,
          "title": "Learning domain-agnostic visual representation for computational pathology using medically-irrelevant style transfer augmentation. (arXiv:2102.01678v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.11049",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huertas_Tato_J/0/1/0/all/0/1\">Javier Huertas-Tato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_A/0/1/0/all/0/1\">Alejandro Mart&#xed;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fierrez_J/0/1/0/all/0/1\">Juli&#xe1;n Fierrez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camacho_D/0/1/0/all/0/1\">David Camacho</a>",
          "description": "Convolutional Networks have dominated the field of computer vision for the\nlast ten years, exhibiting extremely powerful feature extraction capabilities\nand outstanding classification performance. The main strategy to prolong this\ntrend relies on further upscaling networks in size. However, costs increase\nrapidly while performance improvements may be marginal. We hypothesise that\nadding heterogeneous sources of information may be more cost-effective to a CNN\nthan building a bigger network. In this paper, an ensemble method is proposed\nfor accurate image classification, fusing automatically detected features\nthrough Convolutional Neural Network architectures with a set of manually\ndefined statistical indicators. Through a combination of the predictions of a\nCNN and a secondary classifier trained on statistical features, better\nclassification performance can be cheaply achieved. We test multiple learning\nalgorithms and CNN architectures on a diverse number of datasets to validate\nour proposal, making public all our code and data via GitHub. According to our\nresults, the inclusion of additional indicators and an ensemble classification\napproach helps to increase the performance in 8 of 9 datasets, with a\nremarkable increase of more than 10% precision in two of them.",
          "link": "http://arxiv.org/abs/2012.11049",
          "publishedOn": "2021-06-07T03:06:13.271Z",
          "wordCount": 651,
          "title": "Fusing CNNs and statistical indicators to improve image classification. (arXiv:2012.11049v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1912.11603",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Yamaguchi_S/0/1/0/all/0/1\">Shin&#x27;ya Yamaguchi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kanai_S/0/1/0/all/0/1\">Sekitoshi Kanai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shioda_T/0/1/0/all/0/1\">Tetsuya Shioda</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Takeda_S/0/1/0/all/0/1\">Shoichiro Takeda</a>",
          "description": "The rotation prediction (Rotation) is a simple pretext-task for\nself-supervised learning (SSL), where models learn useful representations for\ntarget vision tasks by solving pretext-tasks. Although Rotation captures\ninformation of object shapes, it hardly captures information of textures. To\ntackle this problem, we introduce a novel pretext-task called image enhanced\nrotation prediction (IE-Rot) for SSL. IE-Rot simultaneously solves Rotation and\nanother pretext-task based on image enhancement (e.g., sharpening and\nsolarizing) while maintaining simplicity. Through the simultaneous prediction\nof rotation and image enhancement, models learn representations to capture the\ninformation of not only object shapes but also textures. Our experimental\nresults show that IE-Rot models outperform Rotation on various standard\nbenchmarks including ImageNet classification, PASCAL-VOC detection, and COCO\ndetection/segmentation.",
          "link": "http://arxiv.org/abs/1912.11603",
          "publishedOn": "2021-06-07T03:06:13.256Z",
          "wordCount": 589,
          "title": "Image Enhanced Rotation Prediction for Self-Supervised Learning. (arXiv:1912.11603v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.04960",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Baoquan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xutao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1\">Yunming Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhichao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lisai Zhang</a>",
          "description": "Few-shot learning is a challenging task, which aims to learn a classifier for\nnovel classes with few examples. Pre-training based meta-learning methods\neffectively tackle the problem by pre-training a feature extractor and then\nfine-tuning it through the nearest centroid based meta-learning. However,\nresults show that the fine-tuning step makes very marginal improvements. In\nthis paper, 1) we figure out the key reason, i.e., in the pre-trained feature\nspace, the base classes already form compact clusters while novel classes\nspread as groups with large variances, which implies that fine-tuning the\nfeature extractor is less meaningful; 2) instead of fine-tuning the feature\nextractor, we focus on estimating more representative prototypes during\nmeta-learning. Consequently, we propose a novel prototype completion based\nmeta-learning framework. This framework first introduces primitive knowledge\n(i.e., class-level part or attribute annotations) and extracts representative\nattribute features as priors. Then, we design a prototype completion network to\nlearn to complete prototypes with these priors. To avoid the prototype\ncompletion error caused by primitive knowledge noises or class differences, we\nfurther develop a Gaussian based prototype fusion strategy that combines the\nmean-based and completed prototypes by exploiting the unlabeled samples.\nExtensive experiments show that our method: (i) can obtain more accurate\nprototypes; (ii) outperforms state-of-the-art techniques by 2% - 9% in terms of\nclassification accuracy. Our code is available online.",
          "link": "http://arxiv.org/abs/2009.04960",
          "publishedOn": "2021-06-07T03:06:13.249Z",
          "wordCount": 710,
          "title": "Prototype Completion with Primitive Knowledge for Few-Shot Learning. (arXiv:2009.04960v5 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02343",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yamaguchi_S/0/1/0/all/0/1\">Shin&#x27;ya Yamaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanai_S/0/1/0/all/0/1\">Sekitoshi Kanai</a>",
          "description": "Generative adversarial networks built from deep convolutional neural networks\n(GANs) lack the ability to exactly replicate the high-frequency components of\nnatural images. To alleviate this issue, we introduce two novel training\ntechniques called frequency dropping (F-Drop) and frequency matching (F-Match).\nThe key idea of F-Drop is to filter out unnecessary high-frequency components\nfrom the input images of the discriminators. This simple modification prevents\nthe discriminators from being confused by perturbations of the high-frequency\ncomponents. In addition, F-Drop makes the GANs focus on fitting in the\nlow-frequency domain, in which there are the dominant components of natural\nimages. F-Match minimizes the difference between real and fake images in the\nfrequency domain for generating more realistic images. F-Match is implemented\nas a regularization term in the objective functions of the generators; it\npenalizes the batch mean error in the frequency domain. F-Match helps the\ngenerators to fit in the high-frequency domain filtered out by F-Drop to the\nreal image. We experimentally demonstrate that the combination of F-Drop and\nF-Match improves the generative performance of GANs in both the frequency and\nspatial domain on multiple image benchmarks (CIFAR, TinyImageNet, STL-10,\nCelebA, and ImageNet).",
          "link": "http://arxiv.org/abs/2106.02343",
          "publishedOn": "2021-06-07T03:06:13.231Z",
          "wordCount": 634,
          "title": "F-Drop&Match: GANs with a Dead Zone in the High-Frequency Domain. (arXiv:2106.02343v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2011.07189",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_A/0/1/0/all/0/1\">Andong Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chenglong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1\">Yuqing Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jin Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_B/0/1/0/all/0/1\">Bin Luo</a>",
          "description": "RGBT tracking has attracted increasing attention since RGB and thermal\ninfrared data have strong complementary advantages, which could make trackers\nall-day and all-weather work. However, how to effectively represent RGBT data\nfor visual tracking remains unstudied well. Existing works usually focus on\nextracting modality-shared or modality-specific information, but the potentials\nof these two cues are not well explored and exploited in RGBT tracking. In this\npaper, we propose a novel multi-adapter network to jointly perform\nmodality-shared, modality-specific and instance-aware target representation\nlearning for RGBT tracking. To this end, we design three kinds of adapters\nwithin an end-to-end deep learning framework. In specific, we use the modified\nVGG-M as the generality adapter to extract the modality-shared target\nrepresentations.To extract the modality-specific features while reducing the\ncomputational complexity, we design a modality adapter, which adds a small\nblock to the generality adapter in each layer and each modality in a parallel\nmanner. Such a design could learn multilevel modality-specific representations\nwith a modest number of parameters as the vast majority of parameters are\nshared with the generality adapter. We also design instance adapter to capture\nthe appearance properties and temporal variations of a certain target.\nMoreover, to enhance the shared and specific features, we employ the loss of\nmultiple kernel maximum mean discrepancy to measure the distribution divergence\nof different modal features and integrate it into each layer for more robust\nrepresentation learning. Extensive experiments on two RGBT tracking benchmark\ndatasets demonstrate the outstanding performance of the proposed tracker\nagainst the state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2011.07189",
          "publishedOn": "2021-06-07T03:06:13.225Z",
          "wordCount": 729,
          "title": "RGBT Tracking via Multi-Adapter Network with Hierarchical Divergence Loss. (arXiv:2011.07189v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.08961",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Wei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paxton_C/0/1/0/all/0/1\">Chris Paxton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mousavian_A/0/1/0/all/0/1\">Arsalan Mousavian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chao_Y/0/1/0/all/0/1\">Yu-Wei Chao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cakmak_M/0/1/0/all/0/1\">Maya Cakmak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fox_D/0/1/0/all/0/1\">Dieter Fox</a>",
          "description": "Human-robot object handovers have been an actively studied area of robotics\nover the past decade; however, very few techniques and systems have addressed\nthe challenge of handing over diverse objects with arbitrary appearance, size,\nshape, and rigidity. In this paper, we present a vision-based system that\nenables reactive human-to-robot handovers of unknown objects. Our approach\ncombines closed-loop motion planning with real-time, temporally-consistent\ngrasp generation to ensure reactivity and motion smoothness. Our system is\nrobust to different object positions and orientations, and can grasp both rigid\nand non-rigid objects. We demonstrate the generalizability, usability, and\nrobustness of our approach on a novel benchmark set of 26 diverse household\nobjects, a user study with naive users (N=6) handing over a subset of 15\nobjects, and a systematic evaluation examining different ways of handing\nobjects. More results and videos can be found at\nhttps://sites.google.com/nvidia.com/handovers-of-arbitrary-objects.",
          "link": "http://arxiv.org/abs/2011.08961",
          "publishedOn": "2021-06-07T03:06:13.218Z",
          "wordCount": 615,
          "title": "Reactive Human-to-Robot Handovers of Arbitrary Objects. (arXiv:2011.08961v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02634",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sitzmann_V/0/1/0/all/0/1\">Vincent Sitzmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rezchikov_S/0/1/0/all/0/1\">Semon Rezchikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freeman_W/0/1/0/all/0/1\">William T. Freeman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua B. Tenenbaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durand_F/0/1/0/all/0/1\">Fredo Durand</a>",
          "description": "Inferring representations of 3D scenes from 2D observations is a fundamental\nproblem of computer graphics, computer vision, and artificial intelligence.\nEmerging 3D-structured neural scene representations are a promising approach to\n3D scene understanding. In this work, we propose a novel neural scene\nrepresentation, Light Field Networks or LFNs, which represent both geometry and\nappearance of the underlying 3D scene in a 360-degree, four-dimensional light\nfield parameterized via a neural implicit representation. Rendering a ray from\nan LFN requires only a *single* network evaluation, as opposed to hundreds of\nevaluations per ray for ray-marching or volumetric based renderers in\n3D-structured neural scene representations. In the setting of simple scenes, we\nleverage meta-learning to learn a prior over LFNs that enables multi-view\nconsistent light field reconstruction from as little as a single image\nobservation. This results in dramatic reductions in time and memory complexity,\nand enables real-time rendering. The cost of storing a 360-degree light field\nvia an LFN is two orders of magnitude lower than conventional methods such as\nthe Lumigraph. Utilizing the analytical differentiability of neural implicit\nrepresentations and a novel parameterization of light space, we further\ndemonstrate the extraction of sparse depth maps from LFNs.",
          "link": "http://arxiv.org/abs/2106.02634",
          "publishedOn": "2021-06-07T03:06:13.212Z",
          "wordCount": 657,
          "title": "Light Field Networks: Neural Scene Representations with Single-Evaluation Rendering. (arXiv:2106.02634v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2008.05742",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiapeng Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xiaoguang Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1\">Mingkui Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_X/0/1/0/all/0/1\">Xin Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_K/0/1/0/all/0/1\">Kui Jia</a>",
          "description": "This paper focuses on the challenging task of learning 3D object surface\nreconstructions from RGB images. Existingmethods achieve varying degrees of\nsuccess by using different surface representations. However, they all have\ntheir own drawbacks,and cannot properly reconstruct the surface shapes of\ncomplex topologies, arguably due to a lack of constraints on the\ntopologicalstructures in their learning frameworks. To this end, we propose to\nlearn and use the topology-preserved, skeletal shape representationto assist\nthe downstream task of object surface reconstruction from RGB images.\nTechnically, we propose the novelSkeletonNetdesign that learns a volumetric\nrepresentation of a skeleton via a bridged learning of a skeletal point set,\nwhere we use paralleldecoders each responsible for the learning of points on 1D\nskeletal curves and 2D skeletal sheets, as well as an efficient module\nofglobally guided subvolume synthesis for a refined, high-resolution skeletal\nvolume; we present a differentiablePoint2Voxellayer tomake SkeletonNet\nend-to-end and trainable. With the learned skeletal volumes, we propose two\nmodels, the Skeleton-Based GraphConvolutional Neural Network (SkeGCNN) and the\nSkeleton-Regularized Deep Implicit Surface Network (SkeDISN), which\nrespectivelybuild upon and improve over the existing frameworks of explicit\nmesh deformation and implicit field learning for the downstream\nsurfacereconstruction task. We conduct thorough experiments that verify the\nefficacy of our proposed SkeletonNet. SkeGCNN and SkeDISNoutperform existing\nmethods as well, and they have their own merits when measured by different\nmetrics. Additional results ingeneralized task settings further demonstrate the\nusefulness of our proposed methods. We have made both our implementation\ncodeand the ShapeNet-Skeleton dataset publicly available at ble at\nhttps://github.com/tangjiapeng/SkeletonNet.",
          "link": "http://arxiv.org/abs/2008.05742",
          "publishedOn": "2021-06-07T03:06:13.206Z",
          "wordCount": 735,
          "title": "SkeletonNet: A Topology-Preserving Solution for Learning Mesh Reconstruction of Object Surfaces from RGB Images. (arXiv:2008.05742v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.07042",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1\">Xiangde Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_W/0/1/0/all/0/1\">Wenjun Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jieneng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_T/0/1/0/all/0/1\">Tao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yinan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shichuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nianyong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guotai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shaoting Zhang</a>",
          "description": "Gross Target Volume (GTV) segmentation plays an irreplaceable role in\nradiotherapy planning for Nasopharyngeal Carcinoma (NPC). Despite that\nConvolutional Neural Networks (CNN) have achieved good performance for this\ntask, they rely on a large set of labeled images for training, which is\nexpensive and time-consuming to acquire. In this paper, we propose a novel\nframework with Uncertainty Rectified Pyramid Consistency (URPC) regularization\nfor semi-supervised NPC GTV segmentation. Concretely, we extend a backbone\nsegmentation network to produce pyramid predictions at different scales. The\npyramid predictions network (PPNet) is supervised by the ground truth of\nlabeled images and a multi-scale consistency loss for unlabeled images,\nmotivated by the fact that prediction at different scales for the same input\nshould be similar and consistent. However, due to the different resolution of\nthese predictions, encouraging them to be consistent at each pixel directly has\nlow robustness and may lose some fine details. To address this problem, we\nfurther design a novel uncertainty rectifying module to enable the framework to\ngradually learn from meaningful and reliable consensual regions at different\nscales. Experimental results on a dataset with 258 NPC MR images showed that\nwith only 10% or 20% images labeled, our method largely improved the\nsegmentation performance by leveraging the unlabeled images, and it also\noutperformed five state-of-the-art semi-supervised segmentation methods.\nMoreover, when only 50% images labeled, URPC achieved an average Dice score of\n82.74% that was close to fully supervised learning.",
          "link": "http://arxiv.org/abs/2012.07042",
          "publishedOn": "2021-06-07T03:06:13.197Z",
          "wordCount": 745,
          "title": "Efficient Semi-Supervised Gross Target Volume of Nasopharyngeal Carcinoma Segmentation via Uncertainty Rectified Pyramid Consistency. (arXiv:2012.07042v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.06175",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Junguang Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1\">Yifei Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Ximei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yufeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianmin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_M/0/1/0/all/0/1\">Mingsheng Long</a>",
          "description": "Domain adaptation (DA) aims at transferring knowledge from a labeled source\ndomain to an unlabeled target domain. Though many DA theories and algorithms\nhave been proposed, most of them are tailored into classification settings and\nmay fail in regression tasks, especially in the practical keypoint detection\ntask. To tackle this difficult but significant task, we present a method of\nregressive domain adaptation (RegDA) for unsupervised keypoint detection.\nInspired by the latest theoretical work, we first utilize an adversarial\nregressor to maximize the disparity on the target domain and train a feature\ngenerator to minimize this disparity. However, due to the high dimension of the\noutput space, this regressor fails to detect samples that deviate from the\nsupport of the source. To overcome this problem, we propose two important\nideas. First, based on our observation that the probability density of the\noutput space is sparse, we introduce a spatial probability distribution to\ndescribe this sparsity and then use it to guide the learning of the adversarial\nregressor. Second, to alleviate the optimization difficulty in the\nhigh-dimensional space, we innovatively convert the minimax game in the\nadversarial training to the minimization of two opposite goals. Extensive\nexperiments show that our method brings large improvement by 8% to 11% in terms\nof PCK on different datasets.",
          "link": "http://arxiv.org/abs/2103.06175",
          "publishedOn": "2021-06-07T03:06:13.180Z",
          "wordCount": 680,
          "title": "Regressive Domain Adaptation for Unsupervised Keypoint Detection. (arXiv:2103.06175v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.07498",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wenbin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1\">Jiabao Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1\">Yuxin Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jianguo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_K/0/1/0/all/0/1\">Kui Jia</a>",
          "description": "Shape modeling and reconstruction from raw point clouds of objects stand as a\nfundamental challenge in vision and graphics research. Classical methods\nconsider analytic shape priors; however, their performance degraded when the\nscanned points deviate from the ideal conditions of cleanness and completeness.\nImportant progress has been recently made by data-driven approaches, which\nlearn global and/or local models of implicit surface representations from\nauxiliary sets of training shapes. Motivated from a universal phenomenon that\nself-similar shape patterns of local surface patches repeat across the entire\nsurface of an object, we aim to push forward the data-driven strategies and\npropose to learn a local implicit surface network for a shared, adaptive\nmodeling of the entire surface for a direct surface reconstruction from raw\npoint cloud; we also enhance the leveraging of surface self-similarities by\nimproving correlations among the optimized latent codes of individual surface\npatches. Given that orientations of raw points could be unavailable or noisy,\nwe extend sign agnostic learning into our local implicit model, which enables\nour recovery of signed implicit fields of local surfaces from the unsigned\ninputs. We term our framework as Sign-Agnostic Implicit Learning of Surface\nSelf-Similarities (SAIL-S3). With a global post-optimization of local sign\nflipping, SAIL-S3 is able to directly model raw, un-oriented point clouds and\nreconstruct high-quality object surfaces. Experiments show its superiority over\nexisting methods.",
          "link": "http://arxiv.org/abs/2012.07498",
          "publishedOn": "2021-06-07T03:06:13.173Z",
          "wordCount": 696,
          "title": "Sign-Agnostic Implicit Learning of Surface Self-Similarities for Shape Modeling and Reconstruction from Raw Point Clouds. (arXiv:2012.07498v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1908.04680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_B/0/1/0/all/0/1\">Bohan Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1\">Mingkui Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lingqiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reid_I/0/1/0/all/0/1\">Ian Reid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Chunhua Shen</a>",
          "description": "This paper tackles the problem of training a deep convolutional neural\nnetwork of both low-bitwidth weights and activations. Optimizing a\nlow-precision network is very challenging due to the non-differentiability of\nthe quantizer, which may result in substantial accuracy loss. To address this,\nwe propose three practical approaches, including (i) progressive quantization;\n(ii) stochastic precision; and (iii) joint knowledge distillation to improve\nthe network training. First, for progressive quantization, we propose two\nschemes to progressively find good local minima. Specifically, we propose to\nfirst optimize a net with quantized weights and subsequently quantize\nactivations. This is in contrast to the traditional methods which optimize them\nsimultaneously. Furthermore, we propose a second progressive quantization\nscheme which gradually decreases the bit-width from high-precision to\nlow-precision during training. Second, to alleviate the excessive training\nburden due to the multi-round training stages, we further propose a one-stage\nstochastic precision strategy to randomly sample and quantize sub-networks\nwhile keeping other parts in full-precision. Finally, we adopt a novel learning\nscheme to jointly train a full-precision model alongside the low-precision one.\nBy doing so, the full-precision model provides hints to guide the low-precision\nmodel training and significantly improves the performance of the low-precision\nnetwork. Extensive experiments on various datasets (e.g., CIFAR-100, ImageNet)\nshow the effectiveness of the proposed methods.",
          "link": "http://arxiv.org/abs/1908.04680",
          "publishedOn": "2021-06-07T03:06:13.167Z",
          "wordCount": 709,
          "title": "Effective Training of Convolutional Neural Networks with Low-bitwidth Weights and Activations. (arXiv:1908.04680v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.08057",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fayolle_P/0/1/0/all/0/1\">Pierre-Alain Fayolle</a>",
          "description": "We describe in this short note a technique to convert an implicit surface\ninto a Signed Distance Function (SDF) while exactly preserving the zero\nlevel-set of the implicit. The proposed approach relies on embedding the input\nimplicit in the final layer of a neural network, which is trained to minimize a\nloss function characterizing the SDF.",
          "link": "http://arxiv.org/abs/2104.08057",
          "publishedOn": "2021-06-07T03:06:13.160Z",
          "wordCount": 512,
          "title": "Signed Distance Function Computation from an Implicit Surface. (arXiv:2104.08057v2 [cs.GR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.11958",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hung_A/0/1/0/all/0/1\">Alex Ling Yu Hung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_E/0/1/0/all/0/1\">Edward Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Galeotti_J/0/1/0/all/0/1\">John Galeotti</a>",
          "description": "Ultrasound image quality has continually been improving. However, when\nneedles or other metallic objects are operating inside the tissue, the\nresulting reverberation artifacts can severely corrupt the surrounding image\nquality. Such effects are challenging for existing computer vision algorithms\nfor medical image analysis. Needle reverberation artifacts can be hard to\nidentify at times and affect various pixel values to different degrees. The\nboundaries of such artifacts are ambiguous, leading to disagreement among human\nexperts labeling the artifacts. We propose a weakly- and semi-supervised,\nprobabilistic needle-and-reverberation-artifact segmentation algorithm to\nseparate the desired tissue-based pixel values from the superimposed artifacts.\nOur method models the intensity decay of artifact intensities and is designed\nto minimize the human labeling error. We demonstrate the applicability of the\napproach and compare it against other segmentation algorithms. Our method is\ncapable of differentiating between the reverberations from artifact-free\npatches as well as of modeling the intensity fall-off in the artifacts. Our\nmethod matches state-of-the-art artifact segmentation performance and sets a\nnew standard in estimating the per-pixel contributions of artifact vs\nunderlying anatomy, especially in the immediately adjacent regions between\nreverberation lines. Our algorithm is also able to improve the performance\ndownstream image analysis algorithms.",
          "link": "http://arxiv.org/abs/2011.11958",
          "publishedOn": "2021-06-07T03:06:13.154Z",
          "wordCount": 679,
          "title": "Weakly- and Semi-Supervised Probabilistic Segmentation and Quantification of Ultrasound Needle-Reverberation Artifacts to Allow Better AI Understanding of Tissue Beneath Needles. (arXiv:2011.11958v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.10471",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shaoul_Y/0/1/0/all/0/1\">Yorai Shaoul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Katherine Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ok_K/0/1/0/all/0/1\">Kyel Ok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_N/0/1/0/all/0/1\">Nicholas Roy</a>",
          "description": "Object-level data association is central to robotic applications such as\ntracking-by-detection and object-level simultaneous localization and mapping.\nWhile current learned visual data association methods outperform hand-crafted\nalgorithms, many rely on large collections of domain-specific training examples\nthat can be difficult to obtain without prior knowledge. Additionally, such\nmethods often remain fixed during inference-time and do not harness observed\ninformation to better their performance. We propose a self-supervised method\nfor incrementally refining visual descriptors to improve performance in the\ntask of object-level visual data association. Our method optimizes deep\ndescriptor generators online, by continuously training a widely available image\nclassification network pre-trained with domain-independent data. We show that\nearlier layers in the network outperform later-stage layers for the data\nassociation task while also allowing for a 94% reduction in the number of\nparameters, enabling the online optimization. We show that self-labelling\nchallenging triplets--choosing positive examples separated by large temporal\ndistances and negative examples close in the descriptor space--improves the\nquality of the learned descriptors for the multi-object tracking task. Finally,\nwe demonstrate that our approach surpasses other visual data-association\nmethods applied to a tracking-by-detection task, and show that it provides\nbetter performance-gains when compared to other methods that attempt to adapt\nto observed information.",
          "link": "http://arxiv.org/abs/2011.10471",
          "publishedOn": "2021-06-07T03:06:13.136Z",
          "wordCount": 708,
          "title": "Online Descriptor Enhancement via Self-Labelling Triplets for Visual Data Association. (arXiv:2011.10471v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.09818",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Asif_U/0/1/0/all/0/1\">Umar Asif</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehta_D/0/1/0/all/0/1\">Deval Mehta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cavallar_S/0/1/0/all/0/1\">Stefan von Cavallar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jianbin Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harrer_S/0/1/0/all/0/1\">Stefan Harrer</a>",
          "description": "Existing action recognition methods mainly focus on joint and bone\ninformation in human body skeleton data due to its robustness to complex\nbackgrounds and dynamic characteristics of the environments. In this paper, we\ncombine body skeleton data with spatial and motion features from face and two\nhands, and present \"Deep Action Stamps (DeepActs)\", a novel data representation\nto encode actions from video sequences. We also present \"DeepActsNet\", a deep\nlearning based ensemble model which learns convolutional and structural\nfeatures from Deep Action Stamps for highly accurate action recognition.\nExperiments on three challenging action recognition datasets (NTU60, NTU120,\nand SYSU) show that the proposed model trained using Deep Action Stamps produce\nconsiderable improvements in the action recognition accuracy with less\ncomputational cost compared to the state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2009.09818",
          "publishedOn": "2021-06-07T03:06:13.130Z",
          "wordCount": 620,
          "title": "DeepActsNet: Spatial and Motion features from Face, Hands, and Body Combined with Convolutional and Graph Networks for Improved Action Recognition. (arXiv:2009.09818v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.03340",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Marchetti_F/0/1/0/all/0/1\">Francesco Marchetti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Becattini_F/0/1/0/all/0/1\">Federico Becattini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seidenari_L/0/1/0/all/0/1\">Lorenzo Seidenari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bimbo_A/0/1/0/all/0/1\">Alberto Del Bimbo</a>",
          "description": "Autonomous vehicles are expected to drive in complex scenarios with several\nindependent non cooperating agents. Path planning for safely navigating in such\nenvironments can not just rely on perceiving present location and motion of\nother agents. It requires instead to predict such variables in a far enough\nfuture. In this paper we address the problem of multimodal trajectory\nprediction exploiting a Memory Augmented Neural Network. Our method learns past\nand future trajectory embeddings using recurrent neural networks and exploits\nan associative external memory to store and retrieve such embeddings.\nTrajectory prediction is then performed by decoding in-memory future encodings\nconditioned with the observed past. We incorporate scene knowledge in the\ndecoding state by learning a CNN on top of semantic scene maps. Memory growth\nis limited by learning a writing controller based on the predictive capability\nof existing embeddings. We show that our method is able to natively perform\nmulti-modal trajectory prediction obtaining state-of-the art results on three\ndatasets. Moreover, thanks to the non-parametric nature of the memory module,\nwe show how once trained our system can continuously improve by ingesting novel\npatterns.",
          "link": "http://arxiv.org/abs/2006.03340",
          "publishedOn": "2021-06-07T03:06:13.124Z",
          "wordCount": 647,
          "title": "MANTRA: Memory Augmented Networks for Multiple Trajectory Prediction. (arXiv:2006.03340v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02594",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akada_H/0/1/0/all/0/1\">Hiroyasu Akada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhat_S/0/1/0/all/0/1\">Shariq Farooq Bhat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alhashim_I/0/1/0/all/0/1\">Ibraheem Alhashim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wonka_P/0/1/0/all/0/1\">Peter Wonka</a>",
          "description": "We tackle the problem of unsupervised synthetic-to-realistic domain\nadaptation for single image depth estimation. An essential building block of\nsingle image depth estimation is an encoder-decoder task network that takes RGB\nimages as input and produces depth maps as output. In this paper, we propose a\nnovel training strategy to force the task network to learn domain invariant\nrepresentations in a self-supervised manner. Specifically, we extend\nself-supervised learning from traditional representation learning, which works\non images from a single domain, to domain invariant representation learning,\nwhich works on images from two different domains by utilizing an image-to-image\ntranslation network. Firstly, we use our bidirectional image-to-image\ntranslation network to transfer domain-specific styles between synthetic and\nreal domains. This style transfer operation allows us to obtain similar images\nfrom the different domains. Secondly, we jointly train our task network and\nSiamese network with the same images from the different domains to obtain\ndomain invariance for the task network. Finally, we fine-tune the task network\nusing labeled synthetic and unlabeled real-world data. Our training strategy\nyields improved generalization capability in the real-world domain. We carry\nout an extensive evaluation on two popular datasets for depth estimation, KITTI\nand Make3D. The results demonstrate that our proposed method outperforms the\nstate-of-the-art both qualitatively and quantitatively. The source code and\nmodel weights will be made available.",
          "link": "http://arxiv.org/abs/2106.02594",
          "publishedOn": "2021-06-07T03:06:13.117Z",
          "wordCount": 656,
          "title": "Self-Supervised Learning of Domain Invariant Features for Depth Estimation. (arXiv:2106.02594v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02566",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gomez_T/0/1/0/all/0/1\">Tristan Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_S/0/1/0/all/0/1\">Suiyi Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freour_T/0/1/0/all/0/1\">Thomas Fr&#xe9;our</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mouchere_H/0/1/0/all/0/1\">Harold Mouch&#xe8;re</a>",
          "description": "The prevalence of employing attention mechanisms has brought along concerns\non the interpretability of attention distributions. Although it provides\ninsights about how a model is operating, utilizing attention as the explanation\nof model predictions is still highly dubious. The community is still seeking\nmore interpretable strategies for better identifying local active regions that\ncontribute the most to the final decision. To improve the interpretability of\nexisting attention models, we propose a novel Bilinear Representative\nNon-Parametric Attention (BR-NPA) strategy that captures the task-relevant\nhuman-interpretable information. The target model is first distilled to have\nhigher-resolution intermediate feature maps. From which, representative\nfeatures are then grouped based on local pairwise feature similarity, to\nproduce finer-grained, more precise attention maps highlighting task-relevant\nparts of the input. The obtained attention maps are ranked according to the\n`active level' of the compound feature, which provides information regarding\nthe important level of the highlighted regions. The proposed model can be\neasily adapted in a wide variety of modern deep models, where classification is\ninvolved. It is also more accurate, faster, and with a smaller memory footprint\nthan usual neural attention modules. Extensive experiments showcase more\ncomprehensive visual explanations compared to the state-of-the-art\nvisualization model across multiple tasks including few-shot classification,\nperson re-identification, fine-grained image classification. The proposed\nvisualization model sheds imperative light on how neural networks `pay their\nattention' differently in different tasks.",
          "link": "http://arxiv.org/abs/2106.02566",
          "publishedOn": "2021-06-07T03:06:13.109Z",
          "wordCount": 669,
          "title": "Improve the Interpretability of Attention: A Fast, Accurate, and Interpretable High-Resolution Attention Model. (arXiv:2106.02566v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02106",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Yousefi_B/0/1/0/all/0/1\">Bardia Yousefi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sharifipour_H/0/1/0/all/0/1\">Hossein Memarzadeh Sharifipour</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Maldague_X/0/1/0/all/0/1\">Xavier P.V. Maldague</a>",
          "description": "Thermography has been used extensively as a complementary diagnostic tool in\nbreast cancer detection. Among thermographic methods matrix factorization (MF)\ntechniques show an unequivocal capability to detect thermal patterns\ncorresponding to vasodilation in cancer cases. One of the biggest challenges in\nsuch techniques is selecting the best representation of the thermal basis. In\nthis study, an embedding method is proposed to address this problem and\nDeep-semi-nonnegative matrix factorization (Deep-SemiNMF) for thermography is\nintroduced, then tested for 208 breast cancer screening cases. First, we apply\nDeep-SemiNMF to infrared images to extract low-rank thermal representations for\neach case. Then, we embed low-rank bases to obtain one basis for each patient.\nAfter that, we extract 300 thermal imaging features, called thermomics, to\ndecode imaging information for the automatic diagnostic model. We reduced the\ndimensionality of thermomics by spanning them onto Hilbert space using RBF\nkernel and select the three most efficient features using the block Hilbert\nSchmidt Independence Criterion Lasso (block HSIC Lasso). The preserved thermal\nheterogeneity successfully classified asymptomatic versus symptomatic patients\napplying a random forest model (cross-validated accuracy of 71.36%\n(69.42%-73.3%)).",
          "link": "http://arxiv.org/abs/2106.02106",
          "publishedOn": "2021-06-07T03:06:13.084Z",
          "wordCount": 647,
          "title": "Embedded Deep Regularized Block HSIC Thermomics for Early Diagnosis of Breast Cancer. (arXiv:2106.02106v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2101.02486",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Capobianco_S/0/1/0/all/0/1\">Samuele Capobianco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Millefiori_L/0/1/0/all/0/1\">Leonardo M. Millefiori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forti_N/0/1/0/all/0/1\">Nicola Forti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Braca_P/0/1/0/all/0/1\">Paolo Braca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Willett_P/0/1/0/all/0/1\">Peter Willett</a>",
          "description": "Data-driven methods open up unprecedented possibilities for maritime\nsurveillance using Automatic Identification System (AIS) data. In this work, we\nexplore deep learning strategies using historical AIS observations to address\nthe problem of predicting future vessel trajectories with a prediction horizon\nof several hours. We propose novel sequence-to-sequence vessel trajectory\nprediction models based on encoder-decoder recurrent neural networks (RNNs)\nthat are trained on historical trajectory data to predict future trajectory\nsamples given previous observations. The proposed architecture combines Long\nShort-Term Memory (LSTM) RNNs for sequence modeling to encode the observed data\nand generate future predictions with different intermediate aggregation layers\nto capture space-time dependencies in sequential data. Experimental results on\nvessel trajectories from an AIS dataset made freely available by the Danish\nMaritime Authority show the effectiveness of deep-learning methods for\ntrajectory prediction based on sequence-to-sequence neural networks, which\nachieve better performance than baseline approaches based on linear regression\nor on the Multi-Layer Perceptron (MLP) architecture. The comparative evaluation\nof results shows: i) the superiority of attention pooling over static pooling\nfor the specific application, and ii) the remarkable performance improvement\nthat can be obtained with labeled trajectories, i.e., when predictions are\nconditioned on a low-level context representation encoded from the sequence of\npast observations, as well as on additional inputs (e.g., port of departure or\narrival) about the vessel's high-level intention, which may be available from\nAIS.",
          "link": "http://arxiv.org/abs/2101.02486",
          "publishedOn": "2021-06-07T03:06:13.075Z",
          "wordCount": 714,
          "title": "Deep Learning Methods for Vessel Trajectory Prediction based on Recurrent Neural Networks. (arXiv:2101.02486v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02377",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Triess_L/0/1/0/all/0/1\">Larissa T. Triess</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dreissig_M/0/1/0/all/0/1\">Mariella Dreissig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rist_C/0/1/0/all/0/1\">Christoph B. Rist</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zollner_J/0/1/0/all/0/1\">J. Marius Z&#xf6;llner</a>",
          "description": "Scalable systems for automated driving have to reliably cope with an\nopen-world setting. This means, the perception systems are exposed to drastic\ndomain shifts, like changes in weather conditions, time-dependent aspects, or\ngeographic regions. Covering all domains with annotated data is impossible\nbecause of the endless variations of domains and the time-consuming and\nexpensive annotation process. Furthermore, fast development cycles of the\nsystem additionally introduce hardware changes, such as sensor types and\nvehicle setups, and the required knowledge transfer from simulation. To enable\nscalable automated driving, it is therefore crucial to address these domain\nshifts in a robust and efficient manner. Over the last years, a vast amount of\ndifferent domain adaptation techniques evolved. There already exists a number\nof survey papers for domain adaptation on camera images, however, a survey for\nLiDAR perception is absent. Nevertheless, LiDAR is a vital sensor for automated\ndriving that provides detailed 3D scans of the vehicle's surroundings. To\nstimulate future research, this paper presents a comprehensive review of recent\nprogress in domain adaptation methods and formulates interesting research\nquestions specifically targeted towards LiDAR perception.",
          "link": "http://arxiv.org/abs/2106.02377",
          "publishedOn": "2021-06-07T03:06:13.061Z",
          "wordCount": 642,
          "title": "A Survey on Deep Domain Adaptation for LiDAR Perception. (arXiv:2106.02377v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02118",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sun_J/0/1/0/all/0/1\">Ju Sun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Peng_L/0/1/0/all/0/1\">Le Peng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_T/0/1/0/all/0/1\">Taihui Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Adila_D/0/1/0/all/0/1\">Dyah Adila</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zaiman_Z/0/1/0/all/0/1\">Zach Zaiman</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Melton_G/0/1/0/all/0/1\">Genevieve B. Melton</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ingraham_N/0/1/0/all/0/1\">Nicholas Ingraham</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Murray_E/0/1/0/all/0/1\">Eric Murray</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Boley_D/0/1/0/all/0/1\">Daniel Boley</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Switzer_S/0/1/0/all/0/1\">Sean Switzer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Burns_J/0/1/0/all/0/1\">John L. Burns</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_K/0/1/0/all/0/1\">Kun Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Allen_T/0/1/0/all/0/1\">Tadashi Allen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Steenburg_S/0/1/0/all/0/1\">Scott D. Steenburg</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gichoya_J/0/1/0/all/0/1\">Judy Wawira Gichoya</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kummerfeld_E/0/1/0/all/0/1\">Erich Kummerfeld</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tignanelli_C/0/1/0/all/0/1\">Christopher Tignanelli</a>",
          "description": "Importance: An artificial intelligence (AI)-based model to predict COVID-19\nlikelihood from chest x-ray (CXR) findings can serve as an important adjunct to\naccelerate immediate clinical decision making and improve clinical decision\nmaking. Despite significant efforts, many limitations and biases exist in\npreviously developed AI diagnostic models for COVID-19. Utilizing a large set\nof local and international CXR images, we developed an AI model with high\nperformance on temporal and external validation.\n\nConclusions and Relevance: AI-based diagnostic tools may serve as an adjunct,\nbut not replacement, for clinical decision support of COVID-19 diagnosis, which\nlargely hinges on exposure history, signs, and symptoms. While AI-based tools\nhave not yet reached full diagnostic potential in COVID-19, they may still\noffer valuable information to clinicians taken into consideration along with\nclinical signs and symptoms.",
          "link": "http://arxiv.org/abs/2106.02118",
          "publishedOn": "2021-06-07T03:06:13.030Z",
          "wordCount": 670,
          "title": "A Prospective Observational Study to Investigate Performance of a Chest X-ray Artificial Intelligence Diagnostic Support Tool Across 12 U.S. Hospitals. (arXiv:2106.02118v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02585",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hess_T/0/1/0/all/0/1\">Timm Hess</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mundt_M/0/1/0/all/0/1\">Martin Mundt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pliushch_I/0/1/0/all/0/1\">Iuliia Pliushch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramesh_V/0/1/0/all/0/1\">Visvanathan Ramesh</a>",
          "description": "Several families of continual learning techniques have been proposed to\nalleviate catastrophic interference in deep neural network training on\nnon-stationary data. However, a comprehensive comparison and analysis of\nlimitations remains largely open due to the inaccessibility to suitable\ndatasets. Empirical examination not only varies immensely between individual\nworks, it further currently relies on contrived composition of benchmarks\nthrough subdivision and concatenation of various prevalent static vision\ndatasets. In this work, our goal is to bridge this gap by introducing a\ncomputer graphics simulation framework that repeatedly renders only upcoming\nurban scene fragments in an endless real-time procedural world generation\nprocess. At its core lies a modular parametric generative model with adaptable\ngenerative factors. The latter can be used to flexibly compose data streams,\nwhich significantly facilitates a detailed analysis and allows for effortless\ninvestigation of various continual learning schemes.",
          "link": "http://arxiv.org/abs/2106.02585",
          "publishedOn": "2021-06-07T03:06:13.009Z",
          "wordCount": 576,
          "title": "A Procedural World Generation Framework for Systematic Evaluation of Continual Learning. (arXiv:2106.02585v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02581",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Batra_H/0/1/0/all/0/1\">Himanshu Batra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Punn_N/0/1/0/all/0/1\">Narinder Singh Punn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sonbhadra_S/0/1/0/all/0/1\">Sanjay Kumar Sonbhadra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1\">Sonali Agarwal</a>",
          "description": "Sentiment analysis can provide a suitable lead for the tools used in software\nengineering along with the API recommendation systems and relevant libraries to\nbe used. In this context, the existing tools like SentiCR, SentiStrength-SE,\netc. exhibited low f1-scores that completely defeats the purpose of deployment\nof such strategies, thereby there is enough scope of performance improvement.\nRecent advancements show that transformer based pre-trained models (e.g., BERT,\nRoBERTa, ALBERT, etc.) have displayed better results in the text classification\ntask. Following this context, the present research explores different\nBERT-based models to analyze the sentences in GitHub comments, Jira comments,\nand Stack Overflow posts. The paper presents three different strategies to\nanalyse BERT based model for sentiment analysis, where in the first strategy\nthe BERT based pre-trained models are fine-tuned; in the second strategy an\nensemble model is developed from BERT variants; and in the third strategy a\ncompressed model (Distil BERT) is used. The experimental results show that the\nBERT based ensemble approach and the compressed BERT model attain improvements\nby 6-12% over prevailing tools for the F1 measure on all three datasets.",
          "link": "http://arxiv.org/abs/2106.02581",
          "publishedOn": "2021-06-07T03:06:13.003Z",
          "wordCount": 613,
          "title": "BERT based sentiment analysis: A software engineering perspective. (arXiv:2106.02581v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02636",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zellers_R/0/1/0/all/0/1\">Rowan Zellers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Ximing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hessel_J/0/1/0/all/0/1\">Jack Hessel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Youngjae Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jae Sung Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1\">Jize Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farhadi_A/0/1/0/all/0/1\">Ali Farhadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>",
          "description": "As humans, we understand events in the visual world contextually, performing\nmultimodal reasoning across time to make inferences about the past, present,\nand future. We introduce MERLOT, a model that learns multimodal script\nknowledge by watching millions of YouTube videos with transcribed speech -- in\nan entirely label-free, self-supervised manner. By pretraining with a mix of\nboth frame-level (spatial) and video-level (temporal) objectives, our model not\nonly learns to match images to temporally corresponding words, but also to\ncontextualize what is happening globally over time. As a result, MERLOT\nexhibits strong out-of-the-box representations of temporal commonsense, and\nachieves state-of-the-art performance on 12 different video QA datasets when\nfinetuned. It also transfers well to the world of static images, allowing\nmodels to reason about the dynamic context behind visual scenes. On Visual\nCommonsense Reasoning, MERLOT answers questions correctly with 80.6% accuracy,\noutperforming state-of-the-art models of similar size by over 3%, even those\nthat make heavy use of auxiliary supervised data (like object bounding boxes).\n\nAblation analyses demonstrate the complementary importance of: 1) training on\nvideos versus static images; 2) scaling the magnitude and diversity of the\npretraining video corpus; and 3) using diverse objectives that encourage\nfull-stack multimodal reasoning, from the recognition to cognition level.",
          "link": "http://arxiv.org/abs/2106.02636",
          "publishedOn": "2021-06-07T03:06:12.981Z",
          "wordCount": 655,
          "title": "MERLOT: Multimodal Neural Script Knowledge Models. (arXiv:2106.02636v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02567",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_R/0/1/0/all/0/1\">Ratnajit Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iqbal_H/0/1/0/all/0/1\">Haris Iqbal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marzban_S/0/1/0/all/0/1\">Shabbir Marzban</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Badar_A/0/1/0/all/0/1\">Ahmed Badar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brouns_T/0/1/0/all/0/1\">Terence Brouns</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gowda_S/0/1/0/all/0/1\">Shruthi Gowda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arani_E/0/1/0/all/0/1\">Elahe Arani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zonooz_B/0/1/0/all/0/1\">Bahram Zonooz</a>",
          "description": "Road infrastructure maintenance inspection is typically a labour-intensive\nand critical task to ensure the safety of all the road users. In this work, we\npropose a detailed methodology to use state-of-the-art techniques in artificial\nintelligence and computer vision to automate a sizeable portion of the\nmaintenance inspection subtasks and reduce the labour costs. The proposed\nmethodology uses state-of-the-art computer vision techniques such as object\ndetection and semantic segmentation to automate inspections on primary road\nstructures such as the road surface, markings, barriers (guardrails) and\ntraffic signs. The models are mostly trained on commercially viable datasets\nand augmented with proprietary data. We demonstrate that our AI models can not\nonly automate and scale maintenance inspections on primary road structures but\nalso result in higher recall compared to traditional manual inspections.",
          "link": "http://arxiv.org/abs/2106.02567",
          "publishedOn": "2021-06-07T03:06:12.953Z",
          "wordCount": 575,
          "title": "AI Driven Road Maintenance Inspection. (arXiv:2106.02567v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02598",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kress_V/0/1/0/all/0/1\">Viktor Kress</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeske_F/0/1/0/all/0/1\">Fabian Jeske</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zernetsch_S/0/1/0/all/0/1\">Stefan Zernetsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doll_K/0/1/0/all/0/1\">Konrad Doll</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sick_B/0/1/0/all/0/1\">Bernhard Sick</a>",
          "description": "In this article, an approach for probabilistic trajectory forecasting of\nvulnerable road users (VRUs) is presented, which considers past movements and\nthe surrounding scene. Past movements are represented by 3D poses reflecting\nthe posture and movements of individual body parts. The surrounding scene is\nmodeled in the form of semantic maps showing, e.g., the course of streets,\nsidewalks, and the occurrence of obstacles. The forecasts are generated in\ngrids discretizing the space and in the form of arbitrary discrete probability\ndistributions. The distributions are evaluated in terms of their reliability,\nsharpness, and positional accuracy. We compare our method with an approach that\nprovides forecasts in the form of Gaussian distributions and discuss the\nrespective advantages and disadvantages. Thereby, we investigate the impact of\nusing poses and semantic maps. With a technique called spatial label smoothing,\nour approach achieves reliable forecasts. Overall, the poses have a positive\nimpact on the forecasts. The semantic maps offer the opportunity to adapt the\nprobability distributions to the individual situation, although at the\nconsidered forecasted time horizon of 2.52 s they play a minor role compared to\nthe past movements of the VRU. Our method is evaluated on a dataset recorded in\ninner-city traffic using a research vehicle. The dataset is made publicly\navailable.",
          "link": "http://arxiv.org/abs/2106.02598",
          "publishedOn": "2021-06-07T03:06:12.938Z",
          "wordCount": 648,
          "title": "Pose and Semantic Map Based Probabilistic Forecast of Vulnerable Road Users' Trajectories. (arXiv:2106.02598v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02599",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhang_K/0/1/0/all/0/1\">Kuan Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hu_H/0/1/0/all/0/1\">Haoji Hu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Philbrick_K/0/1/0/all/0/1\">Kenneth Philbrick</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Conte_G/0/1/0/all/0/1\">Gian Marco Conte</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sobek_J/0/1/0/all/0/1\">Joseph D. Sobek</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rouzrokh_P/0/1/0/all/0/1\">Pouria Rouzrokh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Erickson_B/0/1/0/all/0/1\">Bradley J. Erickson</a>",
          "description": "There is a growing demand for high-resolution (HR) medical images in both the\nclinical and research applications. Image quality is inevitably traded off with\nthe acquisition time for better patient comfort, lower examination costs, dose,\nand fewer motion-induced artifacts. For many image-based tasks, increasing the\napparent resolution in the perpendicular plane to produce multi-planar\nreformats or 3D images is commonly used. Single image super-resolution (SR) is\na promising technique to provide HR images based on unsupervised learning to\nincrease resolution of a 2D image, but there are few reports on 3D SR. Further,\nperceptual loss is proposed in the literature to better capture the textual\ndetails and edges than using pixel-wise loss functions, by comparing the\nsemantic distances in the high-dimensional feature space of a pre-trained 2D\nnetwork (e.g., VGG). However, it is not clear how one should generalize it to\n3D medical images, and the attendant implications are still unclear. In this\npaper, we propose a framework called SOUP-GAN: Super-resolution Optimized Using\nPerceptual-tuned Generative Adversarial Network (GAN), in order to produce\nthinner slice (e.g., high resolution in the 'Z' plane) medical images with\nanti-aliasing and deblurring. The proposed method outperforms other\nconventional resolution-enhancement methods and previous SR work on medical\nimages upon both qualitative and quantitative comparisons. Specifically, we\nexamine the model in terms of its generalization for various SR ratios and\nimaging modalities. By addressing those limitations, our model shows promise as\na novel 3D SR interpolation technique, providing potential applications in both\nclinical and research settings.",
          "link": "http://arxiv.org/abs/2106.02599",
          "publishedOn": "2021-06-07T03:06:12.928Z",
          "wordCount": 699,
          "title": "SOUP-GAN: Super-Resolution MRI Using Generative Adversarial Networks. (arXiv:2106.02599v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02495",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bowen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1\">Changhong Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_F/0/1/0/all/0/1\">Fangqiang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Junjie Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1\">Fuling Lin</a>",
          "description": "Prior correlation filter (CF)-based tracking methods for unmanned aerial\nvehicles (UAVs) have virtually focused on tracking in the daytime. However,\nwhen the night falls, the trackers will encounter more harsh scenes, which can\neasily lead to tracking failure. In this regard, this work proposes a novel\ntracker with anti-dark function (ADTrack). The proposed method integrates an\nefficient and effective low-light image enhancer into a CF-based tracker.\nBesides, a target-aware mask is simultaneously generated by virtue of image\nillumination variation. The target-aware mask can be applied to jointly train a\ntarget-focused filter that assists the context filter for robust tracking.\nSpecifically, ADTrack adopts dual regression, where the context filter and the\ntarget-focused filter restrict each other for dual filter learning. Exhaustive\nexperiments are conducted on typical dark sceneries benchmark, consisting of 37\ntypical night sequences from authoritative benchmarks, i.e., UAVDark, and our\nnewly constructed benchmark UAVDark70. The results have shown that ADTrack\nfavorably outperforms other state-of-the-art trackers and achieves a real-time\nspeed of 34 frames/s on a single CPU, greatly extending robust UAV tracking to\nnight scenes.",
          "link": "http://arxiv.org/abs/2106.02495",
          "publishedOn": "2021-06-07T03:06:12.845Z",
          "wordCount": 619,
          "title": "ADTrack: Target-Aware Dual Filter Learning for Real-Time Anti-Dark UAV Tracking. (arXiv:2106.02495v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02531",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Batzolis_G/0/1/0/all/0/1\">Georgios Batzolis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carioni_M/0/1/0/all/0/1\">Marcello Carioni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Etmann_C/0/1/0/all/0/1\">Christian Etmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Afyouni_S/0/1/0/all/0/1\">Soroosh Afyouni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kourtzi_Z/0/1/0/all/0/1\">Zoe Kourtzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schonlieb_C/0/1/0/all/0/1\">Carola Bibiane Sch&#xf6;nlieb</a>",
          "description": "We introduce CAFLOW, a new diverse image-to-image translation model that\nsimultaneously leverages the power of auto-regressive modeling and the modeling\nefficiency of conditional normalizing flows. We transform the conditioning\nimage into a sequence of latent encodings using a multi-scale normalizing flow\nand repeat the process for the conditioned image. We model the conditional\ndistribution of the latent encodings by modeling the auto-regressive\ndistributions with an efficient multi-scale normalizing flow, where each\nconditioning factor affects image synthesis at its respective resolution scale.\nOur proposed framework performs well on a range of image-to-image translation\ntasks. It outperforms former designs of conditional flows because of its\nexpressive auto-regressive structure.",
          "link": "http://arxiv.org/abs/2106.02531",
          "publishedOn": "2021-06-07T03:06:12.818Z",
          "wordCount": 546,
          "title": "CAFLOW: Conditional Autoregressive Flows. (arXiv:2106.02531v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02514",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_C/0/1/0/all/0/1\">Chenjie Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1\">Yuxin Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chengrong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chengming Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_X/0/1/0/all/0/1\">XiangYang Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yanwei Fu</a>",
          "description": "Recently, AutoRegressive (AR) models for the whole image generation empowered\nby transformers have achieved comparable or even better performance to\nGenerative Adversarial Networks (GANs). Unfortunately, directly applying such\nAR models to edit/change local image regions, may suffer from the problems of\nmissing global information, slow inference speed, and information leakage of\nlocal guidance. To address these limitations, we propose a novel model -- image\nLocal Autoregressive Transformer (iLAT), to better facilitate the locally\nguided image synthesis. Our iLAT learns the novel local discrete\nrepresentations, by the newly proposed local autoregressive (LA) transformer of\nthe attention mask and convolution mechanism. Thus iLAT can efficiently\nsynthesize the local image regions by key guidance information. Our iLAT is\nevaluated on various locally guided image syntheses, such as pose-guided person\nimage synthesis and face editing. Both the quantitative and qualitative results\nshow the efficacy of our model.",
          "link": "http://arxiv.org/abs/2106.02514",
          "publishedOn": "2021-06-07T03:06:12.805Z",
          "wordCount": 579,
          "title": "The Image Local Autoregressive Transformer. (arXiv:2106.02514v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02637",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Fangyun Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yue Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhirong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Han Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1\">Stephen Lin</a>",
          "description": "Image-level contrastive representation learning has proven to be highly\neffective as a generic model for transfer learning. Such generality for\ntransfer learning, however, sacrifices specificity if we are interested in a\ncertain downstream task. We argue that this could be sub-optimal and thus\nadvocate a design principle which encourages alignment between the\nself-supervised pretext task and the downstream task. In this paper, we follow\nthis principle with a pretraining method specifically designed for the task of\nobject detection. We attain alignment in the following three aspects: 1)\nobject-level representations are introduced via selective search bounding boxes\nas object proposals; 2) the pretraining network architecture incorporates the\nsame dedicated modules used in the detection pipeline (e.g. FPN); 3) the\npretraining is equipped with object detection properties such as object-level\ntranslation invariance and scale invariance. Our method, called Selective\nObject COntrastive learning (SoCo), achieves state-of-the-art results for\ntransfer performance on COCO detection using a Mask R-CNN framework. Code and\nmodels will be made available.",
          "link": "http://arxiv.org/abs/2106.02637",
          "publishedOn": "2021-06-07T03:06:12.731Z",
          "wordCount": 594,
          "title": "Aligning Pretraining for Detection via Object-Level Contrastive Learning. (arXiv:2106.02637v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02351",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_B/0/1/0/all/0/1\">Bin Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_F/0/1/0/all/0/1\">Fangao Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tiancai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiangyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1\">Yichen Wei</a>",
          "description": "In this paper, we propose an end-to-end framework for instance segmentation.\nBased on the recently introduced DETR [1], our method, termed SOLQ, segments\nobjects by learning unified queries. In SOLQ, each query represents one object\nand has multiple representations: class, location and mask. The object queries\nlearned perform classification, box regression and mask encoding simultaneously\nin an unified vector form. During training phase, the mask vectors encoded are\nsupervised by the compression coding of raw spatial masks. In inference time,\nmask vectors produced can be directly transformed to spatial masks by the\ninverse process of compression coding. Experimental results show that SOLQ can\nachieve state-of-the-art performance, surpassing most of existing approaches.\nMoreover, the joint learning of unified query representation can greatly\nimprove the detection performance of original DETR. We hope our SOLQ can serve\nas a strong baseline for the Transformer-based instance segmentation. Code is\navailable at https://github.com/megvii-research/SOLQ.",
          "link": "http://arxiv.org/abs/2106.02351",
          "publishedOn": "2021-06-07T03:06:12.724Z",
          "wordCount": 587,
          "title": "SOLQ: Segmenting Objects by Learning Queries. (arXiv:2106.02351v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02400",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1\">Manh-Duy Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_B/0/1/0/all/0/1\">Binh T. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurrin_C/0/1/0/all/0/1\">Cathal Gurrin</a>",
          "description": "Conventional approaches to image-text retrieval mainly focus on indexing\nvisual objects appearing in pictures but ignore the interactions between these\nobjects. Such objects occurrences and interactions are equivalently useful and\nimportant in this field as they are usually mentioned in the text. Scene graph\npresentation is a suitable method for the image-text matching challenge and\nobtained good results due to its ability to capture the inter-relationship\ninformation. Both images and text are represented in scene graph levels and\nformulate the retrieval challenge as a scene graph matching challenge. In this\npaper, we introduce the Local and Global Scene Graph Matching (LGSGM) model\nthat enhances the state-of-the-art method by integrating an extra graph\nconvolution network to capture the general information of a graph.\nSpecifically, for a pair of scene graphs of an image and its caption, two\nseparate models are used to learn the features of each graph's nodes and edges.\nThen a Siamese-structure graph convolution model is employed to embed graphs\ninto vector forms. We finally combine the graph-level and the vector-level to\ncalculate the similarity of this image-text pair. The empirical experiments\nshow that our enhancement with the combination of levels can improve the\nperformance of the baseline method by increasing the recall by more than 10% on\nthe Flickr30k dataset.",
          "link": "http://arxiv.org/abs/2106.02400",
          "publishedOn": "2021-06-07T03:06:12.717Z",
          "wordCount": 652,
          "title": "A Deep Local and Global Scene-Graph Matching for Image-Text Retrieval. (arXiv:2106.02400v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02324",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fusen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sang_J/0/1/0/all/0/1\">Jun Sang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhongyuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sang_N/0/1/0/all/0/1\">Nong Sang</a>",
          "description": "The existing crowd counting methods usually adopted attention mechanism to\ntackle background noise, or applied multi-level features or multi-scales\ncontext fusion to tackle scale variation. However, these approaches deal with\nthese two problems separately. In this paper, we propose a Hybrid Attention\nNetwork (HAN) by employing Progressive Embedding Scale-context (PES)\ninformation, which enables the network to simultaneously suppress noise and\nadapt head scale variation. We build the hybrid attention mechanism through\nparalleling spatial attention and channel attention module, which makes the\nnetwork to focus more on the human head area and reduce the interference of\nbackground objects. Besides, we embed certain scale-context to the hybrid\nattention along the spatial and channel dimensions for alleviating these\ncounting errors caused by the variation of perspective and head scale. Finally,\nwe propose a progressive learning strategy through cascading multiple hybrid\nattention modules with embedding different scale-context, which can gradually\nintegrate different scale-context information into the current feature map from\nglobal to local. Ablation experiments provides that the network architecture\ncan gradually learn multi-scale features and suppress background noise.\nExtensive experiments demonstrate that HANet obtain state-of-the-art counting\nperformance on four mainstream datasets.",
          "link": "http://arxiv.org/abs/2106.02324",
          "publishedOn": "2021-06-07T03:06:12.699Z",
          "wordCount": 626,
          "title": "Hybrid attention network based on progressive embedding scale-context for crowd counting. (arXiv:2106.02324v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02473",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Weiming Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaoyan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Haoyuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wanli Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">Changhao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grzegorzek_M/0/1/0/all/0/1\">Marcin Grzegorzek</a>",
          "description": "GasHisSDB is a New Gastric Histopathology Subsize Image Database with a total\nof 245196 images. GasHisSDB is divided into 160*160 pixels sub-database,\n120*120 pixels sub-database and 80*80 pixels sub-database. GasHisSDB is made to\nrealize the function of valuating image classification. In order to prove that\nthe methods of different periods in the field of image classification have\ndiscrepancies on GasHisSDB, we select a variety of classifiers for evaluation.\nSeven classical machine learning classifiers, three CNN classifiers and a novel\ntransformer-based classifier are selected for testing on image classification\ntasks. GasHisSDB is available at the\nURL:https://github.com/NEUhwm/GasHisSDB.git.",
          "link": "http://arxiv.org/abs/2106.02473",
          "publishedOn": "2021-06-07T03:06:12.678Z",
          "wordCount": 553,
          "title": "A New Gastric Histopathology Subsize Image Database (GasHisSDB) for Classification Algorithm Test: from Linear Regression to Visual Transformer. (arXiv:2106.02473v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02385",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Min_Z/0/1/0/all/0/1\">Zhe Min</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bianco_F/0/1/0/all/0/1\">Fernando J. Bianco</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_Q/0/1/0/all/0/1\">Qianye Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rodell_R/0/1/0/all/0/1\">Rachael Rodell</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yan_W/0/1/0/all/0/1\">Wen Yan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Barratt_D/0/1/0/all/0/1\">Dean Barratt</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hu_Y/0/1/0/all/0/1\">Yipeng Hu</a>",
          "description": "Prostate cancer (PCa) is one of the leading causes of death for men\nworldwide. Multi-parametric magnetic resonance (mpMR) imaging has emerged as a\nnon-invasive diagnostic tool for detecting and localising prostate tumours by\nspecialised radiologists. These radiological examinations, for example, for\ndifferentiating malignant lesions from benign prostatic hyperplasia in\ntransition zones and for defining the boundaries of clinically significant\ncancer, remain challenging and highly skill-and-experience-dependent. We first\ninvestigate experimental results in developing object detection neural networks\nthat are trained to predict the radiological assessment, using these\nhigh-variance labels. We further argue that such a computer-assisted diagnosis\n(CAD) system needs to have the ability to control the false-positive rate (FPR)\nor false-negative rate (FNR), in order to be usefully deployed in a clinical\nworkflow, informing clinical decisions without further human intervention. This\nwork proposes a novel PCa detection network that incorporates a lesion-level\ncost-sensitive loss and an additional slice-level loss based on a\nlesion-to-slice mapping function, to manage the lesion- and slice-level costs,\nrespectively. Our experiments based on 290 clinical patients concludes that 1)\nThe lesion-level FNR was effectively reduced from 0.19 to 0.10 and the\nlesion-level FPR was reduced from 1.03 to 0.66 by changing the lesion-level\ncost; 2) The slice-level FNR was reduced from 0.19 to 0.00 by taking into\naccount the slice-level cost; (3) Both lesion-level and slice-level FNRs were\nreduced with lower FP/FPR by changing the lesion-level or slice-level costs,\ncompared with post-training threshold adjustment using networks without the\nproposed cost-aware training.",
          "link": "http://arxiv.org/abs/2106.02385",
          "publishedOn": "2021-06-07T03:06:12.649Z",
          "wordCount": 713,
          "title": "Controlling False Positive/Negative Rates for Deep-Learning-Based Prostate Cancer Detection on Multiparametric MR images. (arXiv:2106.02385v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02280",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sheng_S/0/1/0/all/0/1\">Sasha Sheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Amanpreet Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goswami_V/0/1/0/all/0/1\">Vedanuj Goswami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Magana_J/0/1/0/all/0/1\">Jose Alberto Lopez Magana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galuba_W/0/1/0/all/0/1\">Wojciech Galuba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parikh_D/0/1/0/all/0/1\">Devi Parikh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiela_D/0/1/0/all/0/1\">Douwe Kiela</a>",
          "description": "Performance on the most commonly used Visual Question Answering dataset (VQA\nv2) is starting to approach human accuracy. However, in interacting with\nstate-of-the-art VQA models, it is clear that the problem is far from being\nsolved. In order to stress test VQA models, we benchmark them against\nhuman-adversarial examples. Human subjects interact with a state-of-the-art VQA\nmodel, and for each image in the dataset, attempt to find a question where the\nmodel's predicted answer is incorrect. We find that a wide range of\nstate-of-the-art models perform poorly when evaluated on these examples. We\nconduct an extensive analysis of the collected adversarial examples and provide\nguidance on future research directions. We hope that this Adversarial VQA\n(AdVQA) benchmark can help drive progress in the field and advance the state of\nthe art.",
          "link": "http://arxiv.org/abs/2106.02280",
          "publishedOn": "2021-06-07T03:06:12.620Z",
          "wordCount": 575,
          "title": "Human-Adversarial Visual Question Answering. (arXiv:2106.02280v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02299",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_L/0/1/0/all/0/1\">Liying Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenbo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_X/0/1/0/all/0/1\">Xin Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jiangbo Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1\">Jiaya Jia</a>",
          "description": "Reference-based image super-resolution (RefSR) has shown promising success in\nrecovering high-frequency details by utilizing an external reference image\n(Ref). In this task, texture details are transferred from the Ref image to the\nlow-resolution (LR) image according to their point- or patch-wise\ncorrespondence. Therefore, high-quality correspondence matching is critical. It\nis also desired to be computationally efficient. Besides, existing RefSR\nmethods tend to ignore the potential large disparity in distributions between\nthe LR and Ref images, which hurts the effectiveness of the information\nutilization. In this paper, we propose the MASA network for RefSR, where two\nnovel modules are designed to address these problems. The proposed Match &\nExtraction Module significantly reduces the computational cost by a\ncoarse-to-fine correspondence matching scheme. The Spatial Adaptation Module\nlearns the difference of distribution between the LR and Ref images, and remaps\nthe distribution of Ref features to that of LR features in a spatially adaptive\nway. This scheme makes the network robust to handle different reference images.\nExtensive quantitative and qualitative experiments validate the effectiveness\nof our proposed model.",
          "link": "http://arxiv.org/abs/2106.02299",
          "publishedOn": "2021-06-07T03:06:12.614Z",
          "wordCount": 616,
          "title": "MASA-SR: Matching Acceleration and Spatial Adaptation for Reference-Based Image Super-Resolution. (arXiv:2106.02299v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02520",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cho_S/0/1/0/all/0/1\">Seokju Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_S/0/1/0/all/0/1\">Sunghwan Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeon_S/0/1/0/all/0/1\">Sangryul Jeon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Yunsung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sohn_K/0/1/0/all/0/1\">Kwanghoon Sohn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seungryong Kim</a>",
          "description": "We propose a novel cost aggregation network, called Cost Aggregation with\nTransformers (CATs), to find dense correspondences between semantically similar\nimages with additional challenges posed by large intra-class appearance and\ngeometric variations. Compared to previous hand-crafted or CNN-based methods\naddressing the cost aggregation stage, which either lack robustness to severe\ndeformations or inherit the limitation of CNNs that fail to discriminate\nincorrect matches due to limited receptive fields, CATs explore global\nconsensus among initial correlation map with the help of some architectural\ndesigns that allow us to exploit full potential of self-attention mechanism.\nSpecifically, we include appearance affinity modelling to disambiguate the\ninitial correlation maps and multi-level aggregation to benefit from\nhierarchical feature representations within Transformer-based aggregator, and\ncombine with swapping self-attention and residual connections not only to\nenforce consistent matching, but also to ease the learning process. We conduct\nexperiments to demonstrate the effectiveness of the proposed model over the\nlatest methods and provide extensive ablation studies. Code and trained models\nwill be made available at https://github.com/SunghwanHong/CATs.",
          "link": "http://arxiv.org/abs/2106.02520",
          "publishedOn": "2021-06-07T03:06:12.593Z",
          "wordCount": 608,
          "title": "Semantic Correspondence with Transformers. (arXiv:2106.02520v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02523",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kayhan_O/0/1/0/all/0/1\">Osman Semih Kayhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vredebregt_B/0/1/0/all/0/1\">Bart Vredebregt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gemert_J/0/1/0/all/0/1\">Jan C. van Gemert</a>",
          "description": "We show that object detectors can hallucinate and detect missing objects;\npotentially even accurately localized at their expected, but non-existing,\nposition. This is particularly problematic for applications that rely on visual\npart verification: detecting if an object part is present or absent. We show\nhow popular object detectors hallucinate objects in a visual part verification\ntask and introduce the first visual part verification dataset: DelftBikes,\nwhich has 10,000 bike photographs, with 22 densely annotated parts per image,\nwhere some parts may be missing. We explicitly annotated an extra object state\nlabel for each part to reflect if a part is missing or intact. We propose to\nevaluate visual part verification by relying on recall and compare popular\nobject detectors on DelftBikes.",
          "link": "http://arxiv.org/abs/2106.02523",
          "publishedOn": "2021-06-07T03:06:12.586Z",
          "wordCount": 570,
          "title": "Hallucination In Object Detection -- A Study In Visual Part Verification. (arXiv:2106.02523v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02335",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abrahamsen_M/0/1/0/all/0/1\">Mikkel Abrahamsen</a>",
          "description": "In the MINIMUM CONVEX COVER (MCC) problem, we are given a simple polygon\n$\\mathcal P$ and an integer $k$, and the question is if there exist $k$ convex\npolygons whose union is $\\mathcal P$. It is known that MCC is\n$\\mathsf{NP}$-hard [Culberson & Reckhow: Covering polygons is hard, FOCS\n1988/Journal of Algorithms 1994] and in $\\exists\\mathbb{R}$ [O'Rourke: The\ncomplexity of computing minimum convex covers for polygons, Allerton 1982]. We\nprove that MCC is $\\exists\\mathbb{R}$-hard, and the problem is thus\n$\\exists\\mathbb{R}$-complete. In other words, the problem is equivalent to\ndeciding whether a system of polynomial equations and inequalities with integer\ncoefficients has a real solution.\n\nIf a cover for our constructed polygon exists, then so does a cover\nconsisting entirely of triangles. As a byproduct, we therefore also establish\nthat it is $\\exists\\mathbb{R}$-complete to decide whether $k$ triangles cover a\ngiven polygon.\n\nThe issue that it was not known if finding a minimum cover is in\n$\\mathsf{NP}$ has repeatedly been raised in the literature, and it was\nmentioned as a \"long-standing open question\" already in 2001 [Eidenbenz &\nWidmayer: An approximation algorithm for minimum convex cover with logarithmic\nperformance guarantee, ESA 2001/SIAM Journal on Computing 2003]. We prove that\nassuming the widespread belief that $\\mathsf{NP}\\neq\\exists\\mathbb{R}$, the\nproblem is not in $\\mathsf{NP}$.\n\nAn implication of the result is that many natural approaches to finding small\ncovers are bound to give suboptimal solutions in some cases, since irrational\ncoordinates of arbitrarily high algebraic degree can be needed for the corners\nof the pieces in an optimal solution.",
          "link": "http://arxiv.org/abs/2106.02335",
          "publishedOn": "2021-06-07T03:06:12.579Z",
          "wordCount": 684,
          "title": "Covering Polygons is Even Harder. (arXiv:2106.02335v1 [cs.CG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02527",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1\">Tong Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yuxin Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tongqing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yilun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Q/0/1/0/all/0/1\">Qing Su</a>",
          "description": "Accurate localization is of crucial importance for autonomous driving tasks.\nNowadays, we have seen a lot of sensor-rich vehicles (e.g. Robo-taxi) driving\non the street autonomously, which rely on high-accurate sensors (e.g. Lidar and\nRTK GPS) and high-resolution map. However, low-cost production cars cannot\nafford such high expenses on sensors and maps. How to reduce costs? How do\nsensor-rich vehicles benefit low-cost cars? In this paper, we proposed a\nlight-weight localization solution, which relies on low-cost cameras and\ncompact visual semantic maps. The map is easily produced and updated by\nsensor-rich vehicles in a crowd-sourced way. Specifically, the map consists of\nseveral semantic elements, such as lane line, crosswalk, ground sign, and stop\nline on the road surface. We introduce the whole framework of on-vehicle\nmapping, on-cloud maintenance, and user-end localization. The map data is\ncollected and preprocessed on vehicles. Then, the crowd-sourced data is\nuploaded to a cloud server. The mass data from multiple vehicles are merged on\nthe cloud so that the semantic map is updated in time. Finally, the semantic\nmap is compressed and distributed to production cars, which use this map for\nlocalization. We validate the performance of the proposed map in real-world\nexperiments and compare it against other algorithms. The average size of the\nsemantic map is $36$ kb/km. We highlight that this framework is a reliable and\npractical localization solution for autonomous driving.",
          "link": "http://arxiv.org/abs/2106.02527",
          "publishedOn": "2021-06-07T03:06:12.572Z",
          "wordCount": 679,
          "title": "RoadMap: A Light-Weight Semantic Map for Visual Localization towards Autonomous Driving. (arXiv:2106.02527v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02328",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balaji_T/0/1/0/all/0/1\">Thangapavithraa Balaji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blies_P/0/1/0/all/0/1\">Patrick Blies</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gori_G/0/1/0/all/0/1\">Georg G&#xf6;ri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitsch_R/0/1/0/all/0/1\">Raphael Mitsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wasserer_M/0/1/0/all/0/1\">Marcel Wasserer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schon_T/0/1/0/all/0/1\">Torsten Sch&#xf6;n</a>",
          "description": "This work tackles the problem of temporally coherent face anonymization in\nnatural video streams.We propose JaGAN, a two-stage system starting with\ndetecting and masking out faces with black image patches in all individual\nframes of the video. The second stage leverages a privacy-preserving Video\nGenerative Adversarial Network designed to inpaint the missing image patches\nwith artificially generated faces. Our initial experiments reveal that image\nbased generative models are not capable of inpainting patches showing temporal\ncoherent appearance across neighboring video frames. To address this issue we\nintroduce a newly curated video collection, which is made publicly available\nfor the research community along with this paper. We also introduce the\nIdentity Invariance Score IdI as a means to quantify temporal coherency between\nneighboring frames.",
          "link": "http://arxiv.org/abs/2106.02328",
          "publishedOn": "2021-06-07T03:06:12.565Z",
          "wordCount": 574,
          "title": "Temporally coherent video anonymization through GAN inpainting. (arXiv:2106.02328v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02141",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Keaton_M/0/1/0/all/0/1\">Matthew R. Keaton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaveri_R/0/1/0/all/0/1\">Ram J. Zaveri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kovur_M/0/1/0/all/0/1\">Meghana Kovur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henderson_C/0/1/0/all/0/1\">Cole Henderson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adjeroh_D/0/1/0/all/0/1\">Donald A. Adjeroh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doretto_G/0/1/0/all/0/1\">Gianfranco Doretto</a>",
          "description": "Plant species identification in the wild is a difficult problem in part due\nto the high variability of the input data, but also because of complications\ninduced by the long-tail effects of the datasets distribution. Inspired by the\nmost recent fine-grained visual classification approaches which are based on\nattention to mitigate the effects of data variability, we explore the idea of\nusing object detection as a form of attention. We introduce a bottom-up\napproach based on detecting plant organs and fusing the predictions of a\nvariable number of organ-based species classifiers. We also curate a new\ndataset with a long-tail distribution for evaluating plant organ detection and\norgan-based species identification, which is publicly available.",
          "link": "http://arxiv.org/abs/2106.02141",
          "publishedOn": "2021-06-07T03:06:12.546Z",
          "wordCount": 595,
          "title": "Fine-Grained Visual Classification of Plant Species In The Wild: Object Detection as A Reinforced Means of Attention. (arXiv:2106.02141v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02213",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Diaz_A/0/1/0/all/0/1\">Alex D&#xed;az</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steele_D/0/1/0/all/0/1\">Damian Steele</a>",
          "description": "We examine three non-negative matrix factorization techniques; L2-norm,\nL1-norm, and L2,1-norm. Our aim is to establish the performance of these\ndifferent approaches, and their robustness in real-world applications such as\nfeature selection while managing computational complexity, sensitivity to noise\nand more. We thoroughly examine each approach from a theoretical perspective,\nand examine the performance of each using a series of experiments drawing on\nboth the ORL and YaleB datasets. We examine the Relative Reconstruction Errors\n(RRE), Average Accuracy and Normalized Mutual Information (NMI) as criteria\nunder a range of simulated noise scenarios.",
          "link": "http://arxiv.org/abs/2106.02213",
          "publishedOn": "2021-06-07T03:06:12.539Z",
          "wordCount": 524,
          "title": "Analysis of the robustness of NMF algorithms. (arXiv:2106.02213v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02285",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Shi-Min Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zheng-Ning Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1\">Meng-Hao Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1\">Jun-Xiong Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jiahui Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mu_T/0/1/0/all/0/1\">Tai-Jiang Mu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_R/0/1/0/all/0/1\">Ralph R. Martin</a>",
          "description": "Convolutional neural networks (CNNs) have made great breakthroughs in 2D\ncomputer vision. However, the irregular structure of meshes makes it hard to\nexploit the power of CNNs directly. A subdivision surface provides a\nhierarchical multi-resolution structure, and each face in a closed 2-manifold\ntriangle mesh is exactly adjacent to three faces. Motivated by these two\nproperties, this paper introduces a novel and flexible CNN framework, named\nSubdivNet, for 3D triangle meshes with Loop subdivision sequence connectivity.\nMaking an analogy between mesh faces and pixels in a 2D image allows us to\npresent a mesh convolution operator to aggregate local features from adjacent\nfaces. By exploiting face neighborhoods, this convolution can support standard\n2D convolutional network concepts, e.g. variable kernel size, stride, and\ndilation. Based on the multi-resolution hierarchy, we propose a spatial uniform\npooling layer which merges four faces into one and an upsampling method which\nsplits one face into four. As a result, many popular 2D CNN architectures can\nbe readily adapted to processing 3D meshes. Meshes with arbitrary connectivity\ncan be remeshed to hold Loop subdivision sequence connectivity via\nself-parameterization, making SubdivNet a general approach. Experiments on mesh\nclassification, segmentation, correspondence, and retrieval from the real-world\ndemonstrate the effectiveness and efficiency of SubdivNet.",
          "link": "http://arxiv.org/abs/2106.02285",
          "publishedOn": "2021-06-07T03:06:12.531Z",
          "wordCount": 651,
          "title": "Subdivision-Based Mesh Convolution Networks. (arXiv:2106.02285v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02395",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Granese_F/0/1/0/all/0/1\">Federica Granese</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romanelli_M/0/1/0/all/0/1\">Marco Romanelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gorla_D/0/1/0/all/0/1\">Daniele Gorla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palamidessi_C/0/1/0/all/0/1\">Catuscia Palamidessi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piantanida_P/0/1/0/all/0/1\">Pablo Piantanida</a>",
          "description": "Deep neural networks (DNNs) have shown to perform very well on large scale\nobject recognition problems and lead to widespread use for real-world\napplications, including situations where DNN are implemented as \"black boxes\".\nA promising approach to secure their use is to accept decisions that are likely\nto be correct while discarding the others. In this work, we propose DOCTOR, a\nsimple method that aims to identify whether the prediction of a DNN classifier\nshould (or should not) be trusted so that, consequently, it would be possible\nto accept it or to reject it. Two scenarios are investigated: Totally Black Box\n(TBB) where only the soft-predictions are available and Partially Black Box\n(PBB) where gradient-propagation to perform input pre-processing is allowed.\nEmpirically, we show that DOCTOR outperforms all state-of-the-art methods on\nvarious well-known images and sentiment analysis datasets. In particular, we\nobserve a reduction of up to $4\\%$ of the false rejection rate (FRR) in the PBB\nscenario. DOCTOR can be applied to any pre-trained model, it does not require\nprior information about the underlying dataset and is as simple as the simplest\navailable methods in the literature.",
          "link": "http://arxiv.org/abs/2106.02395",
          "publishedOn": "2021-06-07T03:06:12.525Z",
          "wordCount": 624,
          "title": "DOCTOR: A Simple Method for Detecting Misclassification Errors. (arXiv:2106.02395v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02638",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zongxin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1\">Yunchao Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi Yang</a>",
          "description": "This paper investigates how to realize better and more efficient embedding\nlearning to tackle the semi-supervised video object segmentation under\nchallenging multi-object scenarios. The state-of-the-art methods learn to\ndecode features with a single positive object and thus have to match and\nsegment each target separately under multi-object scenarios, consuming multiple\ntimes computing resources. To solve the problem, we propose an Associating\nObjects with Transformers (AOT) approach to match and decode multiple objects\nuniformly. In detail, AOT employs an identification mechanism to associate\nmultiple targets into the same high-dimensional embedding space. Thus, we can\nsimultaneously process the matching and segmentation decoding of multiple\nobjects as efficiently as processing a single object. For sufficiently modeling\nmulti-object association, a Long Short-Term Transformer is designed for\nconstructing hierarchical matching and propagation. We conduct extensive\nexperiments on both multi-object and single-object benchmarks to examine AOT\nvariant networks with different complexities. Particularly, our AOT-L\noutperforms all the state-of-the-art competitors on three popular benchmarks,\ni.e., YouTube-VOS (83.7% J&F), DAVIS 2017 (83.0%), and DAVIS 2016 (91.0%),\nwhile keeping better multi-object efficiency. Meanwhile, our AOT-T can maintain\nreal-time multi-object speed on above benchmarks. We ranked 1st in the 3rd\nLarge-scale Video Object Segmentation Challenge. The code will be publicly\navailable at https://github.com/z-x-yang/AOT.",
          "link": "http://arxiv.org/abs/2106.02638",
          "publishedOn": "2021-06-07T03:06:12.518Z",
          "wordCount": 640,
          "title": "Associating Objects with Transformers for Video Object Segmentation. (arXiv:2106.02638v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02320",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Gengwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_G/0/1/0/all/0/1\">Guoliang Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1\">Yunchao Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi Yang</a>",
          "description": "Few-shot segmentation aims to train a segmentation model that can fast adapt\nto novel classes with few exemplars. The conventional training paradigm is to\nlearn to make predictions on query images conditioned on the features from\nsupport images. Previous methods only utilized the semantic-level prototypes of\nsupport images as the conditional information. These methods cannot utilize all\npixel-wise support information for the query predictions, which is however\ncritical for the segmentation task. In this paper, we focus on utilizing\npixel-wise relationships between support and target images to facilitate the\nfew-shot semantic segmentation task. We design a novel Cycle-Consistent\nTransformer (CyCTR) module to aggregate pixel-wise support features into query\nones. CyCTR performs cross-attention between features from different images,\ni.e. support and query images. We observe that there may exist unexpected\nirrelevant pixel-level support features. Directly performing cross-attention\nmay aggregate these features from support to query and bias the query features.\nThus, we propose using a novel cycle-consistent attention mechanism to filter\nout possible harmful support features and encourage query features to attend to\nthe most informative pixels from support images. Experiments on all few-shot\nsegmentation benchmarks demonstrate that our proposed CyCTR leads to remarkable\nimprovement compared to previous state-of-the-art methods. Specifically, on\nPascal-$5^i$ and COCO-$20^i$ datasets, we achieve 66.6% and 45.6% mIoU for\n5-shot segmentation, outperforming previous state-of-the-art by 4.6% and 7.1%\nrespectively.",
          "link": "http://arxiv.org/abs/2106.02320",
          "publishedOn": "2021-06-07T03:06:12.511Z",
          "wordCount": 646,
          "title": "Few-Shot Segmentation via Cycle-Consistent Transformer. (arXiv:2106.02320v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1\">Zekun Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1\">Zheng Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Sixiao Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yabiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yanwei Fu</a>",
          "description": "Non-Maximum Suppression (NMS) is essential for object detection and affects\nthe evaluation results by incorporating False Positives (FP) and False\nNegatives (FN), especially in crowd occlusion scenes. In this paper, we raise\nthe problem of weak connection between the training targets and the evaluation\nmetrics caused by NMS and propose a novel NMS-Loss making the NMS procedure can\nbe trained end-to-end without any additional network parameters. Our NMS-Loss\npunishes two cases when FP is not suppressed and FN is wrongly eliminated by\nNMS. Specifically, we propose a pull loss to pull predictions with the same\ntarget close to each other, and a push loss to push predictions with different\ntargets away from each other. Experimental results show that with the help of\nNMS-Loss, our detector, namely NMS-Ped, achieves impressive results with Miss\nRate of 5.92% on Caltech dataset and 10.08% on CityPersons dataset, which are\nboth better than state-of-the-art competitors.",
          "link": "http://arxiv.org/abs/2106.02426",
          "publishedOn": "2021-06-07T03:06:12.494Z",
          "wordCount": 591,
          "title": "NMS-Loss: Learning with Non-Maximum Suppression for Crowded Pedestrian Detection. (arXiv:2106.02426v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02277",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_Q/0/1/0/all/0/1\">Qihang Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yingda Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yutong Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yongyi Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuille_A/0/1/0/all/0/1\">Alan Yuille</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1\">Wei Shen</a>",
          "description": "Recently, there emerges a series of vision Transformers, which show superior\nperformance with a more compact model size than conventional convolutional\nneural networks, thanks to the strong ability of Transformers to model\nlong-range dependencies. However, the advantages of vision Transformers also\ncome with a price: Self-attention, the core part of Transformer, has a\nquadratic complexity to the input sequence length. This leads to a dramatic\nincrease of computation and memory cost with the increase of sequence length,\nthus introducing difficulties when applying Transformers to the vision tasks\nthat require dense predictions based on high-resolution feature maps. In this\npaper, we propose a new vision Transformer, named Glance-and-Gaze Transformer\n(GG-Transformer), to address the aforementioned issues. It is motivated by the\nGlance and Gaze behavior of human beings when recognizing objects in natural\nscenes, with the ability to efficiently model both long-range dependencies and\nlocal context. In GG-Transformer, the Glance and Gaze behavior is realized by\ntwo parallel branches: The Glance branch is achieved by performing\nself-attention on the adaptively-dilated partitions of the input, which leads\nto a linear complexity while still enjoying a global receptive field; The Gaze\nbranch is implemented by a simple depth-wise convolutional layer, which\ncompensates local image context to the features obtained by the Glance\nmechanism. We empirically demonstrate our method achieves consistently superior\nperformance over previous state-of-the-art Transformers on various vision tasks\nand benchmarks. The codes and models will be made available at\nhttps://github.com/yucornetto/GG-Transformer.",
          "link": "http://arxiv.org/abs/2106.02277",
          "publishedOn": "2021-06-07T03:06:12.486Z",
          "wordCount": 676,
          "title": "Glance-and-Gaze Vision Transformer. (arXiv:2106.02277v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02267",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yingtao Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clanuwat_T/0/1/0/all/0/1\">Tarin Clanuwat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suzuki_C/0/1/0/all/0/1\">Chikahiko Suzuki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kitamoto_A/0/1/0/all/0/1\">Asanobu Kitamoto</a>",
          "description": "The study of Ukiyo-e, an important genre of pre-modern Japanese art, focuses\non the object and style like other artwork researches. Such study has benefited\nfrom the renewed interest by the machine learning community in culturally\nimportant topics, leading to interdisciplinary works including collections of\nimages, quantitative approaches, and machine learning-based creativities. They,\nhowever, have several drawbacks, and it remains challenging to integrate these\nworks into a comprehensive view. To bridge this gap, we propose a holistic\napproach We first present a large-scale Ukiyo-e dataset with coherent semantic\nlabels and geometric annotations, then show its value in a quantitative study\nof Ukiyo-e paintings' object using these labels and annotations. We further\ndemonstrate the machine learning methods could help style study through soft\ncolor decomposition of Ukiyo-e, and finally provides joint insights into object\nand style by composing sketches and colors using colorization. Dataset\navailable at https://github.com/rois-codh/arc-ukiyoe-faces",
          "link": "http://arxiv.org/abs/2106.02267",
          "publishedOn": "2021-06-07T03:06:12.479Z",
          "wordCount": 584,
          "title": "Ukiyo-e Analysis and Creativity with Attribute and Geometry Annotation. (arXiv:2106.02267v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02222",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhuo Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomizuka_M/0/1/0/all/0/1\">Masayoshi Tomizuka</a>",
          "description": "In this extended abstract, we investigate the design of learning\nrepresentation for human intention inference. In our designed human intention\nprediction task, we propose a history encoding representation that is both\ninterpretable and effective for prediction. Through extensive experiments, we\nshow our prediction framework with a history encoding representation design is\nsuccessful on the human intention prediction problem.",
          "link": "http://arxiv.org/abs/2106.02222",
          "publishedOn": "2021-06-07T03:06:12.437Z",
          "wordCount": 484,
          "title": "History Encoding Representation Design for Human Intention Inference. (arXiv:2106.02222v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02229",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Miao_Y/0/1/0/all/0/1\">Yingjie Miao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xingyou Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_D/0/1/0/all/0/1\">Daiyi Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_S/0/1/0/all/0/1\">Summer Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brevdo_E/0/1/0/all/0/1\">Eugene Brevdo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faust_A/0/1/0/all/0/1\">Aleksandra Faust</a>",
          "description": "We introduce RL-DARTS, one of the first applications of Differentiable\nArchitecture Search (DARTS) in reinforcement learning (RL) to search for\nconvolutional cells, applied to the Procgen benchmark. We outline the initial\ndifficulties of applying neural architecture search techniques in RL, and\ndemonstrate that by simply replacing the image encoder with a DARTS supernet,\nour search method is sample-efficient, requires minimal extra compute\nresources, and is also compatible with off-policy and on-policy RL algorithms,\nneeding only minor changes in preexisting code. Surprisingly, we find that the\nsupernet can be used as an actor for inference to generate replay data in\nstandard RL training loops, and thus train end-to-end. Throughout this training\nprocess, we show that the supernet gradually learns better cells, leading to\nalternative architectures which can be highly competitive against manually\ndesigned policies, but also verify previous design choices for RL policies.",
          "link": "http://arxiv.org/abs/2106.02229",
          "publishedOn": "2021-06-07T03:06:12.430Z",
          "wordCount": 585,
          "title": "RL-DARTS: Differentiable Architecture Search for Reinforcement Learning. (arXiv:2106.02229v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02253",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xuanhong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_B/0/1/0/all/0/1\">Bingbing Ni</a>",
          "description": "Convolution and self-attention are acting as two fundamental building blocks\nin deep neural networks, where the former extracts local image features in a\nlinear way while the latter non-locally encodes high-order contextual\nrelationships. Though essentially complementary to each other, i.e.,\nfirst-/high-order, stat-of-the-art architectures, i.e., CNNs or transformers\nlack a principled way to simultaneously apply both operations in a single\ncomputational module, due to their heterogeneous computing pattern and\nexcessive burden of global dot-product for visual tasks. In this work, we\ntheoretically derive a global self-attention approximation scheme, which\napproximates a self-attention via the convolution operation on transformed\nfeatures. Based on the approximated scheme, we establish a multi-branch\nelementary module composed of both convolution and self-attention operation,\ncapable of unifying both local and non-local feature interaction. Importantly,\nonce trained, this multi-branch module could be conditionally converted into a\nsingle standard convolution operation via structural re-parameterization,\nrendering a pure convolution styled operator named X-volution, ready to be\nplugged into any modern networks as an atomic operation. Extensive experiments\ndemonstrate that the proposed X-volution, achieves highly competitive visual\nunderstanding improvements (+1.2% top-1 accuracy on ImageNet classification,\n+1.7 box AP and +1.5 mask AP on COCO detection and segmentation).",
          "link": "http://arxiv.org/abs/2106.02253",
          "publishedOn": "2021-06-07T03:06:12.423Z",
          "wordCount": 623,
          "title": "X-volution: On the unification of convolution and self-attention. (arXiv:2106.02253v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02198",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Fard_A/0/1/0/all/0/1\">Azin Shokraei Fard</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Reutens_D/0/1/0/all/0/1\">David C. Reutens</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vegh_V/0/1/0/all/0/1\">Viktor Vegh</a>",
          "description": "Cross-modality image estimation involves the generation of images of one\nmedical imaging modality from that of another modality. Convolutional neural\nnetworks (CNNs) have been shown to be useful in identifying, characterising and\nextracting image patterns. Generative adversarial networks (GANs) use CNNs as\ngenerators and estimated images are discriminated as true or false based on an\nadditional network. CNNs and GANs within the image estimation framework may be\nconsidered more generally as deep learning approaches, since imaging data tends\nto be large, leading to a larger number of network weights. Almost all research\nin the CNN/GAN image estimation literature has involved the use of MRI data\nwith the other modality primarily being PET or CT. This review provides an\noverview of the use of CNNs and GANs for MRI-based cross-modality medical image\nestimation. We outline the neural networks implemented, and detail network\nconstructs employed for CNN and GAN image-to-image estimators. Motivations\nbehind cross-modality image estimation are provided as well. GANs appear to\nprovide better utility in cross-modality image estimation in comparison with\nCNNs, a finding drawn based on our analysis involving metrics comparing\nestimated and actual images. Our final remarks highlight key challenges faced\nby the cross-modality medical image estimation field, and suggestions for\nfuture research are outlined.",
          "link": "http://arxiv.org/abs/2106.02198",
          "publishedOn": "2021-06-07T03:06:12.417Z",
          "wordCount": 647,
          "title": "CNNs and GANs in MRI-based cross-modality medical image estimation. (arXiv:2106.02198v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02257",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1\">Jiayi Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xilian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>",
          "description": "When a human asks questions online, or when a conversational virtual agent\nasks human questions, questions triggering emotions or with details might more\nlikely to get responses or answers. we explore how to automatically rewrite\nnatural language questions to improve the response rate from people. In\nparticular, a new task of Visual Question Rewriting(VQR) task is introduced to\nexplore how visual information can be used to improve the new questions. A data\nset containing around 4K bland questions, attractive questions and images\ntriples is collected. We developed some baseline sequence to sequence models\nand more advanced transformer based models, which take a bland question and a\nrelated image as input and output a rewritten question that is expected to be\nmore attractive. Offline experiments and mechanical Turk based evaluations show\nthat it is possible to rewrite bland questions in a more detailed and\nattractive way to increase the response rate, and images can be helpful.",
          "link": "http://arxiv.org/abs/2106.02257",
          "publishedOn": "2021-06-07T03:06:12.399Z",
          "wordCount": 596,
          "title": "Visual Question Rewriting for Increasing Response Rate. (arXiv:2106.02257v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02342",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1\">Deng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wenhao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Weiwen Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1\">Dongliang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhihua Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiangmiao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1\">Mingkui Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_E/0/1/0/all/0/1\">Errui Ding</a>",
          "description": "We study self-supervised video representation learning, which is a\nchallenging task due to 1) a lack of labels for explicit supervision and 2)\nunstructured and noisy visual information. Existing methods mainly use\ncontrastive loss with video clips as the instances and learn visual\nrepresentation by discriminating instances from each other, but they require\ncareful treatment of negative pairs by relying on large batch sizes, memory\nbanks, extra modalities, or customized mining strategies, inevitably including\nnoisy data. In this paper, we observe that the consistency between positive\nsamples is the key to learn robust video representations. Specifically, we\npropose two tasks to learn the appearance and speed consistency, separately.\nThe appearance consistency task aims to maximize the similarity between two\nclips of the same video with different playback speeds. The speed consistency\ntask aims to maximize the similarity between two clips with the same playback\nspeed but different appearance information. We show that joint optimization of\nthe two tasks consistently improves the performance on downstream tasks, e.g.,\naction recognition and video retrieval. Remarkably, for action recognition on\nthe UCF-101 dataset, we achieve 90.8% accuracy without using any additional\nmodalities or negative pairs for unsupervised pretraining, outperforming the\nImageNet supervised pre-trained model. Codes and models will be available.",
          "link": "http://arxiv.org/abs/2106.02342",
          "publishedOn": "2021-06-07T03:06:12.392Z",
          "wordCount": 648,
          "title": "ASCNet: Self-supervised Video Representation Learning with Appearance-Speed Consistency. (arXiv:2106.02342v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02258",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shangfei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1\">Yanan Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_G/0/1/0/all/0/1\">Guozhu Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_B/0/1/0/all/0/1\">Bowen Pan</a>",
          "description": "Current works formulate facial action unit (AU) recognition as a supervised\nlearning problem, requiring fully AU-labeled facial images during training. It\nis challenging if not impossible to provide AU annotations for large numbers of\nfacial images. Fortunately, AUs appear on all facial images, whether manually\nlabeled or not, satisfy the underlying anatomic mechanisms and human behavioral\nhabits. In this paper, we propose a deep semi-supervised framework for facial\naction unit recognition from partially AU-labeled facial images. Specifically,\nthe proposed deep semi-supervised AU recognition approach consists of a deep\nrecognition network and a discriminator D. The deep recognition network R\nlearns facial representations from large-scale facial images and AU classifiers\nfrom limited ground truth AU labels. The discriminator D is introduced to\nenforce statistical similarity between the AU distribution inherent in ground\ntruth AU labels and the distribution of the predicted AU labels from labeled\nand unlabeled facial images. The deep recognition network aims to minimize\nrecognition loss from the labeled facial images, to faithfully represent\ninherent AU distribution for both labeled and unlabeled facial images, and to\nconfuse the discriminator. During training, the deep recognition network R and\nthe discriminator D are optimized alternately. Thus, the inherent AU\ndistributions caused by underlying anatomic mechanisms are leveraged to\nconstruct better feature representations and AU classifiers from partially\nAU-labeled data during training. Experiments on two benchmark databases\ndemonstrate that the proposed approach successfully captures AU distributions\nthrough adversarial learning and outperforms state-of-the-art AU recognition\nwork.",
          "link": "http://arxiv.org/abs/2106.02258",
          "publishedOn": "2021-06-07T03:06:12.385Z",
          "wordCount": 677,
          "title": "Exploring Adversarial Learning for Deep Semi-Supervised Facial Action Unit Recognition. (arXiv:2106.02258v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02221",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Jimenez_Martin_L/0/1/0/all/0/1\">Lauren Jimenez-Martin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Perez_D/0/1/0/all/0/1\">Daniel A. Vald&#xe9;s P&#xe9;rez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Asteasuainzarra_A/0/1/0/all/0/1\">Ana M. Solares Asteasuainzarra</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Leonard_L/0/1/0/all/0/1\">Ludwig Leonard</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Diaz_Romanach_M/0/1/0/all/0/1\">Marta L. Baguer D&#xed;az-Roma&#xf1;ach</a>",
          "description": "Cervical cancer is a malignant tumor that seriously threatens women's health,\nand is one of the most common that affects women worldwide. For its early\ndetection, colposcopic images of the cervix are used for searching for possible\ninjuries or abnormalities. An inherent characteristic of these images is the\npresence of specular reflections (brightness) that make it difficult to observe\nsome regions, which might imply a misdiagnosis. In this paper, a new strategy\nbased on neural networks is introduced for eliminating specular reflections and\nestimating the unobserved anatomical cervix portion under the bright zones. We\npresent a supervised learning method, despite not knowing the ground truth from\nthe beginning, based on training a neural network to learn how to restore any\nhidden region of colposcopic images. Once the specular reflections are\nidentified, they are removed from the image and the previously trained network\nis used to fulfill these deleted areas. The quality of the processed images was\nevaluated quantitatively and qualitatively. In 21 of the 22 evaluated images,\nthe detected specular reflections were totally eliminated, whereas, in the\nremaining one, these reflections were almost completely eliminated. The\ndistribution of the colors and the content of the restored images are similar\nto those of the originals. The evaluation carried out by a specialist in Cervix\nPathology concluded that, after eliminating the specular reflections, the\nanatomical and physiological elements of the cervix are observable in the\nrestored images, which facilitates the medical diagnosis of cervical\npathologies. Our method has the potential to improve the early detection of\ncervical cancer.",
          "link": "http://arxiv.org/abs/2106.02221",
          "publishedOn": "2021-06-07T03:06:12.330Z",
          "wordCount": 723,
          "title": "Specular reflections removal in colposcopic images based on neural networks: Supervised training with no ground truth previous knowledge. (arXiv:2106.02221v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02288",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Varga_L/0/1/0/all/0/1\">Leon Amadeus Varga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zell_A/0/1/0/all/0/1\">Andreas Zell</a>",
          "description": "Object detection on Unmanned Aerial Vehicles (UAVs) is still a challenging\ntask. The recordings are mostly sparse and contain only small objects. In this\nwork, we propose a simple tiling method that improves the detection capability\nin the remote sensing case without modifying the model itself. By reducing the\nbackground bias and enabling the usage of higher image resolutions during\ntraining, our method can improve the performance of models substantially. The\nprocedure was validated on three different data sets and outperformed similar\napproaches in performance and speed.",
          "link": "http://arxiv.org/abs/2106.02288",
          "publishedOn": "2021-06-07T03:06:12.301Z",
          "wordCount": 523,
          "title": "Tackling the Background Bias in Sparse Object Detection via Cropped Windows. (arXiv:2106.02288v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02067",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mihai_D/0/1/0/all/0/1\">Daniela Mihai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hare_J/0/1/0/all/0/1\">Jonathon Hare</a>",
          "description": "Evidence that visual communication preceded written language and provided a\nbasis for it goes back to prehistory, in forms such as cave and rock paintings\ndepicting traces of our distant ancestors. Emergent communication research has\nsought to explore how agents can learn to communicate in order to\ncollaboratively solve tasks. Existing research has focused on language, with a\nlearned communication channel transmitting sequences of discrete tokens between\nthe agents. In this work, we explore a visual communication channel between\nagents that are allowed to draw with simple strokes. Our agents are\nparameterised by deep neural networks, and the drawing procedure is\ndifferentiable, allowing for end-to-end training. In the framework of a\nreferential communication game, we demonstrate that agents can not only\nsuccessfully learn to communicate by drawing, but with appropriate inductive\nbiases, can do so in a fashion that humans can interpret. We hope to encourage\nfuture research to consider visual communication as a more flexible and\ndirectly interpretable alternative of training collaborative agents.",
          "link": "http://arxiv.org/abs/2106.02067",
          "publishedOn": "2021-06-07T03:06:12.054Z",
          "wordCount": 588,
          "title": "Learning to Draw: Emergent Communication through Sketching. (arXiv:2106.02067v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02207",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jang_R/0/1/0/all/0/1\">Ryoungwoo Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minjee Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eun_D/0/1/0/all/0/1\">Da-in Eun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyungjin Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_J/0/1/0/all/0/1\">Jiyeon Seo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_N/0/1/0/all/0/1\">Namkug Kim</a>",
          "description": "Evaluating the performance of generative models in image synthesis is a\nchallenging task. Although the Fr\\'echet Inception Distance is a widely\naccepted evaluation metric, it integrates different aspects (e.g., fidelity and\ndiversity) of synthesized images into a single score and assumes the normality\nof embedded vectors. Recent methods such as precision-and-recall and its\nvariants such as density-and-coverage have been developed to separate fidelity\nand diversity based on k-nearest neighborhood methods. In this study, we\npropose an algorithm named barcode, which is inspired by the topological data\nanalysis and is almost free of assumption and hyperparameter selections. In\nextensive experiments on real-world datasets as well as theoretical approach on\nhigh-dimensional normal samples, it was found that the 'usual' normality\nassumption of embedded vectors has several drawbacks. The experimental results\ndemonstrate that barcode outperforms other methods in evaluating fidelity and\ndiversity of GAN outputs. Official codes can be found in\nhttps://github.com/minjeekim00/Barcode.",
          "link": "http://arxiv.org/abs/2106.02207",
          "publishedOn": "2021-06-07T03:06:11.936Z",
          "wordCount": 598,
          "title": "Barcode Method for Generative Model Evaluation driven by Topological Data Analysis. (arXiv:2106.02207v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02154",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ghojogh_B/0/1/0/all/0/1\">Benyamin Ghojogh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ghodsi_A/0/1/0/all/0/1\">Ali Ghodsi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Karray_F/0/1/0/all/0/1\">Fakhri Karray</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Crowley_M/0/1/0/all/0/1\">Mark Crowley</a>",
          "description": "This is a tutorial and survey paper for nonlinear dimensionality and feature\nextraction methods which are based on the Laplacian of graph of data. We first\nintroduce adjacency matrix, definition of Laplacian matrix, and the\ninterpretation of Laplacian. Then, we cover the cuts of graph and spectral\nclustering which applies clustering in a subspace of data. Different\noptimization variants of Laplacian eigenmap and its out-of-sample extension are\nexplained. Thereafter, we introduce the locality preserving projection and its\nkernel variant as linear special cases of Laplacian eigenmap. Versions of graph\nembedding are then explained which are generalized versions of Laplacian\neigenmap and locality preserving projection. Finally, diffusion map is\nintroduced which is a method based on Laplacian of data and random walks on the\ndata graph.",
          "link": "http://arxiv.org/abs/2106.02154",
          "publishedOn": "2021-06-07T03:06:11.929Z",
          "wordCount": 598,
          "title": "Laplacian-Based Dimensionality Reduction Including Spectral Clustering, Laplacian Eigenmap, Locality Preserving Projection, Graph Embedding, and Diffusion Map: Tutorial and Survey. (arXiv:2106.02154v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02078",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sridhar_K/0/1/0/all/0/1\">Kaustubh Sridhar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sokolsky_O/0/1/0/all/0/1\">Oleg Sokolsky</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lee_I/0/1/0/all/0/1\">Insup Lee</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Weimer_J/0/1/0/all/0/1\">James Weimer</a>",
          "description": "Improving adversarial robustness of neural networks remains a major\nchallenge. Fundamentally, training a network is a parameter estimation problem.\nIn adaptive control theory, maintaining persistency of excitation (PoE) is\nintegral to ensuring convergence of parameter estimates in dynamical systems to\ntheir robust optima. In this work, we show that network training using gradient\ndescent is equivalent to a dynamical system parameter estimation problem.\nLeveraging this relationship, we prove a sufficient condition for PoE of\ngradient descent is achieved when the learning rate is less than the inverse of\nthe Lipschitz constant of the gradient of loss function. We provide an\nefficient technique for estimating the corresponding Lipschitz constant using\nextreme value theory and demonstrate that by only scaling the learning rate\nschedule we can increase adversarial accuracy by up to 15% on benchmark\ndatasets. Our approach also universally increases the adversarial accuracy by\n0.1% to 0.3% in various state-of-the-art adversarially trained models on the\nAutoAttack benchmark, where every small margin of improvement is significant.",
          "link": "http://arxiv.org/abs/2106.02078",
          "publishedOn": "2021-06-07T03:06:11.921Z",
          "wordCount": 601,
          "title": "Robust Learning via Persistency of Excitation. (arXiv:2106.02078v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2104.07070",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stojnic_V/0/1/0/all/0/1\">Vladan Stojni&#x107;</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Risojevic_V/0/1/0/all/0/1\">Vladimir Risojevi&#x107;</a> (1) ((1) Faculty of Electrical Engineering, University of Banja Luka, Bosnia and Herzegovina)",
          "description": "In recent years self-supervised learning has emerged as a promising candidate\nfor unsupervised representation learning. In the visual domain its applications\nare mostly studied in the context of images of natural scenes. However, its\napplicability is especially interesting in specific areas, like remote sensing\nand medicine, where it is hard to obtain huge amounts of labeled data. In this\nwork, we conduct an extensive analysis of the applicability of self-supervised\nlearning in remote sensing image classification. We analyze the influence of\nthe number and domain of images used for self-supervised pre-training on the\nperformance on downstream tasks. We show that, for the downstream task of\nremote sensing image classification, using self-supervised pre-training on\nremote sensing images can give better results than using supervised\npre-training on images of natural scenes. Besides, we also show that\nself-supervised pre-training can be easily extended to multispectral images\nproducing even better results on our downstream tasks.",
          "link": "http://arxiv.org/abs/2104.07070",
          "publishedOn": "2021-06-04T01:12:31.962Z",
          "wordCount": 625,
          "title": "Self-Supervised Learning of Remote Sensing Scene Representations Using Contrastive Multiview Coding. (arXiv:2104.07070v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.15076",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shu_X/0/1/0/all/0/1\">Xiujun Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shiliang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xianghao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuanqi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Ge Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1\">Qi Tian</a>",
          "description": "Person re-identification (re-ID) in the scenario with large spatial and\ntemporal spans has not been fully explored. This is partially because that,\nexisting benchmark datasets were mainly collected with limited spatial and\ntemporal ranges, e.g., using videos recorded in a few days by cameras in a\nspecific region of the campus. Such limited spatial and temporal ranges make it\nhard to simulate the difficulties of person re-ID in real scenarios. In this\nwork, we contribute a novel Large-scale Spatio-Temporal (LaST) person re-ID\ndataset, including 10,860 identities with more than 224k images. Compared with\nexisting datasets, LaST presents more challenging and high-diversity reID\nsettings, and significantly larger spatial and temporal ranges. For instance,\neach person can appear in different cities or countries, and in various time\nslots from daytime to night, and in different seasons from spring to winter. To\nour best knowledge, LaST is a novel person re-ID dataset with the largest\nspatiotemporal ranges. Based on LaST, we verified its challenge by conducting a\ncomprehensive performance evaluation of 14 re-ID algorithms. We further propose\nan easy-to-implement baseline that works well on such challenging re-ID\nsetting. We also verified that models pre-trained on LaST can generalize well\non existing datasets with short-term and cloth-changing scenarios. We expect\nLaST to inspire future works toward more realistic and challenging re-ID tasks.\nMore information about the dataset is available at\nhttps://github.com/shuxjweb/last.git.",
          "link": "http://arxiv.org/abs/2105.15076",
          "publishedOn": "2021-06-04T01:12:31.942Z",
          "wordCount": 680,
          "title": "Large-Scale Spatio-Temporal Person Re-identification: Algorithm and Benchmark. (arXiv:2105.15076v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.15034",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Tang_F/0/1/0/all/0/1\">Fei Tang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Kopp_M/0/1/0/all/0/1\">Michael Kopp</a>",
          "description": "In their recent paper titled \"Large Associative Memory Problem in\nNeurobiology and Machine Learning\" [arXiv:2008.06996] the authors gave a\nbiologically plausible microscopic theory from which one can recover many dense\nassociative memory models discussed in the literature. We show that the layers\nof the recent \"MLP-mixer\" [arXiv:2105.01601] as well as the essentially\nequivalent model in [arXiv:2105.02723] are amongst them.",
          "link": "http://arxiv.org/abs/2105.15034",
          "publishedOn": "2021-06-04T01:12:31.924Z",
          "wordCount": 522,
          "title": "A remark on a paper of Krotov and Hopfield [arXiv:2008.06996]. (arXiv:2105.15034v2 [q-bio.NC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.04447",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Cheng Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giancola_S/0/1/0/all/0/1\">Silvio Giancola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1\">Bernard Ghanem</a>",
          "description": "We propose a novel scene flow estimation approach to capture and infer 3D\nmotions from point clouds. Estimating 3D motions for point clouds is\nchallenging, since a point cloud is unordered and its density is significantly\nnon-uniform. Such unstructured data poses difficulties in matching\ncorresponding points between point clouds, leading to inaccurate flow\nestimation. We propose a novel architecture named Sparse\nConvolution-Transformer Network (SCTN) that equips the sparse convolution with\nthe transformer. Specifically, by leveraging the sparse convolution, SCTN\ntransfers irregular point cloud into locally consistent flow features for\nestimating continuous and consistent motions within an object/local object\npart. We further propose to explicitly learn point relations using a point\ntransformer module, different from exiting methods. We show that the learned\nrelation-based contextual information is rich and helpful for matching\ncorresponding points, benefiting scene flow estimation. In addition, a novel\nloss function is proposed to adaptively encourage flow consistency according to\nfeature similarity. Extensive experiments demonstrate that our proposed\napproach achieves a new state of the art in scene flow estimation. Our approach\nachieves an error of 0.038 and 0.037 (EPE3D) on FlyingThings3D and KITTI Scene\nFlow respectively, which significantly outperforms previous methods by large\nmargins.",
          "link": "http://arxiv.org/abs/2105.04447",
          "publishedOn": "2021-06-04T01:12:31.898Z",
          "wordCount": 659,
          "title": "SCTN: Sparse Convolution-Transformer Network for Scene Flow Estimation. (arXiv:2105.04447v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.12212",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lou_A/0/1/0/all/0/1\">Ange Lou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loew_M/0/1/0/all/0/1\">Murray Loew</a>",
          "description": "Real-time semantic segmentation is playing a more important role in computer\nvision, due to the growing demand for mobile devices and autonomous driving.\nTherefore, it is very important to achieve a good trade-off among performance,\nmodel size and inference speed. In this paper, we propose a Channel-wise\nFeature Pyramid (CFP) module to balance those factors. Based on the CFP module,\nwe built CFPNet for real-time semantic segmentation which applied a series of\ndilated convolution channels to extract effective features. Experiments on\nCityscapes and CamVid datasets show that the proposed CFPNet achieves an\neffective combination of those factors. For the Cityscapes test dataset, CFPNet\nachieves 70.1% class-wise mIoU with only 0.55 million parameters and 2.5 MB\nmemory. The inference speed can reach 30 FPS on a single RTX 2080Ti GPU with a\n1024x2048-pixel image.",
          "link": "http://arxiv.org/abs/2103.12212",
          "publishedOn": "2021-06-04T01:12:31.876Z",
          "wordCount": 587,
          "title": "CFPNet: Channel-wise Feature Pyramid for Real-Time Semantic Segmentation. (arXiv:2103.12212v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.00454",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Che_F/0/1/0/all/0/1\">Fengying Che</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_R/0/1/0/all/0/1\">Ruichuan Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_J/0/1/0/all/0/1\">Jian Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_H/0/1/0/all/0/1\">Haoran Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_S/0/1/0/all/0/1\">Shuqin Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_W/0/1/0/all/0/1\">Weixing Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_H/0/1/0/all/0/1\">Hao Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_Z/0/1/0/all/0/1\">Zhi Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cui_X/0/1/0/all/0/1\">Xiaoyu Cui</a> (Member, IEEE)",
          "description": "The feature extraction methods of radiomics are mainly based on static\ntomographic images at a certain moment, while the occurrence and development of\ndisease is a dynamic process that cannot be fully reflected by only static\ncharacteristics. This study proposes a new dynamic radiomics feature extraction\nworkflow that uses time-dependent tomographic images of the same patient,\nfocuses on the changes in image features over time, and then quantifies them as\nnew dynamic features for diagnostic or prognostic evaluation. We first define\nthe mathematical paradigm of dynamic radiomics and introduce three specific\nmethods that can describe the transformation process of features over time.\nThree different clinical problems are used to validate the performance of the\nproposed dynamic feature with conventional 2D and 3D static features.",
          "link": "http://arxiv.org/abs/2011.00454",
          "publishedOn": "2021-06-04T01:12:31.854Z",
          "wordCount": 611,
          "title": "Dynamic radiomics: a new methodology to extract quantitative time-related features from tomographic images. (arXiv:2011.00454v3 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.13400",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Weijian Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1\">Kailun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_J/0/1/0/all/0/1\">Jian Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kaiwei Wang</a>",
          "description": "In this paper, we propose panoramic annular simultaneous localization and\nmapping (PA-SLAM), a visual SLAM system based on panoramic annular lens. A\nhybrid point selection strategy is put forward in the tracking front-end, which\nensures repeatability of keypoints and enables loop closure detection based on\nthe bag-of-words approach. Every detected loop candidate is verified\ngeometrically and the $Sim(3)$ relative pose constraint is estimated to perform\npose graph optimization and global bundle adjustment in the back-end. A\ncomprehensive set of experiments on real-world datasets demonstrates that the\nhybrid point selection strategy allows reliable loop closure detection, and the\naccumulated error and scale drift have been significantly reduced via global\noptimization, enabling PA-SLAM to reach state-of-the-art accuracy while\nmaintaining high robustness and efficiency.",
          "link": "http://arxiv.org/abs/2102.13400",
          "publishedOn": "2021-06-04T01:12:31.798Z",
          "wordCount": 602,
          "title": "Panoramic annular SLAM with loop closure and global optimization. (arXiv:2102.13400v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.12827",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pintor_M/0/1/0/all/0/1\">Maura Pintor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roli_F/0/1/0/all/0/1\">Fabio Roli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brendel_W/0/1/0/all/0/1\">Wieland Brendel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biggio_B/0/1/0/all/0/1\">Battista Biggio</a>",
          "description": "Evaluating adversarial robustness amounts to finding the minimum perturbation\nneeded to have an input sample misclassified. The inherent complexity of the\nunderlying optimization requires current gradient-based attacks to be carefully\ntuned, initialized, and possibly executed for many computationally-demanding\niterations, even if specialized to a given perturbation model. In this work, we\novercome these limitations by proposing a fast minimum-norm (FMN) attack that\nworks with different $\\ell_p$-norm perturbation models ($p=0, 1, 2, \\infty$),\nis robust to hyperparameter choices, does not require adversarial starting\npoints, and converges within few lightweight steps. It works by iteratively\nfinding the sample misclassified with maximum confidence within an\n$\\ell_p$-norm constraint of size $\\epsilon$, while adapting $\\epsilon$ to\nminimize the distance of the current sample to the decision boundary. Extensive\nexperiments show that FMN significantly outperforms existing attacks in terms\nof convergence speed and computation time, while reporting comparable or even\nsmaller perturbation sizes.",
          "link": "http://arxiv.org/abs/2102.12827",
          "publishedOn": "2021-06-04T01:12:31.792Z",
          "wordCount": 607,
          "title": "Fast Minimum-norm Adversarial Attacks through Adaptive Norm Constraints. (arXiv:2102.12827v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07944",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Gilton_D/0/1/0/all/0/1\">Davis Gilton</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ongie_G/0/1/0/all/0/1\">Gregory Ongie</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Willett_R/0/1/0/all/0/1\">Rebecca Willett</a>",
          "description": "Recent efforts on solving inverse problems in imaging via deep neural\nnetworks use architectures inspired by a fixed number of iterations of an\noptimization method. The number of iterations is typically quite small due to\ndifficulties in training networks corresponding to more iterations; the\nresulting solvers cannot be run for more iterations at test time without\nincurring significant errors. This paper describes an alternative approach\ncorresponding to an infinite number of iterations, yielding a consistent\nimprovement in reconstruction accuracy above state-of-the-art alternatives and\nwhere the computational budget can be selected at test time to optimize\ncontext-dependent trade-offs between accuracy and computation. The proposed\napproach leverages ideas from Deep Equilibrium Models, where the fixed-point\niteration is constructed to incorporate a known forward model and insights from\nclassical optimization-based reconstruction methods.",
          "link": "http://arxiv.org/abs/2102.07944",
          "publishedOn": "2021-06-04T01:12:31.740Z",
          "wordCount": 582,
          "title": "Deep Equilibrium Architectures for Inverse Problems in Imaging. (arXiv:2102.07944v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.02285",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lewis_K/0/1/0/all/0/1\">Kathleen M Lewis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varadharajan_S/0/1/0/all/0/1\">Srivatsan Varadharajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kemelmacher_Shlizerman_I/0/1/0/all/0/1\">Ira Kemelmacher-Shlizerman</a>",
          "description": "Given a pair of images-target person and garment on another person-we\nautomatically generate the target person in the given garment. Previous methods\nmostly focused on texture transfer via paired data training, while overlooking\nbody shape deformations, skin color, and seamless blending of garment with the\nperson. This work focuses on those three components, while also not requiring\npaired data training. We designed a pose conditioned StyleGAN2 architecture\nwith a clothing segmentation branch that is trained on images of people wearing\ngarments. Once trained, we propose a new layered latent space interpolation\nmethod that allows us to preserve and synthesize skin color and target body\nshape while transferring the garment from a different person. We demonstrate\nresults on high resolution 512x512 images, and extensively compare to state of\nthe art in try-on on both latent space generated and real images.",
          "link": "http://arxiv.org/abs/2101.02285",
          "publishedOn": "2021-06-04T01:12:31.718Z",
          "wordCount": 596,
          "title": "TryOnGAN: Body-Aware Try-On via Layered Interpolation. (arXiv:2101.02285v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1903.06519",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Platonova_G/0/1/0/all/0/1\">Ganna Platonova</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Stys_D/0/1/0/all/0/1\">Dalibor Stys</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Soucek_P/0/1/0/all/0/1\">Pavel Soucek</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lonhus_K/0/1/0/all/0/1\">Kirill Lonhus</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Valenta_J/0/1/0/all/0/1\">Jan Valenta</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rychtarikova_R/0/1/0/all/0/1\">Renata Rychtarikova</a>",
          "description": "The most realistic information about the transparent sample such as a live\ncell can be obtained only using bright-field light microscopy. At\nhigh-intensity pulsing LED illumination, we captured a primary\n12-bit-per-channel (bpc) response froman observed sample using a bright-field\nwide-field microscope equipped with a high-resolution (4872x3248) image sensor.\nIn order to suppress data distortions originating from the light interactions\nwith elements in the optical path, poor sensor reproduction (geometrical\ndefects of the camera sensor and some peculiarities of sensor sensitivity),\nthis uncompressed 12-bpc data underwent a kind of correction after simultaneous\ncalibration of all the parts of the experimental arrangement. Moreover, the\nfinal intensities of the corrected images are proportional to the photon fluxes\ndetected by a camera sensor. It can be visualized in 8-bpc intensity depth\nafter the Least Information Loss compression [Lect. Notes Bioinform. 9656, 527\n(2016)].",
          "link": "http://arxiv.org/abs/1903.06519",
          "publishedOn": "2021-06-04T01:12:31.704Z",
          "wordCount": 614,
          "title": "Spectroscopic Approach to Correction and Visualisation of Bright-Field Light Transmission Microscopy Biological Data. (arXiv:1903.06519v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.14858",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mohan_P/0/1/0/all/0/1\">Puranjay Mohan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paul_A/0/1/0/all/0/1\">Aditya Jyoti Paul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chirania_A/0/1/0/all/0/1\">Abhay Chirania</a>",
          "description": "The world is going through one of the most dangerous pandemics of all time\nwith the rapid spread of the novel coronavirus (COVID-19). According to the\nWorld Health Organisation, the most effective way to thwart the transmission of\ncoronavirus is to wear medical face masks. Monitoring the use of face masks in\npublic places has been a challenge because manual monitoring could be unsafe.\nThis paper proposes an architecture for detecting medical face masks for\ndeployment on resource-constrained endpoints having extremely low memory\nfootprints. A small development board with an ARM Cortex-M7 microcontroller\nclocked at 480 Mhz and having just 496 KB of framebuffer RAM, has been used for\nthe deployment of the model. Using the TensorFlow Lite framework, the model is\nquantized to further reduce its size. The proposed model is 138 KB post\nquantization and runs at the inference speed of 30 FPS.",
          "link": "http://arxiv.org/abs/2011.14858",
          "publishedOn": "2021-06-04T01:12:31.672Z",
          "wordCount": 728,
          "title": "A Tiny CNN Architecture for Medical Face Mask Detection for Resource-Constrained Endpoints. (arXiv:2011.14858v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.08890",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jia_D/0/1/0/all/0/1\">Dan Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinweg_M/0/1/0/all/0/1\">Mats Steinweg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hermans_A/0/1/0/all/0/1\">Alexander Hermans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leibe_B/0/1/0/all/0/1\">Bastian Leibe</a>",
          "description": "Deep learning is the essential building block of state-of-the-art person\ndetectors in 2D range data. However, only a few annotated datasets are\navailable for training and testing these deep networks, potentially limiting\ntheir performance when deployed in new environments or with different LiDAR\nmodels. We propose a method, which uses bounding boxes from an image-based\ndetector (e.g. Faster R-CNN) on a calibrated camera to automatically generate\ntraining labels (called pseudo-labels) for 2D LiDAR-based person detectors.\nThrough experiments on the JackRabbot dataset with two detector models, DROW3\nand DR-SPAAM, we show that self-supervised detectors, trained or fine-tuned\nwith pseudo-labels, outperform detectors trained only on a different dataset.\nCombined with robust training techniques, the self-supervised detectors reach a\nperformance close to the ones trained using manual annotations of the target\ndataset. Our method is an effective way to improve person detectors during\ndeployment without any additional labeling effort, and we release our source\ncode to support relevant robotic applications.",
          "link": "http://arxiv.org/abs/2012.08890",
          "publishedOn": "2021-06-04T01:12:31.647Z",
          "wordCount": 633,
          "title": "Self-Supervised Person Detection in 2D Range Data using a Calibrated Camera. (arXiv:2012.08890v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2003.00865",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Soremekun_E/0/1/0/all/0/1\">Ezekiel Soremekun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Udeshi_S/0/1/0/all/0/1\">Sakshi Udeshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chattopadhyay_S/0/1/0/all/0/1\">Sudipta Chattopadhyay</a>",
          "description": "The introduction of robust optimisation has pushed the state-of-the-art in\ndefending against adversarial attacks. However, the behaviour of such\noptimisation has not been studied in the light of a fundamentally different\nclass of attacks called backdoors. In this paper, we demonstrate that\nadversarially robust models are susceptible to backdoor attacks. Subsequently,\nwe observe that backdoors are reflected in the feature representation of such\nmodels. Then, this observation is leveraged to detect backdoor-infected models\nvia a detection technique called AEGIS. Specifically, AEGIS uses feature\nclustering to effectively detect backdoor-infected robust Deep Neural Networks\n(DNNs). In our evaluation of several visible and hidden backdoor triggers on\nmajor classification tasks using CIFAR-10, MNIST and FMNIST datasets, AEGIS\neffectively detects robust DNNs infected with backdoors. AEGIS detects a\nbackdoor-infected model with 91.6% accuracy, without any false positives.\nFurthermore, AEGIS detects the targeted class in the backdoor-infected model\nwith a reasonably low (11.1%) false positive rate. Our investigation reveals\nthat salient features of adversarially robust DNNs break the stealthy nature of\nbackdoor attacks.",
          "link": "http://arxiv.org/abs/2003.00865",
          "publishedOn": "2021-06-04T01:12:31.627Z",
          "wordCount": 641,
          "title": "Exposing Backdoors in Robust Machine Learning Models. (arXiv:2003.00865v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.04525",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhizheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_C/0/1/0/all/0/1\">Cuiling Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1\">Wenjun Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhibo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Shih-Fu Chang</a>",
          "description": "Few-shot image classification learns to recognize new categories from limited\nlabelled data. Metric learning based approaches have been widely investigated,\nwhere a query sample is classified by finding the nearest prototype from the\nsupport set based on their feature similarities. A neural network has different\nuncertainties on its calculated similarities of different pairs. Understanding\nand modeling the uncertainty on the similarity could promote the exploitation\nof limited samples in few-shot optimization. In this work, we propose\nUncertainty-Aware Few-Shot framework for image classification by modeling\nuncertainty of the similarities of query-support pairs and performing\nuncertainty-aware optimization. Particularly, we exploit such uncertainty by\nconverting observed similarities to probabilistic representations and\nincorporate them to the loss for more effective optimization. In order to\njointly consider the similarities between a query and the prototypes in a\nsupport set, a graph-based model is utilized to estimate the uncertainty of the\npairs. Extensive experiments show our proposed method brings significant\nimprovements on top of a strong baseline and achieves the state-of-the-art\nperformance.",
          "link": "http://arxiv.org/abs/2010.04525",
          "publishedOn": "2021-06-04T01:12:31.597Z",
          "wordCount": 623,
          "title": "Uncertainty-Aware Few-Shot Image Classification. (arXiv:2010.04525v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2003.04696",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Perez_Garcia_F/0/1/0/all/0/1\">Fernando P&#xe9;rez-Garc&#xed;a</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sparks_R/0/1/0/all/0/1\">Rachel Sparks</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ourselin_S/0/1/0/all/0/1\">S&#xe9;bastien Ourselin</a>",
          "description": "Processing of medical images such as MRI or CT presents unique challenges\ncompared to RGB images typically used in computer vision. These include a lack\nof labels for large datasets, high computational costs, and metadata to\ndescribe the physical properties of voxels. Data augmentation is used to\nartificially increase the size of the training datasets. Training with image\npatches decreases the need for computational power. Spatial metadata needs to\nbe carefully taken into account in order to ensure a correct alignment of\nvolumes.\n\nWe present TorchIO, an open-source Python library to enable efficient\nloading, preprocessing, augmentation and patch-based sampling of medical images\nfor deep learning. TorchIO follows the style of PyTorch and integrates standard\nmedical image processing libraries to efficiently process images during\ntraining of neural networks. TorchIO transforms can be composed, reproduced,\ntraced and extended. We provide multiple generic preprocessing and augmentation\noperations as well as simulation of MRI-specific artifacts.\n\nSource code, comprehensive tutorials and extensive documentation for TorchIO\ncan be found at https://github.com/fepegar/torchio. The package can be\ninstalled from the Python Package Index running 'pip install torchio'. It\nincludes a command-line interface which allows users to apply transforms to\nimage files without using Python. Additionally, we provide a graphical\ninterface within a TorchIO extension in 3D Slicer to visualize the effects of\ntransforms.\n\nTorchIO was developed to help researchers standardize medical image\nprocessing pipelines and allow them to focus on the deep learning experiments.\nIt encourages open science, as it supports reproducibility and is version\ncontrolled so that the software can be cited precisely. Due to its modularity,\nthe library is compatible with other frameworks for deep learning with medical\nimages.",
          "link": "http://arxiv.org/abs/2003.04696",
          "publishedOn": "2021-06-04T01:12:31.567Z",
          "wordCount": 802,
          "title": "TorchIO: a Python library for efficient loading, preprocessing, augmentation and patch-based sampling of medical images in deep learning. (arXiv:2003.04696v4 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01548",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiangning Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1\">Cho-Jui Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_B/0/1/0/all/0/1\">Boqing Gong</a>",
          "description": "Vision Transformers (ViTs) and MLPs signal further efforts on replacing\nhand-wired features or inductive biases with general-purpose neural\narchitectures. Existing works empower the models by massive data, such as\nlarge-scale pretraining and/or repeated strong data augmentations, and still\nreport optimization-related problems (e.g., sensitivity to initialization and\nlearning rate). Hence, this paper investigates ViTs and MLP-Mixers from the\nlens of loss geometry, intending to improve the models' data efficiency at\ntraining and generalization at inference. Visualization and Hessian reveal\nextremely sharp local minima of converged models. By promoting smoothness with\na recently proposed sharpness-aware optimizer, we substantially improve the\naccuracy and robustness of ViTs and MLP-Mixers on various tasks spanning\nsupervised, adversarial, contrastive, and transfer learning (e.g., +5.3\\% and\n+11.0\\% top-1 accuracy on ImageNet for ViT-B/16 and Mixer-B/16, respectively,\nwith the simple Inception-style preprocessing). We show that the improved\nsmoothness attributes to sparser active neurons in the first few layers. The\nresultant ViTs outperform ResNets of similar size and throughput when trained\nfrom scratch on ImageNet without large-scale pretraining or strong data\naugmentations. They also possess more perceptive attention maps.",
          "link": "http://arxiv.org/abs/2106.01548",
          "publishedOn": "2021-06-04T01:12:31.333Z",
          "wordCount": 617,
          "title": "When Vision Transformers Outperform ResNets without Pretraining or Strong Data Augmentations. (arXiv:2106.01548v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01544",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hong-Yu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chengdi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haofeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Gang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Weimin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yizhou Yu</a>",
          "description": "Semi-Supervised classification and segmentation methods have been widely\ninvestigated in medical image analysis. Both approaches can improve the\nperformance of fully-supervised methods with additional unlabeled data.\nHowever, as a fundamental task, semi-supervised object detection has not gained\nenough attention in the field of medical image analysis. In this paper, we\npropose a novel Semi-Supervised Medical image Detector (SSMD). The motivation\nbehind SSMD is to provide free yet effective supervision for unlabeled data, by\nregularizing the predictions at each position to be consistent. To achieve the\nabove idea, we develop a novel adaptive consistency cost function to regularize\ndifferent components in the predictions. Moreover, we introduce heterogeneous\nperturbation strategies that work in both feature space and image space, so\nthat the proposed detector is promising to produce powerful image\nrepresentations and robust predictions. Extensive experimental results show\nthat the proposed SSMD achieves the state-of-the-art performance at a wide\nrange of settings. We also demonstrate the strength of each proposed module\nwith comprehensive ablation studies.",
          "link": "http://arxiv.org/abs/2106.01544",
          "publishedOn": "2021-06-04T01:12:31.327Z",
          "wordCount": 610,
          "title": "SSMD: Semi-Supervised Medical Image Detection with Adaptive Consistency and Heterogeneous Perturbation. (arXiv:2106.01544v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01499",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1\">Mina Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivatsa_P/0/1/0/all/0/1\">P Srivatsa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rane_A/0/1/0/all/0/1\">Advait Rane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chenniappa_S/0/1/0/all/0/1\">Shriram Chenniappa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hazariwala_A/0/1/0/all/0/1\">Asadali Hazariwala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maes_P/0/1/0/all/0/1\">Pattie Maes</a>",
          "description": "Self-supervised or weakly supervised models trained on large-scale datasets\nhave shown sample-efficient transfer to diverse datasets in few-shot settings.\nWe consider how upstream pretrained models can be leveraged for downstream\nfew-shot, multilabel, and continual learning tasks. Our model CLIPPER (CLIP\nPERsonalized) uses image representations from CLIP, a large-scale image\nrepresentation learning model trained using weak natural language supervision.\nWe developed a technique, called Multi-label Weight Imprinting (MWI), for\nmulti-label, continual, and few-shot learning, and CLIPPER uses MWI with image\nrepresentations from CLIP. We evaluated CLIPPER on 10 single-label and 5\nmulti-label datasets. Our model shows robust and competitive performance, and\nwe set new benchmarks for few-shot, multi-label, and continual learning. Our\nlightweight technique is also compute-efficient and enables privacy-preserving\napplications as the data is not sent to the upstream model for fine-tuning.",
          "link": "http://arxiv.org/abs/2106.01499",
          "publishedOn": "2021-06-04T01:12:31.320Z",
          "wordCount": 556,
          "title": "Personalizing Pre-trained Models. (arXiv:2106.01499v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01618",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liao_Q/0/1/0/all/0/1\">Quanyu Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_B/0/1/0/all/0/1\">Bin Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_S/0/1/0/all/0/1\">Siwei Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1\">Bin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1\">Youbing Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1\">Qi Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xi Wu</a>",
          "description": "Deep neural networks have been demonstrated to be vulnerable to adversarial\nattacks: subtle perturbation can completely change prediction result. The\nvulnerability has led to a surge of research in this direction, including\nadversarial attacks on object detection networks. However, previous studies are\ndedicated to attacking anchor-based object detectors. In this paper, we present\nthe first adversarial attack on anchor-free object detectors. It conducts\ncategory-wise, instead of previously instance-wise, attacks on object\ndetectors, and leverages high-level semantic information to efficiently\ngenerate transferable adversarial examples, which can also be transferred to\nattack other object detectors, even anchor-based detectors such as Faster\nR-CNN. Experimental results on two benchmark datasets demonstrate that our\nproposed method achieves state-of-the-art performance and transferability.",
          "link": "http://arxiv.org/abs/2106.01618",
          "publishedOn": "2021-06-04T01:12:31.314Z",
          "wordCount": 561,
          "title": "Transferable Adversarial Examples for Anchor Free Object Detection. (arXiv:2106.01618v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01689",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Planamente_M/0/1/0/all/0/1\">Mirco Planamente</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plizzari_C/0/1/0/all/0/1\">Chiara Plizzari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alberti_E/0/1/0/all/0/1\">Emanuele Alberti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caputo_B/0/1/0/all/0/1\">Barbara Caputo</a>",
          "description": "First person action recognition is an increasingly researched topic because\nof the growing popularity of wearable cameras. This is bringing to light\ncross-domain issues that are yet to be addressed in this context. Indeed, the\ninformation extracted from learned representations suffers from an intrinsic\nenvironmental bias. This strongly affects the ability to generalize to unseen\nscenarios, limiting the application of current methods in real settings where\ntrimmed labeled data are not available during training. In this work, we\npropose to leverage over the intrinsic complementary nature of audio-visual\nsignals to learn a representation that works well on data seen during training,\nwhile being able to generalize across different domains. To this end, we\nintroduce an audio-visual loss that aligns the contributions from the two\nmodalities by acting on the magnitude of their feature norm representations.\nThis new loss, plugged into a minimal multi-modal action recognition\narchitecture, leads to strong results in cross-domain first person action\nrecognition, as demonstrated by extensive experiments on the popular\nEPIC-Kitchens dataset.",
          "link": "http://arxiv.org/abs/2106.01689",
          "publishedOn": "2021-06-04T01:12:31.308Z",
          "wordCount": 605,
          "title": "Cross-Domain First Person Audio-Visual Action Recognition through Relative Norm Alignment. (arXiv:2106.01689v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01722",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Weijin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yao Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Linfeng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanchez_L/0/1/0/all/0/1\">Lizeth Patricia Aguirre Sanchez</a>",
          "description": "Recent studies on unsupervised object detection based on spatial attention\nhave achieved promising results. Models, such as AIR and SPAIR, output \"what\"\nand \"where\" latent variables that represent the attributes and locations of\nobjects in a scene, respectively. Most of the previous studies concentrate on\nthe \"where\" localization performance; however, we claim that acquiring \"what\"\nobject attributes is also essential for representation learning. This paper\npresents a framework, GMAIR, for unsupervised object detection. It incorporates\nspatial attention and a Gaussian mixture in a unified deep generative model.\nGMAIR can locate objects in a scene and simultaneously cluster them without\nsupervision. Furthermore, we analyze the \"what\" latent variables and clustering\nprocess. Finally, we evaluate our model on MultiMNIST and Fruit2D datasets and\nshow that GMAIR achieves competitive results on localization and clustering\ncompared to state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2106.01722",
          "publishedOn": "2021-06-04T01:12:31.302Z",
          "wordCount": 577,
          "title": "GMAIR: Unsupervised Object Detection Based on Spatial Attention and Gaussian Mixture. (arXiv:2106.01722v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01538",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Matyasko_A/0/1/0/all/0/1\">Alexander Matyasko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chau_L/0/1/0/all/0/1\">Lap-Pui Chau</a>",
          "description": "State-of-the-art deep neural networks are sensitive to small input\nperturbations. Since the discovery of this intriguing vulnerability, many\ndefence methods have been proposed that attempt to improve robustness to\nadversarial noise. Fast and accurate attacks are required to compare various\ndefence methods. However, evaluating adversarial robustness has proven to be\nextremely challenging. Existing norm minimisation adversarial attacks require\nthousands of iterations (e.g. Carlini & Wagner attack), are limited to the\nspecific norms (e.g. Fast Adaptive Boundary), or produce sub-optimal results\n(e.g. Brendel & Bethge attack). On the other hand, PGD attack, which is fast,\ngeneral and accurate, ignores the norm minimisation penalty and solves a\nsimpler perturbation-constrained problem. In this work, we introduce a fast,\ngeneral and accurate adversarial attack that optimises the original non-convex\nconstrained minimisation problem. We interpret optimising the Lagrangian of the\nadversarial attack optimisation problem as a two-player game: the first player\nminimises the Lagrangian wrt the adversarial noise; the second player maximises\nthe Lagrangian wrt the regularisation penalty. Our attack algorithm\nsimultaneously optimises primal and dual variables to find the minimal\nadversarial perturbation. In addition, for non-smooth $l_p$-norm minimisation,\nsuch as $l_{\\infty}$-, $l_1$-, and $l_0$-norms, we introduce primal-dual\nproximal gradient descent attack. We show in the experiments that our attack\noutperforms current state-of-the-art $l_{\\infty}$-, $l_2$-, $l_1$-, and\n$l_0$-attacks on MNIST, CIFAR-10 and Restricted ImageNet datasets against\nunregularised and adversarially trained models.",
          "link": "http://arxiv.org/abs/2106.01538",
          "publishedOn": "2021-06-04T01:12:31.284Z",
          "wordCount": 656,
          "title": "PDPGD: Primal-Dual Proximal Gradient Descent Adversarial Attack. (arXiv:2106.01538v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01534",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1\">Fuli Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_W/0/1/0/all/0/1\">Wei Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Meng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>",
          "description": "We tackle the task of video moment retrieval (VMR), which aims to localize a\nspecific moment in a video according to a textual query. Existing methods\nprimarily model the matching relationship between query and moment by complex\ncross-modal interactions. Despite their effectiveness, current models mostly\nexploit dataset biases while ignoring the video content, thus leading to poor\ngeneralizability. We argue that the issue is caused by the hidden confounder in\nVMR, {i.e., temporal location of moments}, that spuriously correlates the model\ninput and prediction. How to design robust matching models against the temporal\nlocation biases is crucial but, as far as we know, has not been studied yet for\nVMR.\n\nTo fill the research gap, we propose a causality-inspired VMR framework that\nbuilds structural causal model to capture the true effect of query and video\ncontent on the prediction. Specifically, we develop a Deconfounded Cross-modal\nMatching (DCM) method to remove the confounding effects of moment location. It\nfirst disentangles moment representation to infer the core feature of visual\ncontent, and then applies causal intervention on the disentangled multimodal\ninput based on backdoor adjustment, which forces the model to fairly\nincorporate each possible location of the target into consideration. Extensive\nexperiments clearly show that our approach can achieve significant improvement\nover the state-of-the-art methods in terms of both accuracy and generalization\n(Codes:\n\\color{blue}{\\url{https://github.com/Xun-Yang/Causal_Video_Moment_Retrieval}}",
          "link": "http://arxiv.org/abs/2106.01534",
          "publishedOn": "2021-06-04T01:12:31.278Z",
          "wordCount": 662,
          "title": "Deconfounded Video Moment Retrieval with Causal Intervention. (arXiv:2106.01534v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01505",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_P/0/1/0/all/0/1\">Peihao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdal_R/0/1/0/all/0/1\">Rameen Abdal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Femiani_J/0/1/0/all/0/1\">John Femiani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wonka_P/0/1/0/all/0/1\">Peter Wonka</a>",
          "description": "Seamlessly blending features from multiple images is extremely challenging\nbecause of complex relationships in lighting, geometry, and partial occlusion\nwhich cause coupling between different parts of the image. Even though recent\nwork on GANs enables synthesis of realistic hair or faces, it remains difficult\nto combine them into a single, coherent, and plausible image rather than a\ndisjointed set of image patches. We present a novel solution to image blending,\nparticularly for the problem of hairstyle transfer, based on GAN-inversion. We\npropose a novel latent space for image blending which is better at preserving\ndetail and encoding spatial information, and propose a new GAN-embedding\nalgorithm which is able to slightly modify images to conform to a common\nsegmentation mask. Our novel representation enables the transfer of the visual\nproperties from multiple reference images including specific details such as\nmoles and wrinkles, and because we do image blending in a latent-space we are\nable to synthesize images that are coherent. Our approach avoids blending\nartifacts present in other approaches and finds a globally consistent image.\nOur results demonstrate a significant improvement over the current state of the\nart in a user study, with users preferring our blending solution over 95\npercent of the time.",
          "link": "http://arxiv.org/abs/2106.01505",
          "publishedOn": "2021-06-04T01:12:31.272Z",
          "wordCount": 643,
          "title": "Barbershop: GAN-based Image Compositing using Segmentation Masks. (arXiv:2106.01505v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01423",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kvinge_H/0/1/0/all/0/1\">Henry Kvinge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Howland_S/0/1/0/all/0/1\">Scott Howland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Courts_N/0/1/0/all/0/1\">Nico Courts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phillips_L/0/1/0/all/0/1\">Lauren A. Phillips</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buckheit_J/0/1/0/all/0/1\">John Buckheit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+New_Z/0/1/0/all/0/1\">Zachary New</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Skomski_E/0/1/0/all/0/1\">Elliott Skomski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jung H. Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tiwari_S/0/1/0/all/0/1\">Sandeep Tiwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hibler_J/0/1/0/all/0/1\">Jessica Hibler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Corley_C/0/1/0/all/0/1\">Courtney D. Corley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hodas_N/0/1/0/all/0/1\">Nathan O. Hodas</a>",
          "description": "The field of few-shot learning has made remarkable strides in developing\npowerful models that can operate in the small data regime. Nearly all of these\nmethods assume every unlabeled instance encountered will belong to a handful of\nknown classes for which one has examples. This can be problematic for\nreal-world use cases where one routinely finds 'none-of-the-above' examples. In\nthis paper we describe this challenge of identifying what we term\n'out-of-support' (OOS) examples. We describe how this problem is subtly\ndifferent from out-of-distribution detection and describe a new method of\nidentifying OOS examples within the Prototypical Networks framework using a\nfixed point which we call the generic representation. We show that our method\noutperforms other existing approaches in the literature as well as other\napproaches that we propose in this paper. Finally, we investigate how the use\nof such a generic point affects the geometry of a model's feature space.",
          "link": "http://arxiv.org/abs/2106.01423",
          "publishedOn": "2021-06-04T01:12:31.265Z",
          "wordCount": 627,
          "title": "One Representation to Rule Them All: Identifying Out-of-Support Examples in Few-shot Learning with Generic Representations. (arXiv:2106.01423v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01606",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yinpeng Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Ke Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_T/0/1/0/all/0/1\">Tianyu Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zhijie Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hang Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun Zhu</a>",
          "description": "It is well known that deep learning models have a propensity for fitting the\nentire training set even with random labels, which requires memorization of\nevery training sample. In this paper, we investigate the memorization effect in\nadversarial training (AT) for promoting a deeper understanding of capacity,\nconvergence, generalization, and especially robust overfitting of adversarially\ntrained classifiers. We first demonstrate that deep networks have sufficient\ncapacity to memorize adversarial examples of training data with completely\nrandom labels, but not all AT algorithms can converge under the extreme\ncircumstance. Our study of AT with random labels motivates further analyses on\nthe convergence and generalization of AT. We find that some AT methods suffer\nfrom a gradient instability issue, and the recently suggested complexity\nmeasures cannot explain robust generalization by considering models trained on\nrandom labels. Furthermore, we identify a significant drawback of memorization\nin AT that it could result in robust overfitting. We then propose a new\nmitigation algorithm motivated by detailed memorization analyses. Extensive\nexperiments on various datasets validate the effectiveness of the proposed\nmethod.",
          "link": "http://arxiv.org/abs/2106.01606",
          "publishedOn": "2021-06-04T01:12:31.258Z",
          "wordCount": 611,
          "title": "Exploring Memorization in Adversarial Training. (arXiv:2106.01606v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01439",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Perez_Pellitero_E/0/1/0/all/0/1\">Eduardo P&#xe9;rez-Pellitero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Catley_Chandar_S/0/1/0/all/0/1\">Sibi Catley-Chandar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leonardis_A/0/1/0/all/0/1\">Ale&#x161; Leonardis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Timofte_R/0/1/0/all/0/1\">Radu Timofte</a>",
          "description": "This paper reviews the first challenge on high-dynamic range (HDR) imaging\nthat was part of the New Trends in Image Restoration and Enhancement (NTIRE)\nworkshop, held in conjunction with CVPR 2021. This manuscript focuses on the\nnewly introduced dataset, the proposed methods and their results. The challenge\naims at estimating a HDR image from one or multiple respective low-dynamic\nrange (LDR) observations, which might suffer from under- or over-exposed\nregions and different sources of noise. The challenge is composed by two\ntracks: In Track 1 only a single LDR image is provided as input, whereas in\nTrack 2 three differently-exposed LDR images with inter-frame motion are\navailable. In both tracks, the ultimate goal is to achieve the best objective\nHDR reconstruction in terms of PSNR with respect to a ground-truth image,\nevaluated both directly and with a canonical tonemapping operation.",
          "link": "http://arxiv.org/abs/2106.01439",
          "publishedOn": "2021-06-04T01:12:31.241Z",
          "wordCount": 592,
          "title": "NTIRE 2021 Challenge on High Dynamic Range Imaging: Dataset, Methods and Results. (arXiv:2106.01439v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01617",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1\">Pengfei Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Linyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_R/0/1/0/all/0/1\">Ruoxi Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_K/0/1/0/all/0/1\">Kai Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuhao Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_G/0/1/0/all/0/1\">Guoen Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_B/0/1/0/all/0/1\">Bin Yan</a>",
          "description": "Deep neural networks(DNNs) is vulnerable to be attacked by adversarial\nexamples. Black-box attack is the most threatening attack. At present,\nblack-box attack methods mainly adopt gradient-based iterative attack methods,\nwhich usually limit the relationship between the iteration step size, the\nnumber of iterations, and the maximum perturbation. In this paper, we propose a\nnew gradient iteration framework, which redefines the relationship between the\nabove three. Under this framework, we easily improve the attack success rate of\nDI-TI-MIM. In addition, we propose a gradient iterative attack method based on\ninput dropout, which can be well combined with our framework. We further\npropose a multi dropout rate version of this method. Experimental results show\nthat our best method can achieve attack success rate of 96.2\\% for defense\nmodel on average, which is higher than the state-of-the-art gradient-based\nattacks.",
          "link": "http://arxiv.org/abs/2106.01617",
          "publishedOn": "2021-06-04T01:12:31.235Z",
          "wordCount": 583,
          "title": "Improving the Transferability of Adversarial Examples with New Iteration Framework and Input Dropout. (arXiv:2106.01617v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01607",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jong_M/0/1/0/all/0/1\">Michiel de Jong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishna_S/0/1/0/all/0/1\">Satyapriya Krishna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1\">Anuva Agarwal</a>",
          "description": "Training a reinforcement learning agent to carry out natural language\ninstructions is limited by the available supervision, i.e. knowing when the\ninstruction has been carried out. We adapt the CLEVR visual question answering\ndataset to generate complex natural language navigation instructions and\naccompanying scene graphs, yielding an environment-agnostic supervised dataset.\nTo demonstrate the use of this data set, we map the scenes to the VizDoom\nenvironment and use the architecture in \\citet{gatedattention} to train an\nagent to carry out these more complex language instructions.",
          "link": "http://arxiv.org/abs/2106.01607",
          "publishedOn": "2021-06-04T01:12:31.229Z",
          "wordCount": 527,
          "title": "Grounding Complex Navigational Instructions Using Scene Graphs. (arXiv:2106.01607v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01615",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liao_Q/0/1/0/all/0/1\">Quanyu Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuezun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_B/0/1/0/all/0/1\">Bin Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1\">Bin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_S/0/1/0/all/0/1\">Siwei Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1\">Youbing Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1\">Qi Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xi Wu</a>",
          "description": "Fooling people with highly realistic fake images generated with Deepfake or\nGANs brings a great social disturbance to our society. Many methods have been\nproposed to detect fake images, but they are vulnerable to adversarial\nperturbations -- intentionally designed noises that can lead to the wrong\nprediction. Existing methods of attacking fake image detectors usually generate\nadversarial perturbations to perturb almost the entire image. This is redundant\nand increases the perceptibility of perturbations. In this paper, we propose a\nnovel method to disrupt the fake image detection by determining key pixels to a\nfake image detector and attacking only the key pixels, which results in the\n$L_0$ and the $L_2$ norms of adversarial perturbations much less than those of\nexisting works. Experiments on two public datasets with three fake image\ndetectors indicate that our proposed method achieves state-of-the-art\nperformance in both white-box and black-box attacks.",
          "link": "http://arxiv.org/abs/2106.01615",
          "publishedOn": "2021-06-04T01:12:31.216Z",
          "wordCount": 592,
          "title": "Imperceptible Adversarial Examples for Fake Image Detection. (arXiv:2106.01615v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01489",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Ziyun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinshao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Haojin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1\">Di Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Robertson_N/0/1/0/all/0/1\">Neil M. Robertson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clifton_D/0/1/0/all/0/1\">David A. Clifton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meinel_C/0/1/0/all/0/1\">Christoph Meinel</a>",
          "description": "Mutual knowledge distillation (MKD) improves a model by distilling knowledge\nfrom another model. However, not all knowledge is certain and correct,\nespecially under adverse conditions. For example, label noise usually leads to\nless reliable models due to the undesired memorisation [1, 2]. Wrong knowledge\nmisleads the learning rather than helps. This problem can be handled by two\naspects: (i) improving the reliability of a model where the knowledge is from\n(i.e., knowledge source's reliability); (ii) selecting reliable knowledge for\ndistillation. In the literature, making a model more reliable is widely studied\nwhile selective MKD receives little attention. Therefore, we focus on studying\nselective MKD and highlight its importance in this work.\n\nConcretely, a generic MKD framework, Confident knowledge selection followed\nby Mutual Distillation (CMD), is designed. The key component of CMD is a\ngeneric knowledge selection formulation, making the selection threshold either\nstatic (CMD-S) or progressive (CMD-P). Additionally, CMD covers two special\ncases: zero knowledge and all knowledge, leading to a unified MKD framework. We\nempirically find CMD-P performs better than CMD-S. The main reason is that a\nmodel's knowledge upgrades and becomes confident as the training progresses.\n\nExtensive experiments are present to demonstrate the effectiveness of CMD and\nthoroughly justify the design of CMD. For example, CMD-P obtains new\nstate-of-the-art results in robustness against label noise.",
          "link": "http://arxiv.org/abs/2106.01489",
          "publishedOn": "2021-06-04T01:12:31.198Z",
          "wordCount": 660,
          "title": "Not All Knowledge Is Created Equal. (arXiv:2106.01489v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01401",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_P/0/1/0/all/0/1\">Peng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jiasen Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongsheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mottaghi_R/0/1/0/all/0/1\">Roozbeh Mottaghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kembhavi_A/0/1/0/all/0/1\">Aniruddha Kembhavi</a>",
          "description": "Convolutional neural networks (CNNs) are ubiquitous in computer vision, with\na myriad of effective and efficient variations. Recently, Transformers --\noriginally introduced in natural language processing -- have been increasingly\nadopted in computer vision. While early adopters continue to employ CNN\nbackbones, the latest networks are end-to-end CNN-free Transformer solutions. A\nrecent surprising finding shows that a simple MLP based solution without any\ntraditional convolutional or Transformer components can produce effective\nvisual representations. While CNNs, Transformers and MLP-Mixers may be\nconsidered as completely disparate architectures, we provide a unified view\nshowing that they are in fact special cases of a more general method to\naggregate spatial context in a neural network stack. We present the \\model\n(CONText AggregatIon NEtwoRk), a general-purpose building block for multi-head\ncontext aggregation that can exploit long-range interactions \\emph{a la}\nTransformers while still exploiting the inductive bias of the local convolution\noperation leading to faster convergence speeds, often seen in CNNs. In contrast\nto Transformer-based methods that do not scale well to downstream tasks that\nrely on larger input image resolutions, our efficient network, named\n\\modellight, can be employed in object detection and instance segmentation\nnetworks such as DETR, RetinaNet and Mask-RCNN to obtain an impressive\ndetection mAP of 38.9, 43.8, 45.1 and mask mAP of 41.3, providing large\nimprovements of 6.6, 7.3, 6.9 and 6.6 pts respectively, compared to a ResNet-50\nbackbone with a comparable compute and parameter size. Our method also achieves\npromising results on self-supervised learning compared to DeiT on the DINO\nframework.",
          "link": "http://arxiv.org/abs/2106.01401",
          "publishedOn": "2021-06-04T01:12:31.192Z",
          "wordCount": 674,
          "title": "Container: Context Aggregation Network. (arXiv:2106.01401v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01504",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Killea_R/0/1/0/all/0/1\">Ryan Killea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bastani_S/0/1/0/all/0/1\">Saeed Bastani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McLachlan_P/0/1/0/all/0/1\">Paul McLachlan</a>",
          "description": "Point clouds are a basic data type that is increasingly of interest as 3D\ncontent becomes more ubiquitous. Applications using point clouds include\nvirtual, augmented, and mixed reality and autonomous driving. We propose a more\nefficient deep learning-based encoder architecture for point clouds compression\nthat incorporates principles from established 3D object detection and image\ncompression architectures. Through an ablation study, we show that\nincorporating the learned activation function from Computational Efficient\nNeural Image Compression (CENIC) and designing more parameter-efficient\nconvolutional blocks yields dramatic gains in efficiency and performance. Our\nproposed architecture incorporates Generalized Divisive Normalization\nactivations and propose a spatially separable InceptionV4-inspired block. We\nthen evaluate rate-distortion curves on the standard JPEG Pleno 8i Voxelized\nFull Bodies dataset to evaluate our model's performance. Our proposed\nmodifications outperform the baseline approaches by a small margin in terms of\nBjontegard delta rate and PSNR values, yet reduces necessary encoder\nconvolution operations by 8 percent and reduces total encoder parameters by 20\npercent. Our proposed architecture, when considered on its own, has a small\npenalty of 0.02 percent in Chamfer's Distance and 0.32 percent increased bit\nrate in Point to Plane Distance for the same peak signal-to-noise ratio.",
          "link": "http://arxiv.org/abs/2106.01504",
          "publishedOn": "2021-06-04T01:12:31.180Z",
          "wordCount": 639,
          "title": "DeepCompress: Efficient Point Cloud Geometry Compression. (arXiv:2106.01504v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01603",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Kunchang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xianhang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yali Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>",
          "description": "3D convolution is powerful for video classification but often computationally\nexpensive, recent studies mainly focus on decomposing it on spatial-temporal\nand/or channel dimensions. Unfortunately, most approaches fail to achieve a\npreferable balance between convolutional efficiency and feature-interaction\nsufficiency. For this reason, we propose a concise and novel Channel\nTensorization Network (CT-Net), by treating the channel dimension of input\nfeature as a multiplication of K sub-dimensions. On one hand, it naturally\nfactorizes convolution in a multiple dimension way, leading to a light\ncomputation burden. On the other hand, it can effectively enhance feature\ninteraction from different channels, and progressively enlarge the 3D receptive\nfield of such interaction to boost classification accuracy. Furthermore, we\nequip our CT-Module with a Tensor Excitation (TE) mechanism. It can learn to\nexploit spatial, temporal and channel attention in a high-dimensional manner,\nto improve the cooperative power of all the feature dimensions in our\nCT-Module. Finally, we flexibly adapt ResNet as our CT-Net. Extensive\nexperiments are conducted on several challenging video benchmarks, e.g.,\nKinetics-400, Something-Something V1 and V2. Our CT-Net outperforms a number of\nrecent SOTA approaches, in terms of accuracy and/or efficiency. The codes and\nmodels will be available on https://github.com/Andy1621/CT-Net.",
          "link": "http://arxiv.org/abs/2106.01603",
          "publishedOn": "2021-06-04T01:12:31.173Z",
          "wordCount": 637,
          "title": "CT-Net: Channel Tensorization Network for Video Classification. (arXiv:2106.01603v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01532",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Ang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ke_Q/0/1/0/all/0/1\">Qiuhong Ke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xingjun Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weng_H/0/1/0/all/0/1\">Haiqin Weng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zong_Z/0/1/0/all/0/1\">Zhiyuan Zong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_F/0/1/0/all/0/1\">Feng Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>",
          "description": "Deep image inpainting aims to restore damaged or missing regions in an image\nwith realistic contents. While having a wide range of applications such as\nobject removal and image recovery, deep inpainting techniques also have the\nrisk of being manipulated for image forgery. A promising countermeasure against\nsuch forgeries is deep inpainting detection, which aims to locate the inpainted\nregions in an image. In this paper, we make the first attempt towards universal\ndetection of deep inpainting, where the detection network can generalize well\nwhen detecting different deep inpainting methods. To this end, we first propose\na novel data generation approach to generate a universal training dataset,\nwhich imitates the noise discrepancies exist in real versus inpainted image\ncontents to train universal detectors. We then design a Noise-Image\nCross-fusion Network (NIX-Net) to effectively exploit the discriminative\ninformation contained in both the images and their noise patterns. We\nempirically show, on multiple benchmark datasets, that our approach outperforms\nexisting detection methods by a large margin and generalize well to unseen deep\ninpainting techniques. Our universal training dataset can also significantly\nboost the generalizability of existing detection methods.",
          "link": "http://arxiv.org/abs/2106.01532",
          "publishedOn": "2021-06-04T01:12:31.166Z",
          "wordCount": 629,
          "title": "Noise Doesn't Lie: Towards Universal Detection of Deep Inpainting. (arXiv:2106.01532v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01424",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cagrandi_M/0/1/0/all/0/1\">Marco Cagrandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cornia_M/0/1/0/all/0/1\">Marcella Cornia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stefanini_M/0/1/0/all/0/1\">Matteo Stefanini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baraldi_L/0/1/0/all/0/1\">Lorenzo Baraldi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cucchiara_R/0/1/0/all/0/1\">Rita Cucchiara</a>",
          "description": "Image captioning models have lately shown impressive results when applied to\nstandard datasets. Switching to real-life scenarios, however, constitutes a\nchallenge due to the larger variety of visual concepts which are not covered in\nexisting training sets. For this reason, novel object captioning (NOC) has\nrecently emerged as a paradigm to test captioning models on objects which are\nunseen during the training phase. In this paper, we present a novel approach\nfor NOC that learns to select the most relevant objects of an image, regardless\nof their adherence to the training set, and to constrain the generative process\nof a language model accordingly. Our architecture is fully-attentive and\nend-to-end trainable, also when incorporating constraints. We perform\nexperiments on the held-out COCO dataset, where we demonstrate improvements\nover the state of the art, both in terms of adaptability to novel objects and\ncaption quality.",
          "link": "http://arxiv.org/abs/2106.01424",
          "publishedOn": "2021-06-04T01:12:31.150Z",
          "wordCount": 591,
          "title": "Learning to Select: A Fully Attentive Approach for Novel Object Captioning. (arXiv:2106.01424v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01483",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hnewa_M/0/1/0/all/0/1\">Mazin Hnewa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radha_H/0/1/0/all/0/1\">Hayder Radha</a>",
          "description": "The area of domain adaptation has been instrumental in addressing the domain\nshift problem encountered by many applications. This problem arises due to the\ndifference between the distributions of source data used for training in\ncomparison with target data used during realistic testing scenarios. In this\npaper, we introduce a novel MultiScale Domain Adaptive YOLO (MS-DAYOLO)\nframework that employs multiple domain adaptation paths and corresponding\ndomain classifiers at different scales of the recently introduced YOLOv4 object\ndetector to generate domain-invariant features. We train and test our proposed\nmethod using popular datasets. Our experiments show significant improvements in\nobject detection performance when training YOLOv4 using the proposed MS-DAYOLO\nand when tested on target data representing challenging weather conditions for\nautonomous driving applications.",
          "link": "http://arxiv.org/abs/2106.01483",
          "publishedOn": "2021-06-04T01:12:31.140Z",
          "wordCount": 558,
          "title": "Multiscale Domain Adaptive YOLO for Cross-Domain Object Detection. (arXiv:2106.01483v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01487",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kusupati_A/0/1/0/all/0/1\">Aditya Kusupati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallingford_M/0/1/0/all/0/1\">Matthew Wallingford</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramanujan_V/0/1/0/all/0/1\">Vivek Ramanujan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Somani_R/0/1/0/all/0/1\">Raghav Somani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jae Sung Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pillutla_K/0/1/0/all/0/1\">Krishna Pillutla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1\">Prateek Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1\">Sham Kakade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farhadi_A/0/1/0/all/0/1\">Ali Farhadi</a>",
          "description": "Learning binary representations of instances and classes is a classical\nproblem with several high potential applications. In modern settings, the\ncompression of high-dimensional neural representations to low-dimensional\nbinary codes is a challenging task and often require large bit-codes to be\naccurate. In this work, we propose a novel method for Learning Low-dimensional\nbinary Codes (LLC) for instances as well as classes. Our method does not\nrequire any side-information, like annotated attributes or label meta-data, and\nlearns extremely low-dimensional binary codes (~20 bits for ImageNet-1K). The\nlearnt codes are super-efficient while still ensuring nearly optimal\nclassification accuracy for ResNet50 on ImageNet-1K. We demonstrate that the\nlearnt codes capture intrinsically important features in the data, by\ndiscovering an intuitive taxonomy over classes. We further quantitatively\nmeasure the quality of our codes by applying it to the efficient image\nretrieval as well as out-of-distribution (OOD) detection problems. For\nImageNet-100 retrieval problem, our learnt binary codes outperform 16 bit\nHashNet using only 10 bits and also are as accurate as 10 dimensional real\nrepresentations. Finally, our learnt binary codes can perform OOD detection,\nout-of-the-box, as accurately as a baseline that needs ~3000 samples to tune\nits threshold, while we require none. Code and pre-trained models are available\nat https://github.com/RAIVNLab/LLC.",
          "link": "http://arxiv.org/abs/2106.01487",
          "publishedOn": "2021-06-04T01:12:31.133Z",
          "wordCount": 652,
          "title": "LLC: Accurate, Multi-purpose Learnt Low-dimensional Binary Codes. (arXiv:2106.01487v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01553",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peng-Shuai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yu-Qi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_X/0/1/0/all/0/1\">Xin Tong</a>",
          "description": "Multilayer perceptrons (MLPs) have been successfully used to represent 3D\nshapes implicitly and compactly, by mapping 3D coordinates to the corresponding\nsigned distance values or occupancy values. In this paper, we propose a novel\npositional encoding scheme, called Spline Positional Encoding, to map the input\ncoordinates to a high dimensional space before passing them to MLPs, for\nhelping to recover 3D signed distance fields with fine-scale geometric details\nfrom unorganized 3D point clouds. We verified the superiority of our approach\nover other positional encoding schemes on tasks of 3D shape reconstruction from\ninput point clouds and shape space learning. The efficacy of our approach\nextended to image reconstruction is also demonstrated and evaluated.",
          "link": "http://arxiv.org/abs/2106.01553",
          "publishedOn": "2021-06-04T01:12:31.114Z",
          "wordCount": 555,
          "title": "Spline Positional Encoding for Learning 3D Implicit Signed Distance Fields. (arXiv:2106.01553v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/1912.01875",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yiming He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Wei Hu</a>",
          "description": "This paper addresses the problem of 3D hand pose estimation from a monocular\nRGB image. While previous methods have shown great success, the structure of\nhands has not been fully exploited, which is critical in pose estimation. To\nthis end, we propose a regularized graph representation learning under a\nconditional adversarial learning framework for 3D hand pose estimation, aiming\nto capture structural inter-dependencies of hand joints. In particular, we\nestimate an initial hand pose from a parametric hand model as a prior of hand\nstructure, which regularizes the inference of the structural deformation in the\nprior pose for accurate graph representation learning via residual graph\nconvolution. To optimize the hand structure further, we propose two\nbone-constrained loss functions, which characterize the morphable structure of\nhand poses explicitly. Also, we introduce an adversarial learning framework\nconditioned on the input image with a multi-source discriminator, which imposes\nthe structural constraints onto the distribution of generated 3D hand poses for\nanthropomorphically valid hand poses. Extensive experiments demonstrate that\nour model sets the new state-of-the-art in 3D hand pose estimation from a\nmonocular image on five standard benchmarks.",
          "link": "http://arxiv.org/abs/1912.01875",
          "publishedOn": "2021-06-04T01:12:30.464Z",
          "wordCount": 659,
          "title": "3D Hand Pose Estimation via Regularized Graph Representation Learning. (arXiv:1912.01875v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01863",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yuming Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_K/0/1/0/all/0/1\">Kelvin C.K. Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xintao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loy_C/0/1/0/all/0/1\">Chen Change Loy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Ziwei Liu</a>",
          "description": "Reference-based Super-Resolution (Ref-SR) has recently emerged as a promising\nparadigm to enhance a low-resolution (LR) input image by introducing an\nadditional high-resolution (HR) reference image. Existing Ref-SR methods mostly\nrely on implicit correspondence matching to borrow HR textures from reference\nimages to compensate for the information loss in input images. However,\nperforming local transfer is difficult because of two gaps between input and\nreference images: the transformation gap (e.g. scale and rotation) and the\nresolution gap (e.g. HR and LR). To tackle these challenges, we propose\nC2-Matching in this work, which produces explicit robust matching crossing\ntransformation and resolution. 1) For the transformation gap, we propose a\ncontrastive correspondence network, which learns transformation-robust\ncorrespondences using augmented views of the input image. 2) For the resolution\ngap, we adopt a teacher-student correlation distillation, which distills\nknowledge from the easier HR-HR matching to guide the more ambiguous LR-HR\nmatching. 3) Finally, we design a dynamic aggregation module to address the\npotential misalignment issue. In addition, to faithfully evaluate the\nperformance of Ref-SR under a realistic setting, we contribute the\nWebly-Referenced SR (WR-SR) dataset, mimicking the practical usage scenario.\nExtensive experiments demonstrate that our proposed C2-Matching significantly\noutperforms state of the arts by over 1dB on the standard CUFED5 benchmark.\nNotably, it also shows great generalizability on WR-SR dataset as well as\nrobustness across large scale and rotation transformations.",
          "link": "http://arxiv.org/abs/2106.01863",
          "publishedOn": "2021-06-04T01:12:30.458Z",
          "wordCount": 679,
          "title": "Robust Reference-based Super-Resolution via C2-Matching. (arXiv:2106.01863v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01883",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xue Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaojiang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jirui Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ming_Q/0/1/0/all/0/1\">Qi Ming</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wentao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1\">Qi Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Junchi Yan</a>",
          "description": "Existing rotated object detectors are mostly inherited from the horizontal\ndetection paradigm, as the latter has evolved into a well-developed area.\nHowever, these detectors are difficult to perform prominently in high-precision\ndetection due to the limitation of current regression loss design, especially\nfor objects with large aspect ratios. Taking the perspective that horizontal\ndetection is a special case for rotated object detection, in this paper, we are\nmotivated to change the design of rotation regression loss from induction\nparadigm to deduction methodology, in terms of the relation between rotation\nand horizontal detection. We show that one essential challenge is how to\nmodulate the coupled parameters in the rotation regression loss, as such the\nestimated parameters can influence to each other during the dynamic joint\noptimization, in an adaptive and synergetic way. Specifically, we first convert\nthe rotated bounding box into a 2-D Gaussian distribution, and then calculate\nthe Kullback-Leibler Divergence (KLD) between the Gaussian distributions as the\nregression loss. By analyzing the gradient of each parameter, we show that KLD\n(and its derivatives) can dynamically adjust the parameter gradients according\nto the characteristics of the object. It will adjust the importance (gradient\nweight) of the angle parameter according to the aspect ratio. This mechanism\ncan be vital for high-precision detection as a slight angle error would cause a\nserious accuracy drop for large aspect ratios objects. More importantly, we\nhave proved that KLD is scale invariant. We further show that the KLD loss can\nbe degenerated into the popular $l_{n}$-norm loss for horizontal detection.\nExperimental results on seven datasets using different detectors show its\nconsistent superiority, and codes are available at\nhttps://github.com/yangxue0827/RotationDetection.",
          "link": "http://arxiv.org/abs/2106.01883",
          "publishedOn": "2021-06-04T01:12:30.432Z",
          "wordCount": 731,
          "title": "Learning High-Precision Bounding Box for Rotated Object Detection via Kullback-Leibler Divergence. (arXiv:2106.01883v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02019",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lingjie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Habermann_M/0/1/0/all/0/1\">Marc Habermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudnev_V/0/1/0/all/0/1\">Viktor Rudnev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_K/0/1/0/all/0/1\">Kripasindhu Sarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jiatao Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theobalt_C/0/1/0/all/0/1\">Christian Theobalt</a>",
          "description": "We propose Neural Actor (NA), a new method for high-quality synthesis of\nhumans from arbitrary viewpoints and under arbitrary controllable poses. Our\nmethod is built upon recent neural scene representation and rendering works\nwhich learn representations of geometry and appearance from only 2D images.\nWhile existing works demonstrated compelling rendering of static scenes and\nplayback of dynamic scenes, photo-realistic reconstruction and rendering of\nhumans with neural implicit methods, in particular under user-controlled novel\nposes, is still difficult. To address this problem, we utilize a coarse body\nmodel as the proxy to unwarp the surrounding 3D space into a canonical pose. A\nneural radiance field learns pose-dependent geometric deformations and pose-\nand view-dependent appearance effects in the canonical space from multi-view\nvideo input. To synthesize novel views of high fidelity dynamic geometry and\nappearance, we leverage 2D texture maps defined on the body model as latent\nvariables for predicting residual deformations and the dynamic appearance.\nExperiments demonstrate that our method achieves better quality than the\nstate-of-the-arts on playback as well as novel pose synthesis, and can even\ngeneralize well to new poses that starkly differ from the training poses.\nFurthermore, our method also supports body shape control of the synthesized\nresults.",
          "link": "http://arxiv.org/abs/2106.02019",
          "publishedOn": "2021-06-04T01:12:30.426Z",
          "wordCount": 647,
          "title": "Neural Actor: Neural Free-view Synthesis of Human Actors with Pose Control. (arXiv:2106.02019v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01866",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kasaei_H/0/1/0/all/0/1\">Hamidreza Kasaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1\">Sha Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sasso_R/0/1/0/all/0/1\">Remo Sasso</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasaei_M/0/1/0/all/0/1\">Mohammadreza Kasaei</a>",
          "description": "A robot working in human-centric environments needs to know which kind of\nobjects exist in the scene, where they are, and how to grasp and manipulate\nvarious objects in different situations to help humans in everyday tasks.\nTherefore, object recognition and grasping are two key functionalities for such\nrobots. Most state-of-the-art tackles object recognition and grasping as two\nseparate problems while both use visual input. Furthermore, the knowledge of\nthe robot is fixed after the training phase. In such cases, if the robot faces\nnew object categories, it must retrain from scratch to incorporate new\ninformation without catastrophic interference. To address this problem, we\npropose a deep learning architecture with augmented memory capacities to handle\nopen-ended object recognition and grasping simultaneously. In particular, our\napproach takes multi-views of an object as input and jointly estimates\npixel-wise grasp configuration as well as a deep scale- and rotation-invariant\nrepresentation as outputs. The obtained representation is then used for\nopen-ended object recognition through a meta-active learning technique. We\ndemonstrate the ability of our approach to grasp never-seen-before objects and\nto rapidly learn new object categories using very few examples on-site in both\nsimulation and real-world settings.",
          "link": "http://arxiv.org/abs/2106.01866",
          "publishedOn": "2021-06-04T01:12:30.413Z",
          "wordCount": 632,
          "title": "Simultaneous Multi-View Object Recognition and Grasping in Open-Ended Domains. (arXiv:2106.01866v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02022",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ramamonjisoa_M/0/1/0/all/0/1\">Micha&#xeb;l Ramamonjisoa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Firman_M/0/1/0/all/0/1\">Michael Firman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watson_J/0/1/0/all/0/1\">Jamie Watson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lepetit_V/0/1/0/all/0/1\">Vincent Lepetit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turmukhambetov_D/0/1/0/all/0/1\">Daniyar Turmukhambetov</a>",
          "description": "We present a novel method for predicting accurate depths from monocular\nimages with high efficiency. This optimal efficiency is achieved by exploiting\nwavelet decomposition, which is integrated in a fully differentiable\nencoder-decoder architecture. We demonstrate that we can reconstruct\nhigh-fidelity depth maps by predicting sparse wavelet coefficients. In contrast\nwith previous works, we show that wavelet coefficients can be learned without\ndirect supervision on coefficients. Instead we supervise only the final depth\nimage that is reconstructed through the inverse wavelet transform. We\nadditionally show that wavelet coefficients can be learned in fully\nself-supervised scenarios, without access to ground-truth depth. Finally, we\napply our method to different state-of-the-art monocular depth estimation\nmodels, in each case giving similar or better results compared to the original\nmodel, while requiring less than half the multiply-adds in the decoder network.\nCode at https://github.com/nianticlabs/wavelet-monodepth",
          "link": "http://arxiv.org/abs/2106.02022",
          "publishedOn": "2021-06-04T01:12:30.393Z",
          "wordCount": 573,
          "title": "Single Image Depth Estimation using Wavelet Decomposition. (arXiv:2106.02022v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01835",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Neto_P/0/1/0/all/0/1\">Pedro C. Neto</a>",
          "description": "The diagnosis of prostate cancer faces a problem with overdiagnosis that\nleads to damaging side effects due to unnecessary treatment. Research has shown\nthat the use of multi-parametric magnetic resonance images to conduct biopsies\ncan drastically help to mitigate the overdiagnosis, thus reducing the side\neffects on healthy patients. This study aims to investigate the use of deep\nlearning techniques to explore computer-aid diagnosis based on MRI as input.\nSeveral diagnosis problems ranging from classification of lesions as being\nclinically significant or not to the detection and segmentation of lesions are\naddressed with deep learning based approaches.\n\nThis thesis tackled two main problems regarding the diagnosis of prostate\ncancer. Firstly, XmasNet was used to conduct two large experiments on the\nclassification of lesions. Secondly, detection and segmentation experiments\nwere conducted, first on the prostate and afterward on the prostate cancer\nlesions. The former experiments explored the lesions through a two-dimensional\nspace, while the latter explored models to work with three-dimensional inputs.\nFor this task, the 3D models explored were the 3D U-Net and a pretrained 3D\nResNet-18. A rigorous analysis of all these problems was conducted with a total\nof two networks, two cropping techniques, two resampling techniques, two crop\nsizes, five input sizes and data augmentations experimented for lesion\nclassification. While for segmentation two models, two input sizes and data\naugmentations were experimented. However, while the binary classification of\nthe clinical significance of lesions and the detection and segmentation of the\nprostate already achieve the desired results (0.870 AUC and 0.915 dice score\nrespectively), the classification of the PIRADS score and the segmentation of\nlesions still have a large margin to improve (0.664 accuracy and 0.690 dice\nscore respectively).",
          "link": "http://arxiv.org/abs/2106.01835",
          "publishedOn": "2021-06-04T01:12:30.381Z",
          "wordCount": 716,
          "title": "Deep Learning Based Analysis of Prostate Cancer from MP-MRI. (arXiv:2106.01835v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02036",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Girdhar_R/0/1/0/all/0/1\">Rohit Girdhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grauman_K/0/1/0/all/0/1\">Kristen Grauman</a>",
          "description": "We propose Anticipative Video Transformer (AVT), an end-to-end\nattention-based video modeling architecture that attends to the previously\nobserved video in order to anticipate future actions. We train the model\njointly to predict the next action in a video sequence, while also learning\nframe feature encoders that are predictive of successive future frames'\nfeatures. Compared to existing temporal aggregation strategies, AVT has the\nadvantage of both maintaining the sequential progression of observed actions\nwhile still capturing long-range dependencies--both critical for the\nanticipation task. Through extensive experiments, we show that AVT obtains the\nbest reported performance on four popular action anticipation benchmarks:\nEpicKitchens-55, EpicKitchens-100, EGTEA Gaze+, and 50-Salads, including\noutperforming all submissions to the EpicKitchens-100 CVPR'21 challenge.",
          "link": "http://arxiv.org/abs/2106.02036",
          "publishedOn": "2021-06-04T01:12:30.375Z",
          "wordCount": 557,
          "title": "Anticipative Video Transformer. (arXiv:2106.02036v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01896",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Balnarsaiah_B/0/1/0/all/0/1\">Battula Balnarsaiah</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rajitha_G/0/1/0/all/0/1\">G Rajitha</a>",
          "description": "Optical image data have been used by the Remote Sensing workforce to study\nland use and cover since such data is easily interpretable. Synthetic Aperture\nRadar (SAR) has the characteristic of obtaining images during all-day,\nall-weather and provides object information that is different from visible and\ninfrared sensors. However, SAR images have more speckle noise and fewer\ndimensions. This paper presents a method for denoising, feature extraction and\ncompares classifications of Optical and SAR images. The image was denoised\nusing K-Singular Value Decomposition (K-SVD) algorithm. A method to map the\nextraordinary goal signatures to be had withinside the SAR or Optical image\nusing support vector machine (SVM) through offering given the enter facts to\nthe supervised classifier. Initially, the Gray Level Histogram (GLH) and Gray\nLevel Co-occurrence Matrix (GLCM) are used for feature extraction. Secondly,\nthe extracted feature vectors from the first step were combined using\ncorrelation analysis to reduce the dimensionality of the feature spaces.\nThirdly, the Classification of SAR images was done in Sparse Representations\nClassification (SRC). The above-mentioned classifications techniques were\ndeveloped and performance parameters are accuracy and Kappa Coefficient\ncalculated using MATLAB 2018a.",
          "link": "http://arxiv.org/abs/2106.01896",
          "publishedOn": "2021-06-04T01:12:30.362Z",
          "wordCount": 634,
          "title": "Denoising and Optical and SAR Image Classifications Based on Feature Extraction and Sparse Representation. (arXiv:2106.01896v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02034",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rao_Y/0/1/0/all/0/1\">Yongming Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wenliang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Benlin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jiwen Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1\">Cho-Jui Hsieh</a>",
          "description": "Attention is sparse in vision transformers. We observe the final prediction\nin vision transformers is only based on a subset of most informative tokens,\nwhich is sufficient for accurate image recognition. Based on this observation,\nwe propose a dynamic token sparsification framework to prune redundant tokens\nprogressively and dynamically based on the input. Specifically, we devise a\nlightweight prediction module to estimate the importance score of each token\ngiven the current features. The module is added to different layers to prune\nredundant tokens hierarchically. To optimize the prediction module in an\nend-to-end manner, we propose an attention masking strategy to differentiably\nprune a token by blocking its interactions with other tokens. Benefiting from\nthe nature of self-attention, the unstructured sparse tokens are still hardware\nfriendly, which makes our framework easy to achieve actual speed-up. By\nhierarchically pruning 66% of the input tokens, our method greatly reduces\n31%~37% FLOPs and improves the throughput by over 40% while the drop of\naccuracy is within 0.5% for various vision transformers. Equipped with the\ndynamic token sparsification framework, DynamicViT models can achieve very\ncompetitive complexity/accuracy trade-offs compared to state-of-the-art CNNs\nand vision transformers on ImageNet. Code is available at\nhttps://github.com/raoyongming/DynamicViT",
          "link": "http://arxiv.org/abs/2106.02034",
          "publishedOn": "2021-06-04T01:12:30.337Z",
          "wordCount": 644,
          "title": "DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification. (arXiv:2106.02034v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01805",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiang_T/0/1/0/all/0/1\">Tiange Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chaoyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yang Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Siqi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1\">Hongliang Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_W/0/1/0/all/0/1\">Weidong Cai</a>",
          "description": "Regularizers helped deep neural networks prevent feature co-adaptations.\nDropout,as a commonly used regularization technique, stochastically disables\nneuron ac-tivations during network optimization. However, such complete feature\ndisposal can affect the feature representation and network understanding.\nToward betterdescriptions of latent representations, we present DropGraph that\nlearns regularization function by constructing a stand-alone graph from the\nbackbone features. DropGraph first samples stochastic spatial feature vectors\nand then incorporates graph reasoning methods to generate feature map\ndistortions. This add-on graph regularizes the network during training and can\nbe completely skipped during inference. We provide intuitions on the linkage\nbetween graph reasoning andDropout with further discussions on how partial\ngraph reasoning method reduces feature correlations. To this end, we\nextensively study the modeling of graphvertex dependencies and the utilization\nof the graph for distorting backbone featuremaps. DropGraph was validated on\nfour tasks with a total of 7 different datasets.The experimental results show\nthat our method outperforms other state-of-the-art regularizers while leaving\nthe base model structure unmodified during inference.",
          "link": "http://arxiv.org/abs/2106.01805",
          "publishedOn": "2021-06-04T01:12:30.330Z",
          "wordCount": 599,
          "title": "Partial Graph Reasoning for Neural Network Regularization. (arXiv:2106.01805v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01861",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kinoshita_Y/0/1/0/all/0/1\">Yuma Kinoshita</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kiya_H/0/1/0/all/0/1\">Hitoshi Kiya</a>",
          "description": "In this paper, we propose a novel method for separately estimating spectral\ndistributions from images captured by a typical RGB camera. The proposed method\nallows us to separately estimate a spectral distribution of illumination,\nreflectance, or camera sensitivity, while recent hyperspectral cameras are\nlimited to capturing a joint spectral distribution from a scene. In addition,\nthe use of Bayesian inference makes it possible to take into account prior\ninformation of both spectral distributions and image noise as probability\ndistributions. As a result, the proposed method can estimate spectral\ndistributions in a unified way, and it can enhance the robustness of the\nestimation against noise, which conventional spectral-distribution estimation\nmethods cannot. The use of Bayesian inference also enables us to obtain the\nconfidence of estimation results. In an experiment, the proposed method is\nshown not only to outperform conventional estimation methods in terms of RMSE\nbut also to be robust against noise.",
          "link": "http://arxiv.org/abs/2106.01861",
          "publishedOn": "2021-06-04T01:12:30.299Z",
          "wordCount": 599,
          "title": "Separated-Spectral-Distribution Estimation Based on Bayesian Inference with Single RGB Camera. (arXiv:2106.01861v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01830",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Fukuda_A/0/1/0/all/0/1\">Akihiro Fukuda</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Han_C/0/1/0/all/0/1\">Changhee Han</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hakamada_K/0/1/0/all/0/1\">Kazumi Hakamada</a>",
          "description": "Machine Learning-based fast and quantitative automated screening plays a key\nrole in analyzing human bones on Computed Tomography (CT) scans. However,\ndespite the requirement in drug safety assessment, such research is rare on\nanimal fetus micro-CT scans due to its laborious data collection and\nannotation. Therefore, we propose various bone feature engineering techniques\nto thoroughly automate the skeletal localization/labeling/abnormality detection\nof rat fetuses on whole-body micro-CT scans with minimum effort. Despite\nlimited training data of 49 fetuses, in skeletal labeling and abnormality\ndetection, we achieve accuracy of 0.900 and 0.810, respectively.",
          "link": "http://arxiv.org/abs/2106.01830",
          "publishedOn": "2021-06-04T01:12:30.274Z",
          "wordCount": 550,
          "title": "Effort-free Automated Skeletal Abnormality Detection of Rat Fetuses on Whole-body Micro-CT Scans. (arXiv:2106.01830v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01428",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Zenglin Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yunlu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gavves_E/0/1/0/all/0/1\">Efstratios Gavves</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mettes_P/0/1/0/all/0/1\">Pascal Mettes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Snoek_C/0/1/0/all/0/1\">Cees G.M. Snoek</a>",
          "description": "The goal of this paper is guided image filtering, which emphasizes the\nimportance of structure transfer during filtering by means of an additional\nguidance image. Where classical guided filters transfer structures using\nhand-designed functions, recent guided filters have been considerably advanced\nthrough parametric learning of deep networks. The state-of-the-art leverages\ndeep networks to estimate the two core coefficients of the guided filter. In\nthis work, we posit that simultaneously estimating both coefficients is\nsuboptimal, resulting in halo artifacts and structure inconsistencies. Inspired\nby unsharp masking, a classical technique for edge enhancement that requires\nonly a single coefficient, we propose a new and simplified formulation of the\nguided filter. Our formulation enjoys a filtering prior from a low-pass filter\nand enables explicit structure transfer by estimating a single coefficient.\nBased on our proposed formulation, we introduce a successive guided filtering\nnetwork, which provides multiple filtering results from a single network,\nallowing for a trade-off between accuracy and efficiency. Extensive ablations,\ncomparisons and analysis show the effectiveness and efficiency of our\nformulation and network, resulting in state-of-the-art results across filtering\ntasks like upsampling, denoising, and cross-modality filtering. Code is\navailable at \\url{https://github.com/shizenglin/Unsharp-Mask-Guided-Filtering}.",
          "link": "http://arxiv.org/abs/2106.01428",
          "publishedOn": "2021-06-04T01:12:30.059Z",
          "wordCount": 623,
          "title": "Unsharp Mask Guided Filtering. (arXiv:2106.01428v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01970",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiuming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_P/0/1/0/all/0/1\">Pratul P. Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_B/0/1/0/all/0/1\">Boyang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Debevec_P/0/1/0/all/0/1\">Paul Debevec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freeman_W/0/1/0/all/0/1\">William T. Freeman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barron_J/0/1/0/all/0/1\">Jonathan T. Barron</a>",
          "description": "We address the problem of recovering the shape and spatially-varying\nreflectance of an object from posed multi-view images of the object illuminated\nby one unknown lighting condition. This enables the rendering of novel views of\nthe object under arbitrary environment lighting and editing of the object's\nmaterial properties. The key to our approach, which we call Neural Radiance\nFactorization (NeRFactor), is to distill the volumetric geometry of a Neural\nRadiance Field (NeRF) [Mildenhall et al. 2020] representation of the object\ninto a surface representation and then jointly refine the geometry while\nsolving for the spatially-varying reflectance and the environment lighting.\nSpecifically, NeRFactor recovers 3D neural fields of surface normals, light\nvisibility, albedo, and Bidirectional Reflectance Distribution Functions\n(BRDFs) without any supervision, using only a re-rendering loss, simple\nsmoothness priors, and a data-driven BRDF prior learned from real-world BRDF\nmeasurements. By explicitly modeling light visibility, NeRFactor is able to\nseparate shadows from albedo and synthesize realistic soft or hard shadows\nunder arbitrary lighting conditions. NeRFactor is able to recover convincing 3D\nmodels for free-viewpoint relighting in this challenging and underconstrained\ncapture setup for both synthetic and real scenes. Qualitative and quantitative\nexperiments show that NeRFactor outperforms classic and deep learning-based\nstate of the art across various tasks. Our code and data are available at\npeople.csail.mit.edu/xiuming/projects/nerfactor/.",
          "link": "http://arxiv.org/abs/2106.01970",
          "publishedOn": "2021-06-04T01:12:30.038Z",
          "wordCount": 668,
          "title": "NeRFactor: Neural Factorization of Shape and Reflectance Under an Unknown Illumination. (arXiv:2106.01970v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.14739",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jichao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siarohin_A/0/1/0/all/0/1\">Aliaksandr Siarohin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">Hao Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jingjing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sangineto_E/0/1/0/all/0/1\">Enver Sangineto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sebe_N/0/1/0/all/0/1\">Nicu Sebe</a>",
          "description": "Controllable person image generation aims to produce realistic human images\nwith desirable attributes (e.g., the given pose, cloth textures or hair style).\nHowever, the large spatial misalignment between the source and target images\nmakes the standard architectures for image-to-image translation not suitable\nfor this task. Most of the state-of-the-art architectures avoid the alignment\nstep during the generation, which causes many artifacts, especially for person\nimages with complex textures. To solve this problem, we introduce a novel\nSpatially-Adaptive Warped Normalization (SAWN), which integrates a learned\nflow-field to warp modulation parameters. This allows us to align person\nspatial-adaptive styles with pose features efficiently. Moreover, we propose a\nnovel self-training part replacement strategy to refine the pretrained model\nfor the texture-transfer task, significantly improving the quality of the\ngenerated cloth and the preservation ability of irrelevant regions. Our\nexperimental results on the widely used DeepFashion dataset demonstrate a\nsignificant improvement of the proposed method over the state-of-the-art\nmethods on both pose-transfer and texture-transfer tasks. The source code is\navailable at https://github.com/zhangqianhui/Sawn.",
          "link": "http://arxiv.org/abs/2105.14739",
          "publishedOn": "2021-06-04T01:12:30.023Z",
          "wordCount": 628,
          "title": "Controllable Person Image Synthesis with Spatially-Adaptive Warped Normalization. (arXiv:2105.14739v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.07660",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+David_E/0/1/0/all/0/1\">Etienne David</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Serouart_M/0/1/0/all/0/1\">Mario Serouart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_D/0/1/0/all/0/1\">Daniel Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madec_S/0/1/0/all/0/1\">Simon Madec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Velumani_K/0/1/0/all/0/1\">Kaaviya Velumani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shouyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Espinosa_F/0/1/0/all/0/1\">Francisco Pinto Espinosa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafiee_S/0/1/0/all/0/1\">Shahameh Shafiee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tahir_I/0/1/0/all/0/1\">Izzat S. A. Tahir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsujimoto_H/0/1/0/all/0/1\">Hisashi Tsujimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nasuda_S/0/1/0/all/0/1\">Shuhei Nasuda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1\">Bangyou Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kichgessner_N/0/1/0/all/0/1\">Norbert Kichgessner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aasen_H/0/1/0/all/0/1\">Helge Aasen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hund_A/0/1/0/all/0/1\">Andreas Hund</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sadhegi_Tehran_P/0/1/0/all/0/1\">Pouria Sadhegi-Tehran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagasawa_K/0/1/0/all/0/1\">Koichi Nagasawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishikawa_G/0/1/0/all/0/1\">Goro Ishikawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dandrifosse_S/0/1/0/all/0/1\">S&#xe9;bastien Dandrifosse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carlier_A/0/1/0/all/0/1\">Alexis Carlier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mercatoris_B/0/1/0/all/0/1\">Benoit Mercatoris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuroki_K/0/1/0/all/0/1\">Ken Kuroki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haozhou Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishii_M/0/1/0/all/0/1\">Masanori Ishii</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Badhon_M/0/1/0/all/0/1\">Minhajul A. Badhon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pozniak_C/0/1/0/all/0/1\">Curtis Pozniak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+LeBauer_D/0/1/0/all/0/1\">David Shaner LeBauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lilimo_M/0/1/0/all/0/1\">Morten Lilimo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poland_J/0/1/0/all/0/1\">Jesse Poland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chapman_S/0/1/0/all/0/1\">Scott Chapman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Solan_B/0/1/0/all/0/1\">Benoit de Solan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baret_F/0/1/0/all/0/1\">Fr&#xe9;d&#xe9;ric Baret</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stavness_I/0/1/0/all/0/1\">Ian Stavness</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1\">Wei Guo</a>",
          "description": "The Global Wheat Head Detection (GWHD) dataset was created in 2020 and has\nassembled 193,634 labelled wheat heads from 4,700 RGB images acquired from\nvarious acquisition platforms and 7 countries/institutions. With an associated\ncompetition hosted in Kaggle, GWHD has successfully attracted attention from\nboth the computer vision and agricultural science communities. From this first\nexperience in 2020, a few avenues for improvements have been identified,\nespecially from the perspective of data size, head diversity and label\nreliability. To address these issues, the 2020 dataset has been reexamined,\nrelabeled, and augmented by adding 1,722 images from 5 additional countries,\nallowing for 81,553 additional wheat heads to be added. We now release a new\nversion of the Global Wheat Head Detection (GWHD) dataset in 2021, which is\nbigger, more diverse, and less noisy than the 2020 version. The GWHD 2021 is\nnow publicly available at this http URL and a new data challenge\nhas been organized on AIcrowd to make use of this updated dataset.",
          "link": "http://arxiv.org/abs/2105.07660",
          "publishedOn": "2021-06-04T01:12:30.017Z",
          "wordCount": 713,
          "title": "Global Wheat Head Dataset 2021: more diversity to improve the benchmarking of wheat head localization methods. (arXiv:2105.07660v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01629",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moing_G/0/1/0/all/0/1\">Guillaume Le Moing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vu_T/0/1/0/all/0/1\">Tuan-Hung Vu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_H/0/1/0/all/0/1\">Himalaya Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_P/0/1/0/all/0/1\">Patrick P&#xe9;rez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cord_M/0/1/0/all/0/1\">Matthieu Cord</a>",
          "description": "Despite the recent progress of generative adversarial networks (GANs) at\nsynthesizing photo-realistic images, producing complex urban scenes remains a\nchallenging problem. Previous works break down scene generation into two\nconsecutive phases: unconditional semantic layout synthesis and image synthesis\nconditioned on layouts. In this work, we propose to condition layout generation\nas well for higher semantic control: given a vector of class proportions, we\ngenerate layouts with matching composition. To this end, we introduce a\nconditional framework with novel architecture designs and learning objectives,\nwhich effectively accommodates class proportions to guide the scene generation\nprocess. The proposed architecture also allows partial layout editing with\ninteresting applications. Thanks to the semantic control, we can produce\nlayouts close to the real distribution, helping enhance the whole scene\ngeneration process. On different metrics and urban scene benchmarks, our models\noutperform existing baselines. Moreover, we demonstrate the merit of our\napproach for data augmentation: semantic segmenters trained on real\nlayout-image pairs along with additional ones generated by our approach\noutperform models only trained on real pairs.",
          "link": "http://arxiv.org/abs/2106.01629",
          "publishedOn": "2021-06-04T01:12:30.009Z",
          "wordCount": 611,
          "title": "Semantic Palette: Guiding Scene Generation with Class Proportions. (arXiv:2106.01629v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01700",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bayramoglu_N/0/1/0/all/0/1\">Neslihan Bayramoglu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nieminen_M/0/1/0/all/0/1\">Miika T. Nieminen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Saarakkala_S/0/1/0/all/0/1\">Simo Saarakkala</a>",
          "description": "Objective is to assess the ability of texture features for detecting\nradiographic patellofemoral osteoarthritis (PFOA) from knee lateral view\nradiographs. We used lateral view knee radiographs from MOST public use\ndatasets (n = 5507 knees). Patellar region-of-interest (ROI) was automatically\ndetected using landmark detection tool (BoneFinder). Hand-crafted features,\nbased on LocalBinary Patterns (LBP), were then extracted to describe the\npatellar texture. First, a machine learning model (Gradient Boosting Machine)\nwas trained to detect radiographic PFOA from the LBP features. Furthermore, we\nused end-to-end trained deep convolutional neural networks (CNNs) directly on\nthe texture patches for detecting the PFOA. The proposed classification models\nwere eventually compared with more conventional reference models that use\nclinical assessments and participant characteristics such as age, sex, body\nmass index(BMI), the total WOMAC score, and tibiofemoral Kellgren-Lawrence (KL)\ngrade. Atlas-guided visual assessment of PFOA status by expert readers provided\nin the MOST public use datasets was used as a classification outcome for the\nmodels. Performance of prediction models was assessed using the area under the\nreceiver operating characteristic curve (ROC AUC), the area under the\nprecision-recall (PR) curve-average precision (AP)-, and Brier score in the\nstratified 5-fold cross validation setting.Of the 5507 knees, 953 (17.3%) had\nPFOA. AUC and AP for the strongest reference model including age, sex, BMI,\nWOMAC score, and tibiofemoral KL grade to predict PFOA were 0.817 and 0.487,\nrespectively. Textural ROI classification using CNN significantly improved the\nprediction performance (ROC AUC= 0.889, AP= 0.714). We present the first study\nthat analyses patellar bone texture for diagnosing PFOA. Our results\ndemonstrates the potential of using texture features of patella to predict\nPFOA.",
          "link": "http://arxiv.org/abs/2106.01700",
          "publishedOn": "2021-06-04T01:12:29.989Z",
          "wordCount": 721,
          "title": "Machine Learning Based Texture Analysis of Patella from X-Rays for Detecting Patellofemoral Osteoarthritis. (arXiv:2106.01700v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2010.11929",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dosovitskiy_A/0/1/0/all/0/1\">Alexey Dosovitskiy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beyer_L/0/1/0/all/0/1\">Lucas Beyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolesnikov_A/0/1/0/all/0/1\">Alexander Kolesnikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weissenborn_D/0/1/0/all/0/1\">Dirk Weissenborn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1\">Xiaohua Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Unterthiner_T/0/1/0/all/0/1\">Thomas Unterthiner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dehghani_M/0/1/0/all/0/1\">Mostafa Dehghani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Minderer_M/0/1/0/all/0/1\">Matthias Minderer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heigold_G/0/1/0/all/0/1\">Georg Heigold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gelly_S/0/1/0/all/0/1\">Sylvain Gelly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uszkoreit_J/0/1/0/all/0/1\">Jakob Uszkoreit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1\">Neil Houlsby</a>",
          "description": "While the Transformer architecture has become the de-facto standard for\nnatural language processing tasks, its applications to computer vision remain\nlimited. In vision, attention is either applied in conjunction with\nconvolutional networks, or used to replace certain components of convolutional\nnetworks while keeping their overall structure in place. We show that this\nreliance on CNNs is not necessary and a pure transformer applied directly to\nsequences of image patches can perform very well on image classification tasks.\nWhen pre-trained on large amounts of data and transferred to multiple mid-sized\nor small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision\nTransformer (ViT) attains excellent results compared to state-of-the-art\nconvolutional networks while requiring substantially fewer computational\nresources to train.",
          "link": "http://arxiv.org/abs/2010.11929",
          "publishedOn": "2021-06-04T01:12:29.982Z",
          "wordCount": 668,
          "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. (arXiv:2010.11929v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01907",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Feng_J/0/1/0/all/0/1\">Jinglun Feng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_L/0/1/0/all/0/1\">Liang Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Biao_J/0/1/0/all/0/1\">Jiang Biao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xiao_J/0/1/0/all/0/1\">Jizhong Xiao</a>",
          "description": "Ground Penetrating Radar (GPR) is an effective non-destructive evaluation\n(NDE) device for inspecting and surveying subsurface objects (i.e., rebars,\nutility pipes) in complex environments. However, the current practice for GPR\ndata collection requires a human inspector to move a GPR cart along pre-marked\ngrid lines and record the GPR data in both X and Y directions for\npost-processing by 3D GPR imaging software. It is time-consuming and tedious\nwork to survey a large area. Furthermore, identifying the subsurface targets\ndepends on the knowledge of an experienced engineer, who has to make manual and\nsubjective interpretation that limits the GPR applications, especially in\nlarge-scale scenarios. In addition, the current GPR imaging technology is not\nintuitive, and not for normal users to understand, and not friendly to\nvisualize. To address the above challenges, this paper presents a novel robotic\nsystem to collect GPR data, interpret GPR data, localize the underground\nutilities, reconstruct and visualize the underground objects' dense point cloud\nmodel in a user-friendly manner. This system is composed of three modules: 1) a\nvision-aided Omni-directional robotic data collection platform, which enables\nthe GPR antenna to scan the target area freely with an arbitrary trajectory\nwhile using a visual-inertial-based positioning module tags the GPR\nmeasurements with positioning information; 2) a deep neural network (DNN)\nmigration module to interpret the raw GPR B-scan image into a cross-section of\nobject model; 3) a DNN-based 3D reconstruction method, i.e., GPRNet, to\ngenerate underground utility model represented as fine 3D point cloud.\nComparative studies on synthetic and field GPR raw data with various\nincompleteness and noise are performed.",
          "link": "http://arxiv.org/abs/2106.01907",
          "publishedOn": "2021-06-04T01:12:29.969Z",
          "wordCount": 710,
          "title": "Robotic Inspection and 3D GPR-based Reconstruction for Underground Utilities. (arXiv:2106.01907v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01596",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Ho Hin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1\">Yucheng Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xin Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_S/0/1/0/all/0/1\">Shunxing Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Landman_B/0/1/0/all/0/1\">Bennett A. Landman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huo_Y/0/1/0/all/0/1\">Yuankai Huo</a>",
          "description": "Contrastive learning has shown superior performance in embedding global and\nspatial invariant features in computer vision (e.g., image classification).\nHowever, its overall success of embedding local and spatial variant features is\nstill limited, especially for semantic segmentation. In a per-pixel prediction\ntask, more than one label can exist in a single image for segmentation (e.g.,\nan image contains both cat, dog, and grass), thereby it is difficult to define\n'positive' or 'negative' pairs in a canonical contrastive learning setting. In\nthis paper, we propose an attention-guided supervised contrastive learning\napproach to highlight a single semantic object every time as the target. With\nour design, the same image can be embedded to different semantic clusters with\nsemantic attention (i.e., coerce semantic masks) as an additional input\nchannel. To achieve such attention, a novel two-stage training strategy is\npresented. We evaluate the proposed method on multi-organ medical image\nsegmentation task, as our major task, with both in-house data and BTCV 2015\ndatasets. Comparing with the supervised and semi-supervised training\nstate-of-the-art in the backbone of ResNet-50, our proposed pipeline yields\nsubstantial improvement of 5.53% and 6.09% in Dice score for both medical image\nsegmentation cohorts respectively. The performance of the proposed method on\nnatural images is assessed via PASCAL VOC 2012 dataset, and achieves 2.75%\nsubstantial improvement.",
          "link": "http://arxiv.org/abs/2106.01596",
          "publishedOn": "2021-06-04T01:12:29.963Z",
          "wordCount": 664,
          "title": "Attention-Guided Supervised Contrastive Learning for Semantic Segmentation. (arXiv:2106.01596v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01927",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Ao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Haoyuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hechen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1\">Peng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Weiming Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wanli Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_S/0/1/0/all/0/1\">Shuojia Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grzegorzek_M/0/1/0/all/0/1\">Marcin Grzegorzek</a>",
          "description": "Image classification has achieved unprecedented advance with the the rapid\ndevelopment of deep learning. However, the classification of tiny object images\nis still not well investigated. In this paper, we first briefly review the\ndevelopment of Convolutional Neural Network and Visual Transformer in deep\nlearning, and introduce the sources and development of conventional noises and\nadversarial attacks. Then we use various models of Convolutional Neural Network\nand Visual Transformer to conduct a series of experiments on the image dataset\nof tiny objects (sperms and impurities), and compare various evaluation metrics\nin the experimental results to obtain a model with stable performance. Finally,\nwe discuss the problems in the classification of tiny objects and make a\nprospect for the classification of tiny objects in the future.",
          "link": "http://arxiv.org/abs/2106.01927",
          "publishedOn": "2021-06-04T01:12:29.945Z",
          "wordCount": 599,
          "title": "A Comparison for Anti-noise Robustness of Deep Learning Classification Methods on a Tiny Object Image Dataset: from Convolutional Neural Network to Visual Transformer and Performer. (arXiv:2106.01927v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2012.03129",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khaki_S/0/1/0/all/0/1\">Saeed Khaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1\">Hieu Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lizhi Wang</a>",
          "description": "Large-scale crop yield estimation is, in part, made possible due to the\navailability of remote sensing data allowing for the continuous monitoring of\ncrops throughout their growth cycle. Having this information allows\nstakeholders the ability to make real-time decisions to maximize yield\npotential. Although various models exist that predict yield from remote sensing\ndata, there currently does not exist an approach that can estimate yield for\nmultiple crops simultaneously, and thus leads to more accurate predictions. A\nmodel that predicts the yield of multiple crops and concurrently considers the\ninteraction between multiple crop yields. We propose a new convolutional neural\nnetwork model called YieldNet which utilizes a novel deep learning framework\nthat uses transfer learning between corn and soybean yield predictions by\nsharing the weights of the backbone feature extractor. Additionally, to\nconsider the multi-target response variable, we propose a new loss function. We\nconduct our experiment using data from 1,132 counties for corn and 1,076\ncounties for soybean across the United States. Numerical results demonstrate\nthat our proposed method accurately predicts corn and soybean yield from one to\nfour months before the harvest with a MAE being 8.74% and 8.70% of the average\nyield, respectively, and is competitive to other state-of-the-art approaches.",
          "link": "http://arxiv.org/abs/2012.03129",
          "publishedOn": "2021-06-04T01:12:29.920Z",
          "wordCount": 714,
          "title": "Simultaneous Corn and Soybean Yield Prediction from Remote Sensing Data Using Deep Transfer Learning. (arXiv:2012.03129v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01667",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alcazar_J/0/1/0/all/0/1\">Juan Leon Alcazar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mai_L/0/1/0/all/0/1\">Long Mai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perazzi_F/0/1/0/all/0/1\">Federico Perazzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Joon-Young Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arbelaez_P/0/1/0/all/0/1\">Pablo Arbelaez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1\">Bernard Ghanem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heilbron_F/0/1/0/all/0/1\">Fabian Caba Heilbron</a>",
          "description": "Humans are arguably one of the most important subjects in video streams, many\nreal-world applications such as video summarization or video editing workflows\noften require the automatic search and retrieval of a person of interest.\nDespite tremendous efforts in the person reidentification and retrieval\ndomains, few works have developed audiovisual search strategies. In this paper,\nwe present the Audiovisual Person Search dataset (APES), a new dataset composed\nof untrimmed videos whose audio (voices) and visual (faces) streams are densely\nannotated. APES contains over 1.9K identities labeled along 36 hours of video,\nmaking it the largest dataset available for untrimmed audiovisual person\nsearch. A key property of APES is that it includes dense temporal annotations\nthat link faces to speech segments of the same identity. To showcase the\npotential of our new dataset, we propose an audiovisual baseline and benchmark\nfor person retrieval. Our study shows that modeling audiovisual cues benefits\nthe recognition of people's identities. To enable reproducibility and promote\nfuture research, the dataset annotations and baseline code are available at:\nhttps://github.com/fuankarion/audiovisual-person-search",
          "link": "http://arxiv.org/abs/2106.01667",
          "publishedOn": "2021-06-04T01:12:29.891Z",
          "wordCount": 611,
          "title": "APES: Audiovisual Person Search in Untrimmed Video. (arXiv:2106.01667v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01862",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Paredes_Valles_F/0/1/0/all/0/1\">Federico Paredes-Vall&#xe9;s</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hagenaars_J/0/1/0/all/0/1\">Jesse Hagenaars</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Croon_G/0/1/0/all/0/1\">Guido de Croon</a>",
          "description": "Neuromorphic sensing and computing hold a promise for highly energy-efficient\nand high-bandwidth-sensor processing. A major challenge for neuromorphic\ncomputing is that learning algorithms for traditional artificial neural\nnetworks (ANNs) do not transfer directly to spiking neural networks (SNNs) due\nto the discrete spikes and more complex neuronal dynamics. As a consequence,\nSNNs have not yet been successfully applied to complex, large-scale tasks. In\nthis article, we focus on the self-supervised learning problem of optical flow\nestimation from event-based camera inputs, and investigate the changes that are\nnecessary to the state-of-the-art ANN training pipeline in order to\nsuccessfully tackle it with SNNs. More specifically, we first modify the input\nevent representation to encode a much smaller time slice with minimal explicit\ntemporal information. Consequently, we make the network's neuronal dynamics and\nrecurrent connections responsible for integrating information over time.\nMoreover, we reformulate the self-supervised loss function for event-based\noptical flow to improve its convexity. We perform experiments with various\ntypes of recurrent ANNs and SNNs using the proposed pipeline. Concerning SNNs,\nwe investigate the effects of elements such as parameter initialization and\noptimization, surrogate gradient shape, and adaptive neuronal mechanisms. We\nfind that initialization and surrogate gradient width play a crucial part in\nenabling learning with sparse inputs, while the inclusion of adaptivity and\nlearnable neuronal parameters can improve performance. We show that the\nperformance of the proposed ANNs and SNNs are on par with that of the current\nstate-of-the-art ANNs trained in a self-supervised manner.",
          "link": "http://arxiv.org/abs/2106.01862",
          "publishedOn": "2021-06-04T01:12:29.877Z",
          "wordCount": 686,
          "title": "Self-Supervised Learning of Event-Based Optical Flow with Spiking Neural Networks. (arXiv:2106.01862v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01467",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akhmetov_K/0/1/0/all/0/1\">Kamil Akhmetov</a>",
          "description": "Bringing empathy to a computerized system could significantly improve the\nquality of human-computer communications, as soon as machines would be able to\nunderstand customer intentions and better serve their needs. According to\ndifferent studies (Literature Review), visual information is one of the most\nimportant channels of human interaction and contains significant behavioral\nsignals, that may be captured from facial expressions. Therefore, it is\nconsistent and natural that the research in the field of Facial Expression\nRecognition (FER) has acquired increased interest over the past decade due to\nhaving diverse application area including health-care, sociology, psychology,\ndriver-safety, virtual reality, cognitive sciences, security, entertainment,\nmarketing, etc. We propose a new architecture for the task of FER and examine\nthe impact of domain discrimination loss regularization on the learning\nprocess. With regard to observations, including both classical training\nconditions and unsupervised domain adaptation scenarios, important aspects of\nthe considered domain adaptation approach integration are traced. The results\nmay serve as a foundation for further research in the field.",
          "link": "http://arxiv.org/abs/2106.01467",
          "publishedOn": "2021-06-04T01:12:29.853Z",
          "wordCount": 600,
          "title": "Domain Adaptation for Facial Expression Classifier via Domain Discrimination and Gradient Reversal. (arXiv:2106.01467v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01444",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feinglass_J/0/1/0/all/0/1\">Joshua Feinglass</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yezhou Yang</a>",
          "description": "The open-ended nature of visual captioning makes it a challenging area for\nevaluation. The majority of proposed models rely on specialized training to\nimprove human-correlation, resulting in limited adoption, generalizability, and\nexplainabilty. We introduce \"typicality\", a new formulation of evaluation\nrooted in information theory, which is uniquely suited for problems lacking a\ndefinite ground truth. Typicality serves as our framework to develop a novel\nsemantic comparison, SPARCS, as well as referenceless fluency evaluation\nmetrics. Over the course of our analysis, two separate dimensions of fluency\nnaturally emerge: style, captured by metric SPURTS, and grammar, captured in\nthe form of grammatical outlier penalties. Through extensive experiments and\nablation studies on benchmark datasets, we show how these decomposed dimensions\nof semantics and fluency provide greater system-level insight into captioner\ndifferences. Our proposed metrics along with their combination, SMURF, achieve\nstate-of-the-art correlation with human judgment when compared with other\nrule-based evaluation metrics.",
          "link": "http://arxiv.org/abs/2106.01444",
          "publishedOn": "2021-06-04T01:12:29.846Z",
          "wordCount": 587,
          "title": "SMURF: SeMantic and linguistic UndeRstanding Fusion for Caption Evaluation via Typicality Analysis. (arXiv:2106.01444v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01656",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mitsuzumi_Y/0/1/0/all/0/1\">Yu Mitsuzumi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Irie_G/0/1/0/all/0/1\">Go Irie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ikami_D/0/1/0/all/0/1\">Daiki Ikami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shibata_T/0/1/0/all/0/1\">Takashi Shibata</a>",
          "description": "Many variants of unsupervised domain adaptation (UDA) problems have been\nproposed and solved individually. Its side effect is that a method that works\nfor one variant is often ineffective for or not even applicable to another,\nwhich has prevented practical applications. In this paper, we give a general\nrepresentation of UDA problems, named Generalized Domain Adaptation (GDA). GDA\ncovers the major variants as special cases, which allows us to organize them in\na comprehensive framework. Moreover, this generalization leads to a new\nchallenging setting where existing methods fail, such as when domain labels are\nunknown, and class labels are only partially given to each domain. We propose a\nnovel approach to the new setting. The key to our approach is self-supervised\nclass-destructive learning, which enables the learning of class-invariant\nrepresentations and domain-adversarial classifiers without using any domain\nlabels. Extensive experiments using three benchmark datasets demonstrate that\nour method outperforms the state-of-the-art UDA methods in the new setting and\nthat it is competitive in existing UDA variations as well.",
          "link": "http://arxiv.org/abs/2106.01656",
          "publishedOn": "2021-06-04T01:12:29.684Z",
          "wordCount": 600,
          "title": "Generalized Domain Adaptation. (arXiv:2106.01656v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01860",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Xu_Z/0/1/0/all/0/1\">Zhe Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lu_D/0/1/0/all/0/1\">Donghuan Lu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1\">Yixin Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Luo_J/0/1/0/all/0/1\">Jie Luo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jagadeesan_J/0/1/0/all/0/1\">Jayender Jagadeesan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ma_K/0/1/0/all/0/1\">Kai Ma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zheng_Y/0/1/0/all/0/1\">Yefeng Zheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_X/0/1/0/all/0/1\">Xiu Li</a>",
          "description": "Manually segmenting the hepatic vessels from Computer Tomography (CT) is far\nmore expertise-demanding and laborious than other structures due to the\nlow-contrast and complex morphology of vessels, resulting in the extreme lack\nof high-quality labeled data. Without sufficient high-quality annotations, the\nusual data-driven learning-based approaches struggle with deficient training.\nOn the other hand, directly introducing additional data with low-quality\nannotations may confuse the network, leading to undesirable performance\ndegradation. To address this issue, we propose a novel mean-teacher-assisted\nconfident learning framework to robustly exploit the noisy labeled data for the\nchallenging hepatic vessel segmentation task. Specifically, with the adapted\nconfident learning assisted by a third party, i.e., the weight-averaged teacher\nmodel, the noisy labels in the additional low-quality dataset can be\ntransformed from \"encumbrance\" to \"treasure\" via progressive pixel-wise\nsoft-correction, thus providing productive guidance. Extensive experiments\nusing two public datasets demonstrate the superiority of the proposed framework\nas well as the effectiveness of each component.",
          "link": "http://arxiv.org/abs/2106.01860",
          "publishedOn": "2021-06-04T01:12:29.677Z",
          "wordCount": 616,
          "title": "Noisy Labels are Treasure: Mean-Teacher-Assisted Confident Learning for Hepatic Vessel Segmentation. (arXiv:2106.01860v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01717",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Blanchon_M/0/1/0/all/0/1\">Marc Blanchon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sidibe_D/0/1/0/all/0/1\">D&#xe9;sir&#xe9; Sidib&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morel_O/0/1/0/all/0/1\">Olivier Morel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seulin_R/0/1/0/all/0/1\">Ralph Seulin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meriaudeau_F/0/1/0/all/0/1\">Fabrice Meriaudeau</a>",
          "description": "Autonomous robotics is critically affected by the robustness of its scene\nunderstanding algorithms. We propose a two-axis pipeline based on polarization\nindices to analyze dynamic urban scenes. As robots evolve in unknown\nenvironments, they are prone to encountering specular obstacles. Usually,\nspecular phenomena are rarely taken into account by algorithms which causes\nmisinterpretations and erroneous estimates. By exploiting all the light\nproperties, systems can greatly increase their robustness to events. In\naddition to the conventional photometric characteristics, we propose to include\npolarization sensing.\n\nWe demonstrate in this paper that the contribution of polarization\nmeasurement increases both the performances of segmentation and the quality of\ndepth estimation. Our polarimetry-based approaches are compared here with other\nstate-of-the-art RGB-centric methods showing interest of using polarization\nimaging.",
          "link": "http://arxiv.org/abs/2106.01717",
          "publishedOn": "2021-06-04T01:12:29.642Z",
          "wordCount": 565,
          "title": "Towards urban scenes understanding through polarization cues. (arXiv:2106.01717v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01981",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oreshkin_B/0/1/0/all/0/1\">Boris N. Oreshkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bocquelet_F/0/1/0/all/0/1\">Florent Bocquelet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harvey_F/0/1/0/all/0/1\">F&#xe9;lix H. Harvey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raitt_B/0/1/0/all/0/1\">Bay Raitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laflamme_D/0/1/0/all/0/1\">Dominic Laflamme</a>",
          "description": "Our work focuses on the development of a learnable neural representation of\nhuman pose for advanced AI assisted animation tooling. Specifically, we tackle\nthe problem of constructing a full static human pose based on sparse and\nvariable user inputs (e.g. locations and/or orientations of a subset of body\njoints). To solve this problem, we propose a novel neural architecture that\ncombines residual connections with prototype encoding of a partially specified\npose to create a new complete pose from the learned latent space. We show that\nour architecture outperforms a baseline based on Transformer, both in terms of\naccuracy and computational efficiency. Additionally, we develop a user\ninterface to integrate our neural model in Unity, a real-time 3D development\nplatform. Furthermore, we introduce two new datasets representing the static\nhuman pose modeling problem, based on high-quality human motion capture data,\nwhich will be released publicly along with model code.",
          "link": "http://arxiv.org/abs/2106.01981",
          "publishedOn": "2021-06-04T01:12:29.623Z",
          "wordCount": 592,
          "title": "ProtoRes: Proto-Residual Architecture for Deep Modeling of Human Pose. (arXiv:2106.01981v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01744",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yechao Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Ziyuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Lyuyu Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1\">Hongliang Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ang_M/0/1/0/all/0/1\">Marcelo H. Ang Jr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rus_D/0/1/0/all/0/1\">Daniela Rus</a>",
          "description": "Exploiting multi-scale features has shown great potential in tackling\nsemantic segmentation problems. The aggregation is commonly done with sum or\nconcatenation (concat) followed by convolutional (conv) layers. However, it\nfully passes down the high-level context to the following hierarchy without\nconsidering their interrelation. In this work, we aim to enable the low-level\nfeature to aggregate the complementary context from adjacent high-level feature\nmaps by a cross-scale pixel-to-region relation operation. We leverage\ncross-scale context propagation to make the long-range dependency capturable\neven by the high-resolution low-level features. To this end, we employ an\nefficient feature pyramid network to obtain multi-scale features. We propose a\nRelational Semantics Extractor (RSE) and Relational Semantics Propagator (RSP)\nfor context extraction and propagation respectively. Then we stack several RSP\ninto an RSP head to achieve the progressive top-down distribution of the\ncontext. Experiment results on two challenging datasets Cityscapes and COCO\ndemonstrate that the RSP head performs competitively on both semantic\nsegmentation and panoptic segmentation with high efficiency. It outperforms\nDeeplabV3 [1] by 0.7% with 75% fewer FLOPs (multiply-adds) in the semantic\nsegmentation task.",
          "link": "http://arxiv.org/abs/2106.01744",
          "publishedOn": "2021-06-04T01:12:29.579Z",
          "wordCount": 628,
          "title": "Multi-Scale Feature Aggregation by Cross-Scale Pixel-to-Region Relation Operation for Semantic Segmentation. (arXiv:2106.01744v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01915",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Han_C/0/1/0/all/0/1\">Changhee Han</a>",
          "description": "Convolutional Neural Networks (CNNs) can play a key role in Medical Image\nAnalysis under large-scale annotated datasets. However, preparing such massive\ndataset is demanding. In this context, Generative Adversarial Networks (GANs)\ncan generate realistic but novel samples, and thus effectively cover the real\nimage distribution. In terms of interpolation, the GAN-based medical image\naugmentation is reliable because medical modalities can display the human\nbody's strong anatomical consistency at fixed position while clearly reflecting\ninter-subject variability; thus, we propose to use noise-to-image GANs (e.g.,\nrandom noise samples to diverse pathological images) for (i) medical Data\nAugmentation (DA) and (ii) physician training. Regarding the DA, the\nGAN-generated images can improve Computer-Aided Diagnosis based on supervised\nlearning. For the physician training, the GANs can display novel desired\npathological images and help train medical trainees despite\ninfrastructural/legal constraints. This thesis contains four GAN projects\naiming to present such novel applications' clinical relevance in collaboration\nwith physicians. Whereas the methods are more generally applicable, this thesis\nonly explores a few oncological applications.",
          "link": "http://arxiv.org/abs/2106.01915",
          "publishedOn": "2021-06-04T01:12:29.546Z",
          "wordCount": 631,
          "title": "Pathology-Aware Generative Adversarial Networks for Medical Image Augmentation. (arXiv:2106.01915v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01920",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhardwaj_K/0/1/0/all/0/1\">Kunal Bhardwaj</a>",
          "description": "With technological advancements and the exponential growth of data, we have\nbeen unfolding different capabilities of neural networks in different sectors.\nIn this paper, I have tried to use a specific type of Neural Network known as\nConvolutional Neural Network(CNN/ConvNet) in the stock market. In other words,\nI have tried to construct and train a convolutional neural network on past\nstock prices data and then tried to predict the movement of stock price i.e.\nwhether the stock price would rise or fall, in the coming time.",
          "link": "http://arxiv.org/abs/2106.01920",
          "publishedOn": "2021-06-04T01:12:29.530Z",
          "wordCount": 527,
          "title": "Convolutional Neural Network(CNN/ConvNet) in Stock Price Movement Prediction. (arXiv:2106.01920v1 [cs.NE])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01764",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1\">Kezhou Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaohan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zhedong Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1\">Linchao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi Yang</a>",
          "description": "Obtaining viewer responses from videos can be useful for creators and\nstreaming platforms to analyze the video performance and improve the future\nuser experience. In this report, we present our method for 2021 Evoked\nExpression from Videos Challenge. In particular, our model utilizes both audio\nand image modalities as inputs to predict emotion changes of viewers. To model\nlong-range emotion changes, we use a GRU-based model to predict one sparse\nsignal with 1Hz. We observe that the emotion changes are smooth. Therefore, the\nfinal dense prediction is obtained via linear interpolating the signal, which\nis robust to the prediction fluctuation. Albeit simple, the proposed method has\nachieved pearson's correlation score of 0.04430 on the final private test set.",
          "link": "http://arxiv.org/abs/2106.01764",
          "publishedOn": "2021-06-04T01:12:29.499Z",
          "wordCount": 560,
          "title": "Less is More: Sparse Sampling for Dense Reaction Predictions. (arXiv:2106.01764v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01739",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Paul_A/0/1/0/all/0/1\">Aditya Jyoti Paul</a>",
          "description": "Diabetic Retinopathy (DR) is a severe complication that may lead to retinal\nvascular damage and is one of the leading causes of vision impairment and\nblindness. DR broadly is classified into two stages - non-proliferative (NPDR),\nwhere there are almost no symptoms, except a few microaneurysms, and\nproliferative (PDR) involving a huge number of microaneurysms and hemorrhages,\nsoft and hard exudates, neo-vascularization, macular ischemia or a combination\nof these, making it easier to detect. More specifically, DR is usually\nclassified into five levels, labeled 0-4, from 0 indicating no DR to 4 which is\nmost severe. This paper firstly presents a discussion on the risk factors of\nthe disease, then surveys the recent literature on the topic followed by\nexamining certain techniques which were found to be highly effective in\nimproving the prognosis accuracy. Finally, a convolutional neural network model\nis proposed to detect all the stages of DR on a low-memory edge\nmicrocontroller. The model has a size of just 5.9 MB, accuracy and F1 score\nboth of 94% and an inference speed of about 20 frames per second.",
          "link": "http://arxiv.org/abs/2106.01739",
          "publishedOn": "2021-06-04T01:12:29.492Z",
          "wordCount": 664,
          "title": "Advances in Classifying the Stages of Diabetic Retinopathy Using Convolutional Neural Networks in Low Memory Edge Devices. (arXiv:2106.01739v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01908",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yuming Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Ziyi Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Menghan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1\">Jie Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1\">Philip H.S. Torr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1\">Ling Shao</a>",
          "description": "Recent advances in self-supervised learning with instance-level contrastive\nobjectives facilitate unsupervised clustering. However, a standalone datum is\nnot perceiving the context of the holistic cluster, and may undergo sub-optimal\nassignment. In this paper, we extend the mainstream contrastive learning\nparadigm to a cluster-level scheme, where all the data subjected to the same\ncluster contribute to a unified representation that encodes the context of each\ndata group. Contrastive learning with this representation then rewards the\nassignment of each datum. To implement this vision, we propose twin-contrast\nclustering (TCC). We define a set of categorical variables as clustering\nassignment confidence, which links the instance-level learning track with the\ncluster-level one. On one hand, with the corresponding assignment variables\nbeing the weight, a weighted aggregation along the data points implements the\nset representation of a cluster. We further propose heuristic cluster\naugmentation equivalents to enable cluster-level contrastive learning. On the\nother hand, we derive the evidence lower-bound of the instance-level\ncontrastive objective with the assignments. By reparametrizing the assignment\nvariables, TCC is trained end-to-end, requiring no alternating steps. Extensive\nexperiments show that TCC outperforms the state-of-the-art on challenging\nbenchmarks.",
          "link": "http://arxiv.org/abs/2106.01908",
          "publishedOn": "2021-06-04T01:12:29.480Z",
          "wordCount": 619,
          "title": "You Never Cluster Alone. (arXiv:2106.01908v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01899",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1\">Xinjie Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qifei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ke_J/0/1/0/all/0/1\">Junjie Ke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1\">Feng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_B/0/1/0/all/0/1\">Boqing Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Mingyuan Zhou</a>",
          "description": "Single domain generalization aims to learn a model that performs well on many\nunseen domains with only one domain data for training. Existing works focus on\nstudying the adversarial domain augmentation (ADA) to improve the model's\ngeneralization capability. The impact on domain generalization of the\nstatistics of normalization layers is still underinvestigated. In this paper,\nwe propose a generic normalization approach, adaptive standardization and\nrescaling normalization (ASR-Norm), to complement the missing part in previous\nworks. ASR-Norm learns both the standardization and rescaling statistics via\nneural networks. This new form of normalization can be viewed as a generic form\nof the traditional normalizations. When trained with ADA, the statistics in\nASR-Norm are learned to be adaptive to the data coming from different domains,\nand hence improves the model generalization performance across domains,\nespecially on the target domain with large discrepancy from the source domain.\nThe experimental results show that ASR-Norm can bring consistent improvement to\nthe state-of-the-art ADA approaches by 1.6%, 2.7%, and 6.3% averagely on the\nDigits, CIFAR-10-C, and PACS benchmarks, respectively. As a generic tool, the\nimprovement introduced by ASR-Norm is agnostic to the choice of ADA methods.",
          "link": "http://arxiv.org/abs/2106.01899",
          "publishedOn": "2021-06-04T01:12:29.455Z",
          "wordCount": 624,
          "title": "Adversarially Adaptive Normalization for Single Domain Generalization. (arXiv:2106.01899v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01718",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Katsuno_H/0/1/0/all/0/1\">Hiroyasu Katsuno</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kimura_Y/0/1/0/all/0/1\">Yuki Kimura</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yamazaki_T/0/1/0/all/0/1\">Tomoya Yamazaki</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Takigawa_I/0/1/0/all/0/1\">Ichigaku Takigawa</a>",
          "description": "Low-electron-dose observation is indispensable for observing various samples\nusing a transmission electron microscope; consequently, image processing has\nbeen used to improve transmission electron microscopy (TEM) images. To apply\nsuch image processing to in situ observations, we here apply a convolutional\nneural network to TEM imaging. Using a dataset that includes short-exposure\nimages and long-exposure images, we develop a pipeline for processed\nshort-exposure images, based on end-to-end training. The quality of images\nacquired with a total dose of approximately 5 e- per pixel becomes comparable\nto that of images acquired with a total dose of approximately 1000 e- per\npixel. Because the conversion time is approximately 8 ms, in situ observation\nat 125 fps is possible. This imaging technique enables in situ observation of\nelectron-beam-sensitive specimens.",
          "link": "http://arxiv.org/abs/2106.01718",
          "publishedOn": "2021-06-04T01:12:29.380Z",
          "wordCount": 576,
          "title": "Fast improvement of TEM image with low-dose electrons by deep learning. (arXiv:2106.01718v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01804",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haiyang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_M/0/1/0/all/0/1\">Ming Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chenliang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_B/0/1/0/all/0/1\">Bin Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Songfang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_W/0/1/0/all/0/1\">Wenming Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>",
          "description": "Vision-language pre-training (VLP) on large-scale image-text pairs has\nachieved huge success for the cross-modal downstream tasks. The most existing\npre-training methods mainly adopt a two-step training procedure, which firstly\nemploys a pre-trained object detector to extract region-based visual features,\nthen concatenates the image representation and text embedding as the input of\nTransformer to train. However, these methods face problems of using\ntask-specific visual representation of the specific object detector for generic\ncross-modal understanding, and the computation inefficiency of two-stage\npipeline. In this paper, we propose the first end-to-end vision-language\npre-trained model for both V+L understanding and generation, namely E2E-VLP,\nwhere we build a unified Transformer framework to jointly learn visual\nrepresentation, and semantic alignments between image and text. We incorporate\nthe tasks of object detection and image captioning into pre-training with a\nunified Transformer encoder-decoder architecture for enhancing visual learning.\nAn extensive set of experiments have been conducted on well-established\nvision-language downstream tasks to demonstrate the effectiveness of this novel\nVLP paradigm.",
          "link": "http://arxiv.org/abs/2106.01804",
          "publishedOn": "2021-06-04T01:12:29.358Z",
          "wordCount": 612,
          "title": "E2E-VLP: End-to-End Vision-Language Pre-training Enhanced by Visual Learning. (arXiv:2106.01804v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2012.00517",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Korpihalkola_J/0/1/0/all/0/1\">Joni Korpihalkola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sipola_T/0/1/0/all/0/1\">Tuomo Sipola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Puuska_S/0/1/0/all/0/1\">Samir Puuska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kokkonen_T/0/1/0/all/0/1\">Tero Kokkonen</a>",
          "description": "Computer vision and machine learning can be used to automate various tasks in\ncancer diagnostic and detection. If an attacker can manipulate the automated\nprocessing, the results can be devastating and in the worst case lead to wrong\ndiagnosis and treatment. In this research, the goal is to demonstrate the use\nof one-pixel attacks in a real-life scenario with a real pathology dataset,\nTUPAC16, which consists of digitized whole-slide images. We attack against the\nIBM CODAIT's MAX breast cancer detector using adversarial images. These\nadversarial examples are found using differential evolution to perform the\none-pixel modification to the images in the dataset. The results indicate that\na minor one-pixel modification of a whole slide image under analysis can affect\nthe diagnosis by reversing the automatic diagnosis result. The attack poses a\nthreat from the cyber security perspective: the one-pixel method can be used as\nan attack vector by a motivated attacker.",
          "link": "http://arxiv.org/abs/2012.00517",
          "publishedOn": "2021-06-03T02:10:37.086Z",
          "wordCount": 623,
          "title": "One-Pixel Attack Deceives Computer-Assisted Diagnosis of Cancer. (arXiv:2012.00517v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.09118",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Robinson_J/0/1/0/all/0/1\">Joseph P Robinson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_C/0/1/0/all/0/1\">Can Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henon_Y/0/1/0/all/0/1\">Yann Henon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Timoner_S/0/1/0/all/0/1\">Samson Timoner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yun Fu</a>",
          "description": "There are demographic biases in current models used for facial recognition\n(FR). Our Balanced Faces In the Wild (BFW) dataset serves as a proxy to measure\nbias across ethnicity and gender subgroups, allowing one to characterize FR\nperformances per subgroup. We show performances are non-optimal when a single\nscore threshold is used to determine whether sample pairs are genuine or\nimposter. Across subgroups, performance ratings vary from the reported across\nthe entire dataset. Thus, claims of specific error rates only hold true for\npopulations matching that of the validation data. We mitigate the imbalanced\nperformances using a novel domain adaptation learning scheme on the facial\nfeatures extracted using state-of-the-art. Not only does this technique balance\nperformance, but it also boosts the overall performance. A benefit of the\nproposed is to preserve identity information in facial features while removing\ndemographic knowledge in the lower dimensional features. The removal of\ndemographic knowledge prevents future potential biases from being injected into\ndecision-making. This removal satisfies privacy concerns. We explore why this\nworks qualitatively; we also show quantitatively that subgroup classifiers can\nno longer learn from the features mapped by the proposed.",
          "link": "http://arxiv.org/abs/2103.09118",
          "publishedOn": "2021-06-03T02:10:36.664Z",
          "wordCount": 659,
          "title": "Balancing Biases and Preserving Privacy on Balanced Faces in the Wild. (arXiv:2103.09118v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.08700",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuxin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1\">Mingbao Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chao_F/0/1/0/all/0/1\">Fei Chao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yongjian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Feiyue Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Mingliang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yonghong Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_R/0/1/0/all/0/1\">Rongrong Ji</a>",
          "description": "Network pruning is an effective approach to reduce network complexity without\nperformance compromise. Existing studies achieve the sparsity of neural\nnetworks via time-consuming weight tuning or complex search on networks with\nexpanded width, which greatly limits the applications of network pruning. In\nthis paper, we show that high-performing and sparse sub-networks without the\ninvolvement of weight tuning, termed \"lottery jackpots\", exist in pre-trained\nmodels with unexpanded width. For example, we obtain a lottery jackpot that has\nonly 10% parameters and still reaches the performance of the original dense\nVGGNet-19 without any modifications on the pre-trained weights. Furthermore, we\nobserve that the sparse masks derived from many existing pruning criteria have\na high overlap with the searched mask of our lottery jackpot, among which, the\nmagnitude-based pruning results in the most similar mask with ours. Based on\nthis insight, we initialize our sparse mask using the magnitude pruning,\nresulting in at least 3x cost reduction on the lottery jackpot search while\nachieves comparable or even better performance. Specifically, our\nmagnitude-based lottery jackpot removes 90% weights in the ResNet-50, while\neasily obtains more than 70% top-1 accuracy using only 10 searching epochs on\nImageNet.",
          "link": "http://arxiv.org/abs/2104.08700",
          "publishedOn": "2021-06-03T02:10:36.391Z",
          "wordCount": 663,
          "title": "Lottery Jackpots Exist in Pre-trained Models. (arXiv:2104.08700v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.04165",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1\">Pan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_R/0/1/0/all/0/1\">Ran Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1\">Shibiao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_L/0/1/0/all/0/1\">Liang Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Siyuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1\">Xiaodan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Song-Chun Zhu</a>",
          "description": "Geometry problem solving has attracted much attention in the NLP community\nrecently. The task is challenging as it requires abstract problem understanding\nand symbolic reasoning with axiomatic knowledge. However, current datasets are\neither small in scale or not publicly available. Thus, we construct a new\nlarge-scale benchmark, Geometry3K, consisting of 3,002 geometry problems with\ndense annotation in formal language. We further propose a novel geometry\nsolving approach with formal language and symbolic reasoning, called\nInterpretable Geometry Problem Solver (Inter-GPS). Inter-GPS first parses the\nproblem text and diagram into formal language automatically via rule-based text\nparsing and neural object detecting, respectively. Unlike implicit learning in\nexisting methods, Inter-GPS incorporates theorem knowledge as conditional rules\nand performs symbolic reasoning step by step. Also, a theorem predictor is\ndesigned to infer the theorem application sequence fed to the symbolic solver\nfor the more efficient and reasonable searching path. Extensive experiments on\nthe Geometry3K and GEOS datasets demonstrate that Inter-GPS achieves\nsignificant improvements over existing methods. The project with code and data\nis available at https://lupantech.github.io/inter-gps.",
          "link": "http://arxiv.org/abs/2105.04165",
          "publishedOn": "2021-06-03T02:10:36.348Z",
          "wordCount": 669,
          "title": "Inter-GPS: Interpretable Geometry Problem Solving with Formal Language and Symbolic Reasoning. (arXiv:2105.04165v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.08826",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wickramasinghe_U/0/1/0/all/0/1\">Udaranga Wickramasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knott_G/0/1/0/all/0/1\">Graham Knott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fua_P/0/1/0/all/0/1\">Pascal Fua</a>",
          "description": "Active Surface Models have a long history of being useful to model complex 3D\nsurfaces but only Active Contours have been used in conjunction with deep\nnetworks, and then only to produce the data term as well as meta-parameter maps\ncontrolling them. In this paper, we advocate a much tighter integration. We\nintroduce layers that implement them that can be integrated seamlessly into\nGraph Convolutional Networks to enforce sophisticated smoothness priors at an\nacceptable computational cost. We will show that the resulting Deep Active\nSurface Models outperform equivalent architectures that use traditional\nregularization loss terms to impose smoothness priors for 3D surface\nreconstruction from 2D images and for 3D volume segmentation.",
          "link": "http://arxiv.org/abs/2011.08826",
          "publishedOn": "2021-06-03T02:10:36.057Z",
          "wordCount": 590,
          "title": "Deep Active Surface Models. (arXiv:2011.08826v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01364",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1\">Jong-Chyi Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maji_S/0/1/0/all/0/1\">Subhransu Maji</a>",
          "description": "Semi-iNat is a challenging dataset for semi-supervised classification with a\nlong-tailed distribution of classes, fine-grained categories, and domain shifts\nbetween labeled and unlabeled data. This dataset is behind the second iteration\nof the semi-supervised recognition challenge to be held at the FGVC8 workshop\nat CVPR 2021. Different from the previous one, this dataset (i) includes images\nof species from different kingdoms in the natural taxonomy, (ii) is at a larger\nscale --- with 810 in-class and 1629 out-of-class species for a total of 330k\nimages, and (iii) does not provide in/out-of-class labels, but provides coarse\ntaxonomic labels (kingdom and phylum) for the unlabeled images. This document\ndescribes baseline results and the details of the dataset which is available\nhere: \\url{https://github.com/cvl-umass/semi-inat-2021}.",
          "link": "http://arxiv.org/abs/2106.01364",
          "publishedOn": "2021-06-03T02:10:35.755Z",
          "wordCount": 563,
          "title": "The Semi-Supervised iNaturalist Challenge at the FGVC8 Workshop. (arXiv:2106.01364v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2101.10423",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mai_Z/0/1/0/all/0/1\">Zheda Mai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruiwen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_J/0/1/0/all/0/1\">Jihwan Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quispe_D/0/1/0/all/0/1\">David Quispe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyunwoo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanner_S/0/1/0/all/0/1\">Scott Sanner</a>",
          "description": "Online continual learning for image classification studies the problem of\nlearning to classify images from an online stream of data and tasks, where\ntasks may include new classes (class incremental) or data nonstationarity\n(domain incremental). One of the key challenges of continual learning is to\navoid catastrophic forgetting (CF), i.e., forgetting old tasks in the presence\nof more recent tasks. Over the past few years, many methods and tricks have\nbeen introduced to address this problem, but many have not been fairly and\nsystematically compared under a variety of realistic and practical settings. To\nbetter understand the relative advantages of various approaches and the\nsettings where they work best, this survey aims to (1) compare state-of-the-art\nmethods such as MIR, iCARL, and GDumb and determine which works best at\ndifferent experimental settings; (2) determine if the best class incremental\nmethods are also competitive in domain incremental setting; (3) evaluate the\nperformance of 7 simple but effective trick such as \"review\" trick and nearest\nclass mean (NCM) classifier to assess their relative impact. Regarding (1), we\nobserve iCaRL remains competitive when the memory buffer is small; GDumb\noutperforms many recently proposed methods in medium-size datasets and MIR\nperforms the best in larger-scale datasets. For (2), we note that GDumb\nperforms quite poorly while MIR -- already competitive for (1) -- is also\nstrongly competitive in this very different but important setting. Overall,\nthis allows us to conclude that MIR is overall a strong and versatile method\nacross a wide variety of settings. For (3), we find that all 7 tricks are\nbeneficial, and when augmented with the \"review\" trick and NCM classifier, MIR\nproduces performance levels that bring online continual learning much closer to\nits ultimate goal of matching offline training.",
          "link": "http://arxiv.org/abs/2101.10423",
          "publishedOn": "2021-06-03T02:10:35.742Z",
          "wordCount": 763,
          "title": "Online Continual Learning in Image Classification: An Empirical Survey. (arXiv:2101.10423v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01171",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Staecker_P/0/1/0/all/0/1\">P. Christopher Staecker</a>",
          "description": "In this paper we prove results relating to two homotopy relations and four\nhomology theories developed in the topology of digital images.\n\nWe introduce a new type of homotopy relation for digitally continuous\nfunctions which we call \"strong homotopy.\" Both digital homotopy and strong\nhomotopy are natural digitizations of classical topological homotopy: the\ndifference between them is analogous to the difference between digital\n4-adjacency and 8-adjacency in the plane.\n\nWe also consider four different digital homology theories: a simplicial\nhomology theory by Arslan et al which is the homology of the clique complex, a\nsingular simplicial homology theory by D. W. Lee, a cubical homology theory by\nJamil and Ali, and a new kind of cubical homology for digital images with\n$c_1$-adjacency which is easily computed, and generalizes a construction by\nKaraca \\& Ege. We show that the two simplicial homology theories are isomorphic\nto each other, but distinct from the two cubical theories.\n\nWe also show that homotopic maps have the same induced homomorphisms in the\ncubical homology theory, and strong homotopic maps additionally have the same\ninduced homomorphisms in the simplicial theory.",
          "link": "http://arxiv.org/abs/2106.01171",
          "publishedOn": "2021-06-03T02:10:35.681Z",
          "wordCount": 628,
          "title": "Digital homotopy relations and digital homology theories. (arXiv:2106.01171v1 [math.AT])"
        },
        {
          "id": "http://arxiv.org/abs/2005.10360",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fox_G/0/1/0/all/0/1\">Gereon Fox</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wentao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyeongwoo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seidel_H/0/1/0/all/0/1\">Hans-Peter Seidel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elgharib_M/0/1/0/all/0/1\">Mohamed Elgharib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theobalt_C/0/1/0/all/0/1\">Christian Theobalt</a>",
          "description": "There are concerns that new approaches to the synthesis of high quality face\nvideos may be misused to manipulate videos with malicious intent. The research\ncommunity therefore developed methods for the detection of modified footage and\nassembled benchmark datasets for this task. In this paper, we examine how the\nperformance of forgery detectors depends on the presence of artefacts that the\nhuman eye can see. We introduce a new benchmark dataset for face video forgery\ndetection, of unprecedented quality. It allows us to demonstrate that existing\ndetection techniques have difficulties detecting fakes that reliably fool the\nhuman eye. We thus introduce a new family of detectors that examine\ncombinations of spatial and temporal features and outperform existing\napproaches both in terms of detection accuracy and generalization.",
          "link": "http://arxiv.org/abs/2005.10360",
          "publishedOn": "2021-06-03T02:10:35.113Z",
          "wordCount": 590,
          "title": "VideoForensicsHQ: Detecting High-quality Manipulated Face Videos. (arXiv:2005.10360v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.01308",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Guankai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_G/0/1/0/all/0/1\">Guosheng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qingyao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_R/0/1/0/all/0/1\">Rui Yao</a>",
          "description": "Image co-segmentation is an active computer vision task that aims to segment\nthe common objects from a set of images. Recently, researchers design various\nlearning-based algorithms to undertake the co-segmentation task. The main\ndifficulty in this task is how to effectively transfer information between\nimages to make conditional predictions. In this paper, we present CycleSegNet,\na novel framework for the co-segmentation task. Our network design has two key\ncomponents: a region correspondence module which is the basic operation for\nexchanging information between local image regions, and a cycle refinement\nmodule, which utilizes ConvLSTMs to progressively update image representations\nand exchange information in a cycle and iterative manner. Extensive experiments\ndemonstrate that our proposed method significantly outperforms the\nstate-of-the-art methods on four popular benchmark datasets -- PASCAL VOC\ndataset, MSRC dataset, Internet dataset, and iCoseg dataset, by 2.6%, 7.7%,\n2.2%, and 2.9%, respectively.",
          "link": "http://arxiv.org/abs/2101.01308",
          "publishedOn": "2021-06-03T02:10:35.099Z",
          "wordCount": 607,
          "title": "CycleSegNet: Object Co-segmentation with Cycle Refinement and Region Correspondence. (arXiv:2101.01308v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10283",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_W/0/1/0/all/0/1\">Weixin Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yanhao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zixuan Liu</a>",
          "description": "Images are more than a collection of objects or attributes -- they represent\na web of relationships among interconnected objects. Scene Graph has emerged as\na new modality for a structured graphical representation of images. Scene Graph\nencodes objects as nodes connected via pairwise relations as edges. To support\nquestion answering on scene graphs, we propose GraphVQA, a language-guided\ngraph neural network framework that translates and executes a natural language\nquestion as multiple iterations of message passing among graph nodes. We\nexplore the design space of GraphVQA framework, and discuss the trade-off of\ndifferent design choices. Our experiments on GQA dataset show that GraphVQA\noutperforms the state-of-the-art model by a large margin (88.43% vs. 94.78%).",
          "link": "http://arxiv.org/abs/2104.10283",
          "publishedOn": "2021-06-03T02:10:35.045Z",
          "wordCount": 584,
          "title": "GraghVQA: Language-Guided Graph Neural Networks for Graph-based Visual Question Answering. (arXiv:2104.10283v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.08609",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jinhai Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hua Yang</a>",
          "description": "Crowd segmentation is a fundamental task serving as the basis of crowded\nscene analysis, and it is highly desirable to obtain refined pixel-level\nsegmentation maps. However, it remains a challenging problem, as existing\napproaches either require dense pixel-level annotations to train deep learning\nmodels or merely produce rough segmentation maps from optical or particle flows\nwith physical models. In this paper, we propose the Motion Prior-Aware Siamese\nNetwork (MPASNET) for unsupervised crowd semantic segmentation. This model not\nonly eliminates the need for annotation but also yields high-quality\nsegmentation maps. Specially, we first analyze the coherent motion patterns\nacross the frames and then apply a circular region merging strategy on the\ncollective particles to generate pseudo-labels. Moreover, we equip MPASNET with\nsiamese branches for augmentation-invariant regularization and siamese feature\naggregation. Experiments over benchmark datasets indicate that our model\noutperforms the state-of-the-arts by more than 12% in terms of mIoU.",
          "link": "http://arxiv.org/abs/2101.08609",
          "publishedOn": "2021-06-03T02:10:35.030Z",
          "wordCount": 619,
          "title": "MPASNET: Motion Prior-Aware Siamese Network for Unsupervised Deep Crowd Segmentation in Video Scenes. (arXiv:2101.08609v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01226",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiaokang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1\">Yuhui Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_G/0/1/0/all/0/1\">Gang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jingdong Wang</a>",
          "description": "In this paper, we study the semi-supervised semantic segmentation problem via\nexploring both labeled data and extra unlabeled data. We propose a novel\nconsistency regularization approach, called cross pseudo supervision (CPS). Our\napproach imposes the consistency on two segmentation networks perturbed with\ndifferent initialization for the same input image. The pseudo one-hot label\nmap, output from one perturbed segmentation network, is used to supervise the\nother segmentation network with the standard cross-entropy loss, and vice\nversa. The CPS consistency has two roles: encourage high similarity between the\npredictions of two perturbed networks for the same input image, and expand\ntraining data by using the unlabeled data with pseudo labels. Experiment\nresults show that our approach achieves the state-of-the-art semi-supervised\nsegmentation performance on Cityscapes and PASCAL VOC 2012.",
          "link": "http://arxiv.org/abs/2106.01226",
          "publishedOn": "2021-06-03T02:10:35.001Z",
          "wordCount": 559,
          "title": "Semi-Supervised Semantic Segmentation with Cross Pseudo Supervision. (arXiv:2106.01226v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2004.09317",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jong_D/0/1/0/all/0/1\">D. B. de Jong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paredes_Valles_F/0/1/0/all/0/1\">F. Paredes-Vall&#xe9;s</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Croon_G/0/1/0/all/0/1\">G. C. H. E. de Croon</a>",
          "description": "End-to-end trained convolutional neural networks have led to a breakthrough\nin optical flow estimation. The most recent advances focus on improving the\noptical flow estimation by improving the architecture and setting a new\nbenchmark on the publicly available MPI-Sintel dataset. Instead, in this\narticle, we investigate how deep neural networks estimate optical flow. A\nbetter understanding of how these networks function is important for (i)\nassessing their generalization capabilities to unseen inputs, and (ii)\nsuggesting changes to improve their performance. For our investigation, we\nfocus on FlowNetS, as it is the prototype of an encoder-decoder neural network\nfor optical flow estimation. Furthermore, we use a filter identification method\nthat has played a major role in uncovering the motion filters present in animal\nbrains in neuropsychological research. The method shows that the filters in the\ndeepest layer of FlowNetS are sensitive to a variety of motion patterns. Not\nonly do we find translation filters, as demonstrated in animal brains, but\nthanks to the easier measurements in artificial neural networks, we even unveil\ndilation, rotation, and occlusion filters. Furthermore, we find similarities in\nthe refinement part of the network and the perceptual filling-in process which\noccurs in the mammal primary visual cortex.",
          "link": "http://arxiv.org/abs/2004.09317",
          "publishedOn": "2021-06-03T02:10:34.992Z",
          "wordCount": 698,
          "title": "How Do Neural Networks Estimate Optical Flow? A Neuropsychology-Inspired Study. (arXiv:2004.09317v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01277",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gutierrez_P/0/1/0/all/0/1\">Pierre Gutierrez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cordier_A/0/1/0/all/0/1\">Antoine Cordier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caldeira_T/0/1/0/all/0/1\">Tha&#xef;s Caldeira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sautory_T/0/1/0/all/0/1\">Th&#xe9;ophile Sautory</a>",
          "description": "The use of deep features coming from pre-trained neural networks for\nunsupervised anomaly detection purposes has recently gathered momentum in the\ncomputer vision field. In particular, industrial inspection applications can\ntake advantage of such features, as demonstrated by the multiple successes of\nrelated methods on the MVTec Anomaly Detection (MVTec AD) dataset. These\nmethods make use of neural networks pre-trained on auxiliary classification\ntasks such as ImageNet. However, to our knowledge, no comparative study of\nrobustness to the low data regimes between these approaches has been conducted\nyet. For quality inspection applications, the handling of limited sample sizes\nmay be crucial as large quantities of images are not available for small\nseries. In this work, we aim to compare three approaches based on deep\npre-trained features when varying the quantity of available data in MVTec AD:\nKNN, Mahalanobis, and PaDiM. We show that although these methods are mostly\nrobust to small sample sizes, they still can benefit greatly from using data\naugmentation in the original image space, which allows to deal with very small\nproduction runs.",
          "link": "http://arxiv.org/abs/2106.01277",
          "publishedOn": "2021-06-03T02:10:34.969Z",
          "wordCount": 651,
          "title": "Data augmentation and pre-trained networks for extremely low data regimes unsupervised visual inspection. (arXiv:2106.01277v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01217",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1\">Bo Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_H/0/1/0/all/0/1\">Hongxing Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1\">Jing Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuezun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_S/0/1/0/all/0/1\">Siwei Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zhenan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Han Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Baoying Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yanjie Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1\">Shenghai Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Junrui Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yutong Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Boyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_H/0/1/0/all/0/1\">Hefei Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Guosheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhiliang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1\">Changtao Miao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Changlei Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1\">Shan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiaoyan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_W/0/1/0/all/0/1\">Wanyi Zhuang</a>",
          "description": "This paper presents a summary of the DFGC 2021 competition. DeepFake\ntechnology is developing fast, and realistic face-swaps are increasingly\ndeceiving and hard to detect. At the same time, DeepFake detection methods are\nalso improving. There is a two-party game between DeepFake creators and\ndetectors. This competition provides a common platform for benchmarking the\nadversarial game between current state-of-the-art DeepFake creation and\ndetection methods. In this paper, we present the organization, results and top\nsolutions of this competition and also share our insights obtained during this\nevent. We also release the DFGC-21 testing dataset collected from our\nparticipants to further benefit the research community.",
          "link": "http://arxiv.org/abs/2106.01217",
          "publishedOn": "2021-06-03T02:10:34.964Z",
          "wordCount": 568,
          "title": "DFGC 2021: A DeepFake Game Competition. (arXiv:2106.01217v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2104.08736",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_Q/0/1/0/all/0/1\">Qi Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Youzhi Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1\">Shuiwang Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1\">Tianbao Yang</a>",
          "description": "Areas under ROC (AUROC) and precision-recall curves (AUPRC) are common\nmetrics for evaluating classification performance for imbalanced problems.\nCompared with AUROC, AUPRC is a more appropriate metric for highly imbalanced\ndatasets. While stochastic optimization of AUROC has been studied extensively,\nprincipled stochastic optimization of AUPRC has been rarely explored. In this\nwork, we propose a principled technical method to optimize AUPRC for deep\nlearning. Our approach is based on maximizing the averaged precision (AP),\nwhich is an unbiased point estimator of AUPRC. We cast the objective into a sum\nof {\\it dependent compositional functions} with inner functions dependent on\nrandom variables of the outer level. We propose efficient adaptive and\nnon-adaptive stochastic algorithms with {\\it provable convergence guarantee\nunder mild conditions} by leveraging recent advances in stochastic\ncompositional optimization. Extensive experimental results on image and graph\ndatasets demonstrate that our proposed method outperforms prior methods on\nimbalanced problems in terms of AUPRC. To the best of our knowledge, our work\nrepresents the first attempt to optimize AUPRC with provable convergence.",
          "link": "http://arxiv.org/abs/2104.08736",
          "publishedOn": "2021-06-03T02:10:34.958Z",
          "wordCount": 651,
          "title": "Stochastic Optimization of Areas Under Precision-Recall Curves with Provable Convergence. (arXiv:2104.08736v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.01924",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Damer_N/0/1/0/all/0/1\">Naser Damer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boutros_F/0/1/0/all/0/1\">Fadi Boutros</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sussmilch_M/0/1/0/all/0/1\">Marius S&#xfc;&#xdf;milch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_M/0/1/0/all/0/1\">Meiling Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirchbuchner_F/0/1/0/all/0/1\">Florian Kirchbuchner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuijper_A/0/1/0/all/0/1\">Arjan Kuijper</a>",
          "description": "The recent COVID-19 pandemic has increased the focus on hygienic and\ncontactless identity verification methods. However, the pandemic led to the\nwide use of face masks, essential to keep the pandemic under control. The\neffect of wearing a mask on face recognition in a collaborative environment is\ncurrently sensitive yet understudied issue. Recent reports have tackled this by\nevaluating the masked probe effect on the performance of automatic face\nrecognition solutions. However, such solutions can fail in certain processes,\nleading to performing the verification task by a human expert. This work\nprovides a joint evaluation and in-depth analyses of the face verification\nperformance of human experts in comparison to state-of-the-art automatic face\nrecognition solutions. This involves an extensive evaluation with 12 human\nexperts and 4 automatic recognition solutions. The study concludes with a set\nof take-home messages on different aspects of the correlation between the\nverification behavior of human and machine.",
          "link": "http://arxiv.org/abs/2103.01924",
          "publishedOn": "2021-06-03T02:10:34.912Z",
          "wordCount": 660,
          "title": "Masked Face Recognition: Human vs. Machine. (arXiv:2103.01924v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01153",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Urbann_O/0/1/0/all/0/1\">Oliver Urbann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bredtmann_O/0/1/0/all/0/1\">Oliver Bredtmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Otten_M/0/1/0/all/0/1\">Maximilian Otten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richter_J/0/1/0/all/0/1\">Jan-Philip Richter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bauer_T/0/1/0/all/0/1\">Thilo Bauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zibriczky_D/0/1/0/all/0/1\">David Zibriczky</a>",
          "description": "This paper presents an approach for tracking in a surveillance scenario.\nTypical aspects for this scenario are a 24/7 operation with a static camera\nmounted above the height of a human with many objects or people. The Multiple\nObject Tracking Benchmark 20 (MOT20) reflects this scenario best. We can show\nthat our approach is real-time capable on this benchmark and outperforms all\nother real-time capable approaches in HOTA, MOTA, and IDF1. We achieve this by\ncontributing a fast Siamese network reformulated for linear runtime (instead of\nquadratic) to generate fingerprints from detections. Thus, it is possible to\nassociate the detections to Kalman filters based on multiple tracking specific\nratings: Cosine similarity of fingerprints, Intersection over Union, and pixel\ndistance ratio in the image.",
          "link": "http://arxiv.org/abs/2106.01153",
          "publishedOn": "2021-06-03T02:10:34.341Z",
          "wordCount": 561,
          "title": "Online and Real-Time Tracking in a Surveillance Scenario. (arXiv:2106.01153v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2012.04731",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kiciroglu_S/0/1/0/all/0/1\">Sena Kiciroglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salzmann_M/0/1/0/all/0/1\">Mathieu Salzmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fua_P/0/1/0/all/0/1\">Pascal Fua</a>",
          "description": "Long term human motion prediction is essential in safety-critical\napplications such as human-robot interaction and autonomous driving. In this\npaper, we show that, to achieve long term forecasting, predicting human pose at\nevery time instant is unnecessary. Instead, it is more effective to predict a\nfew keyposes and approximate intermediate ones by linearly interpolating the\nkeyposes.\n\nWe will demonstrate that our approach enables us to predict realistic motions\nfor up to 5 seconds in the future, which is far larger than the typical 1\nsecond encountered in the literature. Over this extended time period, our\npredictions are more realistic and better preserve the motion dynamics than\nthose state-of-the-art methods yield.\n\nFurthermore, because we model future keyposes probabilistically, we can\ngenerate multiple plausible future motions by sampling at inference time. This\nis useful to model because people usually can do one of several things given\nwhat they have already done.",
          "link": "http://arxiv.org/abs/2012.04731",
          "publishedOn": "2021-06-03T02:10:34.030Z",
          "wordCount": 612,
          "title": "Long Term Motion Prediction Using Keyposes. (arXiv:2012.04731v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.00588",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1\">Xin Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_C/0/1/0/all/0/1\">Cuiling Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1\">Wenjun Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhibo Chen</a>",
          "description": "For many practical computer vision applications, the learned models usually\nhave high performance on the datasets used for training but suffer from\nsignificant performance degradation when deployed in new environments, where\nthere are usually style differences between the training images and the testing\nimages. An effective domain generalizable model is expected to be able to learn\nfeature representations that are both generalizable and discriminative. In this\npaper, we design a novel Style Normalization and Restitution module (SNR) to\nsimultaneously ensure both high generalization and discrimination capability of\nthe networks. In the SNR module, particularly, we filter out the style\nvariations (e.g, illumination, color contrast) by performing Instance\nNormalization (IN) to obtain style normalized features, where the discrepancy\namong different samples and domains is reduced. However, such a process is\ntask-ignorant and inevitably removes some task-relevant discriminative\ninformation, which could hurt the performance. To remedy this, we propose to\ndistill task-relevant discriminative features from the residual (i.e, the\ndifference between the original feature and the style normalized feature) and\nadd them back to the network to ensure high discrimination. Moreover, for\nbetter disentanglement, we enforce a dual causality loss constraint in the\nrestitution step to encourage the better separation of task-relevant and\ntask-irrelevant features. We validate the effectiveness of our SNR on different\ncomputer vision tasks, including classification, semantic segmentation, and\nobject detection. Experiments demonstrate that our SNR module is capable of\nimproving the performance of networks for domain generalization (DG) and\nunsupervised domain adaptation (UDA) on many tasks. Code are available at\nhttps://github.com/microsoft/SNR.",
          "link": "http://arxiv.org/abs/2101.00588",
          "publishedOn": "2021-06-03T02:10:34.012Z",
          "wordCount": 738,
          "title": "Style Normalization and Restitution for Domain Generalization and Adaptation. (arXiv:2101.00588v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.13055",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ramasinghe_S/0/1/0/all/0/1\">Sameera Ramasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farazi_M/0/1/0/all/0/1\">Moshiur Farazi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1\">Salman Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barnes_N/0/1/0/all/0/1\">Nick Barnes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gould_S/0/1/0/all/0/1\">Stephen Gould</a>",
          "description": "Conditional GANs (cGAN), in their rudimentary form, suffer from critical\ndrawbacks such as the lack of diversity in generated outputs and distortion\nbetween the latent and output manifolds. Although efforts have been made to\nimprove results, they can suffer from unpleasant side-effects such as the\ntopology mismatch between latent and output spaces. In contrast, we tackle this\nproblem from a geometrical perspective and propose a novel training mechanism\nthat increases both the diversity and the visual quality of a vanilla cGAN, by\nsystematically encouraging a bi-lipschitz mapping between the latent and the\noutput manifolds. We validate the efficacy of our solution on a baseline cGAN\n(i.e., Pix2Pix) which lacks diversity, and show that by only modifying its\ntraining mechanism (i.e., with our proposed Pix2Pix-Geo), one can achieve more\ndiverse and realistic outputs on a broad set of image-to-image translation\ntasks. Codes are available at https://github.com/samgregoost/Rethinking-CGANs.",
          "link": "http://arxiv.org/abs/2011.13055",
          "publishedOn": "2021-06-03T02:10:34.006Z",
          "wordCount": 626,
          "title": "Rethinking conditional GAN training: An approach using geometrically structured latent manifolds. (arXiv:2011.13055v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1909.03396",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Levinboim_T/0/1/0/all/0/1\">Tomer Levinboim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thapliyal_A/0/1/0/all/0/1\">Ashish V. Thapliyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_P/0/1/0/all/0/1\">Piyush Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soricut_R/0/1/0/all/0/1\">Radu Soricut</a>",
          "description": "Automatic image captioning has improved significantly over the last few\nyears, but the problem is far from being solved, with state of the art models\nstill often producing low quality captions when used in the wild. In this\npaper, we focus on the task of Quality Estimation (QE) for image captions,\nwhich attempts to model the caption quality from a human perspective and\nwithout access to ground-truth references, so that it can be applied at\nprediction time to detect low-quality captions produced on previously unseen\nimages. For this task, we develop a human evaluation process that collects\ncoarse-grained caption annotations from crowdsourced users, which is then used\nto collect a large scale dataset spanning more than 600k caption quality\nratings. We then carefully validate the quality of the collected ratings and\nestablish baseline models for this new QE task. Finally, we further collect\nfine-grained caption quality annotations from trained raters, and use them to\ndemonstrate that QE models trained over the coarse ratings can effectively\ndetect and filter out low-quality image captions, thereby improving the user\nexperience from captioning systems.",
          "link": "http://arxiv.org/abs/1909.03396",
          "publishedOn": "2021-06-03T02:10:34.000Z",
          "wordCount": 659,
          "title": "Quality Estimation for Image Captions Based on Large-scale Human Evaluations. (arXiv:1909.03396v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.00212",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_K/0/1/0/all/0/1\">Kunming Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shuaicheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_H/0/1/0/all/0/1\">Haoqiang Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jian Sun</a>",
          "description": "We present an unsupervised learning approach for optical flow estimation by\nimproving the upsampling and learning of pyramid network. We design a\nself-guided upsample module to tackle the interpolation blur problem caused by\nbilinear upsampling between pyramid levels. Moreover, we propose a pyramid\ndistillation loss to add supervision for intermediate levels via distilling the\nfinest flow as pseudo labels. By integrating these two components together, our\nmethod achieves the best performance for unsupervised optical flow learning on\nmultiple leading benchmarks, including MPI-SIntel, KITTI 2012 and KITTI 2015.\nIn particular, we achieve EPE=1.4 on KITTI 2012 and F1=9.38% on KITTI 2015,\nwhich outperform the previous state-of-the-art methods by 22.2% and 15.7%,\nrespectively.",
          "link": "http://arxiv.org/abs/2012.00212",
          "publishedOn": "2021-06-03T02:10:33.966Z",
          "wordCount": 575,
          "title": "UPFlow: Upsampling Pyramid for Unsupervised Optical Flow Learning. (arXiv:2012.00212v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14540",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_T/0/1/0/all/0/1\">Tashnim Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahnemoonfar_M/0/1/0/all/0/1\">Maryam Rahnemoonfar</a>",
          "description": "The detrimental impacts of climate change include stronger and more\ndestructive hurricanes happening all over the world. Identifying different\ndamaged structures of an area including buildings and roads are vital since it\nhelps the rescue team to plan their efforts to minimize the damage caused by a\nnatural disaster. Semantic segmentation helps to identify different parts of an\nimage. We implement a novel self-attention based semantic segmentation model on\na high resolution UAV dataset and attain Mean IoU score of around 88% on the\ntest set. The result inspires to use self-attention schemes in natural disaster\ndamage assessment which will save human lives and reduce economic losses.",
          "link": "http://arxiv.org/abs/2105.14540",
          "publishedOn": "2021-06-03T02:10:33.885Z",
          "wordCount": 571,
          "title": "Attention Based Semantic Segmentation on UAV Dataset for Natural Disaster Damage Assessment. (arXiv:2105.14540v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08050",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hanxiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Z/0/1/0/all/0/1\">Zihang Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+So_D/0/1/0/all/0/1\">David R. So</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1\">Quoc V. Le</a>",
          "description": "Transformers have become one of the most important architectural innovations\nin deep learning and have enabled many breakthroughs over the past few years.\nHere we propose a simple network architecture, gMLP, based on MLPs with gating,\nand show that it can perform as well as Transformers in key language and vision\napplications. Our comparisons show that self-attention is not critical for\nVision Transformers, as gMLP can achieve the same accuracy. For BERT, our model\nachieves parity with Transformers on pretraining perplexity and is better on\nsome downstream NLP tasks. On finetuning tasks where gMLP performs worse,\nmaking the gMLP model substantially larger can close the gap with Transformers.\nIn general, our experiments show that gMLP can scale as well as Transformers\nover increased data and compute.",
          "link": "http://arxiv.org/abs/2105.08050",
          "publishedOn": "2021-06-03T02:10:33.831Z",
          "wordCount": 587,
          "title": "Pay Attention to MLPs. (arXiv:2105.08050v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01178",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rukhovich_D/0/1/0/all/0/1\">Danila Rukhovich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vorontsova_A/0/1/0/all/0/1\">Anna Vorontsova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Konushin_A/0/1/0/all/0/1\">Anton Konushin</a>",
          "description": "In this paper, we introduce the task of multi-view RGB-based 3D object\ndetection as an end-to-end optimization problem. To address this problem, we\npropose ImVoxelNet, a novel fully convolutional method of 3D object detection\nbased on monocular or multi-view RGB images. The number of monocular images in\neach multi-view input can variate during training and inference; actually, this\nnumber might be unique for each multi-view input. ImVoxelNet successfully\nhandles both indoor and outdoor scenes, which makes it general-purpose.\nSpecifically, it achieves state-of-the-art results in car detection on KITTI\n(monocular) and nuScenes (multi-view) benchmarks among all methods that accept\nRGB images. Moreover, it surpasses existing RGB-based 3D object detection\nmethods on the SUN RGB-D dataset. On ScanNet, ImVoxelNet sets a new benchmark\nfor multi-view 3D object detection. The source code and the trained models are\navailable at \\url{https://github.com/saic-vul/imvoxelnet}.",
          "link": "http://arxiv.org/abs/2106.01178",
          "publishedOn": "2021-06-03T02:10:33.823Z",
          "wordCount": 577,
          "title": "ImVoxelNet: Image to Voxels Projection for Monocular and Multi-View General-Purpose 3D Object Detection. (arXiv:2106.01178v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01132",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dufumier_B/0/1/0/all/0/1\">Benoit Dufumier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gori_P/0/1/0/all/0/1\">Pietro Gori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Battaglia_I/0/1/0/all/0/1\">Ilaria Battaglia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Victor_J/0/1/0/all/0/1\">Julie Victor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grigis_A/0/1/0/all/0/1\">Antoine Grigis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duchesnay_E/0/1/0/all/0/1\">Edouard Duchesnay</a>",
          "description": "Deep Learning (DL) and specifically CNN models have become a de facto method\nfor a wide range of vision tasks, outperforming traditional machine learning\n(ML) methods. Consequently, they drew a lot of attention in the neuroimaging\nfield in particular for phenotype prediction or computer-aided diagnosis.\nHowever, most of the current studies often deal with small single-site cohorts,\nalong with a specific pre-processing pipeline and custom CNN architectures,\nwhich make them difficult to compare to. We propose an extensive benchmark of\nrecent state-of-the-art (SOTA) 3D CNN, evaluating also the benefits of data\naugmentation and deep ensemble learning, on both Voxel-Based Morphometry (VBM)\npre-processing and quasi-raw images. Experiments were conducted on a large\nmulti-site 3D brain anatomical MRI data-set comprising N=10k scans on 3\nchallenging tasks: age prediction, sex classification, and schizophrenia\ndiagnosis. We found that all models provide significantly better predictions\nwith VBM images than quasi-raw data. This finding evolved as the training set\napproaches 10k samples where quasi-raw data almost reach the performance of\nVBM. Moreover, we showed that linear models perform comparably with SOTA CNN on\nVBM data. We also demonstrated that DenseNet and tiny-DenseNet, a lighter\nversion that we proposed, provide a good compromise in terms of performance in\nall data regime. Therefore, we suggest to employ them as the architectures by\ndefault. Critically, we also showed that current CNN are still very biased\ntowards the acquisition site, even when trained with N=10k multi-site images.\nIn this context, VBM pre-processing provides an efficient way to limit this\nsite effect. Surprisingly, we did not find any clear benefit from data\naugmentation techniques. Finally, we proved that deep ensemble learning is well\nsuited to re-calibrate big CNN models without sacrificing performance.",
          "link": "http://arxiv.org/abs/2106.01132",
          "publishedOn": "2021-06-03T02:10:33.787Z",
          "wordCount": 744,
          "title": "Benchmarking CNN on 3D Anatomical Brain MRI: Architectures, Data Augmentation and Deep Ensemble Learning. (arXiv:2106.01132v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01351",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Xie_W/0/1/0/all/0/1\">Weiyi Xie</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jacobs_C/0/1/0/all/0/1\">Colin Jacobs</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ginneken_B/0/1/0/all/0/1\">Bram van Ginneken</a>",
          "description": "We propose a deep learning clustering method that exploits dense features\nfrom a segmentation network for emphysema subtyping from computed tomography\n(CT) scans. Using dense features enables high-resolution visualization of image\nregions corresponding to the cluster assignment via dense clustering activation\nmaps (dCAMs). This approach provides model interpretability. We evaluated\nclustering results on 500 subjects from the COPDGenestudy, where radiologists\nmanually annotated emphysema sub-types according to their visual CT assessment.\nWe achieved a 43% unsupervised clustering accuracy, outperforming our baseline\nat 41% and yielding results comparable to supervised classification at 45%. The\nproposed method also offers a better cluster formation than the baseline,\nachieving0.54 in silhouette coefficient and 0.55 in David-Bouldin scores.",
          "link": "http://arxiv.org/abs/2106.01351",
          "publishedOn": "2021-06-03T02:10:33.763Z",
          "wordCount": 547,
          "title": "Deep Clustering Activation Maps for Emphysema Subtyping. (arXiv:2106.01351v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2010.04690",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Parashar_S/0/1/0/all/0/1\">Shaifali Parashar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartoli_A/0/1/0/all/0/1\">Adrien Bartoli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pizarro_D/0/1/0/all/0/1\">Daniel Pizarro</a>",
          "description": "Non-Rigid Structure-from-Motion (NRSfM) reconstructs a deformable 3D object\nfrom the correspondences established between monocular 2D images. Current NRSfM\nmethods lack statistical robustness, which is the ability to cope with\ncorrespondence errors.This prevents one to use automatically established\ncorrespondences, which are prone to errors, thereby strongly limiting the scope\nof NRSfM. We propose a three-step automatic pipeline to solve NRSfM robustly by\nexploiting isometry. Step 1 computes the optical flow from correspondences,\nstep 2 reconstructs each 3D point's normal vector using multiple reference\nimages and integrates them to form surfaces with the best reference and step 3\nrejects the 3D points that break isometry in their local neighborhood.\nImportantly, each step is designed to discard or flag erroneous\ncorrespondences. Our contributions include the robustification of optical flow\nby warp estimation, new fast analytic solutions to local normal reconstruction\nand their robustification, and a new scale-independent measure of 3D local\nisometric coherence. Experimental results show that our robust NRSfM method\nconsistently outperforms existing methods on both synthetic and real datasets.",
          "link": "http://arxiv.org/abs/2010.04690",
          "publishedOn": "2021-06-03T02:10:33.751Z",
          "wordCount": 619,
          "title": "Robust Isometric Non-Rigid Structure-from-Motion. (arXiv:2010.04690v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03000",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Harder_P/0/1/0/all/0/1\">Paula Harder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfreundt_F/0/1/0/all/0/1\">Franz-Josef Pfreundt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keuper_M/0/1/0/all/0/1\">Margret Keuper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keuper_J/0/1/0/all/0/1\">Janis Keuper</a>",
          "description": "Despite the success of convolutional neural networks (CNNs) in many computer\nvision and image analysis tasks, they remain vulnerable against so-called\nadversarial attacks: Small, crafted perturbations in the input images can lead\nto false predictions. A possible defense is to detect adversarial examples. In\nthis work, we show how analysis in the Fourier domain of input images and\nfeature maps can be used to distinguish benign test samples from adversarial\nimages. We propose two novel detection methods: Our first method employs the\nmagnitude spectrum of the input images to detect an adversarial attack. This\nsimple and robust classifier can successfully detect adversarial perturbations\nof three commonly used attack methods. The second method builds upon the first\nand additionally extracts the phase of Fourier coefficients of feature-maps at\ndifferent layers of the network. With this extension, we are able to improve\nadversarial detection rates compared to state-of-the-art detectors on five\ndifferent attack methods.",
          "link": "http://arxiv.org/abs/2103.03000",
          "publishedOn": "2021-06-03T02:10:33.738Z",
          "wordCount": 617,
          "title": "SpectralDefense: Detecting Adversarial Attacks on CNNs in the Fourier Domain. (arXiv:2103.03000v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.08019",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+George_A/0/1/0/all/0/1\">Anjith George</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marcel_S/0/1/0/all/0/1\">Sebastien Marcel</a>",
          "description": "The vulnerability of face recognition systems to presentation attacks has\nlimited their application in security-critical scenarios. Automatic methods of\ndetecting such malicious attempts are essential for the safe use of facial\nrecognition technology. Although various methods have been suggested for\ndetecting such attacks, most of them over-fit the training set and fail in\ngeneralizing to unseen attacks and environments. In this work, we use transfer\nlearning from the vision transformer model for the zero-shot anti-spoofing\ntask. The effectiveness of the proposed approach is demonstrated through\nexperiments in publicly available datasets. The proposed approach outperforms\nthe state-of-the-art methods in the zero-shot protocols in the HQ-WMCA and\nSiW-M datasets by a large margin. Besides, the model achieves a significant\nboost in cross-database performance as well.",
          "link": "http://arxiv.org/abs/2011.08019",
          "publishedOn": "2021-06-03T02:10:33.708Z",
          "wordCount": 589,
          "title": "On the Effectiveness of Vision Transformers for Zero-shot Face Anti-Spoofing. (arXiv:2011.08019v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.03788",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinshao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1\">Yang Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kodirov_E/0/1/0/all/0/1\">Elyor Kodirov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clifton_D/0/1/0/all/0/1\">David A. Clifton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Robertson_N/0/1/0/all/0/1\">Neil M. Robertson</a>",
          "description": "To train robust deep neural networks (DNNs), we systematically study several\ntarget modification approaches, which include output regularisation, self and\nnon-self label correction (LC). Two key issues are discovered: (1) Self LC is\nthe most appealing as it exploits its own knowledge and requires no extra\nmodels. However, how to automatically decide the trust degree of a learner as\ntraining goes is not well answered in the literature? (2) Some methods penalise\nwhile the others reward low-entropy predictions, prompting us to ask which one\nis better?\n\nTo resolve the first issue, taking two well-accepted propositions--deep\nneural networks learn meaningful patterns before fitting noise [3] and minimum\nentropy regularisation principle [10]--we propose a novel end-to-end method\nnamed ProSelfLC, which is designed according to learning time and entropy.\nSpecifically, given a data point, we progressively increase trust in its\npredicted label distribution versus its annotated one if a model has been\ntrained for enough time and the prediction is of low entropy (high confidence).\nFor the second issue, according to ProSelfLC, we empirically prove that it is\nbetter to redefine a meaningful low-entropy status and optimise the learner\ntoward it. This serves as a defence of entropy minimisation.\n\nWe demonstrate the effectiveness of ProSelfLC through extensive experiments\nin both clean and noisy settings. The source code is available at\nhttps://github.com/XinshaoAmosWang/ProSelfLC-CVPR2021.\n\nKeywords: entropy minimisation, maximum entropy, confidence penalty, self\nknowledge distillation, label correction, label noise, semi-supervised\nlearning, output regularisation",
          "link": "http://arxiv.org/abs/2005.03788",
          "publishedOn": "2021-06-03T02:10:33.703Z",
          "wordCount": 787,
          "title": "ProSelfLC: Progressive Self Label Correction for Training Robust Deep Neural Networks. (arXiv:2005.03788v6 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.00113",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mirsky_Y/0/1/0/all/0/1\">Yisroel Mirsky</a>",
          "description": "Applications such as autonomous vehicles and medical screening use deep\nlearning models to localize and identify hundreds of objects in a single frame.\nIn the past, it has been shown how an attacker can fool these models by placing\nan adversarial patch within a scene. However, these patches must be placed in\nthe target location and do not explicitly alter the semantics elsewhere in the\nimage.\n\nIn this paper, we introduce a new type of adversarial patch which alters a\nmodel's perception of an image's semantics. These patches can be placed\nanywhere within an image to change the classification or semantics of locations\nfar from the patch. We call this new class of adversarial examples `remote\nadversarial patches' (RAP).\n\nWe implement our own RAP called IPatch and perform an in-depth analysis on\nimage segmentation RAP attacks using five state-of-the-art architectures with\neight different encoders on the CamVid street view dataset. Moreover, we\ndemonstrate that the attack can be extended to object recognition models with\npreliminary results on the popular YOLOv3 model. We found that the patch can\nchange the classification of a remote target region with a success rate of up\nto 93% on average.",
          "link": "http://arxiv.org/abs/2105.00113",
          "publishedOn": "2021-06-03T02:10:33.697Z",
          "wordCount": 652,
          "title": "IPatch: A Remote Adversarial Patch. (arXiv:2105.00113v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.04012",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yao Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_H/0/1/0/all/0/1\">Haiwen Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Black_M/0/1/0/all/0/1\">Michael J. Black</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bolkart_T/0/1/0/all/0/1\">Timo Bolkart</a>",
          "description": "While current monocular 3D face reconstruction methods can recover fine\ngeometric details, they suffer several limitations. Some methods produce faces\nthat cannot be realistically animated because they do not model how wrinkles\nvary with expression. Other methods are trained on high-quality face scans and\ndo not generalize well to in-the-wild images. We present the first approach\nthat regresses 3D face shape and animatable details that are specific to an\nindividual but change with expression. Our model, DECA (Detailed Expression\nCapture and Animation), is trained to robustly produce a UV displacement map\nfrom a low-dimensional latent representation that consists of person-specific\ndetail parameters and generic expression parameters, while a regressor is\ntrained to predict detail, shape, albedo, expression, pose and illumination\nparameters from a single image. To enable this, we introduce a novel\ndetail-consistency loss that disentangles person-specific details from\nexpression-dependent wrinkles. This disentanglement allows us to synthesize\nrealistic person-specific wrinkles by controlling expression parameters while\nkeeping person-specific details unchanged. DECA is learned from in-the-wild\nimages with no paired 3D supervision and achieves state-of-the-art shape\nreconstruction accuracy on two benchmarks. Qualitative results on in-the-wild\ndata demonstrate DECA's robustness and its ability to disentangle identity- and\nexpression-dependent details enabling animation of reconstructed faces. The\nmodel and code are publicly available at https://deca.is.tue.mpg.de.",
          "link": "http://arxiv.org/abs/2012.04012",
          "publishedOn": "2021-06-03T02:10:33.662Z",
          "wordCount": 697,
          "title": "Learning an Animatable Detailed 3D Face Model from In-The-Wild Images. (arXiv:2012.04012v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.10185",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhouyong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1\">Shun Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wubin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jingben Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yufan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Shilei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chunguo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Luxi Yang</a>",
          "description": "Deep Convolutional Neural Networks (CNNs) are powerful models that have\nachieved excellent performance on difficult computer vision tasks. Although\nCNNs perform well whenever large labeled training samples are available, they\nwork badly on video frame synthesis due to objects deforming and moving, scene\nlighting changes, and cameras moving in video sequence. In this paper, we\npresent a novel and general end-to-end architecture, called convolutional\nTransformer or ConvTransformer, for video frame sequence learning and video\nframe synthesis. The core ingredient of ConvTransformer is the proposed\nattention layer, i.e., multi-head convolutional self-attention layer, that\nlearns the sequential dependence of video sequence. ConvTransformer uses an\nencoder, built upon multi-head convolutional self-attention layer, to encode\nthe sequential dependence between the input frames, and then a decoder decodes\nthe long-term dependence between the target synthesized frames and the input\nframes. Experiments on video future frame extrapolation task show\nConvTransformer to be superior in quality while being more parallelizable to\nrecent approaches built upon convolutional LSTM (ConvLSTM). To the best of our\nknowledge, this is the first time that ConvTransformer architecture is proposed\nand applied to video frame synthesis.",
          "link": "http://arxiv.org/abs/2011.10185",
          "publishedOn": "2021-06-03T02:10:33.648Z",
          "wordCount": 650,
          "title": "ConvTransformer: A Convolutional Transformer Network for Video Frame Synthesis. (arXiv:2011.10185v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.06504",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_P/0/1/0/all/0/1\">Pingchuan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martinez_B/0/1/0/all/0/1\">Brais Martinez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petridis_S/0/1/0/all/0/1\">Stavros Petridis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pantic_M/0/1/0/all/0/1\">Maja Pantic</a>",
          "description": "Lipreading has witnessed a lot of progress due to the resurgence of neural\nnetworks. Recent works have placed emphasis on aspects such as improving\nperformance by finding the optimal architecture or improving generalization.\nHowever, there is still a significant gap between the current methodologies and\nthe requirements for an effective deployment of lipreading in practical\nscenarios. In this work, we propose a series of innovations that significantly\nbridge that gap: first, we raise the state-of-the-art performance by a wide\nmargin on LRW and LRW-1000 to 88.5% and 46.6%, respectively using\nself-distillation. Secondly, we propose a series of architectural changes,\nincluding a novel Depthwise Separable Temporal Convolutional Network (DS-TCN)\nhead, that slashes the computational cost to a fraction of the (already quite\nefficient) original model. Thirdly, we show that knowledge distillation is a\nvery effective tool for recovering performance of the lightweight models. This\nresults in a range of models with different accuracy-efficiency trade-offs.\nHowever, our most promising lightweight models are on par with the current\nstate-of-the-art while showing a reduction of 8.2x and 3.9x in terms of\ncomputational cost and number of parameters, respectively, which we hope will\nenable the deployment of lipreading models in practical applications.",
          "link": "http://arxiv.org/abs/2007.06504",
          "publishedOn": "2021-06-03T02:10:33.624Z",
          "wordCount": 674,
          "title": "Towards Practical Lipreading with Distilled and Efficient Models. (arXiv:2007.06504v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.14963",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wolflein_G/0/1/0/all/0/1\">Georg W&#xf6;lflein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arandjelovic_O/0/1/0/all/0/1\">Ognjen Arandjelovi&#x107;</a>",
          "description": "Identifying the configuration of chess pieces from an image of a chessboard\nis a problem in computer vision that has not yet been solved accurately.\nHowever, it is important for helping amateur chess players improve their games\nby facilitating automatic computer analysis without the overhead of manually\nentering the pieces. Current approaches are limited by the lack of large\ndatasets and are not designed to adapt to unseen chess sets. This paper puts\nforth a new dataset synthesised from a 3D model that is an order of magnitude\nlarger than existing ones. Trained on this dataset, a novel end-to-end chess\nrecognition system is presented that combines traditional computer vision\ntechniques with deep learning. It localises the chessboard using a RANSAC-based\nalgorithm that computes a projective transformation of the board onto a regular\ngrid. Using two convolutional neural networks, it then predicts an occupancy\nmask for the squares in the warped image and finally classifies the pieces. The\ndescribed system achieves an error rate of 0.23% per square on the test set, 28\ntimes better than the current state of the art. Further, a few-shot transfer\nlearning approach is developed that is able to adapt the inference system to a\npreviously unseen chess set using just two photos of the starting position,\nobtaining a per-square accuracy of 99.83% on images of that new chess set. The\ncode, dataset, and trained models are made available online.",
          "link": "http://arxiv.org/abs/2104.14963",
          "publishedOn": "2021-06-03T02:10:33.618Z",
          "wordCount": 700,
          "title": "Determining Chess Game State From an Image. (arXiv:2104.14963v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.05049",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zongheng Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1\">Yue Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Si Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Guanbin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1\">Xiaojie Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Hongxu Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Q/0/1/0/all/0/1\">Qian Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1\">Dong Xu</a>",
          "description": "In this work, we introduce a novel task - Humancentric Spatio-Temporal Video\nGrounding (HC-STVG). Unlike the existing referring expression tasks in images\nor videos, by focusing on humans, HC-STVG aims to localize a spatiotemporal\ntube of the target person from an untrimmed video based on a given textural\ndescription. This task is useful, especially for healthcare and\nsecurity-related applications, where the surveillance videos can be extremely\nlong but only a specific person during a specific period of time is concerned.\nHC-STVG is a video grounding task that requires both spatial (where) and\ntemporal (when) localization. Unfortunately, the existing grounding methods\ncannot handle this task well. We tackle this task by proposing an effective\nbaseline method named Spatio-Temporal Grounding with Visual Transformers\n(STGVT), which utilizes Visual Transformers to extract cross-modal\nrepresentations for video-sentence matching and temporal localization. To\nfacilitate this task, we also contribute an HC-STVG dataset consisting of 5,660\nvideo-sentence pairs on complex multi-person scenes. Specifically, each video\nlasts for 20 seconds, pairing with a natural query sentence with an average of\n17.25 words. Extensive experiments are conducted on this dataset, demonstrating\nthe newly-proposed method outperforms the existing baseline methods.",
          "link": "http://arxiv.org/abs/2011.05049",
          "publishedOn": "2021-06-03T02:10:33.599Z",
          "wordCount": 667,
          "title": "Human-centric Spatio-Temporal Video Grounding With Visual Transformers. (arXiv:2011.05049v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01085",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1\">Jaehong Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madaan_D/0/1/0/all/0/1\">Divyam Madaan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1\">Eunho Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>",
          "description": "A dataset is a shred of crucial evidence to describe a task. However, each\ndata point in the dataset does not have the same potential, as some of the data\npoints can be more representative or informative than others. This unequal\nimportance among the data points may have a large impact in rehearsal-based\ncontinual learning, where we store a subset of the training examples (coreset)\nto be replayed later to alleviate catastrophic forgetting. In continual\nlearning, the quality of the samples stored in the coreset directly affects the\nmodel's effectiveness and efficiency. The coreset selection problem becomes\neven more important under realistic settings, such as imbalanced continual\nlearning or noisy data scenarios. To tackle this problem, we propose Online\nCoreset Selection (OCS), a simple yet effective method that selects the most\nrepresentative and informative coreset at each iteration and trains them in an\nonline manner. Our proposed method maximizes the model's adaptation to a target\ndataset while selecting high-affinity samples to past tasks, which directly\ninhibits catastrophic forgetting. We validate the effectiveness of our coreset\nselection mechanism over various standard, imbalanced, and noisy datasets\nagainst strong continual learning baselines, demonstrating that it improves\ntask adaptation and prevents catastrophic forgetting in a sample-efficient\nmanner.",
          "link": "http://arxiv.org/abs/2106.01085",
          "publishedOn": "2021-06-03T02:10:33.575Z",
          "wordCount": 632,
          "title": "Online Coreset Selection for Rehearsal-based Continual Learning. (arXiv:2106.01085v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01088",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Haisheng Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jinyuan Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dongliang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_W/0/1/0/all/0/1\">Weihao Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>",
          "description": "Efficient spatiotemporal modeling is an important yet challenging problem for\nvideo action recognition. Existing state-of-the-art methods exploit motion\nclues to assist in short-term temporal modeling through temporal difference\nover consecutive frames. However, background noises will be inevitably\nintroduced due to the camera movement. Besides, movements of different actions\ncan vary greatly. In this paper, we propose a Temporal Saliency Integration\n(TSI) block, which mainly contains a Salient Motion Excitation (SME) module and\na Cross-scale Temporal Integration (CTI) module. Specifically, SME aims to\nhighlight the motion-sensitive area through local-global motion modeling, where\nthe background suppression and pyramidal feature difference are conducted\nsuccessively between neighboring frames to capture motion dynamics with less\nbackground noises. CTI is designed to perform multi-scale temporal modeling\nthrough a group of separate 1D convolutions respectively. Meanwhile, temporal\ninteractions across different scales are integrated with attention mechanism.\nThrough these two modules, long short-term temporal relationships can be\nencoded efficiently by introducing limited additional parameters. Extensive\nexperiments are conducted on several popular benchmarks (i.e.,\nSomething-Something v1 & v2, Kinetics-400, UCF-101, and HMDB-51), which\ndemonstrate the effectiveness and superiority of our proposed method.",
          "link": "http://arxiv.org/abs/2106.01088",
          "publishedOn": "2021-06-03T02:10:33.566Z",
          "wordCount": 617,
          "title": "TSI: Temporal Saliency Integration for Video Action Recognition. (arXiv:2106.01088v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01111",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sun_W/0/1/0/all/0/1\">Wei Sun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_T/0/1/0/all/0/1\">Tao Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Min_X/0/1/0/all/0/1\">Xiongkuo Min</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yi_F/0/1/0/all/0/1\">Fuwang Yi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhai_G/0/1/0/all/0/1\">Guangtao Zhai</a>",
          "description": "In this paper, we propose a deep learning based video quality assessment\n(VQA) framework to evaluate the quality of the compressed user's generated\ncontent (UGC) videos. The proposed VQA framework consists of three modules, the\nfeature extraction module, the quality regression module, and the quality\npooling module. For the feature extraction module, we fuse the features from\nintermediate layers of the convolutional neural network (CNN) network into\nfinal quality-aware feature representation, which enables the model to make\nfull use of visual information from low-level to high-level. Specifically, the\nstructure and texture similarities of feature maps extracted from all\nintermediate layers are calculated as the feature representation for the full\nreference (FR) VQA model, and the global mean and standard deviation of the\nfinal feature maps fused by intermediate feature maps are calculated as the\nfeature representation for the no reference (NR) VQA model. For the quality\nregression module, we use the fully connected (FC) layer to regress the\nquality-aware features into frame-level scores. Finally, a\nsubjectively-inspired temporal pooling strategy is adopted to pool frame-level\nscores into the video-level score. The proposed model achieves the best\nperformance among the state-of-the-art FR and NR VQA models on the Compressed\nUGC VQA database and also achieves pretty good performance on the in-the-wild\nUGC VQA databases.",
          "link": "http://arxiv.org/abs/2106.01111",
          "publishedOn": "2021-06-03T02:10:33.559Z",
          "wordCount": 666,
          "title": "Deep Learning based Full-reference and No-reference Quality Assessment Models for Compressed UGC Videos. (arXiv:2106.01111v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01035",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Daochang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qiyue Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_T/0/1/0/all/0/1\">Tingting Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yizhou Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miao_R/0/1/0/all/0/1\">Rulin Miao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shan_F/0/1/0/all/0/1\">Fei Shan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Ziyu Li</a>",
          "description": "Surgical skills have a great influence on surgical safety and patients'\nwell-being. Traditional assessment of surgical skills involves strenuous manual\nefforts, which lacks efficiency and repeatability. Therefore, we attempt to\nautomatically predict how well the surgery is performed using the surgical\nvideo. In this paper, a unified multi-path framework for automatic surgical\nskill assessment is proposed, which takes care of multiple composing aspects of\nsurgical skills, including surgical tool usage, intraoperative event pattern,\nand other skill proxies. The dependency relationships among these different\naspects are specially modeled by a path dependency module in the framework. We\nconduct extensive experiments on the JIGSAWS dataset of simulated surgical\ntasks, and a new clinical dataset of real laparoscopic surgeries. The proposed\nframework achieves promising results on both datasets, with the\nstate-of-the-art on the simulated dataset advanced from 0.71 Spearman's\ncorrelation to 0.80. It is also shown that combining multiple skill aspects\nyields better performance than relying on a single aspect.",
          "link": "http://arxiv.org/abs/2106.01035",
          "publishedOn": "2021-06-03T02:10:33.550Z",
          "wordCount": 590,
          "title": "Towards Unified Surgical Skill Assessment. (arXiv:2106.01035v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00952",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dang_T/0/1/0/all/0/1\">Tuan-Anh Nguyen Dang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1\">Dat-Thanh Nguyen</a>",
          "description": "Information extraction from document images has received a lot of attention\nrecently, due to the need for digitizing a large volume of unstructured\ndocuments such as invoices, receipts, bank transfers, etc. In this paper, we\npropose a novel deep learning architecture for end-to-end information\nextraction on the 2D character-grid embedding of the document, namely the\n\\textit{Multi-Stage Attentional U-Net}. To effectively capture the textual and\nspatial relations between 2D elements, our model leverages a specialized\nmulti-stage encoder-decoders design, in conjunction with efficient uses of the\nself-attention mechanism and the box convolution. Experimental results on\ndifferent datasets show that our model outperforms the baseline U-Net\narchitecture by a large margin while using 40\\% fewer parameters. Moreover, it\nalso significantly improved the baseline in erroneous OCR and limited training\ndata scenario, thus becomes practical for real-world applications.",
          "link": "http://arxiv.org/abs/2106.00952",
          "publishedOn": "2021-06-03T02:10:33.545Z",
          "wordCount": 590,
          "title": "End-to-End Information Extraction by Character-Level Embedding and Multi-Stage Attentional U-Net. (arXiv:2106.00952v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00919",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+To_M/0/1/0/all/0/1\">Minh-Son To</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sarno_I/0/1/0/all/0/1\">Ian G Sarno</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chong_C/0/1/0/all/0/1\">Chee Chong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jenkinson_M/0/1/0/all/0/1\">Mark Jenkinson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Carneiro_G/0/1/0/all/0/1\">Gustavo Carneiro</a>",
          "description": "Longitudinal imaging forms an essential component in the management and\nfollow-up of many medical conditions. The presence of lesion changes on serial\nimaging can have significant impact on clinical decision making, highlighting\nthe important role for automated change detection. Lesion changes can represent\nanomalies in serial imaging, which implies a limited availability of\nannotations and a wide variety of possible changes that need to be considered.\nHence, we introduce a new unsupervised anomaly detection and localisation\nmethod trained exclusively with serial images that do not contain any lesion\nchanges. Our training automatically synthesises lesion changes in serial\nimages, introducing detection and localisation pseudo-labels that are used to\nself-supervise the training of our model. Given the rarity of these lesion\nchanges in the synthesised images, we train the model with the imbalance robust\nfocal Tversky loss. When compared to supervised models trained on different\ndatasets, our method shows competitive performance in the detection and\nlocalisation of new demyelinating lesions on longitudinal magnetic resonance\nimaging in multiple sclerosis patients. Code for the models will be made\navailable on GitHub.",
          "link": "http://arxiv.org/abs/2106.00919",
          "publishedOn": "2021-06-03T02:10:33.486Z",
          "wordCount": 633,
          "title": "Self-supervised Lesion Change Detection and Localisation in Longitudinal Multiple Sclerosis Brain Imaging. (arXiv:2106.00919v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01100",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Pohl_M/0/1/0/all/0/1\">Michel Pohl</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Uesaka_M/0/1/0/all/0/1\">Mitsuru Uesaka</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Takahashi_H/0/1/0/all/0/1\">Hiroyuki Takahashi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Demachi_K/0/1/0/all/0/1\">Kazuyuki Demachi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chhatkuli_R/0/1/0/all/0/1\">Ritu Bhusal Chhatkuli</a>",
          "description": "During lung cancer radiotherapy, the position of infrared reflective objects\non the chest can be recorded to estimate the tumor location. However,\nradiotherapy systems usually have a latency inherent to robot control\nlimitations that impedes the radiation delivery precision. Not taking this\nphenomenon into account may cause unwanted damage to healthy tissues and lead\nto side effects such as radiation pneumonitis. In this research, we use nine\nobservation records of the three-dimensional position of three external markers\non the chest and abdomen of healthy individuals breathing during intervals from\n73s to 222s. The sampling frequency is equal to 10Hz and the amplitudes of the\nrecorded trajectories range from 6mm to 40mm in the superior-inferior\ndirection. We forecast the location of each marker simultaneously with a\nhorizon value (the time interval in advance for which the prediction is made)\nbetween 0.1s and 2.0s, using a recurrent neural network (RNN) trained with\nunbiased online recurrent optimization (UORO). We compare its performance with\nan RNN trained with real-time recurrent learning, least mean squares (LMS), and\noffline linear regression. Training and cross-validation are performed during\nthe first minute of each sequence. On average, UORO achieves the lowest\nroot-mean-square (RMS) and maximum error, equal respectively to 1.3mm and\n8.8mm, with a prediction time per time step lower than 2.8ms (Dell Intel core\ni9-9900K 3.60Ghz). Linear regression has the lowest RMS error for the horizon\nvalues 0.1s and 0.2s, followed by LMS for horizon values between 0.3s and 0.5s,\nand UORO for horizon values greater than 0.6s.",
          "link": "http://arxiv.org/abs/2106.01100",
          "publishedOn": "2021-06-03T02:10:33.480Z",
          "wordCount": 737,
          "title": "Prediction of the Position of External Markers Using a Recurrent Neural Network Trained With Unbiased Online Recurrent Optimization for Safe Lung Cancer Radiotherapy. (arXiv:2106.01100v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01127",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1\">Chun-Hao Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adam_G/0/1/0/all/0/1\">George Alexandru Adam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldenberg_A/0/1/0/all/0/1\">Anna Goldenberg</a>",
          "description": "Despite the success of machine learning applications in science, industry,\nand society in general, many approaches are known to be non-robust, often\nrelying on spurious correlations to make predictions. Spuriousness occurs when\nsome features correlate with labels but are not causal; relying on such\nfeatures prevents models from generalizing to unseen environments where such\ncorrelations break. In this work, we focus on image classification and propose\ntwo data generation processes to reduce spuriousness. Given human annotations\nof the subset of the features responsible (causal) for the labels (e.g.\nbounding boxes), we modify this causal set to generate a surrogate image that\nno longer has the same label (i.e. a counterfactual image). We also alter\nnon-causal features to generate images still recognized as the original labels,\nwhich helps to learn a model invariant to these features. In several\nchallenging datasets, our data generations outperform state-of-the-art methods\nin accuracy when spurious correlations break, and increase the saliency focus\non causal features providing better explanations.",
          "link": "http://arxiv.org/abs/2106.01127",
          "publishedOn": "2021-06-03T02:10:33.440Z",
          "wordCount": 601,
          "title": "Towards Robust Classification Model by Counterfactual and Invariant Data Generation. (arXiv:2106.01127v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01055",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Orhei_C/0/1/0/all/0/1\">Ciprian Orhei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vert_S/0/1/0/all/0/1\">Silviu Vert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasiu_R/0/1/0/all/0/1\">Radu Vasiu</a>",
          "description": "Augmented Reality is an environment-enhancing technology, widely applied in\nmany domains, such as tourism and culture. One of the major challenges in this\nfield is precise detection and extraction of building information through\nComputer Vision techniques. Edge detection is one of the building blocks\noperations for many feature extraction solutions in Computer Vision. AR systems\nuse edge detection for building extraction or for extraction of facade details\nfrom buildings. In this paper, we propose a novel filter operator for edge\ndetection that aims to extract building contours or facade features better. The\nproposed filter gives more weight for finding vertical and horizontal edges\nthat is an important feature for our aim.",
          "link": "http://arxiv.org/abs/2106.01055",
          "publishedOn": "2021-06-03T02:10:33.434Z",
          "wordCount": 548,
          "title": "A Novel Edge Detection Operator for Identifying Buildings in Augmented Reality Applications. (arXiv:2106.01055v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00985",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_Q/0/1/0/all/0/1\">Qinyan Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Juncheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_Q/0/1/0/all/0/1\">Qiaosi Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_F/0/1/0/all/0/1\">Faming Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Guixu Zhang</a>",
          "description": "Under stereo settings, the problem of image super-resolution (SR) and\ndisparity estimation are interrelated that the result of each problem could\nhelp to solve the other. The effective exploitation of correspondence between\ndifferent views facilitates the SR performance, while the high-resolution (HR)\nfeatures with richer details benefit the correspondence estimation. According\nto this motivation, we propose a Stereo Super-Resolution and Disparity\nEstimation Feedback Network (SSRDE-FNet), which simultaneously handles the\nstereo image super-resolution and disparity estimation in a unified framework\nand interact them with each other to further improve their performance.\nSpecifically, the SSRDE-FNet is composed of two dual recursive sub-networks for\nleft and right views. Besides the cross-view information exploitation in the\nlow-resolution (LR) space, HR representations produced by the SR process are\nutilized to perform HR disparity estimation with higher accuracy, through which\nthe HR features can be aggregated to generate a finer SR result. Afterward, the\nproposed HR Disparity Information Feedback (HRDIF) mechanism delivers\ninformation carried by HR disparity back to previous layers to further refine\nthe SR image reconstruction. Extensive experiments demonstrate the\neffectiveness and advancement of SSRDE-FNet.",
          "link": "http://arxiv.org/abs/2106.00985",
          "publishedOn": "2021-06-03T02:10:33.402Z",
          "wordCount": 618,
          "title": "Feedback Network for Mutually Boosted Stereo Image Super-Resolution and Disparity Estimation. (arXiv:2106.00985v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01061",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1\">Chen Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1\">Tianfei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenguan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zongxin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1\">Yunchao Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi Yang</a>",
          "description": "Referring video object segmentation (RVOS) aims to segment video objects with\nthe guidance of natural language reference. Previous methods typically tackle\nRVOS through directly grounding linguistic reference over the image lattice.\nSuch bottom-up strategy fails to explore object-level cues, easily leading to\ninferior results. In this work, we instead put forward a two-stage, top-down\nRVOS solution. First, an exhaustive set of object tracklets is constructed by\npropagating object masks detected from several sampled frames to the entire\nvideo. Second, a Transformer-based tracklet-language grounding module is\nproposed, which models instance-level visual relations and cross-modal\ninteractions simultaneously and efficiently. Our model ranks first place on\nCVPR2021 Referring Youtube-VOS challenge.",
          "link": "http://arxiv.org/abs/2106.01061",
          "publishedOn": "2021-06-03T02:10:33.396Z",
          "wordCount": 551,
          "title": "Rethinking Cross-modal Interaction from a Top-down Perspective for Referring Video Object Segmentation. (arXiv:2106.01061v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00997",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Han_C/0/1/0/all/0/1\">Changhee Han</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Okamoto_T/0/1/0/all/0/1\">Takayuki Okamoto</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Takeuchi_K/0/1/0/all/0/1\">Koichi Takeuchi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Katsios_D/0/1/0/all/0/1\">Dimitris Katsios</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Grushnikov_A/0/1/0/all/0/1\">Andrey Grushnikov</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kobayashi_M/0/1/0/all/0/1\">Masaaki Kobayashi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Choppin_A/0/1/0/all/0/1\">Antoine Choppin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kurashina_Y/0/1/0/all/0/1\">Yutaka Kurashina</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shimahara_Y/0/1/0/all/0/1\">Yuki Shimahara</a>",
          "description": "Convolutional Neural Networks (CNNs) intrinsically requires large-scale data\nwhereas Chest X-Ray (CXR) images tend to be data/annotation-scarce, leading to\nover-fitting. Therefore, based on our development experience and related work,\nthis paper thoroughly introduces tricks to improve generalization in the CXR\ndiagnosis: how to (i) leverage additional data, (ii) augment/distillate data,\n(iii) regularize training, and (iv) conduct efficient segmentation. As a\ndevelopment example based on such optimization techniques, we also feature\nLPIXEL's CNN-based CXR solution, EIRL Chest Nodule, which improved\nradiologists/non-radiologists' nodule detection sensitivity by 0.100/0.131,\nrespectively, while maintaining specificity.",
          "link": "http://arxiv.org/abs/2106.00997",
          "publishedOn": "2021-06-03T02:10:33.388Z",
          "wordCount": 561,
          "title": "Tips and Tricks to Improve CNN-based Chest X-ray Diagnosis: A Survey. (arXiv:2106.00997v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00799",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rosa_L/0/1/0/all/0/1\">Laura Elena Cu&#xe9; La Rosa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sothe_C/0/1/0/all/0/1\">Camile Sothe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feitosa_R/0/1/0/all/0/1\">Raul Queiroz Feitosa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Almeida_C/0/1/0/all/0/1\">Cl&#xe1;udia Maria de Almeida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schimalski_M/0/1/0/all/0/1\">Marcos Benedito Schimalski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oliveira_D/0/1/0/all/0/1\">Dario Augusto Borges Oliveira</a>",
          "description": "This work proposes a multi-task fully convolutional architecture for tree\nspecies mapping in dense forests from sparse and scarce polygon-level\nannotations using hyperspectral UAV-borne data. Our model implements a partial\nloss function that enables dense tree semantic labeling outcomes from non-dense\ntraining samples, and a distance regression complementary task that enforces\ntree crown boundary constraints and substantially improves the model\nperformance. Our multi-task architecture uses a shared backbone network that\nlearns common representations for both tasks and two task-specific decoders,\none for the semantic segmentation output and one for the distance map\nregression. We report that introducing the complementary task boosts the\nsemantic segmentation performance compared to the single-task counterpart in up\nto 10% reaching an overall F1 score of 87.5% and an overall accuracy of 85.9%,\nachieving state-of-art performance for tree species classification in tropical\nforests.",
          "link": "http://arxiv.org/abs/2106.00799",
          "publishedOn": "2021-06-03T02:10:33.301Z",
          "wordCount": 599,
          "title": "Multi-task fully convolutional network for tree species mapping in dense forests using small training hyperspectral data. (arXiv:2106.00799v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00739",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tolosana_R/0/1/0/all/0/1\">Ruben Tolosana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vera_Rodriguez_R/0/1/0/all/0/1\">Ruben Vera-Rodriguez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_Garcia_C/0/1/0/all/0/1\">Carlos Gonzalez-Garcia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fierrez_J/0/1/0/all/0/1\">Julian Fierrez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rengifo_S/0/1/0/all/0/1\">Santiago Rengifo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morales_A/0/1/0/all/0/1\">Aythami Morales</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ortega_Garcia_J/0/1/0/all/0/1\">Javier Ortega-Garcia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruiz_Garcia_J/0/1/0/all/0/1\">Juan Carlos Ruiz-Garcia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romero_Tapiador_S/0/1/0/all/0/1\">Sergio Romero-Tapiador</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jiajia Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_S/0/1/0/all/0/1\">Songxuan Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1\">Lianwen Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yecheng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galbally_J/0/1/0/all/0/1\">Javier Galbally</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diaz_M/0/1/0/all/0/1\">Moises Diaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferrer_M/0/1/0/all/0/1\">Miguel Angel Ferrer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_Barrero_M/0/1/0/all/0/1\">Marta Gomez-Barrero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hodashinsky_I/0/1/0/all/0/1\">Ilya Hodashinsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarin_K/0/1/0/all/0/1\">Konstantin Sarin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slezkin_A/0/1/0/all/0/1\">Artem Slezkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bardamova_M/0/1/0/all/0/1\">Marina Bardamova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Svetlakov_M/0/1/0/all/0/1\">Mikhail Svetlakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saleem_M/0/1/0/all/0/1\">Mohammad Saleem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szucs_C/0/1/0/all/0/1\">Cintia Lia Sz&#xfc;cs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kovari_B/0/1/0/all/0/1\">Bence Kovari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pulsmeyer_F/0/1/0/all/0/1\">Falk Pulsmeyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wehbi_M/0/1/0/all/0/1\">Mohamad Wehbi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zanca_D/0/1/0/all/0/1\">Dario Zanca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_S/0/1/0/all/0/1\">Sumaiya Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Sarthak Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jabin_S/0/1/0/all/0/1\">Suraiya Jabin</a>",
          "description": "This paper describes the experimental framework and results of the ICDAR 2021\nCompetition on On-Line Signature Verification (SVC 2021). The goal of SVC 2021\nis to evaluate the limits of on-line signature verification systems on popular\nscenarios (office/mobile) and writing inputs (stylus/finger) through\nlarge-scale public databases. Three different tasks are considered in the\ncompetition, simulating realistic scenarios as both random and skilled\nforgeries are simultaneously considered on each task. The results obtained in\nSVC 2021 prove the high potential of deep learning methods. In particular, the\nbest on-line signature verification system of SVC 2021 obtained Equal Error\nRate (EER) values of 3.33% (Task 1), 7.41% (Task 2), and 6.04% (Task 3).\n\nSVC 2021 will be established as an on-going competition, where researchers\ncan easily benchmark their systems against the state of the art in an open\ncommon platform using large-scale public databases such as DeepSignDB and\nSVC2021_EvalDB, and standard experimental protocols.",
          "link": "http://arxiv.org/abs/2106.00739",
          "publishedOn": "2021-06-03T02:10:33.296Z",
          "wordCount": 651,
          "title": "ICDAR 2021 Competition on On-Line Signature Verification. (arXiv:2106.00739v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00783",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Fuoli_D/0/1/0/all/0/1\">Dario Fuoli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gool_L/0/1/0/all/0/1\">Luc Van Gool</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Timofte_R/0/1/0/all/0/1\">Radu Timofte</a>",
          "description": "Many super-resolution (SR) models are optimized for high performance only and\ntherefore lack efficiency due to large model complexity. As large models are\noften not practical in real-world applications, we investigate and propose\nnovel loss functions, to enable SR with high perceptual quality from much more\nefficient models. The representative power for a given low-complexity generator\nnetwork can only be fully leveraged by strong guidance towards the optimal set\nof parameters. We show that it is possible to improve the performance of a\nrecently introduced efficient generator architecture solely with the\napplication of our proposed loss functions. In particular, we use a Fourier\nspace supervision loss for improved restoration of missing high-frequency (HF)\ncontent from the ground truth image and design a discriminator architecture\nworking directly in the Fourier domain to better match the target HF\ndistribution. We show that our losses' direct emphasis on the frequencies in\nFourier-space significantly boosts the perceptual image quality, while at the\nsame time retaining high restoration quality in comparison to previously\nproposed loss functions for this task. The performance is further improved by\nutilizing a combination of spatial and frequency domain losses, as both\nrepresentations provide complementary information during training. On top of\nthat, the trained generator achieves comparable results with and is 2.4x and\n48x faster than state-of-the-art perceptual SR methods RankSRGAN and SRFlow\nrespectively.",
          "link": "http://arxiv.org/abs/2106.00783",
          "publishedOn": "2021-06-03T02:10:33.205Z",
          "wordCount": 661,
          "title": "Fourier Space Losses for Efficient Perceptual Image Super-Resolution. (arXiv:2106.00783v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00817",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baumgartner_M/0/1/0/all/0/1\">Michael Baumgartner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaeger_P/0/1/0/all/0/1\">Paul F. Jaeger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isensee_F/0/1/0/all/0/1\">Fabian Isensee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maier_Hein_K/0/1/0/all/0/1\">Klaus H. Maier-Hein</a>",
          "description": "Simultaneous localisation and categorization of objects in medical images,\nalso referred to as medical object detection, is of high clinical relevance\nbecause diagnostic decisions often depend on rating of objects rather than e.g.\npixels. For this task, the cumbersome and iterative process of method\nconfiguration constitutes a major research bottleneck. Recently, nnU-Net has\ntackled this challenge for the task of image segmentation with great success.\nFollowing nnU-Net's agenda, in this work we systematize and automate the\nconfiguration process for medical object detection. The resulting\nself-configuring method, nnDetection, adapts itself without any manual\nintervention to arbitrary medical detection problems while achieving results en\npar with or superior to the state-of-the-art. We demonstrate the effectiveness\nof nnDetection on two public benchmarks, ADAM and LUNA16, and propose 10\nfurther medical object detection tasks on public data sets for comprehensive\nmethod evaluation. Code is at https://github.com/MIC-DKFZ/nnDetection .",
          "link": "http://arxiv.org/abs/2106.00817",
          "publishedOn": "2021-06-03T02:10:33.198Z",
          "wordCount": 586,
          "title": "nnDetection: A Self-configuring Method for Medical Object Detection. (arXiv:2106.00817v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00908",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1\">Zhuchen Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bian_H/0/1/0/all/0/1\">Hao Bian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yifeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_X/0/1/0/all/0/1\">Xiangyang Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongbing Zhang</a>",
          "description": "Multiple instance learning (MIL) is a powerful tool to solve the weakly\nsupervised classification in whole slide image (WSI) based pathology diagnosis.\nHowever, the current MIL methods are usually based on independent and identical\ndistribution hypothesis, thus neglect the correlation among different\ninstances. To address this problem, we proposed a new framework, called\ncorrelated MIL, and provided a proof for convergence. Based on this framework,\nwe devised a Transformer based MIL (TransMIL), which explored both\nmorphological and spatial information. The proposed TransMIL can effectively\ndeal with unbalanced/balanced and binary/multiple classification with great\nvisualization and interpretability. We conducted various experiments for three\ndifferent computational pathology problems and achieved better performance and\nfaster convergence compared with state-of-the-art methods. The test AUC for the\nbinary tumor classification can be up to 93.09% over CAMELYON16 dataset. And\nthe AUC over the cancer subtypes classification can be up to 96.03% and 98.82%\nover TCGA-NSCLC dataset and TCGA-RCC dataset, respectively.",
          "link": "http://arxiv.org/abs/2106.00908",
          "publishedOn": "2021-06-03T02:10:33.189Z",
          "wordCount": 597,
          "title": "TransMIL: Transformer based Correlated Multiple Instance Learning for Whole Slide Image Classication. (arXiv:2106.00908v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00815",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_V/0/1/0/all/0/1\">Vivien Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sunnie S. Y. Kim</a>",
          "description": "The iMet 2020 dataset is a valuable resource in the space of fine-grained art\nattribution recognition, but we believe it has yet to reach its true potential.\nWe document the unique properties of the dataset and observe that many of the\nattribute labels are noisy, more than is implied by the dataset description.\nOftentimes, there are also semantic relationships between the labels (e.g.,\nidentical, mutual exclusion, subsumption, overlap with uncertainty) which we\nbelieve are underutilized. We propose an approach to cleaning and structuring\nthe iMet 2020 labels, and discuss the implications and value of doing so.\nFurther, we demonstrate the benefits of our proposed approach through several\nexperiments. Our code and cleaned labels are available at\nhttps://github.com/sunniesuhyoung/iMet2020cleaned.",
          "link": "http://arxiv.org/abs/2106.00815",
          "publishedOn": "2021-06-03T02:10:33.166Z",
          "wordCount": 569,
          "title": "Cleaning and Structuring the Label Space of the iMet Collection 2020. (arXiv:2106.00815v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00828",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kaya_E/0/1/0/all/0/1\">Emre Can Kaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwarz_S/0/1/0/all/0/1\">Sebastian Schwarz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tabus_I/0/1/0/all/0/1\">Ioan Tabus</a>",
          "description": "This paper describes a novel lossless compression method for point cloud\ngeometry, building on a recent lossy compression method that aimed at\nreconstructing only the bounding volume of a point cloud. The proposed scheme\nstarts by partially reconstructing the geometry from the two depthmaps\nassociated to a single projection direction. The partial reconstruction\nobtained from the depthmaps is completed to a full reconstruction of the point\ncloud by sweeping section by section along one direction and encoding the\npoints which were not contained in the two depthmaps. The main ingredient is a\nlist-based encoding of the inner points (situated inside the feasible regions)\nby a novel arithmetic three dimensional context coding procedure that\nefficiently utilizes rotational invariances present in the input data.\nState-of-the-art bits-per-voxel results are obtained on benchmark datasets.",
          "link": "http://arxiv.org/abs/2106.00828",
          "publishedOn": "2021-06-03T02:10:33.036Z",
          "wordCount": 632,
          "title": "Refining the bounding volumes for lossless compression of voxelized point clouds geometry. (arXiv:2106.00828v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00728",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sakib_M/0/1/0/all/0/1\">Md Sadman Sakib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baez_H/0/1/0/all/0/1\">Hailey Baez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paulius_D/0/1/0/all/0/1\">David Paulius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yu Sun</a>",
          "description": "The functional object-oriented network (FOON) has been introduced as a\nknowledge representation, which takes the form of a graph, for symbolic task\nplanning. To get a sequential plan for a manipulation task, a robot can obtain\na task tree through a knowledge retrieval process from the FOON. To evaluate\nthe quality of an acquired task tree, we compare it with a conventional form of\ntask knowledge, such as recipes or manuals. We first automatically convert task\ntrees to recipes, and we then compare them with the human-created recipes in\nthe Recipe1M+ dataset via a survey. Our preliminary study finds no significant\ndifference between the recipes in Recipe1M+ and the recipes generated from FOON\ntask trees in terms of correctness, completeness, and clarity.",
          "link": "http://arxiv.org/abs/2106.00728",
          "publishedOn": "2021-06-03T02:10:33.016Z",
          "wordCount": 560,
          "title": "Evaluating Recipes Generated from Functional Object-Oriented Network. (arXiv:2106.00728v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00880",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shamsolmoali_P/0/1/0/all/0/1\">Pourya Shamsolmoali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zareapoor_M/0/1/0/all/0/1\">Masoumeh Zareapoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chanussot_J/0/1/0/all/0/1\">Jocelyn Chanussot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Huiyu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jie Yang</a>",
          "description": "Over the last few years, there has been substantial progress in object\ndetection on remote sensing images (RSIs) where objects are generally\ndistributed with large-scale variations and have different types of\norientations. Nevertheless, most of the current convolution neural network\napproaches lack the ability to deal with the challenges such as size and\nrotation variations. To address these problems, we propose the rotation\nequivariant feature image pyramid network (REFIPN), an image pyramid network\nbased on rotation equivariance convolution. The proposed pyramid network\nextracts features in a wide range of scales and orientations by using novel\nconvolution filters. These features are used to generate vector fields and\ndetermine the weight and angle of the highest-scoring orientation for all\nspatial locations on an image. Finally, the extracted features go through the\nprediction layers of the detector. The detection performance of the proposed\nmodel is validated on two commonly used aerial benchmarks and the results show\nour propose model can achieve state-of-the-art performance with satisfactory\nefficiency.",
          "link": "http://arxiv.org/abs/2106.00880",
          "publishedOn": "2021-06-03T02:10:32.995Z",
          "wordCount": 607,
          "title": "Rotation Equivariant Feature Image Pyramid Network for Object Detection in Optical Remote Sensing Imagery. (arXiv:2106.00880v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00918",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Korhonen_J/0/1/0/all/0/1\">Jari Korhonen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yicheng Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_J/0/1/0/all/0/1\">Junyong You</a>",
          "description": "Promising results for subjective image quality prediction have been achieved\nduring the past few years by using convolutional neural networks (CNN).\nHowever, the use of CNNs for high resolution image quality assessment remains a\nchallenge, since typical CNN architectures have been designed for small\nresolution input images. In this study, we propose an image quality model that\nattempts to mimic the attention mechanism of human visual system (HVS) by using\na recurrent neural network (RNN) for spatial pooling of the features extracted\nfrom different spatial areas (patches) by a deep CNN-based feature extractor.\nThe experimental study, conducted by using images with different resolutions\nfrom two recently published image quality datasets, indicates that the quality\nprediction accuracy of the proposed method is competitive against benchmark\nmodels representing the state-of-the-art, and the proposed method also performs\nconsistently on different resolution versions of the same dataset.",
          "link": "http://arxiv.org/abs/2106.00918",
          "publishedOn": "2021-06-03T02:10:32.987Z",
          "wordCount": 578,
          "title": "Consumer Image Quality Prediction using Recurrent Neural Networks for Spatial Pooling. (arXiv:2106.00918v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00912",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hantang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wentong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jianke Zhu</a>",
          "description": "Effectively parsing the facade is essential to 3D building reconstruction,\nwhich is an important computer vision problem with a large amount of\napplications in high precision map for navigation, computer aided design, and\ncity generation for digital entertainments. To this end, the key is how to\nobtain the shape grammars from 2D images accurately and efficiently. Although\nenjoying the merits of promising results on the semantic parsing, deep learning\nmethods cannot directly make use of the architectural rules, which play an\nimportant role for man-made structures. In this paper, we present a novel\ntranslational symmetry-based approach to improving the deep neural networks.\nOur method employs deep learning models as the base parser, and a module taking\nadvantage of translational symmetry is used to refine the initial parsing\nresults. In contrast to conventional semantic segmentation or bounding box\nprediction, we propose a novel scheme to fuse segmentation with anchor-free\ndetection in a single stage network, which enables the efficient training and\nbetter convergence. After parsing the facades into shape grammars, we employ an\noff-the-shelf rendering engine like Blender to reconstruct the realistic\nhigh-quality 3D models using procedural modeling. We conduct experiments on\nthree public datasets, where our proposed approach outperforms the\nstate-of-the-art methods. In addition, we have illustrated the 3D building\nmodels built from 2D facade images.",
          "link": "http://arxiv.org/abs/2106.00912",
          "publishedOn": "2021-06-03T02:10:32.968Z",
          "wordCount": 646,
          "title": "Translational Symmetry-Aware Facade Parsing for 3D Building Reconstruction. (arXiv:2106.00912v1 [cs.CV])"
        }
      ]
    },
    {
      "title": "cs.LG updates on arXiv.org",
      "feedUrl": "http://export.arxiv.org/rss/cs.LG",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2106.02985",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun-Kun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chi-Heng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abernethy_J/0/1/0/all/0/1\">Jacob Abernethy</a>",
          "description": "Stochastic gradient descent (SGD) with stochastic momentum is popular in\nnonconvex stochastic optimization and particularly for the training of deep\nneural networks. In standard SGD, parameters are updated by improving along the\npath of the gradient at the current iterate on a batch of examples, where the\naddition of a ``momentum'' term biases the update in the direction of the\nprevious change in parameters. In non-stochastic convex optimization one can\nshow that a momentum adjustment provably reduces convergence time in many\nsettings, yet such results have been elusive in the stochastic and non-convex\nsettings. At the same time, a widely-observed empirical phenomenon is that in\ntraining deep networks stochastic momentum appears to significantly improve\nconvergence time, variants of it have flourished in the development of other\npopular update methods, e.g. ADAM [KB15], AMSGrad [RKK18], etc. Yet theoretical\njustification for the use of stochastic momentum has remained a significant\nopen question. In this paper we propose an answer: stochastic momentum improves\ndeep network training because it modifies SGD to escape saddle points faster\nand, consequently, to more quickly find a second order stationary point. Our\ntheoretical results also shed light on the related question of how to choose\nthe ideal momentum parameter--our analysis suggests that $\\beta \\in [0,1)$\nshould be large (close to 1), which comports with empirical findings. We also\nprovide experimental findings that further validate these conclusions.",
          "link": "http://arxiv.org/abs/2106.02985",
          "publishedOn": "2021-06-08T02:20:28.095Z",
          "wordCount": 653,
          "title": "Escaping Saddle Points Faster with Stochastic Momentum. (arXiv:2106.02985v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02711",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Para_W/0/1/0/all/0/1\">Wamiq Reyaz Para</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhat_S/0/1/0/all/0/1\">Shariq Farooq Bhat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guerrero_P/0/1/0/all/0/1\">Paul Guerrero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kelly_T/0/1/0/all/0/1\">Tom Kelly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitra_N/0/1/0/all/0/1\">Niloy Mitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guibas_L/0/1/0/all/0/1\">Leonidas Guibas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wonka_P/0/1/0/all/0/1\">Peter Wonka</a>",
          "description": "Computer-aided design (CAD) is the most widely used modeling approach for\ntechnical design. The typical starting point in these designs is 2D sketches\nwhich can later be extruded and combined to obtain complex three-dimensional\nassemblies. Such sketches are typically composed of parametric primitives, such\nas points, lines, and circular arcs, augmented with geometric constraints\nlinking the primitives, such as coincidence, parallelism, or orthogonality.\nSketches can be represented as graphs, with the primitives as nodes and the\nconstraints as edges. Training a model to automatically generate CAD sketches\ncan enable several novel workflows, but is challenging due to the complexity of\nthe graphs and the heterogeneity of the primitives and constraints. In\nparticular, each type of primitive and constraint may require a record of\ndifferent size and parameter types. We propose SketchGen as a generative model\nbased on a transformer architecture to address the heterogeneity problem by\ncarefully designing a sequential language for the primitives and constraints\nthat allows distinguishing between different primitive or constraint types and\ntheir parameters, while encouraging our model to re-use information across\nrelated parameters, encoding shared structure. A particular highlight of our\nwork is the ability to produce primitives linked via constraints that enables\nthe final output to be further regularized via a constraint solver. We evaluate\nour model by demonstrating constraint prediction for given sets of primitives\nand full sketch generation from scratch, showing that our approach\nsignificantly out performs the state-of-the-art in CAD sketch generation.",
          "link": "http://arxiv.org/abs/2106.02711",
          "publishedOn": "2021-06-08T02:20:28.076Z",
          "wordCount": 688,
          "title": "SketchGen: Generating Constrained CAD Sketches. (arXiv:2106.02711v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02695",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1\">Huaxiu Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Linjun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1\">Chelsea Finn</a>",
          "description": "Meta-learning enables algorithms to quickly learn a newly encountered task\nwith just a few labeled examples by transferring previously learned knowledge.\nHowever, the bottleneck of current meta-learning algorithms is the requirement\nof a large number of meta-training tasks, which may not be accessible in\nreal-world scenarios. To address the challenge that available tasks may not\ndensely sample the space of tasks, we propose to augment the task set through\ninterpolation. By meta-learning with task interpolation (MLTI), our approach\neffectively generates additional tasks by randomly sampling a pair of tasks and\ninterpolating the corresponding features and labels. Under both gradient-based\nand metric-based meta-learning settings, our theoretical analysis shows MLTI\ncorresponds to a data-adaptive meta-regularization and further improves the\ngeneralization. Empirically, in our experiments on eight datasets from diverse\ndomains including image recognition, pose prediction, molecule property\nprediction, and medical image classification, we find that the proposed general\nMLTI framework is compatible with representative meta-learning algorithms and\nconsistently outperforms other state-of-the-art strategies.",
          "link": "http://arxiv.org/abs/2106.02695",
          "publishedOn": "2021-06-08T02:20:28.057Z",
          "wordCount": 580,
          "title": "Meta-Learning with Fewer Tasks through Task Interpolation. (arXiv:2106.02695v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02964",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Nath_R/0/1/0/all/0/1\">Rajdeep Kumar Nath</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Thapliyal_H/0/1/0/all/0/1\">Himanshu Thapliyal</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Humble_T/0/1/0/all/0/1\">Travis S. Humble</a>",
          "description": "Optimizing the training of a machine learning pipeline helps in reducing\ntraining costs and improving model performance. One such optimizing strategy is\nquantum annealing, which is an emerging computing paradigm that has shown\npotential in optimizing the training of a machine learning model. The\nimplementation of a physical quantum annealer has been realized by D-Wave\nsystems and is available to the research community for experiments. Recent\nexperimental results on a variety of machine learning applications using\nquantum annealing have shown interesting results where the performance of\nclassical machine learning techniques is limited by limited training data and\nhigh dimensional features. This article explores the application of D-Wave's\nquantum annealer for optimizing machine learning pipelines for real-world\nclassification problems. We review the application domains on which a physical\nquantum annealer has been used to train machine learning classifiers. We\ndiscuss and analyze the experiments performed on the D-Wave quantum annealer\nfor applications such as image recognition, remote sensing imagery,\ncomputational biology, and particle physics. We discuss the possible advantages\nand the problems for which quantum annealing is likely to be advantageous over\nclassical computation.",
          "link": "http://arxiv.org/abs/2106.02964",
          "publishedOn": "2021-06-08T02:20:28.031Z",
          "wordCount": 628,
          "title": "A Review of Machine Learning Classification Using Quantum Annealing for Real-world Applications. (arXiv:2106.02964v1 [quant-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02821",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qian_J/0/1/0/all/0/1\">Jing Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+ElSherief_M/0/1/0/all/0/1\">Mai ElSherief</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1\">Xifeng Yan</a>",
          "description": "Existing work on automated hate speech classification assumes that the\ndataset is fixed and the classes are pre-defined. However, the amount of data\nin social media increases every day, and the hot topics changes rapidly,\nrequiring the classifiers to be able to continuously adapt to new data without\nforgetting the previously learned knowledge. This ability, referred to as\nlifelong learning, is crucial for the real-word application of hate speech\nclassifiers in social media. In this work, we propose lifelong learning of hate\nspeech classification on social media. To alleviate catastrophic forgetting, we\npropose to use Variational Representation Learning (VRL) along with a memory\nmodule based on LB-SOINN (Load-Balancing Self-Organizing Incremental Neural\nNetwork). Experimentally, we show that combining variational representation\nlearning and the LB-SOINN memory module achieves better performance than the\ncommonly-used lifelong learning techniques.",
          "link": "http://arxiv.org/abs/2106.02821",
          "publishedOn": "2021-06-08T02:20:27.999Z",
          "wordCount": 568,
          "title": "Lifelong Learning of Hate Speech Classification on Social Media. (arXiv:2106.02821v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02866",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1\">Yao-Hung Hubert Tsai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1\">Martin Q. Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Han Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morency_L/0/1/0/all/0/1\">Louis-Philippe Morency</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1\">Ruslan Salakhutdinov</a>",
          "description": "Self-supervised learning is a form of unsupervised learning that leverages\nrich information in data to learn representations. However, data sometimes\ncontains certain information that may be undesirable for downstream tasks. For\ninstance, gender information may lead to biased decisions on many\ngender-irrelevant tasks. In this paper, we develop conditional contrastive\nlearning to remove undesirable information in self-supervised representations.\nTo remove the effect of the undesirable variable, our proposed approach\nconditions on the undesirable variable (i.e., by fixing the variations of it)\nduring the contrastive learning process. In particular, inspired by the\ncontrastive objective InfoNCE, we introduce Conditional InfoNCE (C-InfoNCE),\nand its computationally efficient variant, Weak-Conditional InfoNCE\n(WeaC-InfoNCE), for conditional contrastive learning. We demonstrate\nempirically that our methods can successfully learn self-supervised\nrepresentations for downstream tasks while removing a great level of\ninformation related to the undesirable variables. We study three scenarios,\neach with a different type of undesirable variables: task-irrelevant\nmeta-information for self-supervised speech representation learning, sensitive\nattributes for fair representation learning, and domain specification for\nmulti-domain visual representation learning.",
          "link": "http://arxiv.org/abs/2106.02866",
          "publishedOn": "2021-06-08T02:20:27.986Z",
          "wordCount": 602,
          "title": "Conditional Contrastive Learning: Removing Undesirable Information in Self-Supervised Representations. (arXiv:2106.02866v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02817",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1\">Liang Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Huaisheng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1\">Ruiqi Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yuhui Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1\">Hongzhi Yin</a>",
          "description": "Imbalanced classification on graphs is ubiquitous yet challenging in many\nreal-world applications, such as fraudulent node detection. Recently, graph\nneural networks (GNNs) have shown promising performance on many network\nanalysis tasks. However, most existing GNNs have almost exclusively focused on\nthe balanced networks, and would get unappealing performance on the imbalanced\nnetworks. To bridge this gap, in this paper, we present a generative\nadversarial graph network model, called ImGAGN to address the imbalanced\nclassification problem on graphs. It introduces a novel generator for graph\nstructure data, named GraphGenerator, which can simulate both the minority\nclass nodes' attribute distribution and network topological structure\ndistribution by generating a set of synthetic minority nodes such that the\nnumber of nodes in different classes can be balanced. Then a graph\nconvolutional network (GCN) discriminator is trained to discriminate between\nreal nodes and fake (i.e., generated) nodes, and also between minority nodes\nand majority nodes on the synthetic balanced network. To validate the\neffectiveness of the proposed method, extensive experiments are conducted on\nfour real-world imbalanced network datasets. Experimental results demonstrate\nthat the proposed method ImGAGN outperforms state-of-the-art algorithms for\nsemi-supervised imbalanced node classification task.",
          "link": "http://arxiv.org/abs/2106.02817",
          "publishedOn": "2021-06-08T02:20:27.959Z",
          "wordCount": 626,
          "title": "ImGAGN:Imbalanced Network Embedding via Generative Adversarial Graph Networks. (arXiv:2106.02817v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02836",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Watanabe_A/0/1/0/all/0/1\">Akihisa Watanabe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuramata_M/0/1/0/all/0/1\">Michiya Kuramata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Majima_K/0/1/0/all/0/1\">Kaito Majima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiyohara_H/0/1/0/all/0/1\">Haruka Kiyohara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kondo_K/0/1/0/all/0/1\">Kensho Kondo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakata_K/0/1/0/all/0/1\">Kazuhide Nakata</a>",
          "description": "In recent years, machine learning and AI have been introduced in many\nindustrial fields. In fields such as finance, medicine, and autonomous driving,\nwhere the inference results of a model may have serious consequences, high\ninterpretability as well as prediction accuracy is required. In this study, we\npropose CGA2M+, which is based on the Generalized Additive 2 Model (GA2M) and\ndiffers from it in two major ways. The first is the introduction of\nmonotonicity. Imposing monotonicity on some functions based on an analyst's\nknowledge is expected to improve not only interpretability but also\ngeneralization performance. The second is the introduction of a higher-order\nterm: given that GA2M considers only second-order interactions, we aim to\nbalance interpretability and prediction accuracy by introducing a higher-order\nterm that can capture higher-order interactions. In this way, we can improve\nprediction performance without compromising interpretability by applying\nlearning innovation. Numerical experiments showed that the proposed model has\nhigh predictive performance and interpretability. Furthermore, we confirmed\nthat generalization performance is improved by introducing monotonicity.",
          "link": "http://arxiv.org/abs/2106.02836",
          "publishedOn": "2021-06-08T02:20:27.896Z",
          "wordCount": 598,
          "title": "Constrained Generalized Additive 2 Model with Consideration of High-Order Interactions. (arXiv:2106.02836v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02886",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tonghan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_L/0/1/0/all/0/1\">Liang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_W/0/1/0/all/0/1\">Weijun Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qianlan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yang Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chongjie Zhang</a>",
          "description": "Learning sparse coordination graphs adaptive to the coordination dynamics\namong agents is a long-standing problem in cooperative multi-agent learning.\nThis paper studies this problem by proposing several value-based and\nobservation-based schemes for learning dynamic topologies and evaluating them\non a new Multi-Agent COordination (MACO) benchmark. The benchmark collects\nclassic coordination problems in the literature, increases their difficulty,\nand classifies them into different types. By analyzing the individual\nadvantages of each learning scheme on each type of problem and their overall\nperformance, we propose a novel method using the variance of utility difference\nfunctions to learn context-aware sparse coordination topologies. Moreover, our\nmethod learns action representations that effectively reduce the influence of\nutility functions' estimation errors on graph construction. Experiments show\nthat our method significantly outperforms dense and static topologies across\nthe MACO and StarCraft II micromanagement benchmark.",
          "link": "http://arxiv.org/abs/2106.02886",
          "publishedOn": "2021-06-08T02:20:27.884Z",
          "wordCount": 559,
          "title": "Context-Aware Sparse Deep Coordination Graphs. (arXiv:2106.02886v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02968",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahmood_R/0/1/0/all/0/1\">Rafid Mahmood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fidler_S/0/1/0/all/0/1\">Sanja Fidler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Law_M/0/1/0/all/0/1\">Marc T. Law</a>",
          "description": "Given restrictions on the availability of data, active learning is the\nprocess of training a model with limited labeled data by selecting a core\nsubset of an unlabeled data pool to label. Although selecting the most useful\npoints for training is an optimization problem, the scale of deep learning data\nsets forces most selection strategies to employ efficient heuristics. Instead,\nwe propose a new integer optimization problem for selecting a core set that\nminimizes the discrete Wasserstein distance from the unlabeled pool. We\ndemonstrate that this problem can be tractably solved with a Generalized\nBenders Decomposition algorithm. Our strategy requires high-quality latent\nfeatures which we obtain by unsupervised learning on the unlabeled pool.\nNumerical results on several data sets show that our optimization approach is\ncompetitive with baselines and particularly outperforms them in the low budget\nregime where less than one percent of the data set is labeled.",
          "link": "http://arxiv.org/abs/2106.02968",
          "publishedOn": "2021-06-08T02:20:27.867Z",
          "wordCount": 582,
          "title": "Low Budget Active Learning via Wasserstein Distance: An Integer Programming Approach. (arXiv:2106.02968v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02771",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Pan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Que_M/0/1/0/all/0/1\">Maofei Que</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhichao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yao Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuzhilin_A/0/1/0/all/0/1\">Alexander Tuzhilin</a>",
          "description": "Classical recommender system methods typically face the filter bubble problem\nwhen users only receive recommendations of their familiar items, making them\nbored and dissatisfied. To address the filter bubble problem, unexpected\nrecommendations have been proposed to recommend items significantly deviating\nfrom user's prior expectations and thus surprising them by presenting \"fresh\"\nand previously unexplored items to the users. In this paper, we describe a\nnovel Personalized Unexpected Recommender System (PURS) model that incorporates\nunexpectedness into the recommendation process by providing multi-cluster\nmodeling of user interests in the latent space and personalized unexpectedness\nvia the self-attention mechanism and via selection of an appropriate unexpected\nactivation function. Extensive offline experiments on three real-world datasets\nillustrate that the proposed PURS model significantly outperforms the\nstate-of-the-art baseline approaches in terms of both accuracy and\nunexpectedness measures. In addition, we conduct an online A/B test at a major\nvideo platform Alibaba-Youku, where our model achieves over 3\\% increase in the\naverage video view per user metric. The proposed model is in the process of\nbeing deployed by the company.",
          "link": "http://arxiv.org/abs/2106.02771",
          "publishedOn": "2021-06-08T02:20:27.861Z",
          "wordCount": 609,
          "title": "PURS: Personalized Unexpected Recommender System for Improving User Satisfaction. (arXiv:2106.02771v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2001.10980",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jing Jiang</a>",
          "description": "Traditionally, text generation models take in a sequence of text as input,\nand iteratively generate the next most probable word using pre-trained\nparameters. In this work, we propose the architecture to use images instead of\ntext as the input of the text generation model, called StoryGen. In the\narchitecture, we design a Relational Text Data Generator algorithm that relates\ndifferent features from multiple images. The output samples from the model\ndemonstrate the ability to generate meaningful paragraphs of text containing\nthe extracted features from the input images. This is an undergraduate project\nreport. Completed Dec. 2019 at the Cooper Union.",
          "link": "http://arxiv.org/abs/2001.10980",
          "publishedOn": "2021-06-08T02:20:27.854Z",
          "wordCount": 572,
          "title": "Multimodal Story Generation on Plural Images. (arXiv:2001.10980v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2001.06471",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Dedieu_A/0/1/0/all/0/1\">Antoine Dedieu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hazimeh_H/0/1/0/all/0/1\">Hussein Hazimeh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mazumder_R/0/1/0/all/0/1\">Rahul Mazumder</a>",
          "description": "We consider a discrete optimization formulation for learning sparse\nclassifiers, where the outcome depends upon a linear combination of a small\nsubset of features. Recent work has shown that mixed integer programming (MIP)\ncan be used to solve (to optimality) $\\ell_0$-regularized regression problems\nat scales much larger than what was conventionally considered possible. Despite\ntheir usefulness, MIP-based global optimization approaches are significantly\nslower compared to the relatively mature algorithms for $\\ell_1$-regularization\nand heuristics for nonconvex regularized problems. We aim to bridge this gap in\ncomputation times by developing new MIP-based algorithms for\n$\\ell_0$-regularized classification. We propose two classes of scalable\nalgorithms: an exact algorithm that can handle $p\\approx 50,000$ features in a\nfew minutes, and approximate algorithms that can address instances with\n$p\\approx 10^6$ in times comparable to the fast $\\ell_1$-based algorithms. Our\nexact algorithm is based on the novel idea of \\textsl{integrality generation},\nwhich solves the original problem (with $p$ binary variables) via a sequence of\nmixed integer programs that involve a small number of binary variables. Our\napproximate algorithms are based on coordinate descent and local combinatorial\nsearch. In addition, we present new estimation error bounds for a class of\n$\\ell_0$-regularized estimators. Experiments on real and synthetic data\ndemonstrate that our approach leads to models with considerably improved\nstatistical performance (especially, variable selection) when compared to\ncompeting methods.",
          "link": "http://arxiv.org/abs/2001.06471",
          "publishedOn": "2021-06-08T02:20:27.845Z",
          "wordCount": 679,
          "title": "Learning Sparse Classifiers: Continuous and Mixed Integer Optimization Perspectives. (arXiv:2001.06471v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02714",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rajan_S/0/1/0/all/0/1\">Subramaniam Rajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khaled_B/0/1/0/all/0/1\">Bilal Khaled</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shyamsunder_L/0/1/0/all/0/1\">Loukham Shyamsunder</a>",
          "description": "Numerous theories of failure have been postulated and implemented in various\ncommercial programs for composite materials. Even the best theories have had\nlimited success in predicting damage and failure in validation exercises. In\nview of this background, many researchers have started exploring the use of\nmultiscale modeling to improve the fidelity of the modeling and simulation of\nvarious structural and materials systems. In this paper, a multi-scale modeling\nscheme is used to illustrate how a combination of virtual and laboratory\ntesting programs can be used to generate a point cloud of failure surface data\nthat can then be queried during finite element analysis at the continuum scale\nto ascertain if the onset of failure has occurred. The k-nearest neighbor\n(k-NN) classification concept is used to obtain the answer to the query. A\nlinear, elastic, static finite element example using a unidirectional composite\nshows that the framework can be generated and used effectively and efficiently\nwith the possibility to extend the approach for all types of composite\narchitectures and behaviors.",
          "link": "http://arxiv.org/abs/2106.02714",
          "publishedOn": "2021-06-08T02:20:27.824Z",
          "wordCount": 598,
          "title": "Point Cloud Failure Criterion for Composites using k-Nearest Neighbor Classification. (arXiv:2106.02714v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.11797",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1\">Fuli Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Weiran Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiangnan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xin_X/0/1/0/all/0/1\">Xin Xin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>",
          "description": "Graph Convolutional Network (GCN) is an emerging technique for information\nretrieval (IR) applications. While GCN assumes the homophily property of a\ngraph, real-world graphs are never perfect: the local structure of a node may\ncontain discrepancy, e.g., the labels of a node's neighbors could vary. This\npushes us to consider the discrepancy of local structure in GCN modeling.\nExisting work approaches this issue by introducing an additional module such as\ngraph attention, which is expected to learn the contribution of each neighbor.\nHowever, such module may not work reliably as expected, especially when there\nlacks supervision signal, e.g., when the labeled data is small. Moreover,\nexisting methods focus on modeling the nodes in the training data, and never\nconsider the local structure discrepancy of testing nodes.\n\nThis work focuses on the local structure discrepancy issue for testing nodes,\nwhich has received little scrutiny. From a novel perspective of causality, we\ninvestigate whether a GCN should trust the local structure of a testing node\nwhen predicting its label. To this end, we analyze the working mechanism of GCN\nwith causal graph, estimating the causal effect of a node's local structure for\nthe prediction. The idea is simple yet effective: given a trained GCN model, we\nfirst intervene the prediction by blocking the graph structure; we then compare\nthe original prediction with the intervened prediction to assess the causal\neffect of the local structure on the prediction. Through this way, we can\neliminate the impact of local structure discrepancy and make more accurate\nprediction. Extensive experiments on seven node classification datasets show\nthat our method effectively enhances the inference stage of GCN.",
          "link": "http://arxiv.org/abs/2010.11797",
          "publishedOn": "2021-06-08T02:20:26.099Z",
          "wordCount": 743,
          "title": "Should Graph Convolution Trust Neighbors? A Simple Causal Inference Method. (arXiv:2010.11797v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03019",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_M/0/1/0/all/0/1\">Mandy Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Anqi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wyk_K/0/1/0/all/0/1\">Karl Van Wyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dellaert_F/0/1/0/all/0/1\">Frank Dellaert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boots_B/0/1/0/all/0/1\">Byron Boots</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ratliff_N/0/1/0/all/0/1\">Nathan Ratliff</a>",
          "description": "Imitation learning (IL) is a frequently used approach for data-efficient\npolicy learning. Many IL methods, such as Dataset Aggregation (DAgger), combat\nchallenges like distributional shift by interacting with oracular experts.\nUnfortunately, assuming access to oracular experts is often unrealistic in\npractice; data used in IL frequently comes from offline processes such as\nlead-through or teleoperation. In this paper, we present a novel imitation\nlearning technique called Collocation for Demonstration Encoding (CoDE) that\noperates on only a fixed set of trajectory demonstrations. We circumvent\nchallenges with methods like back-propagation-through-time by introducing an\nauxiliary trajectory network, which takes inspiration from collocation\ntechniques in optimal control. Our method generalizes well and more accurately\nreproduces the demonstrated behavior with fewer guiding trajectories when\ncompared to standard behavioral cloning methods. We present simulation results\non a 7-degree-of-freedom (DoF) robotic manipulator that learns to exhibit\nlifting, target-reaching, and obstacle avoidance behaviors.",
          "link": "http://arxiv.org/abs/2105.03019",
          "publishedOn": "2021-06-08T02:20:26.066Z",
          "wordCount": 612,
          "title": "Imitation Learning via Simultaneous Optimization of Policies and Auxiliary Trajectories. (arXiv:2105.03019v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.09599",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gohari_P/0/1/0/all/0/1\">Parham Gohari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1\">Bo Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hale_M/0/1/0/all/0/1\">Matthew Hale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Topcu_U/0/1/0/all/0/1\">Ufuk Topcu</a>",
          "description": "Kickstarting deep reinforcement learning algorithms facilitate a\nteacher-student relationship among the agents and allow for a well-performing\nteacher to share demonstrations with a student to expedite the student's\ntraining. However, despite the known benefits, the demonstrations may contain\nsensitive information about the teacher's training data and existing\nkickstarting methods do not take any measures to protect it. Therefore, we use\nthe framework of differential privacy to develop a mechanism that securely\nshares the teacher's demonstrations with the student. The mechanism allows for\nthe teacher to decide upon the accuracy of its demonstrations with respect to\nthe privacy budget that it consumes, thereby granting the teacher full control\nover its data privacy. We then develop a kickstarted deep reinforcement\nlearning algorithm for the student that is privacy-aware because we calibrate\nits objective with the parameters of the teacher's privacy mechanism. The\nprivacy-aware design of the algorithm makes it possible to kickstart the\nstudent's learning despite the perturbations induced by the privacy mechanism.\nFrom numerical experiments, we highlight three empirical results: (i) the\nalgorithm succeeds in expediting the student's learning, (ii) the student\nconverges to a performance level that was not possible without the\ndemonstrations, and (iii) the student maintains its enhanced performance even\nafter the teacher stops sharing useful demonstrations due to its privacy budget\nconstraints.",
          "link": "http://arxiv.org/abs/2102.09599",
          "publishedOn": "2021-06-08T02:20:26.023Z",
          "wordCount": 684,
          "title": "Privacy-Preserving Kickstarting Deep Reinforcement Learning with Privacy-Aware Learners. (arXiv:2102.09599v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.03736",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Su Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Han-Jia Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_L/0/1/0/all/0/1\">Le Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_D/0/1/0/all/0/1\">De-Chuan Zhan</a>",
          "description": "Meta-learning can extract an inductive bias from previous learning experience\nand assist the training processes of new tasks. It is often realized through\noptimizing a meta-model with the evaluation loss of a series of task-specific\nsolvers. Most existing algorithms sample non-overlapping $\\mathit{support}$\nsets and $\\mathit{query}$ sets to train and evaluate the solvers respectively\ndue to simplicity ($\\mathcal{S}/\\mathcal{Q}$ protocol). However, another\nevaluation method that assesses the discrepancy between the solver and a target\nmodel is short of research ($\\mathcal{S}/\\mathcal{T}$ protocol).\n$\\mathcal{S}/\\mathcal{T}$ protocol has unique advantages such as offering more\ninformative supervision, but it is computationally expensive. This paper looks\ninto this special evaluation method and takes a step towards putting it into\npractice. We find that with a small ratio of tasks armed with target models,\nclassic meta-learning algorithms can be improved a lot without consuming many\nresources. Furthermore, we empirically verify the effectiveness of\n$\\mathcal{S}/\\mathcal{T}$ protocol in a typical application of meta-learning,\n$\\mathit{i.e.}$, few-shot learning. In detail, after constructing target models\nby fine-tuning the pre-trained network on those hard tasks, we match the\ntask-specific solvers to target models via knowledge distillation. Experiments\ndemonstrate the superiority of our proposal.",
          "link": "http://arxiv.org/abs/2104.03736",
          "publishedOn": "2021-06-08T02:20:25.998Z",
          "wordCount": 645,
          "title": "Towards Enabling Meta-Learning from Target Models. (arXiv:2104.03736v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.07253",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xue_Z/0/1/0/all/0/1\">Zhenghai Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xu-Hui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_J/0/1/0/all/0/1\">Jing-Cheng Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1\">Shengyi Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1\">Feng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yang Yu</a>",
          "description": "In reinforcement learning, experience replay stores past samples for further\nreuse. Prioritized sampling is a promising technique to better utilize these\nsamples. Previous criteria of prioritization include TD error, recentness and\ncorrective feedback, which are mostly heuristically designed. In this work, we\nstart from the regret minimization objective, and obtain an optimal\nprioritization strategy for Bellman update that can directly maximize the\nreturn of the policy. The theory suggests that data with higher hindsight TD\nerror, better on-policiness and more accurate Q value should be assigned with\nhigher weights during sampling. Thus most previous criteria only consider this\nstrategy partially. We not only provide theoretical justifications for previous\ncriteria, but also propose two new methods to compute the prioritization\nweight, namely ReMERN and ReMERT. ReMERN learns an error network, while ReMERT\nexploits the temporal ordering of states. Both methods outperform previous\nprioritized sampling algorithms in challenging RL benchmarks, including MuJoCo,\nAtari and Meta-World.",
          "link": "http://arxiv.org/abs/2105.07253",
          "publishedOn": "2021-06-08T02:20:25.992Z",
          "wordCount": 604,
          "title": "Regret Minimization Experience Replay. (arXiv:2105.07253v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.01028",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bechavod_Y/0/1/0/all/0/1\">Yahav Bechavod</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Podimata_C/0/1/0/all/0/1\">Chara Podimata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiwei Steven Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ziani_J/0/1/0/all/0/1\">Juba Ziani</a>",
          "description": "We study the effects of information discrepancy across sub-populations on\ntheir ability to simultaneously improve their features in strategic learning\nsettings. Specifically, we consider a game where a principal deploys a decision\nrule in an attempt to optimize the whole population's welfare, and agents\nstrategically adapt to it to receive better scores. Inspired by real-life\nsettings, such as loan approvals and college admissions, we remove the typical\nassumption made in the strategic learning literature that the decision rule is\nfully known to the agents, and focus on settings where it is inaccessible. In\ntheir lack of knowledge, individuals try to infer this rule by learning from\ntheir peers (e.g., friends and acquaintances who previously applied for a\nloan), naturally forming groups in the population, each with possibly different\ntype and level of information about the decision rule. In our equilibrium\nanalysis, we show that the principal's decision rule optimizing the welfare\nacross subgroups may cause a surprising negative externality; the true quality\nof some of the subgroups can actually deteriorate. On the positive side, we\nshow that in many natural cases, optimal improvement is guaranteed\nsimultaneously for all subgroups in equilibrium. We also characterize the\ndisparity in improvements across subgroups via a measure of their informational\noverlap. Finally, we complement our theoretical analysis with experiments on\nreal-world datasets.",
          "link": "http://arxiv.org/abs/2103.01028",
          "publishedOn": "2021-06-08T02:20:25.986Z",
          "wordCount": 692,
          "title": "Information Discrepancy in Strategic Learning. (arXiv:2103.01028v3 [cs.GT] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.13523",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_Y/0/1/0/all/0/1\">Yikun Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1\">Yen-Chi Chen</a>",
          "description": "Directional data consist of observations distributed on a (hyper)sphere, and\nappear in many applied fields, such as astronomy, ecology, and environmental\nscience. This paper studies both statistical and computational problems of\nkernel smoothing for directional data. We generalize the classical mean shift\nalgorithm to directional data, which allows us to identify local modes of the\ndirectional kernel density estimator (KDE). The statistical convergence rates\nof the directional KDE and its derivatives are derived, and the problem of mode\nestimation is examined. We also prove the ascending property of the directional\nmean shift algorithm and investigate a general problem of gradient ascent on\nthe unit hypersphere. To demonstrate the applicability of the algorithm, we\nevaluate it as a mode clustering method on both simulated and real-world data\nsets.",
          "link": "http://arxiv.org/abs/2010.13523",
          "publishedOn": "2021-06-08T02:20:25.979Z",
          "wordCount": 589,
          "title": "Kernel Smoothing, Mean Shift, and Their Learning Theory with Directional Data. (arXiv:2010.13523v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03399",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rolf_E/0/1/0/all/0/1\">Esther Rolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Worledge_T/0/1/0/all/0/1\">Theodora Worledge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Recht_B/0/1/0/all/0/1\">Benjamin Recht</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>",
          "description": "Collecting more diverse and representative training data is often touted as a\nremedy for the disparate performance of machine learning predictors across\nsubpopulations. However, a precise framework for understanding how dataset\nproperties like diversity affect learning outcomes is largely lacking. By\ncasting data collection as part of the learning process, we demonstrate that\ndiverse representation in training data is key not only to increasing subgroup\nperformances, but also to achieving population level objectives. Our analysis\nand experiments describe how dataset compositions influence performance and\nprovide constructive results for using trends in existing data, alongside\ndomain knowledge, to help guide intentional, objective-aware dataset design.",
          "link": "http://arxiv.org/abs/2103.03399",
          "publishedOn": "2021-06-08T02:20:25.973Z",
          "wordCount": 576,
          "title": "Representation Matters: Assessing the Importance of Subgroup Allocations in Training Data. (arXiv:2103.03399v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.10058",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roddenberry_T/0/1/0/all/0/1\">T. Mitchell Roddenberry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glaze_N/0/1/0/all/0/1\">Nicholas Glaze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Segarra_S/0/1/0/all/0/1\">Santiago Segarra</a>",
          "description": "We consider the construction of neural network architectures for data on\nsimplicial complexes. In studying maps on the chain complex of a simplicial\ncomplex, we define three desirable properties of a simplicial neural network\narchitecture: namely, permutation equivariance, orientation equivariance, and\nsimplicial awareness. The first two properties respectively account for the\nfact that the node indexing and the simplex orientations in a simplicial\ncomplex are arbitrary. The last property encodes the desirable feature that the\noutput of the neural network depends on the entire simplicial complex and not\non a subset of its dimensions. Based on these properties, we propose a simple\nconvolutional architecture, rooted in tools from algebraic topology, for the\nproblem of trajectory prediction, and show that it obeys all three of these\nproperties when an odd, nonlinear activation function is used. We then\ndemonstrate the effectiveness of this architecture in extrapolating\ntrajectories on synthetic and real datasets, with particular emphasis on the\ngains in generalizability to unseen trajectories.",
          "link": "http://arxiv.org/abs/2102.10058",
          "publishedOn": "2021-06-08T02:20:25.965Z",
          "wordCount": 630,
          "title": "Principled Simplicial Neural Networks for Trajectory Prediction. (arXiv:2102.10058v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.08267",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1\">Sen Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_W/0/1/0/all/0/1\">Weishen Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Changshui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fei Wang</a>",
          "description": "Bipartite ranking, which aims to learn a scoring function that ranks positive\nindividuals higher than negative ones from labeled data, is widely adopted in\nvarious applications where sample prioritization is needed. Recently, there\nhave been rising concerns on whether the learned scoring function can cause\nsystematic disparity across different protected groups defined by sensitive\nattributes. While there could be trade-off between fairness and performance, in\nthis paper we propose a model agnostic post-processing framework for balancing\nthem in the bipartite ranking scenario. Specifically, we maximize a weighted\nsum of the utility and fairness by directly adjusting the relative ordering of\nsamples across groups. By formulating this problem as the identification of an\noptimal warping path across different protected groups, we propose a\nnon-parametric method to search for such an optimal path through a dynamic\nprogramming process. Our method is compatible with various classification\nmodels and applicable to a variety of ranking fairness metrics. Comprehensive\nexperiments on a suite of benchmark data sets and two real-world patient\nelectronic health record repositories show that our method can achieve a great\nbalance between the algorithm utility and ranking fairness. Furthermore, we\nexperimentally verify the robustness of our method when faced with the fewer\ntraining samples and the difference between training and testing ranking score\ndistributions.",
          "link": "http://arxiv.org/abs/2006.08267",
          "publishedOn": "2021-06-08T02:20:25.948Z",
          "wordCount": 697,
          "title": "Towards Model-Agnostic Post-Hoc Adjustment for Balancing Ranking Fairness and Algorithm Utility. (arXiv:2006.08267v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.04792",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Vygon_R/0/1/0/all/0/1\">Roman Vygon</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mikhaylovskiy_N/0/1/0/all/0/1\">Nikolay Mikhaylovskiy</a>",
          "description": "In the past few years, triplet loss-based metric embeddings have become a\nde-facto standard for several important computer vision problems, most\nno-tably, person reidentification. On the other hand, in the area of speech\nrecognition the metric embeddings generated by the triplet loss are rarely used\neven for classification problems. We fill this gap showing that a combination\nof two representation learning techniques: a triplet loss-based embedding and a\nvariant of kNN for classification instead of cross-entropy loss significantly\n(by 26% to 38%) improves the classification accuracy for convolutional networks\non a LibriSpeech-derived LibriWords datasets. To do so, we propose a novel\nphonetic similarity based triplet mining approach. We also improve the current\nbest published SOTA for Google Speech Commands dataset V1 10+2 -class\nclassification by about 34%, achieving 98.55% accuracy, V2 10+2-class\nclassification by about 20%, achieving 98.37% accuracy, and V2 35-class\nclassification by over 50%, achieving 97.0% accuracy.",
          "link": "http://arxiv.org/abs/2101.04792",
          "publishedOn": "2021-06-08T02:20:25.935Z",
          "wordCount": 626,
          "title": "Learning Efficient Representations for Keyword Spotting with Triplet Loss. (arXiv:2101.04792v4 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.03448",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singhal_K/0/1/0/all/0/1\">Karan Singhal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sidahmed_H/0/1/0/all/0/1\">Hakim Sidahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garrett_Z/0/1/0/all/0/1\">Zachary Garrett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shanshan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rush_K/0/1/0/all/0/1\">Keith Rush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prakash_S/0/1/0/all/0/1\">Sushant Prakash</a>",
          "description": "Personalization methods in federated learning aim to balance the benefits of\nfederated and local training for data availability, communication cost, and\nrobustness to client heterogeneity. Approaches that require clients to\ncommunicate all model parameters can be undesirable due to privacy and\ncommunication constraints. Other approaches require always-available or\nstateful clients, impractical in large-scale cross-device settings. We\nintroduce Federated Reconstruction, the first model-agnostic framework for\npartially local federated learning suitable for training and inference at\nscale. We motivate the framework via a connection to model-agnostic meta\nlearning, empirically demonstrate its performance over existing approaches for\ncollaborative filtering and next word prediction, and release an open-source\nlibrary for evaluating approaches in this setting. We also describe the\nsuccessful deployment of this approach at scale for federated collaborative\nfiltering in a mobile keyboard application.",
          "link": "http://arxiv.org/abs/2102.03448",
          "publishedOn": "2021-06-08T02:20:25.930Z",
          "wordCount": 607,
          "title": "Federated Reconstruction: Partially Local Federated Learning. (arXiv:2102.03448v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.03279",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Seidl_P/0/1/0/all/0/1\">Philipp Seidl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Renz_P/0/1/0/all/0/1\">Philipp Renz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dyubankova_N/0/1/0/all/0/1\">Natalia Dyubankova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neves_P/0/1/0/all/0/1\">Paulo Neves</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verhoeven_J/0/1/0/all/0/1\">Jonas Verhoeven</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Segler_M/0/1/0/all/0/1\">Marwin Segler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wegner_J/0/1/0/all/0/1\">J&#xf6;rg K. Wegner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hochreiter_S/0/1/0/all/0/1\">Sepp Hochreiter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klambauer_G/0/1/0/all/0/1\">G&#xfc;nter Klambauer</a>",
          "description": "Finding synthesis routes for molecules of interest is an essential step in\nthe discovery of new drugs and materials. To find such routes,\ncomputer-assisted synthesis planning (CASP) methods are employed which rely on\na model of chemical reactivity. In this study, we model single-step\nretrosynthesis in a template-based approach using modern Hopfield networks\n(MHNs). We adapt MHNs to associate different modalities, reaction templates and\nmolecules, which allows the model to leverage structural information about\nreaction templates. This approach significantly improves the performance of\ntemplate relevance prediction, especially for templates with few or zero\ntraining examples. With inference speed several times faster than that of\nbaseline methods, we improve predictive performance for top-k exact match\naccuracy for $\\mathrm{k}\\geq5$ in the retrosynthesis benchmark USPTO-50k.",
          "link": "http://arxiv.org/abs/2104.03279",
          "publishedOn": "2021-06-08T02:20:25.923Z",
          "wordCount": 611,
          "title": "Modern Hopfield Networks for Few- and Zero-Shot Reaction Template Prediction. (arXiv:2104.03279v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.17182",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1\">Zeke Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1\">Li Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zhanxing Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "It is well-known that stochastic gradient noise (SGN) acts as implicit\nregularization for deep learning and is essentially important for both\noptimization and generalization of deep networks. Some works attempted to\nartificially simulate SGN by injecting random noise to improve deep learning.\nHowever, it turned out that the injected simple random noise cannot work as\nwell as SGN, which is anisotropic and parameter-dependent. For simulating SGN\nat low computational costs and without changing the learning rate or batch\nsize, we propose the Positive-Negative Momentum (PNM) approach that is a\npowerful alternative to conventional Momentum in classic optimizers. The\nintroduced PNM method maintains two approximate independent momentum terms.\nThen, we can control the magnitude of SGN explicitly by adjusting the momentum\ndifference. We theoretically prove the convergence guarantee and the\ngeneralization advantage of PNM over Stochastic Gradient Descent (SGD). By\nincorporating PNM into the two conventional optimizers, SGD with Momentum and\nAdam, our extensive experiments empirically verified the significant advantage\nof the PNM-based variants over the corresponding conventional Momentum-based\noptimizers.",
          "link": "http://arxiv.org/abs/2103.17182",
          "publishedOn": "2021-06-08T02:20:25.906Z",
          "wordCount": 650,
          "title": "Positive-Negative Momentum: Manipulating Stochastic Gradient Noise to Improve Generalization. (arXiv:2103.17182v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.08228",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Paria_D/0/1/0/all/0/1\">Debjit Paria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinha_A/0/1/0/all/0/1\">Abhishek Sinha</a>",
          "description": "We consider a set-valued online prediction problem in the context of network\ncaching. Assume that users are connected to a number of caches via a bipartite\nnetwork. At any time slot, each user requests some file chosen from a large\ncatalog. A user's request is met if the requested file is cached in at least\none of the caches connected to the user. The objective is to predict and\noptimally store the files on the caches to maximize the total number of cache\nhits. We propose $\\texttt{LeadCache}$ - an online caching policy based on the\nFollow-the-Perturbed-Leader paradigm. We show that the policy is regret-optimal\nup to a factor of $\\tilde{O}(n^{3/8}),$ where $n$ is the number of users. We\nimplement the policy by designing a new linear-time Pipage rounding algorithm.\nWith an additional Strong-Law-type assumption, we show that the total number of\nfile fetches under $\\texttt{LeadCache}$ remains almost surely finite.\nAdditionally, we derive a tight regret lower bound using results from graph\ncoloring. Our conclusion is that the proposed learning-based caching policy\ndecisively outperforms the classical policies both theoretically and\nempirically.",
          "link": "http://arxiv.org/abs/2009.08228",
          "publishedOn": "2021-06-08T02:20:25.900Z",
          "wordCount": 635,
          "title": "LeadCache: Regret-Optimal Caching in Networks. (arXiv:2009.08228v2 [cs.IT] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.03955",
          "author": "<a href=\"http://arxiv.org/find/hep-th/1/au:+Craven_J/0/1/0/all/0/1\">Jessica Craven</a>, <a href=\"http://arxiv.org/find/hep-th/1/au:+Jejjala_V/0/1/0/all/0/1\">Vishnu Jejjala</a>, <a href=\"http://arxiv.org/find/hep-th/1/au:+Kar_A/0/1/0/all/0/1\">Arjun Kar</a>",
          "description": "We present a simple phenomenological formula which approximates the\nhyperbolic volume of a knot using only a single evaluation of its Jones\npolynomial at a root of unity. The average error is just $2.86$% on the first\n$1.7$ million knots, which represents a large improvement over previous\nformulas of this kind. To find the approximation formula, we use layer-wise\nrelevance propagation to reverse engineer a black box neural network which\nachieves a similar average error for the same approximation task when trained\non $10$% of the total dataset. The particular roots of unity which appear in\nour analysis cannot be written as $e^{2\\pi i / (k+2)}$ with integer $k$;\ntherefore, the relevant Jones polynomial evaluations are not given by\nunknot-normalized expectation values of Wilson loop operators in conventional\n$SU(2)$ Chern$\\unicode{x2013}$Simons theory with level $k$. Instead, they\ncorrespond to an analytic continuation of such expectation values to fractional\nlevel. We briefly review the continuation procedure and comment on the presence\nof certain Lefschetz thimbles, to which our approximation formula is sensitive,\nin the analytically continued Chern$\\unicode{x2013}$Simons integration cycle.",
          "link": "http://arxiv.org/abs/2012.03955",
          "publishedOn": "2021-06-08T02:20:25.894Z",
          "wordCount": 645,
          "title": "Disentangling a Deep Learned Volume Formula. (arXiv:2012.03955v2 [hep-th] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.09345",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Parekh_J/0/1/0/all/0/1\">Jayneel Parekh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mozharovskyi_P/0/1/0/all/0/1\">Pavlo Mozharovskyi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+dAlche_Buc_F/0/1/0/all/0/1\">Florence d&#x27;Alch&#xe9;-Buc</a>",
          "description": "To tackle interpretability in deep learning, we present a novel framework to\njointly learn a predictive model and its associated interpretation model. The\ninterpreter provides both local and global interpretability about the\npredictive model in terms of human-understandable high level attribute\nfunctions, with minimal loss of accuracy. This is achieved by a dedicated\narchitecture and well chosen regularization penalties. We seek for a small-size\ndictionary of high level attribute functions that take as inputs the outputs of\nselected hidden layers and whose outputs feed a linear classifier. We impose\nstrong conciseness on the activation of attributes with an entropy-based\ncriterion while enforcing fidelity to both inputs and outputs of the predictive\nmodel. A detailed pipeline to visualize the learnt features is also developed.\nMoreover, besides generating interpretable models by design, our approach can\nbe specialized to provide post-hoc interpretations for a pre-trained neural\nnetwork. We validate our approach against several state-of-the-art methods on\nmultiple datasets and show its efficacy on both kinds of tasks.",
          "link": "http://arxiv.org/abs/2010.09345",
          "publishedOn": "2021-06-08T02:20:25.882Z",
          "wordCount": 623,
          "title": "A Framework to Learn with Interpretation. (arXiv:2010.09345v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.08474",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1\">Honglin Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaheer_M/0/1/0/all/0/1\">Manzil Zaheer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddi_S/0/1/0/all/0/1\">Sashank Reddi</a>",
          "description": "Federated Learning (FL) is a distributed learning paradigm that scales\non-device learning collaboratively and privately. Standard FL algorithms such\nas FedAvg are primarily geared towards smooth unconstrained settings. In this\npaper, we study the Federated Composite Optimization (FCO) problem, in which\nthe loss function contains a non-smooth regularizer. Such problems arise\nnaturally in FL applications that involve sparsity, low-rank, monotonicity, or\nmore general constraints. We first show that straightforward extensions of\nprimal algorithms such as FedAvg are not well-suited for FCO since they suffer\nfrom the \"curse of primal averaging,\" resulting in poor convergence. As a\nsolution, we propose a new primal-dual algorithm, Federated Dual Averaging\n(FedDualAvg), which by employing a novel server dual averaging procedure\ncircumvents the curse of primal averaging. Our theoretical analysis and\nempirical experiments demonstrate that FedDualAvg outperforms the other\nbaselines.",
          "link": "http://arxiv.org/abs/2011.08474",
          "publishedOn": "2021-06-08T02:20:25.875Z",
          "wordCount": 613,
          "title": "Federated Composite Optimization. (arXiv:2011.08474v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.14250",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chandra_R/0/1/0/all/0/1\">Rohitash Chandra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_S/0/1/0/all/0/1\">Shaurya Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_R/0/1/0/all/0/1\">Rishabh Gupta</a>",
          "description": "Time series prediction with neural networks has been the focus of much\nresearch in the past few decades. Given the recent deep learning revolution,\nthere has been much attention in using deep learning models for time series\nprediction, and hence it is important to evaluate their strengths and\nweaknesses. In this paper, we present an evaluation study that compares the\nperformance of deep learning models for multi-step ahead time series\nprediction. The deep learning methods comprise simple recurrent neural\nnetworks, long short-term memory (LSTM) networks, bidirectional LSTM networks,\nencoder-decoder LSTM networks, and convolutional neural networks. We provide a\nfurther comparison with simple neural networks that use stochastic gradient\ndescent and adaptive moment estimation (Adam) for training. We focus on\nunivariate time series for multi-step-ahead prediction from benchmark\ntime-series datasets and provide a further comparison of the results with\nrelated methods from the literature. The results show that the bidirectional\nand encoder-decoder LSTM network provides the best performance in accuracy for\nthe given time series problems.",
          "link": "http://arxiv.org/abs/2103.14250",
          "publishedOn": "2021-06-08T02:20:25.858Z",
          "wordCount": 630,
          "title": "Evaluation of deep learning models for multi-step ahead time series prediction. (arXiv:2103.14250v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.02400",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xuefeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Gang Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "In label-noise learning, the transition matrix plays a key role in building\nstatistically consistent classifiers. Existing consistent estimators for the\ntransition matrix have been developed by exploiting anchor points. However, the\nanchor-point assumption is not always satisfied in real scenarios. In this\npaper, we propose an end-to-end framework for solving label-noise learning\nwithout anchor points, in which we simultaneously optimize two objectives: the\ncross entropy loss between the prediction by the neural network and the given\nnoisy label, and the volume of the simplex formed by the columns of the\ntransition matrix. Our proposed framework can identify the transition matrix if\nthe clean class-posterior probabilities are sufficiently scattered. This is by\nfar the mildest assumption under which the transition matrix is provably\nidentifiable and the learned classifier is statistically consistent.\nExperimental results on benchmark datasets demonstrate the effectiveness and\nrobustness of the proposed method.",
          "link": "http://arxiv.org/abs/2102.02400",
          "publishedOn": "2021-06-08T02:20:25.852Z",
          "wordCount": 598,
          "title": "Provably End-to-end Label-Noise Learning without Anchor Points. (arXiv:2102.02400v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.00889",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Snoswell_A/0/1/0/all/0/1\">Aaron J. Snoswell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Surya P. N. Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_N/0/1/0/all/0/1\">Nan Ye</a>",
          "description": "We provide new perspectives and inference algorithms for Maximum Entropy\n(MaxEnt) Inverse Reinforcement Learning (IRL), which provides a principled\nmethod to find a most non-committal reward function consistent with given\nexpert demonstrations, among many consistent reward functions.\n\nWe first present a generalized MaxEnt formulation based on minimizing a\nKL-divergence instead of maximizing an entropy. This improves the previous\nheuristic derivation of the MaxEnt IRL model (for stochastic MDPs), allows a\nunified view of MaxEnt IRL and Relative Entropy IRL, and leads to a model-free\nlearning algorithm for the MaxEnt IRL model. Second, a careful review of\nexisting inference algorithms and implementations showed that they\napproximately compute the marginals required for learning the model. We provide\nexamples to illustrate this, and present an efficient and exact inference\nalgorithm. Our algorithm can handle variable length demonstrations; in\naddition, while a basic version takes time quadratic in the maximum\ndemonstration length L, an improved version of this algorithm reduces this to\nlinear using a padding trick.\n\nExperiments show that our exact algorithm improves reward learning as\ncompared to the approximate ones. Furthermore, our algorithm scales up to a\nlarge, real-world dataset involving driver behaviour forecasting. We provide an\noptimized implementation compatible with the OpenAI Gym interface. Our new\ninsight and algorithms could possibly lead to further interest and exploration\nof the original MaxEnt IRL model.",
          "link": "http://arxiv.org/abs/2012.00889",
          "publishedOn": "2021-06-08T02:20:25.838Z",
          "wordCount": 700,
          "title": "Revisiting Maximum Entropy Inverse Reinforcement Learning: New Perspectives and Algorithms. (arXiv:2012.00889v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05313",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Remlinger_C/0/1/0/all/0/1\">Carl Remlinger</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mikael_J/0/1/0/all/0/1\">Joseph Mikael</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Elie_R/0/1/0/all/0/1\">Romuald Elie</a>",
          "description": "We introduce three new generative models for time series. Based on Euler\ndiscretization and Wasserstein metrics, they are able to capture time marginal\ndistributions and temporal dynamics. Two of these methods rely on the\nadaptation of generative adversarial networks (GANs) to time series. Both of\nthem outperform state-of-the-art benchmarks by capturing the underlying\ntemporal structure on synthetic time series. The third algorithm, called\nConditional Euler Generator (CEGEN), minimizes a dedicated distance between the\ntransition probability distributions over all time steps. In the context of Ito\nprocesses, we provide theoretical guarantees that minimizing this criterion\nimplies accurate estimations of the drift and volatility parameters. We\ndemonstrate empirically that CEGEN outperforms state-of-the-art and GAN\ngenerators on both marginal and temporal dynamics metrics. Besides, it\nidentifies accurate correlation structures in high dimension. When few data\npoints are available, we verify the effectiveness of CEGEN, when combined with\ntransfer learning methods on Monte Carlo simulations. Finally, we illustrate\nthe robustness of our method on various real-world datasets.",
          "link": "http://arxiv.org/abs/2102.05313",
          "publishedOn": "2021-06-08T02:20:25.820Z",
          "wordCount": 614,
          "title": "Conditional Versus Adversarial Euler-based Generators For Time Series. (arXiv:2102.05313v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.02992",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Shaojun Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yongxin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zha_H/0/1/0/all/0/1\">Hongyuan Zha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Haomin Zhou</a>",
          "description": "We propose a new formulation and learning strategy for computing the\nWasserstein geodesic between two probability distributions in high dimensions.\nBy applying the method of Lagrange multipliers to the dynamic formulation of\nthe optimal transport (OT) problem, we derive a minimax problem whose saddle\npoint is the Wasserstein geodesic. We then parametrize the functions by deep\nneural networks and design a sample based bidirectional learning algorithm for\ntraining. The trained networks enable sampling from the Wasserstein geodesic.\nAs by-products, the algorithm also computes the Wasserstein distance and OT map\nbetween the marginal distributions. We demonstrate the performance of our\nalgorithms through a series of experiments with both synthetic and realistic\ndata.",
          "link": "http://arxiv.org/abs/2102.02992",
          "publishedOn": "2021-06-08T02:20:25.814Z",
          "wordCount": 587,
          "title": "Learning High Dimensional Wasserstein Geodesics. (arXiv:2102.02992v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03417",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aka_O/0/1/0/all/0/1\">Osman Aka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burke_K/0/1/0/all/0/1\">Ken Burke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bauerle_A/0/1/0/all/0/1\">Alex B&#xe4;uerle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greer_C/0/1/0/all/0/1\">Christina Greer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitchell_M/0/1/0/all/0/1\">Margaret Mitchell</a>",
          "description": "The measurement of bias in machine learning often focuses on model\nperformance across identity subgroups (such as man and woman) with respect to\ngroundtruth labels. However, these methods do not directly measure the\nassociations that a model may have learned, for example between labels and\nidentity subgroups. Further, measuring a model's bias requires a fully\nannotated evaluation dataset which may not be easily available in practice. We\npresent an elegant mathematical solution that tackles both issues\nsimultaneously, using image classification as a working example. By treating a\nclassification model's predictions for a given image as a set of labels\nanalogous to a bag of words, we rank the biases that a model has learned with\nrespect to different identity labels. We use (man, woman) as a concrete example\nof an identity label set (although this set need not be binary), and present\nrankings for the labels that are most biased towards one identity or the other.\nWe demonstrate how the statistical properties of different association metrics\ncan lead to different rankings of the most \"gender biased\" labels, and conclude\nthat normalized pointwise mutual information (nPMI) is most useful in practice.\nFinally, we announce an open-sourced nPMI visualization tool using TensorBoard.",
          "link": "http://arxiv.org/abs/2103.03417",
          "publishedOn": "2021-06-08T02:20:25.808Z",
          "wordCount": 675,
          "title": "Measuring Model Biases in the Absence of Ground Truth. (arXiv:2103.03417v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.08463",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cioba_A/0/1/0/all/0/1\">Alexandru Cioba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bromberg_M/0/1/0/all/0/1\">Michael Bromberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niyogi_R/0/1/0/all/0/1\">Ritwik Niyogi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Batzolis_G/0/1/0/all/0/1\">Georgios Batzolis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_J/0/1/0/all/0/1\">Jezabel Garcia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shiu_D/0/1/0/all/0/1\">Da-shan Shiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bernacchia_A/0/1/0/all/0/1\">Alberto Bernacchia</a>",
          "description": "Meta-learning models transfer the knowledge acquired from previous tasks to\nquickly learn new ones. They are trained on benchmarks with a fixed number of\ndata points per task. This number is usually arbitrary and it is unknown how it\naffects performance at testing. Since labelling of data is expensive, finding\nthe optimal allocation of labels across training tasks may reduce costs. Given\na fixed budget of labels, should we use a small number of highly labelled\ntasks, or many tasks with few labels each? Should we allocate more labels to\nsome tasks and less to others? We show that: 1) If tasks are homogeneous, there\nis a uniform optimal allocation, whereby all tasks get the same amount of data;\n2) At fixed budget, there is a trade-off between number of tasks and number of\ndata points per task, with a unique and constant optimum; 3) When trained\nseparately, harder task should get more data, at the cost of a smaller number\nof tasks; 4) When training on a mixture of easy and hard tasks, more data\nshould be allocated to easy tasks. Interestingly, Neuroscience experiments have\nshown that human visual skills also transfer better from easy tasks. We prove\nthese results mathematically on mixed linear regression, and we show\nempirically that the same results hold for few-shot image classification on\nCIFAR-FS and mini-ImageNet. Our results provide guidance for allocating labels\nacross tasks when collecting data for meta-learning.",
          "link": "http://arxiv.org/abs/2103.08463",
          "publishedOn": "2021-06-08T02:20:25.801Z",
          "wordCount": 696,
          "title": "How to distribute data across tasks for meta-learning?. (arXiv:2103.08463v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.07524",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1\">Jiaheng Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Minghao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jiahao Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qiutong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1\">James Davis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>",
          "description": "In this paper, we introduce PeerGAN, a generative adversarial network (GAN)\nsolution to improve the stability of the generated samples and to mitigate mode\ncollapse. Built upon the Vanilla GAN's two-player game between the\ndiscriminator $D_1$ and the generator $G$, we introduce a peer discriminator\n$D_2$ to the min-max game. Similar to previous work using two discriminators,\nthe first role of both $D_1$, $D_2$ is to distinguish between generated samples\nand real ones, while the generator tries to generate high-quality samples which\nare able to fool both discriminators. Different from existing methods, we\nintroduce another game between $D_1$ and $D_2$ to discourage their agreement\nand therefore increase the level of diversity of the generated samples. This\nproperty alleviates the issue of early mode collapse by preventing $D_1$ and\n$D_2$ from converging too fast. We provide theoretical analysis for the\nequilibrium of the min-max game formed among $G, D_1, D_2$. We offer\nconvergence behavior of PeerGAN as well as stability of the min-max game. It's\nworth mentioning that PeerGAN operates in the unsupervised setting, and the\nadditional game between $D_1$ and $D_2$ does not need any label supervision.\nExperiments results on a synthetic dataset and on real-world image datasets\n(MNIST, Fashion MNIST, CIFAR-10, STL-10, CelebA, VGG) demonstrate that PeerGAN\noutperforms competitive baseline work in generating diverse and high-quality\nsamples, while only introduces negligible computation cost.",
          "link": "http://arxiv.org/abs/2101.07524",
          "publishedOn": "2021-06-08T02:20:25.794Z",
          "wordCount": 684,
          "title": "PeerGAN: Generative Adversarial Networks with a Competing Peer Discriminator. (arXiv:2101.07524v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.09850",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tomar_M/0/1/0/all/0/1\">Manan Tomar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Amy Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calandra_R/0/1/0/all/0/1\">Roberto Calandra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taylor_M/0/1/0/all/0/1\">Matthew E. Taylor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1\">Joelle Pineau</a>",
          "description": "Accuracy and generalization of dynamics models is key to the success of\nmodel-based reinforcement learning (MBRL). As the complexity of tasks\nincreases, so does the sample inefficiency of learning accurate dynamics\nmodels. However, many complex tasks also exhibit sparsity in the dynamics,\ni.e., actions have only a local effect on the system dynamics. In this paper,\nwe exploit this property with a causal invariance perspective in the\nsingle-task setting, introducing a new type of state abstraction called\n\\textit{model-invariance}. Unlike previous forms of state abstractions, a\nmodel-invariance state abstraction leverages causal sparsity over state\nvariables. This allows for compositional generalization to unseen states,\nsomething that non-factored forms of state abstractions cannot do. We prove\nthat an optimal policy can be learned over this model-invariance state\nabstraction and show improved generalization in a simple toy domain. Next, we\npropose a practical method to approximately learn a model-invariant\nrepresentation for complex domains and validate our approach by showing\nimproved modelling performance over standard maximum likelihood approaches on\nchallenging tasks, such as the MuJoCo-based Humanoid. Finally, within the MBRL\nsetting we show strong performance gains with respect to sample efficiency\nacross a host of other continuous control tasks.",
          "link": "http://arxiv.org/abs/2102.09850",
          "publishedOn": "2021-06-08T02:20:25.788Z",
          "wordCount": 658,
          "title": "Model-Invariant State Abstractions for Model-Based Reinforcement Learning. (arXiv:2102.09850v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.00330",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thananjeyan_B/0/1/0/all/0/1\">Brijen Thananjeyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kandasamy_K/0/1/0/all/0/1\">Kirthevasan Kandasamy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoica_I/0/1/0/all/0/1\">Ion Stoica</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_K/0/1/0/all/0/1\">Ken Goldberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1\">Joseph E. Gonzalez</a>",
          "description": "We study exploration in stochastic multi-armed bandits when we have access to\na divisible resource that can be allocated in varying amounts to arm pulls. We\nfocus in particular on the allocation of distributed computing resources, where\nwe may obtain results faster by allocating more resources per pull, but might\nhave reduced throughput due to nonlinear scaling. For example, in\nsimulation-based scientific studies, an expensive simulation can be sped up by\nrunning it on multiple cores. This speed-up however, is partly offset by the\ncommunication among cores, which results in lower throughput than if fewer\ncores were allocated per trial to run more trials in parallel. In this paper,\nwe explore these trade-offs in two settings. First, in a fixed confidence\nsetting, we need to find the best arm with a given target success probability\nas quickly as possible. We propose an algorithm which trades off between\ninformation accumulation and throughput and show that the time taken can be\nupper bounded by the solution of a dynamic program whose inputs are the gaps\nbetween the sub-optimal and optimal arms. We also prove a matching hardness\nresult. Second, we present an algorithm for a fixed deadline setting, where we\nare given a time deadline and need to maximize the probability of finding the\nbest arm. We corroborate our theoretical insights with simulation experiments\nthat show that the algorithms consistently match or outperform baseline\nalgorithms on a variety of problem instances.",
          "link": "http://arxiv.org/abs/2011.00330",
          "publishedOn": "2021-06-08T02:20:25.770Z",
          "wordCount": 730,
          "title": "Resource Allocation in Multi-armed Bandit Exploration: Overcoming Sublinear Scaling with Adaptive Parallelism. (arXiv:2011.00330v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05573",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kubler_J/0/1/0/all/0/1\">Jonas M. K&#xfc;bler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jitkrittum_W/0/1/0/all/0/1\">Wittawat Jitkrittum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muandet_K/0/1/0/all/0/1\">Krikamol Muandet</a>",
          "description": "The Maximum Mean Discrepancy (MMD) has been the state-of-the-art\nnonparametric test for tackling the two-sample problem. Its statistic is given\nby the difference in expectations of the witness function, a real-valued\nfunction defined as a weighted sum of kernel evaluations on a set of basis\npoints. Typically the kernel is optimized on a training set, and hypothesis\ntesting is performed on a separate test set to avoid overfitting (i.e., control\ntype-I error). That is, the test set is used to simultaneously estimate the\nexpectations and define the basis points, while the training set only serves to\nselect the kernel and is discarded. In this work, we argue that this data\nsplitting scheme is overly conservative, and propose to use the training data\nto also define the weights and the basis points for better data efficiency. We\nshow that 1) the new test is consistent and has a well-controlled type-I error;\n2) the optimal witness function is given by a precision-weighted mean in the\nreproducing kernel Hilbert space associated with the kernel, and is closely\nrelated to kernel Fisher discriminant analysis; and 3) the test power of the\nproposed test is comparable or exceeds that of the MMD and other modern tests,\nas verified empirically on challenging synthetic and real problems (e.g., Higgs\ndata).",
          "link": "http://arxiv.org/abs/2102.05573",
          "publishedOn": "2021-06-08T02:20:25.764Z",
          "wordCount": 674,
          "title": "A Witness Two-Sample Test. (arXiv:2102.05573v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.05908",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chua_F/0/1/0/all/0/1\">Freddy C. Chua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duffy_N/0/1/0/all/0/1\">Nigel P. Duffy</a>",
          "description": "We address the challenge of extracting structured information from business\ndocuments without detailed annotations. We propose Deep Conditional\nProbabilistic Context Free Grammars (DeepCPCFG) to parse two-dimensional\ncomplex documents and use Recursive Neural Networks to create an end-to-end\nsystem for finding the most probable parse that represents the structured\ninformation to be extracted. This system is trained end-to-end with scanned\ndocuments as input and only relational-records as labels. The\nrelational-records are extracted from existing databases avoiding the cost of\nannotating documents by hand. We apply this approach to extract information\nfrom scanned invoices achieving state-of-the-art results despite using no\nhand-annotations.",
          "link": "http://arxiv.org/abs/2103.05908",
          "publishedOn": "2021-06-08T02:20:25.757Z",
          "wordCount": 561,
          "title": "DeepCPCFG: Deep Learning and Context Free Grammars for End-to-End Information Extraction. (arXiv:2103.05908v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.05001",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Manupriya_P/0/1/0/all/0/1\">Piyushi Manupriya</a> (IIT Hyderabad, INDIA), <a href=\"http://arxiv.org/find/cs/1/au:+Nath_J/0/1/0/all/0/1\">J. Saketha Nath</a> (IIT Hyderabad, INDIA), <a href=\"http://arxiv.org/find/cs/1/au:+Jawanpuria_P/0/1/0/all/0/1\">Pratik Jawanpuria</a> (Microsoft IDC, INDIA)",
          "description": "Regularization in Optimal Transport (OT) problems has been shown to\ncritically affect the associated computational and sample complexities. It also\nhas been observed that regularization effectively helps in handling noisy\nmarginals as well as marginals with unequal masses. However, existing works on\nOT restrict themselves to $\\phi$-divergences based regularization. In this\nwork, we propose and analyze Integral Probability Metric (IPM) based\nregularization in OT problems. While it is expected that the well-established\nadvantages of IPMs are inherited by the IPM-regularized OT variants, we\ninterestingly observe that some useful aspects of $\\phi$-regularization are\npreserved. For example, we show that the OT formulation, where the marginal\nconstraints are relaxed using IPM-regularization, also lifts the ground metric\nto that over (perhaps un-normalized) measures. Infact, the lifted metric turns\nout to be another IPM whose generating set is the intersection of that of the\nIPM employed for regularization and the set of 1-Lipschitz functions under the\nground metric. Also, in the special case where the regularization is squared\nmaximum mean discrepancy based, the proposed OT variant, as well as the\ncorresponding Barycenter formulation, turn out to be those of minimizing a\nconvex quadratic subject to non-negativity/simplex constraints and hence can be\nsolved efficiently. Simulations confirm that the optimal transport plans/maps\nobtained with IPM-regularization are intrinsically different from those\nobtained with $\\phi$-regularization. Empirical results illustrate the efficacy\nof the proposed IPM-regularized OT formulation.\n\nThis draft contains the main paper and the Appendices.",
          "link": "http://arxiv.org/abs/2011.05001",
          "publishedOn": "2021-06-08T02:20:25.750Z",
          "wordCount": 703,
          "title": "Integral Probability Metric based Regularization for Optimal Transport. (arXiv:2011.05001v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.11994",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ariu_K/0/1/0/all/0/1\">Kaito Ariu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Abe_K/0/1/0/all/0/1\">Kenshi Abe</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Proutiere_A/0/1/0/all/0/1\">Alexandre Prouti&#xe8;re</a>",
          "description": "In this paper, we revisit the regret minimization problem in sparse\nstochastic contextual linear bandits, where feature vectors may be of large\ndimension $d$, but where the reward function depends on a few, say $s_0\\ll d$,\nof these features only. We present Thresholded Lasso bandit, an algorithm that\n(i) estimates the vector defining the reward function as well as its sparse\nsupport, i.e., significant feature elements, using the Lasso framework with\nthresholding, and (ii) selects an arm greedily according to this estimate\nprojected on its support. The algorithm does not require prior knowledge of the\nsparsity index $s_0$. For this simple algorithm, we establish non-asymptotic\nregret upper bounds scaling as $\\mathcal{O}( \\log d + \\sqrt{T} )$ in general,\nand as $\\mathcal{O}( \\log d + \\log T)$ under the so-called margin condition (a\nsetting where arms are well separated). The regret of previous algorithms\nscales as $\\mathcal{O}( \\log d + \\sqrt{T \\log (d T)})$ and $\\mathcal{O}( \\log T\n\\log d)$ in the two settings, respectively. Through numerical experiments, we\nconfirm that our algorithm outperforms existing methods.",
          "link": "http://arxiv.org/abs/2010.11994",
          "publishedOn": "2021-06-08T02:20:25.725Z",
          "wordCount": 608,
          "title": "Thresholded Lasso Bandit. (arXiv:2010.11994v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.13086",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goldsteen_A/0/1/0/all/0/1\">Abigail Goldsteen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ezov_G/0/1/0/all/0/1\">Gilad Ezov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shmelkin_R/0/1/0/all/0/1\">Ron Shmelkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moffie_M/0/1/0/all/0/1\">Micha Moffie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farkash_A/0/1/0/all/0/1\">Ariel Farkash</a>",
          "description": "There is a known tension between the need to analyze personal data to drive\nbusiness and privacy concerns. Many data protection regulations, including the\nEU General Data Protection Regulation (GDPR) and the California Consumer\nProtection Act (CCPA), set out strict restrictions and obligations on companies\nthat collect or process personal data. Moreover, machine learning models\nthemselves can be used to derive personal information, as demonstrated by\nrecent membership and attribute inference attacks. Anonymized data, however, is\nexempt from data protection principles and obligations. Thus, models built on\nanonymized data are also exempt from any privacy obligations, in addition to\nproviding better protection against such attacks on the training data. Learning\non anonymized data typically results in a significant degradation in accuracy.\nWe address this challenge by guiding our anonymization using the knowledge\nencoded within the model, and targeting it to minimize the impact on the\nmodel's accuracy, a process we call accuracy-guided anonymization. We\ndemonstrate that by focusing on the model's accuracy rather than information\nloss, our method outperforms state of the art k-anonymity methods in terms of\nthe achieved utility, in particular with high values of k and large numbers of\nquasi-identifiers. We also demonstrate that our approach achieves similar\nresults in its ability to prevent membership inference attacks as alternative\napproaches based on differential privacy. This shows that model-guided\nanonymization can, in some cases, be a legitimate substitute for such methods,\nwhile averting some of their inherent drawbacks such as complexity, performance\noverhead and being fitted to specific model types. As opposed to methods that\nrely on adding noise during training, our approach does not rely on making any\nmodifications to the training algorithm itself.",
          "link": "http://arxiv.org/abs/2007.13086",
          "publishedOn": "2021-06-08T02:20:25.718Z",
          "wordCount": 731,
          "title": "Anonymizing Machine Learning Models. (arXiv:2007.13086v2 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03966",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_H/0/1/0/all/0/1\">Huiru Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1\">Caigao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yangqiu Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">James Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_J/0/1/0/all/0/1\">Junwu Xiong</a>",
          "description": "Learning the representation of data with hierarchical structures in the\nhyperbolic space attracts increasing attention in recent years. Due to the\nconstant negative curvature, the hyperbolic space resembles tree metrics and\ncaptures the tree-like properties naturally, which enables the hyperbolic\nembeddings to improve over traditional Euclidean models. However, many\nreal-world hierarchically structured data such as taxonomies and multitree\nnetworks have varying local structures and they are not trees, thus they do not\nubiquitously match the constant curvature property of the hyperbolic space. To\naddress this limitation of hyperbolic embeddings, we explore the complex\nhyperbolic space, which has the variable negative curvature, for representation\nlearning. Specifically, we propose to learn the embeddings of hierarchically\nstructured data in the unit ball model of the complex hyperbolic space. The\nunit ball model based embeddings have a more powerful representation capacity\nto capture a variety of hierarchical structures. Through experiments on\nsynthetic and real-world data, we show that our approach improves over the\nhyperbolic embedding models significantly.",
          "link": "http://arxiv.org/abs/2105.03966",
          "publishedOn": "2021-06-08T02:20:25.711Z",
          "wordCount": 625,
          "title": "Unit Ball Model for Embedding Hierarchical Structures in the Complex Hyperbolic Space. (arXiv:2105.03966v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.10784",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kang_W/0/1/0/all/0/1\">Wang-Cheng Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_D/0/1/0/all/0/1\">Derek Zhiyuan Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_T/0/1/0/all/0/1\">Tiansheng Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1\">Xinyang Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Ting Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_L/0/1/0/all/0/1\">Lichan Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chi_E/0/1/0/all/0/1\">Ed H. Chi</a>",
          "description": "Embedding learning of categorical features (e.g. user/item IDs) is at the\ncore of various recommendation models including matrix factorization and neural\ncollaborative filtering. The standard approach creates an embedding table where\neach row represents a dedicated embedding vector for every unique feature\nvalue. However, this method fails to efficiently handle high-cardinality\nfeatures and unseen feature values (e.g. new video ID) that are prevalent in\nreal-world recommendation systems. In this paper, we propose an alternative\nembedding framework Deep Hash Embedding (DHE), replacing embedding tables by a\ndeep embedding network to compute embeddings on the fly. DHE first encodes the\nfeature value to a unique identifier vector with multiple hashing functions and\ntransformations, and then applies a DNN to convert the identifier vector to an\nembedding. The encoding module is deterministic, non-learnable, and free of\nstorage, while the embedding network is updated during the training time to\nlearn embedding generation. Empirical results show that DHE achieves comparable\nAUC against the standard one-hot full embedding, with smaller model sizes. Our\nwork sheds light on the design of DNN-based alternative embedding schemes for\ncategorical features without using embedding table lookup.",
          "link": "http://arxiv.org/abs/2010.10784",
          "publishedOn": "2021-06-08T02:20:25.704Z",
          "wordCount": 663,
          "title": "Learning to Embed Categorical Features without Embedding Tables for Recommendation. (arXiv:2010.10784v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.11622",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1\">Han Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1\">Chuang Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1\">Ligeng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Song Han</a>",
          "description": "On-device learning enables edge devices to continually adapt the AI models to\nnew data, which requires a small memory footprint to fit the tight memory\nconstraint of edge devices. Existing work solves this problem by reducing the\nnumber of trainable parameters. However, this doesn't directly translate to\nmemory saving since the major bottleneck is the activations, not parameters. In\nthis work, we present Tiny-Transfer-Learning (TinyTL) for memory-efficient\non-device learning. TinyTL freezes the weights while only learns the bias\nmodules, thus no need to store the intermediate activations. To maintain the\nadaptation capacity, we introduce a new memory-efficient bias module, the lite\nresidual module, to refine the feature extractor by learning small residual\nfeature maps adding only 3.8% memory overhead. Extensive experiments show that\nTinyTL significantly saves the memory (up to 6.5x) with little accuracy loss\ncompared to fine-tuning the full network. Compared to fine-tuning the last\nlayer, TinyTL provides significant accuracy improvements (up to 34.1%) with\nlittle memory overhead. Furthermore, combined with feature extractor\nadaptation, TinyTL provides 7.3-12.9x memory saving without sacrificing\naccuracy compared to fine-tuning the full Inception-V3.",
          "link": "http://arxiv.org/abs/2007.11622",
          "publishedOn": "2021-06-08T02:20:25.698Z",
          "wordCount": 675,
          "title": "TinyTL: Reduce Activations, Not Trainable Parameters for Efficient On-Device Learning. (arXiv:2007.11622v5 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.14439",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Bill Yuchen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Haitian Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhingra_B/0/1/0/all/0/1\">Bhuwan Dhingra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaheer_M/0/1/0/all/0/1\">Manzil Zaheer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_W/0/1/0/all/0/1\">William W. Cohen</a>",
          "description": "Current commonsense reasoning research focuses on developing models that use\ncommonsense knowledge to answer multiple-choice questions. However, systems\ndesigned to answer multiple-choice questions may not be useful in applications\nthat do not provide a small list of candidate answers to choose from. As a step\ntowards making commonsense reasoning research more realistic, we propose to\nstudy open-ended commonsense reasoning (OpenCSR) -- the task of answering a\ncommonsense question without any pre-defined choices -- using as a resource\nonly a corpus of commonsense facts written in natural language. OpenCSR is\nchallenging due to a large decision space, and because many questions require\nimplicit multi-hop reasoning. As an approach to OpenCSR, we propose DrFact, an\nefficient Differentiable model for multi-hop Reasoning over knowledge Facts. To\nevaluate OpenCSR methods, we adapt several popular commonsense reasoning\nbenchmarks, and collect multiple new answers for each test question via\ncrowd-sourcing. Experiments show that DrFact outperforms strong baseline\nmethods by a large margin.",
          "link": "http://arxiv.org/abs/2010.14439",
          "publishedOn": "2021-06-08T02:20:25.690Z",
          "wordCount": 631,
          "title": "Differentiable Open-Ended Commonsense Reasoning. (arXiv:2010.14439v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.07423",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bertossi_L/0/1/0/all/0/1\">Leopoldo Bertossi</a>",
          "description": "We propose answer-set programs that specify and compute counterfactual\ninterventions on entities that are input on a classification model. In relation\nto the outcome of the model, the resulting counterfactual entities serve as a\nbasis for the definition and computation of causality-based explanation scores\nfor the feature values in the entity under classification, namely\n\"responsibility scores\". The approach and the programs can be applied with\nblack-box models, and also with models that can be specified as logic programs,\nsuch as rule-based classifiers. The main focus of this work is on the\nspecification and computation of \"best\" counterfactual entities, i.e. those\nthat lead to maximum responsibility scores. From them one can read off the\nexplanations as maximum responsibility feature values in the original entity.\nWe also extend the programs to bring into the picture semantic or domain\nknowledge. We show how the approach could be extended by means of probabilistic\nmethods, and how the underlying probability distributions could be modified\nthrough the use of constraints.",
          "link": "http://arxiv.org/abs/2011.07423",
          "publishedOn": "2021-06-08T02:20:25.684Z",
          "wordCount": 638,
          "title": "Declarative Approaches to Counterfactual Explanations for Classification. (arXiv:2011.07423v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10488",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Bonner_S/0/1/0/all/0/1\">Stephen Bonner</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Barrett_I/0/1/0/all/0/1\">Ian P Barrett</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ye_C/0/1/0/all/0/1\">Cheng Ye</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Swiers_R/0/1/0/all/0/1\">Rowan Swiers</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Engkvist_O/0/1/0/all/0/1\">Ola Engkvist</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Hoyt_C/0/1/0/all/0/1\">Charles Tapley Hoyt</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Hamilton_W/0/1/0/all/0/1\">William L Hamilton</a>",
          "description": "Knowledge Graphs (KG) and associated Knowledge Graph Embedding (KGE) models\nhave recently begun to be explored in the context of drug discovery and have\nthe potential to assist in key challenges such as target identification. In the\ndrug discovery domain, KGs can be employed as part of a process which can\nresult in lab-based experiments being performed, or impact on other decisions,\nincurring significant time and financial costs and most importantly, ultimately\ninfluencing patient healthcare. For KGE models to have impact in this domain, a\nbetter understanding of not only of performance, but also the various factors\nwhich determine it, is required.\n\nIn this study we investigate, over the course of many thousands of\nexperiments, the predictive performance of five KGE models on two public drug\ndiscovery-oriented KGs. Our goal is not to focus on the best overall model or\nconfiguration, instead we take a deeper look at how performance can be affected\nby changes in the training setup, choice of hyperparameters, model parameter\ninitialisation seed and different splits of the datasets. Our results highlight\nthat these factors have significant impact on performance and can even affect\nthe ranking of models. Indeed these factors should be reported along with model\narchitectures to ensure complete reproducibility and fair comparisons of future\nwork, and we argue this is critical for the acceptance of use, and impact of\nKGEs in a biomedical setting. To aid reproducibility of our own work, we\nrelease all experimentation code.",
          "link": "http://arxiv.org/abs/2105.10488",
          "publishedOn": "2021-06-08T02:20:25.677Z",
          "wordCount": 702,
          "title": "Understanding the Performance of Knowledge Graph Embeddings in Drug Discovery. (arXiv:2105.10488v2 [q-bio.BM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.06997",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ragot_S/0/1/0/all/0/1\">S&#xe9;bastien Ragot</a>",
          "description": "Originality criteria are frequently used to compare assets and, in\nparticular, to assess the validity of intellectual property (IP) rights such as\ncopyright and design rights. In this work, the originality of an asset is\nformulated as a function of the distances between this asset and its\ncomparands, using concepts of maximum entropy and surprisal analysis. Namely,\nthe originality function is defined according to the surprisal associated with\na given asset. Creative assets can be justifiably compared to particles that\nrepel each other via an electrostatic-like pair potential. This allows a very\nsimple, suitably bounded formula to be obtained, in which the originality of an\nasset writes as the ratio of a reference energy to an interaction energy\nimparted to that asset. In particular, the originality of an asset can be\nexpressed as a ratio of two average distances, i.e., the harmonic mean of the\ndistances from this asset to its comparands divided by the harmonic mean of the\ndistances between the sole comparands. Accordingly, the originality of objects\nsuch as IP assets can be simply estimated based on distances computed thanks to\nunsupervised machine learning techniques or other distance computation\nalgorithms. Application is made to various types of assets, including emojis,\ntypeface designs, paintings, and novel titles.",
          "link": "http://arxiv.org/abs/2010.06997",
          "publishedOn": "2021-06-08T02:20:25.623Z",
          "wordCount": 676,
          "title": "Measuring the originality of intellectual property assets based on machine learning outputs. (arXiv:2010.06997v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14655",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Z/0/1/0/all/0/1\">Zhuoran Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christensen_A/0/1/0/all/0/1\">Anders S. Christensen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welborn_M/0/1/0/all/0/1\">Matthew Welborn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manby_F/0/1/0/all/0/1\">Frederick R. Manby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miller_T/0/1/0/all/0/1\">Thomas F. Miller III</a>",
          "description": "Equivariant neural networks have been successful in incorporating various\ntypes of symmetries, but are mostly limited to vector representations of\ngeometric objects. Despite the prevalence of higher-order tensors in various\napplication domains, e.g. in quantum chemistry, equivariant neural networks for\ngeneral tensors remain unexplored. Previous strategies for learning equivariant\nfunctions on tensors mostly rely on expensive tensor factorization which is not\nscalable when the dimensionality of the problem becomes large. In this work, we\npropose unitary $N$-body tensor equivariant neural network (UNiTE), an\narchitecture for a general class of symmetric tensors called $N$-body tensors.\nThe proposed neural network is equivariant with respect to the actions of a\nunitary group, such as the group of 3D rotations. Furthermore, it has a linear\ntime complexity with respect to the number of non-zero elements in the tensor.\nWe also introduce a normalization method, viz., Equivariant Normalization, to\nimprove generalization of the neural network while preserving symmetry. When\napplied to quantum chemistry, UNiTE outperforms all state-of-the-art machine\nlearning methods of that domain with over 110% average improvements on multiple\nbenchmarks. Finally, we show that UNiTE achieves a robust zero-shot\ngeneralization performance on diverse down stream chemistry tasks, while being\nthree orders of magnitude faster than conventional numerical methods with\ncompetitive accuracy.",
          "link": "http://arxiv.org/abs/2105.14655",
          "publishedOn": "2021-06-08T02:20:25.610Z",
          "wordCount": 667,
          "title": "UNiTE: Unitary N-body Tensor Equivariant Network with Applications to Quantum Chemistry. (arXiv:2105.14655v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03757",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mathelin_A/0/1/0/all/0/1\">Antoine de Mathelin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deheeger_F/0/1/0/all/0/1\">Francois Deheeger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mougeot_M/0/1/0/all/0/1\">Mathilde Mougeot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vayatis_N/0/1/0/all/0/1\">Nicolas Vayatis</a>",
          "description": "The goal of the paper is to design active learning strategies which lead to\ndomain adaptation under an assumption of covariate shift in the case of\nLipschitz labeling function. Building on previous work by Mansour et al. (2009)\nwe adapt the concept of discrepancy distance between source and target\ndistributions to restrict the maximization over the hypothesis class to a\nlocalized class of functions which are performing accurate labeling on the\nsource domain. We derive generalization error bounds for such active learning\nstrategies in terms of Rademacher average and localized discrepancy for general\nloss functions which satisfy a regularity condition. A practical K-medoids\nalgorithm that can address the case of large data set is inferred from the\ntheoretical bounds. Our numerical experiments show that the proposed algorithm\nis competitive against other state-of-the-art active learning techniques in the\ncontext of domain adaptation, in particular on large data sets of around one\nhundred thousand images.",
          "link": "http://arxiv.org/abs/2103.03757",
          "publishedOn": "2021-06-08T02:20:25.600Z",
          "wordCount": 606,
          "title": "Discrepancy-Based Active Learning for Domain Adaptation. (arXiv:2103.03757v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.00780",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ansari_A/0/1/0/all/0/1\">Abdul Fatir Ansari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ang_M/0/1/0/all/0/1\">Ming Liang Ang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soh_H/0/1/0/all/0/1\">Harold Soh</a>",
          "description": "Deep generative modeling has seen impressive advances in recent years, to the\npoint where it is now commonplace to see simulated samples (e.g., images) that\nclosely resemble real-world data. However, generation quality is generally\ninconsistent for any given model and can vary dramatically between samples. We\nintroduce Discriminator Gradient flow (DGflow), a new technique that improves\ngenerated samples via the gradient flow of entropy-regularized f-divergences\nbetween the real and the generated data distributions. The gradient flow takes\nthe form of a non-linear Fokker-Plank equation, which can be easily simulated\nby sampling from the equivalent McKean-Vlasov process. By refining inferior\nsamples, our technique avoids wasteful sample rejection used by previous\nmethods (DRS & MH-GAN). Compared to existing works that focus on specific GAN\nvariants, we show our refinement approach can be applied to GANs with\nvector-valued critics and even other deep generative models such as VAEs and\nNormalizing Flows. Empirical results on multiple synthetic, image, and text\ndatasets demonstrate that DGflow leads to significant improvement in the\nquality of generated samples for a variety of generative models, outperforming\nthe state-of-the-art Discriminator Optimal Transport (DOT) and Discriminator\nDriven Latent Sampling (DDLS) methods.",
          "link": "http://arxiv.org/abs/2012.00780",
          "publishedOn": "2021-06-08T02:20:25.585Z",
          "wordCount": 684,
          "title": "Refining Deep Generative Models via Discriminator Gradient Flow. (arXiv:2012.00780v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.07873",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zimmer_M/0/1/0/all/0/1\">Michael F. Zimmer</a>",
          "description": "The purpose of this paper is to improve upon existing variants of gradient\ndescent by solving two problems: (1) removing (or reducing) the plateau that\noccurs while minimizing the cost function,(2) continually adjusting the\nlearning rate to an \"ideal\" value. The approach taken is to approximately solve\nfor the learning rate as a function of a trust metric. When this technique is\nhybridized with momentum, it creates an especially effective gradient descent\nvariant, called NeogradM. It is shown to outperform Adam on several test\nproblems, and can easily reach cost function values that are smaller by a\nfactor of $10^8$.",
          "link": "http://arxiv.org/abs/2010.07873",
          "publishedOn": "2021-06-08T02:20:25.572Z",
          "wordCount": 559,
          "title": "Neograd: Near-Ideal Gradient Descent. (arXiv:2010.07873v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.06828",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chu_Z/0/1/0/all/0/1\">Zhixuan Chu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rathbun_S/0/1/0/all/0/1\">Stephen L. Rathbun</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_S/0/1/0/all/0/1\">Sheng Li</a>",
          "description": "The dramatically growing availability of observational data is being\nwitnessed in various domains of science and technology, which facilitates the\nstudy of causal inference. However, estimating treatment effects from\nobservational data is faced with two major challenges, missing counterfactual\noutcomes and treatment selection bias. Matching methods are among the most\nwidely used and fundamental approaches to estimating treatment effects, but\nexisting matching methods have poor performance when facing data with high\ndimensional and complicated variables. We propose a feature selection\nrepresentation matching (FSRM) method based on deep representation learning and\nmatching, which maps the original covariate space into a selective, nonlinear,\nand balanced representation space, and then conducts matching in the learned\nrepresentation space. FSRM adopts deep feature selection to minimize the\ninfluence of irrelevant variables for estimating treatment effects and\nincorporates a regularizer based on the Wasserstein distance to learn balanced\nrepresentations. We evaluate the performance of our FSRM method on three\ndatasets, and the results demonstrate superiority over the state-of-the-art\nmethods.",
          "link": "http://arxiv.org/abs/2009.06828",
          "publishedOn": "2021-06-08T02:20:25.555Z",
          "wordCount": 638,
          "title": "Matching in Selective and Balanced Representation Space for Treatment Effects Estimation. (arXiv:2009.06828v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.06866",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nozawa_K/0/1/0/all/0/1\">Kento Nozawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sato_I/0/1/0/all/0/1\">Issei Sato</a>",
          "description": "Instance discriminative self-supervised representation learning has been\nattracted attention thanks to its unsupervised nature and informative feature\nrepresentation for downstream tasks. In practice, it commonly uses a larger\nnumber of negative samples than the number of supervised classes. However,\nthere is an inconsistency in the existing analysis; theoretically, a large\nnumber of negative samples degrade classification performance on a downstream\nsupervised task, while empirically, they improve the performance. We provide a\nnovel framework to analyze this empirical result regarding negative samples\nusing the coupon collector's problem. Our bound can implicitly incorporate the\nsupervised loss of the downstream task in the self-supervised loss by\nincreasing the number of negative samples. We confirm that our proposed\nanalysis holds on real-world benchmark datasets.",
          "link": "http://arxiv.org/abs/2102.06866",
          "publishedOn": "2021-06-08T02:20:25.537Z",
          "wordCount": 582,
          "title": "Understanding Negative Samples in Instance Discriminative Self-supervised Representation Learning. (arXiv:2102.06866v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.04324",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cabannes_V/0/1/0/all/0/1\">Vivien Cabannes</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pillaud_Vivien_L/0/1/0/all/0/1\">Loucas Pillaud-Vivien</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bach_F/0/1/0/all/0/1\">Francis Bach</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rudi_A/0/1/0/all/0/1\">Alessandro Rudi</a>",
          "description": "As annotations of data can be scarce in large-scale practical problems,\nleveraging unlabelled examples is one of the most important aspects of machine\nlearning. This is the aim of semi-supervised learning. To benefit from the\naccess to unlabelled data, it is natural to diffuse smoothly knowledge of\nlabelled data to unlabelled one. This induces to the use of Laplacian\nregularization. Yet, current implementations of Laplacian regularization suffer\nfrom several drawbacks, notably the well-known curse of dimensionality. In this\npaper, we provide a statistical analysis to overcome those issues, and unveil a\nlarge body of spectral filtering methods that exhibit desirable behaviors. They\nare implemented through (reproducing) kernel methods, for which we provide\nrealistic computational guidelines in order to make our method usable with\nlarge amounts of data.",
          "link": "http://arxiv.org/abs/2009.04324",
          "publishedOn": "2021-06-08T02:20:25.531Z",
          "wordCount": 592,
          "title": "Overcoming the curse of dimensionality with Laplacian regularization in semi-supervised learning. (arXiv:2009.04324v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.12909",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chau_S/0/1/0/all/0/1\">Siu Lun Chau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouabid_S/0/1/0/all/0/1\">Shahine Bouabid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sejdinovic_D/0/1/0/all/0/1\">Dino Sejdinovic</a>",
          "description": "Refining low-resolution (LR) spatial fields with high-resolution (HR)\ninformation is challenging as the diversity of spatial datasets often prevents\ndirect matching of observations. Yet, when LR samples are modeled as aggregate\nconditional means of HR samples with respect to a mediating variable that is\nglobally observed, the recovery of the underlying fine-grained field can be\nframed as taking an \"inverse\" of the conditional expectation, namely a\ndeconditioning problem. In this work, we introduce conditional mean processes\n(CMP), a new class of Gaussian Processes describing conditional means. By\ntreating CMPs as inter-domain features of the underlying field, a posterior for\nthe latent field can be established as a solution to the deconditioning\nproblem. Furthermore, we show that this solution can be viewed as a two-staged\nvector-valued kernel ridge regressor and show that it has a minimax optimal\nconvergence rate under mild assumptions. Lastly, we demonstrate its proficiency\nin a synthetic and a real-world atmospheric field downscaling problem, showing\nsubstantial improvements over existing methods.",
          "link": "http://arxiv.org/abs/2105.12909",
          "publishedOn": "2021-06-08T02:20:25.525Z",
          "wordCount": 609,
          "title": "Deconditional Downscaling with Gaussian Processes. (arXiv:2105.12909v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.04337",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Hwanjun Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minseok Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1\">Dongmin Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_Y/0/1/0/all/0/1\">Yooju Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jae-Gil Lee</a>",
          "description": "Real-world data inevitably contains noisy labels, which induce the poor\ngeneralization of deep neural networks. It is known that the network typically\nbegins to rapidly memorize false-labeled samples after a certain point of\ntraining. Thus, to counter the label noise challenge, we propose a novel\nself-transitional learning method called MORPH, which automatically switches\nits learning phase at the transition point from seeding to evolution. In the\nseeding phase, the network is updated using all the samples to collect a seed\nof clean samples. Then, in the evolution phase, the network is updated using\nonly the set of arguably clean samples, which precisely keeps expanding by the\nupdated network. Thus, MORPH effectively avoids the overfitting to\nfalse-labeled samples throughout the entire training period. Extensive\nexperiments using five real-world or synthetic benchmark datasets demonstrate\nsubstantial improvements over state-of-the-art methods in terms of robustness\nand efficiency.",
          "link": "http://arxiv.org/abs/2012.04337",
          "publishedOn": "2021-06-08T02:20:25.519Z",
          "wordCount": 614,
          "title": "Robust Learning by Self-Transition for Handling Noisy Labels. (arXiv:2012.04337v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.06419",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1\">Jinke Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lv_P/0/1/0/all/0/1\">Peiqing Lv</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1\">Haiying Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_C/0/1/0/all/0/1\">Changfa Shi</a>",
          "description": "Background and objective: In this paper, a modified U-Net based framework is\npresented, which leverages techniques from Squeeze-and-Excitation (SE) block,\nAtrous Spatial Pyramid Pooling (ASPP) and residual learning for accurate and\nrobust liver CT segmentation, and the effectiveness of the proposed method was\ntested on two public datasets LiTS17 and SLiver07.\n\nMethods: A new network architecture called SAR-U-Net was designed. Firstly,\nthe SE block is introduced to adaptively extract image features after each\nconvolution in the U-Net encoder, while suppressing irrelevant regions, and\nhighlighting features of specific segmentation task; Secondly, ASPP was\nemployed to replace the transition layer and the output layer, and acquire\nmulti-scale image information via different receptive fields. Thirdly, to\nalleviate the degradation problem, the traditional convolution block was\nreplaced with the residual block and thus prompt the network to gain accuracy\nfrom considerably increased depth.\n\nResults: In the LiTS17 experiment, the mean values of Dice, VOE, RVD, ASD and\nMSD were 95.71, 9.52, -0.84, 1.54 and 29.14, respectively. Compared with other\nclosely related 2D-based models, the proposed method achieved the highest\naccuracy. In the experiment of the SLiver07, the mean values of Dice, VOE, RVD,\nASD and MSD were 97.31, 5.37, -1.08, 1.85 and 27.45, respectively. Compared\nwith other closely related models, the proposed method achieved the highest\nsegmentation accuracy except for the RVD.\n\nConclusion: The proposed model enables a great improvement on the accuracy\ncompared to 2D-based models, and its robustness in circumvent challenging\nproblems, such as small liver regions, discontinuous liver regions, and fuzzy\nliver boundaries, is also well demonstrated and validated.",
          "link": "http://arxiv.org/abs/2103.06419",
          "publishedOn": "2021-06-08T02:20:25.512Z",
          "wordCount": 744,
          "title": "SAR-U-Net: squeeze-and-excitation block and atrous spatial pyramid pooling based residual U-Net for automatic liver segmentation in Computed Tomography. (arXiv:2103.06419v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.12055",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Mostafa_F/0/1/0/all/0/1\">Fahad B. Mostafa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hasan_M/0/1/0/all/0/1\">Md Easin Hasan</a>",
          "description": "For a medical diagnosis, health professionals use different kinds of\npathological ways to make a decision for medical reports in terms of patients\nmedical condition. In the modern era, because of the advantage of computers and\ntechnologies, one can collect data and visualize many hidden outcomes from\nthem. Statistical machine learning algorithms based on specific problems can\nassist one to make decisions. Machine learning data driven algorithms can be\nused to validate existing methods and help researchers to suggest potential new\ndecisions. In this paper, multiple imputation by chained equations was applied\nto deal with missing data, and Principal Component Analysis to reduce the\ndimensionality. To reveal significant findings, data visualizations were\nimplemented. We presented and compared many binary classifier machine learning\nalgorithms (Artificial Neural Network, Random Forest, Support Vector Machine)\nwhich were used to classify blood donors and non-blood donors with hepatitis,\nfibrosis and cirrhosis diseases. From the data published in UCI-MLR [1], all\nmentioned techniques were applied to find one better method to classify blood\ndonors and non-blood donors (hepatitis, fibrosis, and cirrhosis) that can help\nhealth professionals in a laboratory to make better decisions. Our proposed\nML-method showed better accuracy score (e.g. 98.23% for SVM). Thus, it improved\nthe quality of classification.",
          "link": "http://arxiv.org/abs/2104.12055",
          "publishedOn": "2021-06-08T02:20:25.495Z",
          "wordCount": 660,
          "title": "Machine Learning Approaches for Binary Classification to Discover Liver Diseases using Clinical Data. (arXiv:2104.12055v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.08786",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Toenshoff_J/0/1/0/all/0/1\">Jan Toenshoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ritzert_M/0/1/0/all/0/1\">Martin Ritzert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_H/0/1/0/all/0/1\">Hinrikus Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grohe_M/0/1/0/all/0/1\">Martin Grohe</a>",
          "description": "We propose CRaWl (CNNs for Random Walks), a novel neural network architecture\nfor graph learning. It is based on processing sequences of small subgraphs\ninduced by random walks with standard 1D CNNs. Thus, CRaWl is fundamentally\ndifferent from typical message passing graph neural network architectures. It\nis inspired by techniques counting small subgraphs, such as the graphlet kernel\nand motif counting, and combines them with random walk based techniques in a\nhighly efficient and scalable neural architecture. We demonstrate empirically\nthat CRaWl matches or outperforms state-of-the-art GNN architectures across a\nmultitude of benchmark datasets for classification and regression on graphs.",
          "link": "http://arxiv.org/abs/2102.08786",
          "publishedOn": "2021-06-08T02:20:25.488Z",
          "wordCount": 556,
          "title": "Graph Learning with 1D Convolutions on Random Walks. (arXiv:2102.08786v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.09161",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tu_S/0/1/0/all/0/1\">Stephen Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Robey_A/0/1/0/all/0/1\">Alexander Robey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tingnan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matni_N/0/1/0/all/0/1\">Nikolai Matni</a>",
          "description": "We study the following question in the context of imitation learning for\ncontinuous control: how are the underlying stability properties of an expert\npolicy reflected in the sample-complexity of an imitation learning task? We\nprovide the first results showing that a surprisingly granular connection can\nbe made between the underlying expert system's incremental gain stability, a\nnovel measure of robust convergence between pairs of system trajectories, and\nthe dependency on the task horizon $T$ of the resulting generalization bounds.\nIn particular, we propose and analyze incremental gain stability constrained\nversions of behavior cloning and a DAgger-like algorithm, and show that the\nresulting sample-complexity bounds naturally reflect the underlying stability\nproperties of the expert system. As a special case, we delineate a class of\nsystems for which the number of trajectories needed to achieve\n$\\varepsilon$-suboptimality is sublinear in the task horizon $T$, and do so\nwithout requiring (strong) convexity of the loss function in the policy\nparameters. Finally, we conduct numerical experiments demonstrating the\nvalidity of our insights on both a simple nonlinear system for which the\nunderlying stability properties can be easily tuned, and on a high-dimensional\nquadrupedal robotic simulation.",
          "link": "http://arxiv.org/abs/2102.09161",
          "publishedOn": "2021-06-08T02:20:25.476Z",
          "wordCount": 651,
          "title": "On the Sample Complexity of Stability Constrained Imitation Learning. (arXiv:2102.09161v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05375",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ziyin_L/0/1/0/all/0/1\">Liu Ziyin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kangqiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mori_T/0/1/0/all/0/1\">Takashi Mori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ueda_M/0/1/0/all/0/1\">Masahito Ueda</a>",
          "description": "The noise in stochastic gradient descent (SGD), caused by minibatch sampling,\nis poorly understood despite its practical importance in deep learning. In this\nwork, we study the nature of SGD noise and fluctuation. We show that some\ndegree of mismatch between model and data complexity is needed for SGD to\n``stir\" a noise; such mismatch may be due to a label or input noise,\nregularization, or underparametrization. Compared with previous works, the\npresent work focuses on deriving exactly solvable analytical results. Our work\nalso motivates a more accurate general formulation to describe minibatch noise,\nand we show that the SGD noise takes different shapes and strengths in\ndifferent kinds of minima.",
          "link": "http://arxiv.org/abs/2102.05375",
          "publishedOn": "2021-06-08T02:20:25.460Z",
          "wordCount": 570,
          "title": "Strength of Minibatch Noise in SGD. (arXiv:2102.05375v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.05126",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tamas_A/0/1/0/all/0/1\">Ambrus Tam&#xe1;s</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Csaji_B/0/1/0/all/0/1\">Bal&#xe1;zs Csan&#xe1;d Cs&#xe1;ji</a>",
          "description": "In this paper we suggest two statistical hypothesis tests for the regression\nfunction of binary classification based on conditional kernel mean embeddings.\nThe regression function is a fundamental object in classification as it\ndetermines both the Bayes optimal classifier and the misclassification\nprobabilities. A resampling based framework is presented and combined with\nconsistent point estimators of the conditional kernel mean map, in order to\nconstruct distribution-free hypothesis tests. These tests are introduced in a\nflexible manner allowing us to control the exact probability of type I error\nfor any sample size. We also prove that both proposed techniques are consistent\nunder weak statistical assumptions, i.e., the type II error probabilities\npointwise converge to zero.",
          "link": "http://arxiv.org/abs/2103.05126",
          "publishedOn": "2021-06-08T02:20:25.366Z",
          "wordCount": null,
          "title": "Exact Distribution-Free Hypothesis Tests for the Regression Function of Binary Classification via Conditional Kernel Mean Embeddings. (arXiv:2103.05126v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.13515",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Campos_V/0/1/0/all/0/1\">V&#xed;ctor Campos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sprechmann_P/0/1/0/all/0/1\">Pablo Sprechmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hansen_S/0/1/0/all/0/1\">Steven Hansen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barreto_A/0/1/0/all/0/1\">Andre Barreto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kapturowski_S/0/1/0/all/0/1\">Steven Kapturowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vitvitskyi_A/0/1/0/all/0/1\">Alex Vitvitskyi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Badia_A/0/1/0/all/0/1\">Adri&#xe0; Puigdom&#xe8;nech Badia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blundell_C/0/1/0/all/0/1\">Charles Blundell</a>",
          "description": "Designing agents that acquire knowledge autonomously and use it to solve new\ntasks efficiently is an important challenge in reinforcement learning.\nKnowledge acquired during an unsupervised pre-training phase is often\ntransferred by fine-tuning neural network weights once rewards are exposed, as\nis common practice in supervised domains. Given the nature of the reinforcement\nlearning problem, we argue that standard fine-tuning strategies alone are not\nenough for efficient transfer in challenging domains. We introduce Behavior\nTransfer (BT), a technique that leverages pre-trained policies for exploration\nand that is complementary to transferring neural network weights. Our\nexperiments show that, when combined with large-scale pre-training in the\nabsence of rewards, existing intrinsic motivation objectives can lead to the\nemergence of complex behaviors. These pre-trained policies can then be\nleveraged by BT to discover better solutions than without pre-training, and\ncombining BT with standard fine-tuning strategies results in additional\nbenefits. The largest gains are generally observed in domains requiring\nstructured exploration, including settings where the behavior of the\npre-trained policies is misaligned with the downstream task.",
          "link": "http://arxiv.org/abs/2102.13515",
          "publishedOn": "2021-06-08T02:20:25.365Z",
          "wordCount": null,
          "title": "Beyond Fine-Tuning: Transferring Behavior in Reinforcement Learning. (arXiv:2102.13515v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02697",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Etter_P/0/1/0/all/0/1\">Philip A. Etter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_K/0/1/0/all/0/1\">Kai Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hsiang-Fu Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ying_L/0/1/0/all/0/1\">Lexing Ying</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhillon_I/0/1/0/all/0/1\">Inderjit Dhillon</a>",
          "description": "Tree-based models underpin many modern semantic search engines and\nrecommender systems due to their sub-linear inference times. In industrial\napplications, these models operate at extreme scales, where every bit of\nperformance is critical. Memory constraints at extreme scales also require that\nmodels be sparse, hence tree-based models are often back-ended by sparse matrix\nalgebra routines. However, there are currently no sparse matrix techniques\nspecifically designed for the sparsity structure one encounters in tree-based\nmodels for extreme multi-label ranking/classification (XMR/XMC) problems. To\naddress this issue, we present the masked sparse chunk multiplication (MSCM)\ntechnique, a sparse matrix technique specifically tailored to XMR trees. MSCM\nis easy to implement, embarrassingly parallelizable, and offers a significant\nperformance boost to any existing tree inference pipeline at no cost. We\nperform a comprehensive study of MSCM applied to several different sparse\ninference schemes and benchmark our methods on a general purpose extreme\nmulti-label ranking framework. We observe that MSCM gives consistently dramatic\nspeedups across both the online and batch inference settings, single- and\nmulti-threaded settings, and on many different tree models and datasets. To\ndemonstrate its utility in industrial applications, we apply MSCM to an\nenterprise-scale semantic product search problem with 100 million products and\nachieve sub-millisecond latency of 0.88 ms per query on a single thread -- an\n8x reduction in latency over vanilla inference techniques. The MSCM technique\nrequires absolutely no sacrifices to model accuracy as it gives exactly the\nsame results as standard sparse matrix techniques. Therefore, we believe that\nMSCM will enable users of XMR trees to save a substantial amount of compute\nresources in their inference pipelines at very little cost.",
          "link": "http://arxiv.org/abs/2106.02697",
          "publishedOn": "2021-06-08T02:20:25.295Z",
          "wordCount": null,
          "title": "Accelerating Inference for Sparse Extreme Multi-Label Ranking Trees. (arXiv:2106.02697v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2004.13954",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1\">Haoyi Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">Dongrui Wu</a>",
          "description": "Over-parameterized deep neural networks (DNNs) with sufficient capacity to\nmemorize random noise can achieve excellent generalization performance,\nchallenging the bias-variance trade-off in classical learning theory. Recent\nstudies claimed that DNNs first learn simple patterns and then memorize noise;\nsome other works showed a phenomenon that DNNs have a spectral bias to learn\ntarget functions from low to high frequencies during training. However, we show\nthat the monotonicity of the learning bias does not always hold: under the\nexperimental setup of deep double descent, the high-frequency components of\nDNNs diminish in the late stage of training, leading to the second descent of\nthe test error. Besides, we find that the spectrum of DNNs can be applied to\nindicating the second descent of the test error, even though it is calculated\nfrom the training set only.",
          "link": "http://arxiv.org/abs/2004.13954",
          "publishedOn": "2021-06-08T02:20:25.295Z",
          "wordCount": null,
          "title": "Rethink the Connections among Generalization, Memorization and the Spectral Bias of DNNs. (arXiv:2004.13954v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02797",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Whang_J/0/1/0/all/0/1\">Jay Whang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Acharya_A/0/1/0/all/0/1\">Anish Acharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyeji Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dimakis_A/0/1/0/all/0/1\">Alexandros G. Dimakis</a>",
          "description": "Distributed source coding is the task of encoding an input in the absence of\ncorrelated side information that is only available to the decoder. Remarkably,\nSlepian and Wolf showed in 1973 that an encoder that has no access to the\ncorrelated side information can asymptotically achieve the same compression\nrate as when the side information is available at both the encoder and the\ndecoder. While there is significant prior work on this topic in information\ntheory, practical distributed source coding has been limited to synthetic\ndatasets and specific correlation structures. Here we present a general\nframework for lossy distributed source coding that is agnostic to the\ncorrelation structure and can scale to high dimensions. Rather than relying on\nhand-crafted source-modeling, our method utilizes a powerful conditional deep\ngenerative model to learn the distributed encoder and decoder. We evaluate our\nmethod on realistic high-dimensional datasets and show substantial improvements\nin distributed compression performance.",
          "link": "http://arxiv.org/abs/2106.02797",
          "publishedOn": "2021-06-08T02:20:25.294Z",
          "wordCount": null,
          "title": "Neural Distributed Source Coding. (arXiv:2106.02797v1 [cs.IT])"
        },
        {
          "id": "http://arxiv.org/abs/2005.13273",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Watanabe_C/0/1/0/all/0/1\">Chihiro Watanabe</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Suzuki_T/0/1/0/all/0/1\">Taiji Suzuki</a>",
          "description": "Model selection in latent block models has been a challenging but important\ntask in the field of statistics. Specifically, a major challenge is encountered\nwhen constructing a test on a block structure obtained by applying a specific\nclustering algorithm to a finite size matrix. In this case, it becomes crucial\nto consider the selective bias in the block structure, that is, the block\nstructure is selected from all the possible cluster memberships based on some\ncriterion by the clustering algorithm. To cope with this problem, this study\nprovides a selective inference method for latent block models. Specifically, we\nconstruct a statistical test on a set of row and column cluster memberships of\na latent block model, which is given by a squared residue minimization\nalgorithm. The proposed test, by its nature, includes and thus can also be used\nas the test on the set of row and column cluster numbers. We also propose an\napproximated version of the test based on simulated annealing to avoid\ncombinatorial explosion in searching the optimal block structure. The results\nshow that the proposed exact and approximated tests work effectively, compared\nto the naive test that did not take the selective bias into account.",
          "link": "http://arxiv.org/abs/2005.13273",
          "publishedOn": "2021-06-08T02:20:25.294Z",
          "wordCount": null,
          "title": "Selective Inference for Latent Block Models. (arXiv:2005.13273v5 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14083",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dawson_G/0/1/0/all/0/1\">Glenn Dawson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polikar_R/0/1/0/all/0/1\">Robi Polikar</a>",
          "description": "Most studies on learning from noisy labels rely on unrealistic models of\ni.i.d. label noise, such as class-conditional transition matrices. More recent\nwork on instance-dependent noise models are more realistic, but assume a single\ngenerative process for label noise across the entire dataset. We propose a more\nprincipled model of label noise that generalizes instance-dependent noise to\nmultiple labelers, based on the observation that modern datasets are typically\nannotated using distributed crowdsourcing methods. Under our labeler-dependent\nmodel, label noise manifests itself under two modalities: natural error of\ngood-faith labelers, and adversarial labels provided by malicious actors. We\npresent two adversarial attack vectors that more accurately reflect the label\nnoise that may be encountered in real-world settings, and demonstrate that\nunder our multimodal noisy labels model, state-of-the-art approaches for\nlearning from noisy labels are defeated by adversarial label attacks. Finally,\nwe propose a multi-stage, labeler-aware, model-agnostic framework that reliably\nfilters noisy labels by leveraging knowledge about which data partitions were\nlabeled by which labeler, and show that our proposed framework remains robust\neven in the presence of extreme adversarial label noise.",
          "link": "http://arxiv.org/abs/2105.14083",
          "publishedOn": "2021-06-08T02:20:25.285Z",
          "wordCount": null,
          "title": "Rethinking Noisy Label Models: Labeler-Dependent Noise with Adversarial Awareness. (arXiv:2105.14083v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.14625",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zijie J. Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turko_R/0/1/0/all/0/1\">Robert Turko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chau_D/0/1/0/all/0/1\">Duen Horng Chau</a>",
          "description": "Why do large pre-trained transformer-based models perform so well across a\nwide variety of NLP tasks? Recent research suggests the key may lie in\nmulti-headed attention mechanism's ability to learn and represent linguistic\ninformation. Understanding how these models represent both syntactic and\nsemantic knowledge is vital to investigate why they succeed and fail, what they\nhave learned, and how they can improve. We present Dodrio, an open-source\ninteractive visualization tool to help NLP researchers and practitioners\nanalyze attention mechanisms in transformer-based models with linguistic\nknowledge. Dodrio tightly integrates an overview that summarizes the roles of\ndifferent attention heads, and detailed views that help users compare attention\nweights with the syntactic structure and semantic information in the input\ntext. To facilitate the visual comparison of attention weights and linguistic\nknowledge, Dodrio applies different graph visualization techniques to represent\nattention weights scalable to longer input text. Case studies highlight how\nDodrio provides insights into understanding the attention mechanism in\ntransformer-based models. Dodrio is available at\nhttps://poloclub.github.io/dodrio/.",
          "link": "http://arxiv.org/abs/2103.14625",
          "publishedOn": "2021-06-08T02:20:25.284Z",
          "wordCount": null,
          "title": "Dodrio: Exploring Transformer Models with Interactive Visualization. (arXiv:2103.14625v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.05993",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guangtao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1\">Qinbao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaoyan Zhu</a>",
          "description": "Recommending appropriate algorithms to a classification problem is one of the\nmost challenging issues in the field of data mining. The existing algorithm\nrecommendation models are generally constructed on only one kind of\nmeta-features by single learners. Considering that i) ensemble learners usually\nshow better performance and ii) different kinds of meta-features characterize\nthe classification problems in different viewpoints independently, and further\nthe models constructed with different sets of meta-features will be\ncomplementary with each other and applicable for ensemble. This paper proposes\nan ensemble learning-based algorithm recommendation method. To evaluate the\nproposed recommendation method, extensive experiments with 13 well-known\ncandidate classification algorithms and five different kinds of meta-features\nare conducted on 1090 benchmark classification problems. The results show the\neffectiveness of the proposed ensemble learning based recommendation method.",
          "link": "http://arxiv.org/abs/2101.05993",
          "publishedOn": "2021-06-08T02:20:25.282Z",
          "wordCount": null,
          "title": "Ensemble Learning Based Classification Algorithm Recommendation. (arXiv:2101.05993v1 [cs.IR] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05884",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dawson_G/0/1/0/all/0/1\">Glenn Dawson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polikar_R/0/1/0/all/0/1\">Robi Polikar</a>",
          "description": "As larger and more comprehensive datasets become standard in contemporary\nmachine learning, it becomes increasingly more difficult to obtain reliable,\ntrustworthy label information with which to train sophisticated models. To\naddress this problem, crowdsourcing has emerged as a popular, inexpensive, and\nefficient data mining solution for performing distributed label collection.\nHowever, crowdsourced annotations are inherently untrustworthy, as the labels\nare provided by anonymous volunteers who may have varying, unreliable\nexpertise. Worse yet, some participants on commonly used platforms such as\nAmazon Mechanical Turk may be adversarial, and provide intentionally incorrect\nlabel information without the end user's knowledge. We discuss three\nconventional models of the label generation process, describing their\nparameterizations and the model-based approaches used to solve them. We then\npropose OpinionRank, a model-free, interpretable, graph-based spectral\nalgorithm for integrating crowdsourced annotations into reliable labels for\nperforming supervised or semi-supervised learning. Our experiments show that\nOpinionRank performs favorably when compared against more highly parameterized\nalgorithms. We also show that OpinionRank is scalable to very large datasets\nand numbers of label sources, and requires considerably fewer computational\nresources than previous approaches.",
          "link": "http://arxiv.org/abs/2102.05884",
          "publishedOn": "2021-06-08T02:20:25.282Z",
          "wordCount": null,
          "title": "OpinionRank: Extracting Ground Truth Labels from Unreliable Expert Opinions with Graph-Based Spectral Ranking. (arXiv:2102.05884v2 [cs.LG] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02774",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jerry Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Allen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moitra_A/0/1/0/all/0/1\">Ankur Moitra</a>",
          "description": "Many works in signal processing and learning theory operate under the\nassumption that the underlying model is simple, e.g. that a signal is\napproximately $k$-Fourier-sparse or that a distribution can be approximated by\na mixture model that has at most $k$ components. However the problem of fitting\nthe parameters of such a model becomes more challenging when the\nfrequencies/components are too close together.\n\nIn this work we introduce new methods for sparsifying sums of exponentials\nand give various algorithmic applications. First we study Fourier-sparse\ninterpolation without a frequency gap, where Chen et al. gave an algorithm for\nfinding an $\\epsilon$-approximate solution which uses $k' = \\mbox{poly}(k, \\log\n1/\\epsilon)$ frequencies. Second, we study learning Gaussian mixture models in\none dimension without a separation condition. Kernel density estimators give an\n$\\epsilon$-approximation that uses $k' = O(k/\\epsilon^2)$ components. These\nmethods both output models that are much more complex than what we started out\nwith. We show how to post-process to reduce the number of\nfrequencies/components down to $k' = \\widetilde{O}(k)$, which is optimal up to\nlogarithmic factors. Moreover we give applications to model selection. In\nparticular, we give the first algorithms for approximately (and robustly)\ndetermining the number of components in a Gaussian mixture model that work\nwithout a separation condition.",
          "link": "http://arxiv.org/abs/2106.02774",
          "publishedOn": "2021-06-08T02:20:25.281Z",
          "wordCount": null,
          "title": "Sparsification for Sums of Exponentials and its Algorithmic Applications. (arXiv:2106.02774v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02666",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Slack_D/0/1/0/all/0/1\">Dylan Slack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hilgard_S/0/1/0/all/0/1\">Sophie Hilgard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1\">Himabindu Lakkaraju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sameer Singh</a>",
          "description": "Counterfactual explanations are emerging as an attractive option for\nproviding recourse to individuals adversely impacted by algorithmic decisions.\nAs they are deployed in critical applications (e.g. law enforcement, financial\nlending), it becomes important to ensure that we clearly understand the\nvulnerabilities of these methods and find ways to address them. However, there\nis little understanding of the vulnerabilities and shortcomings of\ncounterfactual explanations. In this work, we introduce the first framework\nthat describes the vulnerabilities of counterfactual explanations and shows how\nthey can be manipulated. More specifically, we show counterfactual explanations\nmay converge to drastically different counterfactuals under a small\nperturbation indicating they are not robust. Leveraging this insight, we\nintroduce a novel objective to train seemingly fair models where counterfactual\nexplanations find much lower cost recourse under a slight perturbation. We\ndescribe how these models can unfairly provide low-cost recourse for specific\nsubgroups in the data while appearing fair to auditors. We perform experiments\non loan and violent crime prediction data sets where certain subgroups achieve\nup to 20x lower cost recourse under the perturbation. These results raise\nconcerns regarding the dependability of current counterfactual explanation\ntechniques, which we hope will inspire investigations in robust counterfactual\nexplanations.",
          "link": "http://arxiv.org/abs/2106.02666",
          "publishedOn": "2021-06-08T02:20:25.275Z",
          "wordCount": null,
          "title": "Counterfactual Explanations Can Be Manipulated. (arXiv:2106.02666v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.07945",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fountoulakis_K/0/1/0/all/0/1\">Kimon Fountoulakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Pan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shenghao Yang</a>",
          "description": "Recently, hypergraphs have attracted a lot of attention due to their ability\nto capture complex relations among entities. The insurgence of hypergraphs has\nresulted in data of increasing size and complexity that exhibit interesting\nsmall-scale and local structure, e.g., small-scale communities and localized\nnode-ranking around a given set of seed nodes. Popular and principled ways to\ncapture the local structure are the local hypergraph clustering problem and\nrelated seed set expansion problem. In this work, we propose the first local\ndiffusion method that achieves edge-size-independent Cheeger-type guarantee for\nthe problem of local hypergraph clustering while applying to a rich class of\nhigher-order relations that covers many previously studied special cases. Our\nmethod is based on a primal-dual optimization formulation where the primal\nproblem has a natural network flow interpretation, and the dual problem has a\ncut-based interpretation using the $\\ell_2$-norm penalty on associated\ncut-costs. We demonstrate the new technique is significantly better than\nstate-of-the-art methods on both synthetic and real-world data.",
          "link": "http://arxiv.org/abs/2102.07945",
          "publishedOn": "2021-06-08T02:20:25.270Z",
          "wordCount": null,
          "title": "Local Hyper-Flow Diffusion. (arXiv:2102.07945v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.02720",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kristiadi_A/0/1/0/all/0/1\">Agustinus Kristiadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hein_M/0/1/0/all/0/1\">Matthias Hein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hennig_P/0/1/0/all/0/1\">Philipp Hennig</a>",
          "description": "Laplace approximations are classic, computationally lightweight means for\nconstructing Bayesian neural networks (BNNs). As in other approximate BNNs, one\ncannot necessarily expect the induced predictive uncertainty to be calibrated.\nHere we develop a formalism to explicitly \"train\" the uncertainty in a\ndecoupled way to the prediction itself. To this end, we introduce uncertainty\nunits for Laplace-approximated networks: Hidden units associated with a\nparticular weight structure that can be added to any pre-trained,\npoint-estimated network. Due to their weights, these units are inactive -- they\ndo not affect the predictions. But their presence changes the geometry (in\nparticular the Hessian) of the loss landscape, thereby affecting the network's\nuncertainty estimates under a Laplace approximation. We show that such units\ncan be trained via an uncertainty-aware objective, improving standard Laplace\napproximations' performance in various uncertainty quantification tasks.",
          "link": "http://arxiv.org/abs/2010.02720",
          "publishedOn": "2021-06-08T02:20:25.225Z",
          "wordCount": null,
          "title": "Learnable Uncertainty under Laplace Approximations. (arXiv:2010.02720v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.02119",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bakshi_A/0/1/0/all/0/1\">Ainesh Bakshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diakonikolas_I/0/1/0/all/0/1\">Ilias Diakonikolas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_H/0/1/0/all/0/1\">He Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kane_D/0/1/0/all/0/1\">Daniel M. Kane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kothari_P/0/1/0/all/0/1\">Pravesh K. Kothari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vempala_S/0/1/0/all/0/1\">Santosh S. Vempala</a>",
          "description": "We give a polynomial-time algorithm for the problem of robustly estimating a\nmixture of $k$ arbitrary Gaussians in $\\mathbb{R}^d$, for any fixed $k$, in the\npresence of a constant fraction of arbitrary corruptions. This resolves the\nmain open problem in several previous works on algorithmic robust statistics,\nwhich addressed the special cases of robustly estimating (a) a single Gaussian,\n(b) a mixture of TV-distance separated Gaussians, and (c) a uniform mixture of\ntwo Gaussians. Our main tools are an efficient \\emph{partial clustering}\nalgorithm that relies on the sum-of-squares method, and a novel \\emph{tensor\ndecomposition} algorithm that allows errors in both Frobenius norm and low-rank\nterms.",
          "link": "http://arxiv.org/abs/2012.02119",
          "publishedOn": "2021-06-08T02:20:25.176Z",
          "wordCount": null,
          "title": "Robustly Learning Mixtures of $k$ Arbitrary Gaussians. (arXiv:2012.02119v3 [cs.DS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.06466",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1\">Chun-Hao Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1\">Sarah Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lengerich_B/0/1/0/all/0/1\">Ben Lengerich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldenberg_A/0/1/0/all/0/1\">Anna Goldenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caruana_R/0/1/0/all/0/1\">Rich Caruana</a>",
          "description": "Generalized additive models (GAMs) have become a leading modelclass for\ninterpretable machine learning. However, there are many algorithms for training\nGAMs, and these can learn different or even contradictory models, while being\nequally accurate. Which GAM should we trust? In this paper, we quantitatively\nand qualitatively investigate a variety of GAM algorithms on real and simulated\ndatasets. We find that GAMs with high feature sparsity (only using afew\nvariables to make predictions) can miss patterns in the data and be unfair to\nrare subpopulations. Our results suggest that inductive bias plays a crucial\nrole in what interpretable models learn and that tree-based GAMs represent the\nbest balance of sparsity, fidelity and accuracy and thus appear to be the most\ntrustworthy GAM.",
          "link": "http://arxiv.org/abs/2006.06466",
          "publishedOn": "2021-06-08T02:20:25.174Z",
          "wordCount": null,
          "title": "How Interpretable and Trustworthy are GAMs?. (arXiv:2006.06466v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.14251",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Azizzadenesheli_K/0/1/0/all/0/1\">Kamyar Azizzadenesheli</a>",
          "description": "We study generalization under labeled shift for categorical and general\nnormed label spaces. We propose a series of methods to estimate the importance\nweights from labeled source to unlabeled target domain and provide confidence\nbounds for these estimators. We deploy these estimators and provide\ngeneralization bounds in the unlabeled target domain.",
          "link": "http://arxiv.org/abs/2011.14251",
          "publishedOn": "2021-06-08T02:20:25.174Z",
          "wordCount": null,
          "title": "Importance Weight Estimation and Generalization in Domain Adaptation under Label Shift. (arXiv:2011.14251v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.08894",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gautam_C/0/1/0/all/0/1\">Chandan Gautam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parameswaran_S/0/1/0/all/0/1\">Sethupathy Parameswaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_A/0/1/0/all/0/1\">Ashish Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sundaram_S/0/1/0/all/0/1\">Suresh Sundaram</a>",
          "description": "Zero-shot learning is a new paradigm to classify objects from classes that\nare not available at training time. Zero-shot learning (ZSL) methods have\nattracted considerable attention in recent years because of their ability to\nclassify unseen/novel class examples. Most of the existing approaches on ZSL\nworks when all the samples from seen classes are available to train the model,\nwhich does not suit real life. In this paper, we tackle this hindrance by\ndeveloping a generative replay-based continual ZSL (GRCZSL). The proposed\nmethod endows traditional ZSL to learn from streaming data and acquire new\nknowledge without forgetting the previous tasks' gained experience. We handle\ncatastrophic forgetting in GRCZSL by replaying the synthetic samples of seen\nclasses, which have appeared in the earlier tasks. These synthetic samples are\nsynthesized using the trained conditional variational autoencoder (VAE) over\nthe immediate past task. Moreover, we only require the current and immediate\nprevious VAE at any time for training and testing. The proposed GRZSL method is\ndeveloped for a single-head setting of continual learning, simulating a\nreal-world problem setting. In this setting, task identity is given during\ntraining but unavailable during testing. GRCZSL performance is evaluated on\nfive benchmark datasets for the generalized setup of ZSL with fixed and dynamic\n(incremental class) settings of continual learning. The existing class setting\npresented recently in the literature is not suitable for a class-incremental\nsetting. Therefore, this paper proposes a new setting to address this issue.\nExperimental results show that the proposed method significantly outperforms\nthe baseline and the state-of-the-art method and makes it more suitable for\nreal-world applications.",
          "link": "http://arxiv.org/abs/2101.08894",
          "publishedOn": "2021-06-08T02:20:25.174Z",
          "wordCount": null,
          "title": "Generative Replay-based Continual Zero-Shot Learning. (arXiv:2101.08894v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02793",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Raghavan_G/0/1/0/all/0/1\">Guruprasad Raghavan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thomson_M/0/1/0/all/0/1\">Matt Thomson</a>",
          "description": "Machine learning problems have an intrinsic geometric structure as central\nobjects including a neural network's weight space and the loss function\nassociated with a particular task can be viewed as encoding the intrinsic\ngeometry of a given machine learning problem. Therefore, geometric concepts can\nbe applied to analyze and understand theoretical properties of machine learning\nstrategies as well as to develop new algorithms. In this paper, we address\nthree seemingly unrelated open questions in machine learning by viewing them\nthrough a unified framework grounded in differential geometry. Specifically, we\nview the weight space of a neural network as a manifold endowed with a\nRiemannian metric that encodes performance on specific tasks. By defining a\nmetric, we can construct geodesic, minimum length, paths in weight space that\nrepresent sets of networks of equivalent or near equivalent functional\nperformance on a specific task. We, then, traverse geodesic paths while\nidentifying networks that satisfy a second objective. Inspired by the geometric\ninsight, we apply our geodesic framework to 3 major applications: (i) Network\nsparsification (ii) Mitigating catastrophic forgetting by constructing networks\nwith high performance on a series of objectives and (iii) Finding high-accuracy\npaths connecting distinct local optima of deep networks in the non-convex loss\nlandscape. Our results are obtained on a wide range of network architectures\n(MLP, VGG11/16) trained on MNIST, CIFAR-10/100. Broadly, we introduce a\ngeometric framework that unifies a range of machine learning objectives and\nthat can be applied to multiple classes of neural network architectures.",
          "link": "http://arxiv.org/abs/2106.02793",
          "publishedOn": "2021-06-08T02:20:25.173Z",
          "wordCount": null,
          "title": "Solving hybrid machine learning tasks by traversing weight space geodesics. (arXiv:2106.02793v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.00815",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1\">Chi Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qinghua Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miryoosefi_S/0/1/0/all/0/1\">Sobhan Miryoosefi</a>",
          "description": "Finding the minimal structural assumptions that empower sample-efficient\nlearning is one of the most important research directions in Reinforcement\nLearning (RL). This paper advances our understanding of this fundamental\nquestion by introducing a new complexity measure -- Bellman Eluder (BE)\ndimension. We show that the family of RL problems of low BE dimension is\nremarkably rich, which subsumes a vast majority of existing tractable RL\nproblems including but not limited to tabular MDPs, linear MDPs, reactive\nPOMDPs, low Bellman rank problems as well as low Eluder dimension problems.\nThis paper further designs a new optimization-based algorithm -- GOLF, and\nreanalyzes a hypothesis elimination-based algorithm -- OLIVE (proposed in Jiang\net al., 2017). We prove that both algorithms learn the near-optimal policies of\nlow BE dimension problems in a number of samples that is polynomial in all\nrelevant parameters, but independent of the size of state-action space. Our\nregret and sample complexity results match or improve the best existing results\nfor several well-known subclasses of low BE dimension problems.",
          "link": "http://arxiv.org/abs/2102.00815",
          "publishedOn": "2021-06-08T02:20:25.173Z",
          "wordCount": null,
          "title": "Bellman Eluder Dimension: New Rich Classes of RL Problems, and Sample-Efficient Algorithms. (arXiv:2102.00815v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.08950",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1\">Honglin Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengyu Ma</a>",
          "description": "We propose Federated Accelerated Stochastic Gradient Descent (FedAc), a\nprincipled acceleration of Federated Averaging (FedAvg, also known as Local\nSGD) for distributed optimization. FedAc is the first provable acceleration of\nFedAvg that improves convergence speed and communication efficiency on various\ntypes of convex functions. For example, for strongly convex and smooth\nfunctions, when using $M$ workers, the previous state-of-the-art FedAvg\nanalysis can achieve a linear speedup in $M$ if given $M$ rounds of\nsynchronization, whereas FedAc only requires $M^{\\frac{1}{3}}$ rounds.\nMoreover, we prove stronger guarantees for FedAc when the objectives are\nthird-order smooth. Our technique is based on a potential-based perturbed\niterate analysis, a novel stability analysis of generalized accelerated SGD,\nand a strategic tradeoff between acceleration and stability.",
          "link": "http://arxiv.org/abs/2006.08950",
          "publishedOn": "2021-06-08T02:20:25.166Z",
          "wordCount": 626,
          "title": "Federated Accelerated Stochastic Gradient Descent. (arXiv:2006.08950v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1902.07436",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sakata_A/0/1/0/all/0/1\">Ayaka Sakata</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Obuchi_T/0/1/0/all/0/1\">Tomoyuki Obuchi</a>",
          "description": "We consider compressed sensing formulated as a minimization problem of\nnonconvex sparse penalties, Smoothly Clipped Absolute deviation (SCAD) and\nMinimax Concave Penalty (MCP). The nonconvexity of these penalties is\ncontrolled by nonconvexity parameters, and L1 penalty is contained as a limit\nwith respect to these parameters. The analytically derived reconstruction limit\novercomes that of L1 and the algorithmic limit in the Bayes-optimal setting,\nwhen the nonconvexity parameters have suitable values. However, for small\nnonconvexity parameters, where the reconstruction of the relatively dense\nsignals is theoretically guaranteed, the corresponding approximate message\npassing (AMP) cannot achieve perfect reconstruction. We identify that the\nshrinks in the basin of attraction to the perfect reconstruction causes the\ndiscrepancy between the AMP and corresponding theory using state evolution. A\npart of the discrepancy is resolved by introducing the control of the\nnonconvexity parameters to guide the AMP trajectory to the basin of the\nattraction.",
          "link": "http://arxiv.org/abs/1902.07436",
          "publishedOn": "2021-06-08T02:20:25.147Z",
          "wordCount": 613,
          "title": "Perfect reconstruction of sparse signals with piecewise continuous nonconvex penalties and nonconvexity control. (arXiv:1902.07436v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.07162",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Yue_M/0/1/0/all/0/1\">Man-Chung Yue</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kuhn_D/0/1/0/all/0/1\">Daniel Kuhn</a>, <a href=\"http://arxiv.org/find/math/1/au:+Wiesemann_W/0/1/0/all/0/1\">Wolfram Wiesemann</a>",
          "description": "Wasserstein balls, which contain all probability measures within a\npre-specified Wasserstein distance to a reference measure, have recently\nenjoyed wide popularity in the distributionally robust optimization and machine\nlearning communities to formulate and solve data-driven optimization problems\nwith rigorous statistical guarantees. In this technical note we prove that the\nWasserstein ball is weakly compact under mild conditions, and we offer\nnecessary and sufficient conditions for the existence of optimal solutions. We\nalso characterize the sparsity of solutions if the Wasserstein ball is centred\nat a discrete reference measure. In comparison with the existing literature,\nwhich has proved similar results under different conditions, our proofs are\nself-contained and shorter, yet mathematically rigorous, and our necessary and\nsufficient conditions for the existence of optimal solutions are easily\nverifiable in practice.",
          "link": "http://arxiv.org/abs/2004.07162",
          "publishedOn": "2021-06-08T02:20:25.138Z",
          "wordCount": null,
          "title": "On Linear Optimization over Wasserstein Balls. (arXiv:2004.07162v2 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.02610",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahmood_K/0/1/0/all/0/1\">Kaleel Mahmood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmood_R/0/1/0/all/0/1\">Rigel Mahmood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dijk_M/0/1/0/all/0/1\">Marten van Dijk</a>",
          "description": "Recent advances in attention-based networks have shown that Vision\nTransformers can achieve state-of-the-art or near state-of-the-art results on\nmany image classification tasks. This puts transformers in the unique position\nof being a promising alternative to traditional convolutional neural networks\n(CNNs). While CNNs have been carefully studied with respect to adversarial\nattacks, the same cannot be said of Vision Transformers. In this paper, we\nstudy the robustness of Vision Transformers to adversarial examples. Our\nanalyses of transformer security is divided into three parts. First, we test\nthe transformer under standard white-box and black-box attacks. Second, we\nstudy the transferability of adversarial examples between CNNs and\ntransformers. We show that adversarial examples do not readily transfer between\nCNNs and transformers. Based on this finding, we analyze the security of a\nsimple ensemble defense of CNNs and transformers. By creating a new attack, the\nself-attention blended gradient attack, we show that such an ensemble is not\nsecure under a white-box adversary. However, under a black-box adversary, we\nshow that an ensemble can achieve unprecedented robustness without sacrificing\nclean accuracy. Our analysis for this work is done using six types of white-box\nattacks and two types of black-box attacks. Our study encompasses multiple\nVision Transformers, Big Transfer Models and CNN architectures trained on\nCIFAR-10, CIFAR-100 and ImageNet.",
          "link": "http://arxiv.org/abs/2104.02610",
          "publishedOn": "2021-06-08T02:20:25.137Z",
          "wordCount": null,
          "title": "On the Robustness of Vision Transformers to Adversarial Examples. (arXiv:2104.02610v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.02951",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Larios_Cardenas_L/0/1/0/all/0/1\">Luis &#xc1;ngel Larios-C&#xe1;rdenas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gibou_F/0/1/0/all/0/1\">Frederic Gibou</a>",
          "description": "We present a novel hybrid strategy based on machine learning to improve\ncurvature estimation in the level-set method. The proposed inference system\ncouples enhanced neural networks with standard numerical schemes to compute\ncurvature more accurately. The core of our hybrid framework is a switching\nmechanism that relies on well established numerical techniques to gauge\ncurvature. If the curvature magnitude is larger than a resolution-dependent\nthreshold, it uses a neural network to yield a better approximation. Our\nnetworks are multilayer perceptrons fitted to synthetic data sets composed of\nsinusoidal- and circular-interface samples at various configurations. To reduce\ndata set size and training complexity, we leverage the problem's characteristic\nsymmetry and build our models on just half of the curvature spectrum. These\nsavings lead to a powerful inference system able to outperform any of its\nnumerical or neural component alone. Experiments with static, smooth interfaces\nshow that our hybrid solver is notably superior to conventional numerical\nmethods in coarse grids and along steep interface regions. Compared to prior\nresearch, we have observed outstanding gains in precision after training the\nregression model with data pairs from more than a single interface type and\ntransforming data with specialized input preprocessing. In particular, our\nfindings confirm that machine learning is a promising venue for reducing or\nremoving mass loss in the level-set method.",
          "link": "http://arxiv.org/abs/2104.02951",
          "publishedOn": "2021-06-08T02:20:25.136Z",
          "wordCount": null,
          "title": "A Hybrid Inference System for Improved Curvature Estimation in the Level-Set Method Using Machine Learning. (arXiv:2104.02951v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.05123",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pony_R/0/1/0/all/0/1\">Roi Pony</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naeh_I/0/1/0/all/0/1\">Itay Naeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mannor_S/0/1/0/all/0/1\">Shie Mannor</a>",
          "description": "Deep neural networks for video classification, just like image classification\nnetworks, may be subjected to adversarial manipulation. The main difference\nbetween image classifiers and video classifiers is that the latter usually use\ntemporal information contained within the video. In this work we present a\nmanipulation scheme for fooling video classifiers by introducing a flickering\ntemporal perturbation that in some cases may be unnoticeable by human observers\nand is implementable in the real world. After demonstrating the manipulation of\naction classification of single videos, we generalize the procedure to make\nuniversal adversarial perturbation, achieving high fooling ratio. In addition,\nwe generalize the universal perturbation and produce a temporal-invariant\nperturbation, which can be applied to the video without synchronizing the\nperturbation to the input. The attack was implemented on several target models\nand the transferability of the attack was demonstrated. These properties allow\nus to bridge the gap between simulated environment and real-world application,\nas will be demonstrated in this paper for the first time for an over-the-air\nflickering attack.",
          "link": "http://arxiv.org/abs/2002.05123",
          "publishedOn": "2021-06-08T02:20:25.135Z",
          "wordCount": null,
          "title": "Over-the-Air Adversarial Flickering Attacks against Video Recognition Networks. (arXiv:2002.05123v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.06303",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Pengqian Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kundu_A/0/1/0/all/0/1\">Achintya Kundu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wynter_L/0/1/0/all/0/1\">Laura Wynter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1\">Shiau Hong Lim</a>",
          "description": "We present a class of methods for robust, personalized federated learning,\ncalled Fed+, that unifies many federated learning algorithms. The principal\nadvantage of this class of methods is to better accommodate the real-world\ncharacteristics found in federated training, such as the lack of IID data\nacross parties, the need for robustness to outliers or stragglers, and the\nrequirement to perform well on party-specific datasets. We achieve this through\na problem formulation that allows the central server to employ robust ways of\naggregating the local models while keeping the structure of local computation\nintact. Without making any statistical assumption on the degree of\nheterogeneity of local data across parties, we provide convergence guarantees\nfor Fed+ for convex and non-convex loss functions and robust aggregation. The\nFed+ theory is also equipped to handle heterogeneous computing environments\nincluding stragglers without additional assumptions; specifically, the\nconvergence results cover the general setting where the number of local update\nsteps across parties can vary. We demonstrate the benefits of Fed+ through\nextensive experiments across standard benchmark datasets as well as on a\nchallenging real-world problem in financial portfolio management where the\nheterogeneity of party-level data can lead to training failure in standard\nfederated learning approaches.",
          "link": "http://arxiv.org/abs/2009.06303",
          "publishedOn": "2021-06-08T02:20:25.134Z",
          "wordCount": null,
          "title": "Fed+: A Unified Approach to Robust Personalized Federated Learning. (arXiv:2009.06303v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.02437",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Luo_Y/0/1/0/all/0/1\">Yuetian Luo</a>, <a href=\"http://arxiv.org/find/math/1/au:+Raskutti_G/0/1/0/all/0/1\">Garvesh Raskutti</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yuan_M/0/1/0/all/0/1\">Ming Yuan</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_A/0/1/0/all/0/1\">Anru R. Zhang</a>",
          "description": "In this paper, we develop novel perturbation bounds for the high-order\northogonal iteration (HOOI) [DLDMV00b]. Under mild regularity conditions, we\nestablish blockwise tensor perturbation bounds for HOOI with guarantees for\nboth tensor reconstruction in Hilbert-Schmidt norm $\\|\\widehat{\\bcT} - \\bcT\n\\|_{\\tHS}$ and mode-$k$ singular subspace estimation in Schatten-$q$ norm $\\|\n\\sin \\Theta (\\widehat{\\U}_k, \\U_k) \\|_q$ for any $q \\geq 1$. We show the upper\nbounds of mode-$k$ singular subspace estimation are unilateral and converge\nlinearly to a quantity characterized by blockwise errors of the perturbation\nand signal strength. For the tensor reconstruction error bound, we express the\nbound through a simple quantity $\\xi$, which depends only on perturbation and\nthe multilinear rank of the underlying signal. Rate matching deterministic\nlower bound for tensor reconstruction, which demonstrates the optimality of\nHOOI, is also provided. Furthermore, we prove that one-step HOOI (i.e., HOOI\nwith only a single iteration) is also optimal in terms of tensor reconstruction\nand can be used to lower the computational cost. The perturbation results are\nalso extended to the case that only partial modes of $\\bcT$ have low-rank\nstructure. We support our theoretical results by extensive numerical studies.\nFinally, we apply the novel perturbation bounds of HOOI on two applications,\ntensor denoising and tensor co-clustering, from machine learning and\nstatistics, which demonstrates the superiority of the new perturbation results.",
          "link": "http://arxiv.org/abs/2008.02437",
          "publishedOn": "2021-06-08T02:20:25.133Z",
          "wordCount": null,
          "title": "A Sharp Blockwise Tensor Perturbation Bound for Orthogonal Iteration. (arXiv:2008.02437v2 [math.ST] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.04509",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grathwohl_W/0/1/0/all/0/1\">Will Grathwohl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swersky_K/0/1/0/all/0/1\">Kevin Swersky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashemi_M/0/1/0/all/0/1\">Milad Hashemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duvenaud_D/0/1/0/all/0/1\">David Duvenaud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maddison_C/0/1/0/all/0/1\">Chris J. Maddison</a>",
          "description": "We propose a general and scalable approximate sampling strategy for\nprobabilistic models with discrete variables. Our approach uses gradients of\nthe likelihood function with respect to its discrete inputs to propose updates\nin a Metropolis-Hastings sampler. We show empirically that this approach\noutperforms generic samplers in a number of difficult settings including Ising\nmodels, Potts models, restricted Boltzmann machines, and factorial hidden\nMarkov models. We also demonstrate the use of our improved sampler for training\ndeep energy-based models on high dimensional discrete data. This approach\noutperforms variational auto-encoders and existing energy-based models.\nFinally, we give bounds showing that our approach is near-optimal in the class\nof samplers which propose local updates.",
          "link": "http://arxiv.org/abs/2102.04509",
          "publishedOn": "2021-06-08T02:20:25.131Z",
          "wordCount": null,
          "title": "Oops I Took A Gradient: Scalable Sampling for Discrete Distributions. (arXiv:2102.04509v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07868",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Achituve_I/0/1/0/all/0/1\">Idan Achituve</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Navon_A/0/1/0/all/0/1\">Aviv Navon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yemini_Y/0/1/0/all/0/1\">Yochai Yemini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1\">Gal Chechik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fetaya_E/0/1/0/all/0/1\">Ethan Fetaya</a>",
          "description": "Gaussian processes (GPs) are non-parametric, flexible, models that work well\nin many tasks. Combining GPs with deep learning methods via deep kernel\nlearning (DKL) is especially compelling due to the strong representational\npower induced by the network. However, inference in GPs, whether with or\nwithout DKL, can be computationally challenging on large datasets. Here, we\npropose GP-Tree, a novel method for multi-class classification with Gaussian\nprocesses and DKL. We develop a tree-based hierarchical model in which each\ninternal node of the tree fits a GP to the data using the P\\'olya-Gamma\naugmentation scheme. As a result, our method scales well with both the number\nof classes and data size. We demonstrate the effectiveness of our method\nagainst other Gaussian process training baselines, and we show how our general\nGP approach achieves improved accuracy on standard incremental few-shot\nlearning benchmarks.",
          "link": "http://arxiv.org/abs/2102.07868",
          "publishedOn": "2021-06-08T02:20:25.130Z",
          "wordCount": null,
          "title": "GP-Tree: A Gaussian Process Classifier for Few-Shot Incremental Learning. (arXiv:2102.07868v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.09612",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1\">Quynh Nguyen</a>",
          "description": "We give a simple proof for the global convergence of gradient descent in\ntraining deep ReLU networks with the standard square loss, and show some of its\nimprovements over the state-of-the-art. In particular, while prior works\nrequire all the hidden layers to be wide with width at least $\\Omega(N^8)$ ($N$\nbeing the number of training samples), we require a single wide layer of\nlinear, quadratic or cubic width depending on the type of initialization.\nUnlike many recent proofs based on the Neural Tangent Kernel (NTK), our proof\nneed not track the evolution of the entire NTK matrix, or more generally, any\nquantities related to the changes of activation patterns during training.\nInstead, we only need to track the evolution of the output at the last hidden\nlayer, which can be done much more easily thanks to the Lipschitz property of\nReLU. Some highlights of our setting: (i) all the layers are trained with\nstandard gradient descent, (ii) the network has standard parameterization as\nopposed to the NTK one, and (iii) the network has a single wide layer as\nopposed to having all wide hidden layers as in most of NTK-related results.",
          "link": "http://arxiv.org/abs/2101.09612",
          "publishedOn": "2021-06-08T02:20:25.129Z",
          "wordCount": null,
          "title": "On the Proof of Global Convergence of Gradient Descent for Deep ReLU Networks with Linear Widths. (arXiv:2101.09612v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.08047",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Neklyudov_K/0/1/0/all/0/1\">Kirill Neklyudov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1\">Max Welling</a>",
          "description": "Markov Chain Monte Carlo (MCMC) algorithms ubiquitously employ complex\ndeterministic transformations to generate proposal points that are then\nfiltered by the Metropolis-Hastings-Green (MHG) test. However, the condition of\nthe target measure invariance puts restrictions on the design of these\ntransformations. In this paper, we first derive the acceptance test for the\nstochastic Markov kernel considering arbitrary deterministic maps as proposal\ngenerators. When applied to the transformations with orbits of period two\n(involutions), the test reduces to the MHG test. Based on the derived test we\npropose two practical algorithms: one operates by constructing periodic orbits\nfrom any diffeomorphism, another on contractions of the state space (such as\noptimization trajectories). Finally, we perform an empirical study\ndemonstrating the practical advantages of both kernels.",
          "link": "http://arxiv.org/abs/2010.08047",
          "publishedOn": "2021-06-08T02:20:25.125Z",
          "wordCount": null,
          "title": "Orbital MCMC. (arXiv:2010.08047v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.03479",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jian Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1\">Siyang Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harding_S/0/1/0/all/0/1\">Seth Austin Harding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Haibin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_S/0/1/0/all/0/1\">Shih-wei Liao</a>",
          "description": "Multi-Agent Reinforcement Learning (MARL) has seen revolutionary\nbreakthroughs with its successful application to multi-agent cooperative tasks\nsuch as computer games and robot swarms. QMIX, a widely popular MARL algorithm,\nhas been used to solve cooperative tasks, e.g. Starcraft Multi-Agent Challenge\n(SMAC), Difficulty-Enhanced Predator-Prey (DEPP). Recent variants of QMIX\ntarget relaxing the monotonicity constraint of QMIX, allowing for performance\nimprovement in SMAC. However, in this paper, we investigate the code-level\noptimizations of these variants and the monotonicity constraint. We find that\n(1) such improvements of the variants are significantly affected by various\ncode-level optimizations; (2) QMIX with normalized optimizations outperforms\nother previous works in SMAC; (3) the monotonicity constraint may improve\nsample efficiency in SMAC and DEPP. Last, a discussion with theoretical\nanalysis is demonstrated about why QMIX works well in SMAC. We open-source the\ncode at \\url{https://github.com/hijkzzz/pymarl2}.",
          "link": "http://arxiv.org/abs/2102.03479",
          "publishedOn": "2021-06-08T02:20:25.124Z",
          "wordCount": null,
          "title": "Rethinking the Implementation Matters in Cooperative Multi-Agent Reinforcement Learning. (arXiv:2102.03479v11 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02067",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mihai_D/0/1/0/all/0/1\">Daniela Mihai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hare_J/0/1/0/all/0/1\">Jonathon Hare</a>",
          "description": "Evidence that visual communication preceded written language and provided a\nbasis for it goes back to prehistory, in forms such as cave and rock paintings\ndepicting traces of our distant ancestors. Emergent communication research has\nsought to explore how agents can learn to communicate in order to\ncollaboratively solve tasks. Existing research has focused on language, with a\nlearned communication channel transmitting sequences of discrete tokens between\nthe agents. In this work, we explore a visual communication channel between\nagents that are allowed to draw with simple strokes. Our agents are\nparameterised by deep neural networks, and the drawing procedure is\ndifferentiable, allowing for end-to-end training. In the framework of a\nreferential communication game, we demonstrate that agents can not only\nsuccessfully learn to communicate by drawing, but with appropriate inductive\nbiases, can do so in a fashion that humans can interpret. We hope to encourage\nfuture research to consider visual communication as a more flexible and\ndirectly interpretable alternative of training collaborative agents.",
          "link": "http://arxiv.org/abs/2106.02067",
          "publishedOn": "2021-06-08T02:20:25.103Z",
          "wordCount": 600,
          "title": "Learning to Draw: Emergent Communication through Sketching. (arXiv:2106.02067v1 [cs.CV] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14363",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chatterji_N/0/1/0/all/0/1\">Niladri S. Chatterji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pacchiano_A/0/1/0/all/0/1\">Aldo Pacchiano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartlett_P/0/1/0/all/0/1\">Peter L. Bartlett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>",
          "description": "We study a theory of reinforcement learning (RL) in which the learner\nreceives binary feedback only once at the end of an episode. While this is an\nextreme test case for theory, it is also arguably more representative of\nreal-world applications than the traditional requirement in RL practice that\nthe learner receive feedback at every time step. Indeed, in many real-world\napplications of reinforcement learning, such as self-driving cars and robotics,\nit is easier to evaluate whether a learner's complete trajectory was either\n\"good\" or \"bad,\" but harder to provide a reward signal at each step. To show\nthat learning is possible in this more challenging setting, we study the case\nwhere trajectory labels are generated by an unknown parametric model, and\nprovide a statistically and computationally efficient algorithm that achieves\nsub-linear regret.",
          "link": "http://arxiv.org/abs/2105.14363",
          "publishedOn": "2021-06-08T02:20:25.097Z",
          "wordCount": 588,
          "title": "On the Theory of Reinforcement Learning with Once-per-Episode Feedback. (arXiv:2105.14363v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.09890",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Simin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianrui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vakilian_A/0/1/0/all/0/1\">Ali Vakilian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_Y/0/1/0/all/0/1\">Yulin Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1\">David P. Woodruff</a>",
          "description": "We consider sketching algorithms which first quickly compress data by\nmultiplication with a random sketch matrix, and then apply the sketch to\nquickly solve an optimization problem, e.g., low rank approximation. In the\nlearning-based sketching paradigm proposed by Indyk et al. [2019], the sketch\nmatrix is found by choosing a random sparse matrix, e.g., the CountSketch, and\nthen updating the values of the non-zero entries by running gradient descent on\na training data set. Despite the growing body of work on this paradigm, a\nnoticeable omission is that the locations of the non-zero entries of previous\nalgorithms were fixed, and only their values were learned. In this work we\npropose the first learning algorithm that also optimizes the locations of the\nnon-zero entries. We show this algorithm gives better accuracy for low rank\napproximation than previous work, and apply it to other problems such as\n$k$-means clustering for the first time. We show that our algorithm is provably\nbetter in the spiked covariance model and for Zipfian matrices. We also show\nthe importance of the sketch monotonicity property for combining learned\nsketches. Our empirical results show the importance of optimizing not only the\nvalues of the non-zero entries but also their positions.",
          "link": "http://arxiv.org/abs/2007.09890",
          "publishedOn": "2021-06-08T02:20:25.089Z",
          "wordCount": 678,
          "title": "Learning the Positions in CountSketch. (arXiv:2007.09890v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.04522",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Englesson_E/0/1/0/all/0/1\">Erik Englesson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azizpour_H/0/1/0/all/0/1\">Hossein Azizpour</a>",
          "description": "Prior works have found it beneficial to combine provably noise-robust loss\nfunctions e.g., mean absolute error (MAE) with standard categorical loss\nfunction e.g. cross entropy (CE) to improve their learnability. Here, we\npropose to use Jensen-Shannon divergence as a noise-robust loss function and\nshow that it interestingly interpolate between CE and MAE with a controllable\nmixing parameter. Furthermore, we make a crucial observation that CE exhibit\nlower consistency around noisy data points. Based on this observation, we adopt\na generalized version of the Jensen-Shannon divergence for multiple\ndistributions to encourage consistency around data points. Using this loss\nfunction, we show state-of-the-art results on both synthetic (CIFAR), and\nreal-world (WebVision) noise with varying noise rates.",
          "link": "http://arxiv.org/abs/2105.04522",
          "publishedOn": "2021-06-08T02:20:25.078Z",
          "wordCount": 584,
          "title": "Generalized Jensen-Shannon Divergence Loss for Learning with Noisy Labels. (arXiv:2105.04522v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.12254",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thomas_D/0/1/0/all/0/1\">Deepak-George Thomas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olshanskyi_D/0/1/0/all/0/1\">Daniil Olshanskyi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krueger_K/0/1/0/all/0/1\">Karter Krueger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wongpiromsarn_T/0/1/0/all/0/1\">Tichakorn Wongpiromsarn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jannesari_A/0/1/0/all/0/1\">Ali Jannesari</a>",
          "description": "The significant components of any successful autonomous flight system are\ntask completion and collision avoidance. Most deep learning algorithms\nsuccessfully execute these aspects under the environment and conditions they\nare trained. However, they fail when subjected to novel environments. This\npaper presents an autonomous multi-rotor flight algorithm, using Deep\nReinforcement Learning augmented with Self-Attention Models, that can\neffectively reason when subjected to varying inputs. In addition to their\nreasoning ability, they are also interpretable, enabling it to be used under\nreal-world conditions. We have tested our algorithm under different weather\nconditions and environments and found it robust compared to conventional Deep\nReinforcement Learning algorithms.",
          "link": "http://arxiv.org/abs/2105.12254",
          "publishedOn": "2021-06-08T02:20:25.039Z",
          "wordCount": 558,
          "title": "Interpretable UAV Collision Avoidance using Deep Reinforcement Learning. (arXiv:2105.12254v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.15203",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_E/0/1/0/all/0/1\">Enze Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenhai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhiding Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alvarez_J/0/1/0/all/0/1\">Jose M. Alvarez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1\">Ping Luo</a>",
          "description": "We present SegFormer, a simple, efficient yet powerful semantic segmentation\nframework which unifies Transformers with lightweight multilayer perception\n(MLP) decoders. SegFormer has two appealing features: 1) SegFormer comprises a\nnovel hierarchically structured Transformer encoder which outputs multiscale\nfeatures. It does not need positional encoding, thereby avoiding the\ninterpolation of positional codes which leads to decreased performance when the\ntesting resolution differs from training. 2) SegFormer avoids complex decoders.\nThe proposed MLP decoder aggregates information from different layers, and thus\ncombining both local attention and global attention to render powerful\nrepresentations. We show that this simple and lightweight design is the key to\nefficient segmentation on Transformers. We scale our approach up to obtain a\nseries of models from SegFormer-B0 to SegFormer-B5, reaching significantly\nbetter performance and efficiency than previous counterparts. For example,\nSegFormer-B4 achieves 50.3% mIoU on ADE20K with 64M parameters, being 5x\nsmaller and 2.2% better than the previous best method. Our best model,\nSegFormer-B5, achieves 84.0% mIoU on Cityscapes validation set and shows\nexcellent zero-shot robustness on Cityscapes-C. Code will be released at:\ngithub.com/NVlabs/SegFormer.",
          "link": "http://arxiv.org/abs/2105.15203",
          "publishedOn": "2021-06-08T02:20:25.030Z",
          "wordCount": 641,
          "title": "SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers. (arXiv:2105.15203v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02847",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Marjani_A/0/1/0/all/0/1\">Aymen Al Marjani</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Garivier_A/0/1/0/all/0/1\">Aur&#xe9;lien Garivier</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Proutiere_A/0/1/0/all/0/1\">Alexandre Proutiere</a>",
          "description": "We investigate the classical active pure exploration problem in Markov\nDecision Processes, where the agent sequentially selects actions and, from the\nresulting system trajectory, aims at identifying the best policy as fast as\npossible. We propose an information-theoretic lower bound on the average number\nof steps required before a correct answer can be given with probability at\nleast $1-\\delta$. This lower bound involves a non-convex optimization problem,\nfor which we propose a convex relaxation. We further provide an algorithm whose\nsample complexity matches the relaxed lower bound up to a factor $2$. This\nalgorithm addresses general communicating MDPs; we propose a variant with\nreduced exploration rate (and hence faster convergence) under an additional\nergodicity assumption. This work extends previous results relative to the\n\\emph{generative setting}~\\cite{marjani2020adaptive}, where the agent could at\neach step observe the random outcome of any (state, action) pair. In contrast,\nwe show here how to deal with the \\emph{navigation constraints}. Our analysis\nrelies on an ergodic theorem for non-homogeneous Markov chains which we\nconsider of wide interest in the analysis of Markov Decision Processes.",
          "link": "http://arxiv.org/abs/2106.02847",
          "publishedOn": "2021-06-08T02:20:25.022Z",
          "wordCount": 607,
          "title": "Navigating to the Best Policy in Markov Decision Processes. (arXiv:2106.02847v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2105.06464",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lan_S/0/1/0/all/0/1\">Shiyi Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhiding Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choy_C/0/1/0/all/0/1\">Christopher Choy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radhakrishnan_S/0/1/0/all/0/1\">Subhashree Radhakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guilin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yuke Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davis_L/0/1/0/all/0/1\">Larry S. Davis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>",
          "description": "We introduce DiscoBox, a novel framework that jointly learns instance\nsegmentation and semantic correspondence using bounding box supervision.\nSpecifically, we propose a self-ensembling framework where instance\nsegmentation and semantic correspondence are jointly guided by a structured\nteacher in addition to the bounding box supervision. The teacher is a\nstructured energy model incorporating a pairwise potential and a cross-image\npotential to model the pairwise pixel relationships both within and across the\nboxes. Minimizing the teacher energy simultaneously yields refined object masks\nand dense correspondences between intra-class objects, which are taken as\npseudo-labels to supervise the task network and provide positive/negative\ncorrespondence pairs for dense constrastive learning. We show a symbiotic\nrelationship where the two tasks mutually benefit from each other. Our best\nmodel achieves 37.9% AP on COCO instance segmentation, surpassing prior weakly\nsupervised methods and is competitive to supervised methods. We also obtain\nstate of the art weakly supervised results on PASCAL VOC12 and PF-PASCAL with\nreal-time inference.",
          "link": "http://arxiv.org/abs/2105.06464",
          "publishedOn": "2021-06-08T02:20:25.014Z",
          "wordCount": 642,
          "title": "DiscoBox: Weakly Supervised Instance Segmentation and Semantic Correspondence from Box Supervision. (arXiv:2105.06464v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.00558",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sellke_M/0/1/0/all/0/1\">Mark Sellke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slivkins_A/0/1/0/all/0/1\">Aleksandrs Slivkins</a>",
          "description": "We consider incentivized exploration: a version of multi-armed bandits where\nthe choice of arms is controlled by self-interested agents, and the algorithm\ncan only issue recommendations. The algorithm controls the flow of information,\nand the information asymmetry can incentivize the agents to explore. Prior work\nachieves optimal regret rates up to multiplicative factors that become\narbitrarily large depending on the Bayesian priors, and scale exponentially in\nthe number of arms. A more basic problem of sampling each arm once runs into\nsimilar factors.\n\nWe focus on the price of incentives: the loss in performance, broadly\nconstrued, incurred for the sake of incentive-compatibility. We prove that\nThompson Sampling, a standard bandit algorithm, is incentive-compatible if\ninitialized with sufficiently many data points. The performance loss due to\nincentives is therefore limited to the initial rounds when these data points\nare collected. The problem is largely reduced to that of sample complexity: how\nmany rounds are needed? We address this question, providing matching upper and\nlower bounds and instantiating them in various corollaries. Typically, the\noptimal sample complexity is polynomial in the number of arms and exponential\nin the \"strength of beliefs\".",
          "link": "http://arxiv.org/abs/2002.00558",
          "publishedOn": "2021-06-08T02:20:25.006Z",
          "wordCount": 681,
          "title": "The Price of Incentivizing Exploration: A Characterization via Thompson Sampling and Sample Complexity. (arXiv:2002.00558v4 [cs.GT] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02770",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">Dongxia Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chinazzi_M/0/1/0/all/0/1\">Matteo Chinazzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vespignani_A/0/1/0/all/0/1\">Alessandro Vespignani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yi-An Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1\">Rose Yu</a>",
          "description": "Stochastic simulations such as large-scale, spatiotemporal, age-structured\nepidemic models are computationally expensive at fine-grained resolution. We\npropose Interactive Neural Process (INP), an interactive framework to\ncontinuously learn a deep learning surrogate model and accelerate simulation.\nOur framework is based on the novel integration of Bayesian active learning,\nstochastic simulation and deep sequence modeling. In particular, we develop a\nnovel spatiotemporal neural process model to mimic the underlying process\ndynamics. Our model automatically infers the latent process which describes the\nintrinsic uncertainty of the simulator. This also gives rise to a new\nacquisition function that can quantify the uncertainty of deep learning\npredictions. We design Bayesian active learning algorithms to iteratively query\nthe simulator, gather more data, and continuously improve the model. We perform\ntheoretical analysis and demonstrate that our approach reduces sample\ncomplexity compared with random sampling in high dimension. Empirically, we\ndemonstrate our framework can faithfully imitate the behavior of a complex\ninfectious disease simulator with a small number of examples, enabling rapid\nsimulation and scenario exploration.",
          "link": "http://arxiv.org/abs/2106.02770",
          "publishedOn": "2021-06-08T02:20:24.988Z",
          "wordCount": 597,
          "title": "Accelerating Stochastic Simulation with Interactive Neural Processes. (arXiv:2106.02770v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.05051",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brantley_K/0/1/0/all/0/1\">Kiant&#xe9; Brantley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dudik_M/0/1/0/all/0/1\">Miroslav Dudik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lykouris_T/0/1/0/all/0/1\">Thodoris Lykouris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miryoosefi_S/0/1/0/all/0/1\">Sobhan Miryoosefi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simchowitz_M/0/1/0/all/0/1\">Max Simchowitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slivkins_A/0/1/0/all/0/1\">Aleksandrs Slivkins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Wen Sun</a>",
          "description": "We propose an algorithm for tabular episodic reinforcement learning with\nconstraints. We provide a modular analysis with strong theoretical guarantees\nfor settings with concave rewards and convex constraints, and for settings with\nhard constraints (knapsacks). Most of the previous work in constrained\nreinforcement learning is limited to linear constraints, and the remaining work\nfocuses on either the feasibility question or settings with a single episode.\nOur experiments demonstrate that the proposed algorithm significantly\noutperforms these approaches in existing constrained episodic environments.",
          "link": "http://arxiv.org/abs/2006.05051",
          "publishedOn": "2021-06-08T02:20:24.977Z",
          "wordCount": 622,
          "title": "Constrained episodic reinforcement learning in concave-convex and knapsack settings. (arXiv:2006.05051v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.11646",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tingyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zhedong Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_C/0/1/0/all/0/1\">Chenggang Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiyong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yaoqi Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1\">Bolun Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi Yang</a>",
          "description": "Cross-view geo-localization is to spot images of the same geographic target\nfrom different platforms, e.g., drone-view cameras and satellites. It is\nchallenging in the large visual appearance changes caused by extreme viewpoint\nvariations. Existing methods usually concentrate on mining the fine-grained\nfeature of the geographic target in the image center, but underestimate the\ncontextual information in neighbor areas. In this work, we argue that neighbor\nareas can be leveraged as auxiliary information, enriching discriminative clues\nfor geolocalization. Specifically, we introduce a simple and effective deep\nneural network, called Local Pattern Network (LPN), to take advantage of\ncontextual information in an end-to-end manner. Without using extra part\nestimators, LPN adopts a square-ring feature partition strategy, which provides\nthe attention according to the distance to the image center. It eases the part\nmatching and enables the part-wise representation learning. Owing to the\nsquare-ring partition design, the proposed LPN has good scalability to rotation\nvariations and achieves competitive results on three prevailing benchmarks,\ni.e., University-1652, CVUSA and CVACT. Besides, we also show the proposed LPN\ncan be easily embedded into other frameworks to further boost performance.",
          "link": "http://arxiv.org/abs/2008.11646",
          "publishedOn": "2021-06-08T02:20:24.967Z",
          "wordCount": 666,
          "title": "Each Part Matters: Local Patterns Facilitate Cross-view Geo-localization. (arXiv:2008.11646v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.08251",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mathelin_A/0/1/0/all/0/1\">Antoine de Mathelin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richard_G/0/1/0/all/0/1\">Guillaume Richard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deheeger_F/0/1/0/all/0/1\">Francois Deheeger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mougeot_M/0/1/0/all/0/1\">Mathilde Mougeot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vayatis_N/0/1/0/all/0/1\">Nicolas Vayatis</a>",
          "description": "We present a novel instance-based approach to handle regression tasks in the\ncontext of supervised domain adaptation. The approach developed in this paper\nrelies on the assumption that the task on the target domain can be efficiently\nlearned by adequately reweighting the source instances during training phase.\nWe introduce a novel formulation of the optimization objective for domain\nadaptation which relies on a discrepancy distance characterizing the difference\nbetween domains according to a specific task and a class of hypotheses. To\nsolve this problem, we develop an adversarial network algorithm which learns\nboth the source weighting scheme and the task in one feed-forward gradient\ndescent. We provide numerical evidence of the relevance of the method on public\ndatasets for domain adaptation through reproducible experiments accessible via\nan online demo interface at: https://antoinedemathelin.github.io/demo/",
          "link": "http://arxiv.org/abs/2006.08251",
          "publishedOn": "2021-06-08T02:20:24.958Z",
          "wordCount": 609,
          "title": "Weighting Adversarial Neural Network for Domain Adaptation in Regression. (arXiv:2006.08251v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02702",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1\">Quan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marecek_J/0/1/0/all/0/1\">Jakub Marecek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shorten_R/0/1/0/all/0/1\">Robert N. Shorten</a>",
          "description": "It is well known that two-sided markets are unfair in a number of ways. For\ninstance, female workers at Uber earn less than their male colleagues per mile\ndriven. Similar observations have been made for other minority subgroups in\nother two-sided markets. Here, we suggest a novel market-clearing mechanism for\ntwo-sided markets, which promotes equalisation of the pay per hour worked\nacross multiple subgroups, as well as within each subgroup. In the process, we\nintroduce a novel notion of subgroup fairness (which we call Inter-fairness),\nwhich can be combined with other notions of fairness within each subgroup\n(called Intra-fairness), and the utility for the customers (Customer-Care) in\nthe objective of the market-clearing problem. While the novel non-linear terms\nin the objective complicate market clearing by making the problem non-convex,\nwe show that a certain non-convex augmented Lagrangian relaxation can be\napproximated to any precision in time polynomial in the number of market\nparticipants using semi-definite programming. This makes it possible to\nimplement the market-clearing mechanism efficiently. On the example of\ndriver-ride assignment in an Uber-like system, we demonstrate the efficacy and\nscalability of the approach, and trade-offs between Inter- and Intra-fairness.",
          "link": "http://arxiv.org/abs/2106.02702",
          "publishedOn": "2021-06-08T02:20:24.947Z",
          "wordCount": 626,
          "title": "Subgroup Fairness in Two-Sided Markets. (arXiv:2106.02702v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2008.05558",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Ahmadi_A/0/1/0/all/0/1\">Amir Ali Ahmadi</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_J/0/1/0/all/0/1\">Jeffrey Zhang</a>",
          "description": "We show that unless P=NP, there cannot be a polynomial-time algorithm that\nfinds a point within Euclidean distance $c^n$ (for any constant $c \\ge 0$) of a\nlocal minimizer of an $n$-variate quadratic function over a polytope. This\nresult (even with $c=0$) answers a question of Pardalos and Vavasis that\nappeared in 1992 on a list of seven open problems in complexity theory for\nnumerical optimization. Our proof technique also implies that the problem of\ndeciding whether a quadratic function has a local minimizer over an (unbounded)\npolyhedron, and that of deciding if a quartic polynomial has a local minimizer\nare NP-hard.",
          "link": "http://arxiv.org/abs/2008.05558",
          "publishedOn": "2021-06-08T02:20:24.927Z",
          "wordCount": 584,
          "title": "On the complexity of finding a local minimizer of a quadratic function over a polytope. (arXiv:2008.05558v3 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.04012",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_Q/0/1/0/all/0/1\">Qin Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1\">Cho-Jui Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharpnack_J/0/1/0/all/0/1\">James Sharpnack</a>",
          "description": "We consider the contextual bandit problem, where a player sequentially makes\ndecisions based on past observations to maximize the cumulative reward.\nAlthough many algorithms have been proposed for contextual bandit, most of them\nrely on finding the maximum likelihood estimator at each iteration, which\nrequires $O(t)$ time at the $t$-th iteration and are memory inefficient. A\nnatural way to resolve this problem is to apply online stochastic gradient\ndescent (SGD) so that the per-step time and memory complexity can be reduced to\nconstant with respect to $t$, but a contextual bandit policy based on online\nSGD updates that balances exploration and exploitation has remained elusive. In\nthis work, we show that online SGD can be applied to the generalized linear\nbandit problem. The proposed SGD-TS algorithm, which uses a single-step SGD\nupdate to exploit past information and uses Thompson Sampling for exploration,\nachieves $\\tilde{O}(\\sqrt{T})$ regret with the total time complexity that\nscales linearly in $T$ and $d$, where $T$ is the total number of rounds and $d$\nis the number of features. Experimental results show that SGD-TS consistently\noutperforms existing algorithms on both synthetic and real datasets.",
          "link": "http://arxiv.org/abs/2006.04012",
          "publishedOn": "2021-06-08T02:20:24.912Z",
          "wordCount": null,
          "title": "An Efficient Algorithm For Generalized Linear Bandit: Online Stochastic Gradient Descent and Thompson Sampling. (arXiv:2006.04012v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.02014",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mladenovic_A/0/1/0/all/0/1\">Andjela Mladenovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bose_A/0/1/0/all/0/1\">Avishek Joey Bose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berard_H/0/1/0/all/0/1\">Hugo Berard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamilton_W/0/1/0/all/0/1\">William L. Hamilton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lacoste_Julien_S/0/1/0/all/0/1\">Simon Lacoste-Julien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vincent_P/0/1/0/all/0/1\">Pascal Vincent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gidel_G/0/1/0/all/0/1\">Gauthier Gidel</a>",
          "description": "Adversarial attacks expose important vulnerabilities of deep learning models,\nyet little attention has been paid to settings where data arrives as a stream.\nIn this paper, we formalize the online adversarial attack problem, emphasizing\ntwo key elements found in real-world use-cases: attackers must operate under\npartial knowledge of the target model, and the decisions made by the attacker\nare irrevocable since they operate on a transient data stream. We first\nrigorously analyze a deterministic variant of the online threat model by\ndrawing parallels to the well-studied $k$-secretary problem in theoretical\ncomputer science and propose Virtual+, a simple yet practical online algorithm.\nOur main theoretical result show Virtual+ yields provably the best competitive\nratio over all single-threshold algorithms for $k<5$ -- extending previous\nanalysis of the $k$-secretary problem. We also introduce the \\textit{stochastic\n$k$-secretary} -- effectively reducing online blackbox transfer attacks to a\n$k$-secretary problem under noise -- and prove theoretical bounds on the\nperformance of \\textit{any} online algorithms adapted to this setting. Finally,\nwe complement our theoretical results by conducting experiments on both MNIST\nand CIFAR-10 with both vanilla and robust classifiers, revealing not only the\nnecessity of online algorithms in achieving near-optimal performance but also\nthe rich interplay of a given attack strategy towards online attack selection,\nenabling simple strategies like FGSM to outperform classically strong whitebox\nadversaries.",
          "link": "http://arxiv.org/abs/2103.02014",
          "publishedOn": "2021-06-08T02:20:24.905Z",
          "wordCount": null,
          "title": "Online Adversarial Attacks. (arXiv:2103.02014v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.16689",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1\">Wenshuo Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Serena Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_P/0/1/0/all/0/1\">Peng Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yixin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>",
          "description": "While many areas of machine learning have benefited from the increasing\navailability of large and varied datasets, the benefit to causal inference has\nbeen limited given the strong assumptions needed to ensure identifiability of\ncausal effects; these are often not satisfied in real-world datasets. For\nexample, many large observational datasets (e.g., case-control studies in\nepidemiology, click-through data in recommender systems) suffer from selection\nbias on the outcome, which makes the average treatment effect (ATE)\nunidentifiable. We propose a general algorithm to estimate causal effects from\n\\emph{multiple} data sources, where the ATE may be identifiable only in some\ndatasets but not others. The key idea is to construct control variates using\nthe datasets in which the ATE is not identifiable. We show theoretically that\nthis reduces the variance of the ATE estimate. We apply this framework to\ninference from observational data under outcome selection bias, assuming access\nto an auxiliary small dataset from which we can obtain a consistent estimate of\nthe ATE. We construct a control variate by taking the difference of the odds\nratio estimates from the two datasets. Across simulations and two case studies\nwith real data, we show that this control variate can significantly reduce the\nvariance of the ATE estimate.",
          "link": "http://arxiv.org/abs/2103.16689",
          "publishedOn": "2021-06-08T02:20:24.903Z",
          "wordCount": null,
          "title": "Multi-Source Causal Inference Using Control Variates. (arXiv:2103.16689v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.09814",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tomar_M/0/1/0/all/0/1\">Manan Tomar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shani_L/0/1/0/all/0/1\">Lior Shani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Efroni_Y/0/1/0/all/0/1\">Yonathan Efroni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1\">Mohammad Ghavamzadeh</a>",
          "description": "Mirror descent (MD), a well-known first-order method in constrained convex\noptimization, has recently been shown as an important tool to analyze\ntrust-region algorithms in reinforcement learning (RL). However, there remains\na considerable gap between such theoretically analyzed algorithms and the ones\nused in practice. Inspired by this, we propose an efficient RL algorithm,\ncalled {\\em mirror descent policy optimization} (MDPO). MDPO iteratively\nupdates the policy by {\\em approximately} solving a trust-region problem, whose\nobjective function consists of two terms: a linearization of the standard RL\nobjective and a proximity term that restricts two consecutive policies to be\nclose to each other. Each update performs this approximation by taking multiple\ngradient steps on this objective function. We derive {\\em on-policy} and {\\em\noff-policy} variants of MDPO, while emphasizing important design choices\nmotivated by the existing theory of MD in RL. We highlight the connections\nbetween on-policy MDPO and two popular trust-region RL algorithms: TRPO and\nPPO, and show that explicitly enforcing the trust-region constraint is in fact\n{\\em not} a necessity for high performance gains in TRPO. We then show how the\npopular soft actor-critic (SAC) algorithm can be derived by slight\nmodifications of off-policy MDPO. Overall, MDPO is derived from the MD\nprinciples, offers a unified approach to viewing a number of popular RL\nalgorithms, and performs better than or on-par with TRPO, PPO, and SAC in a\nnumber of continuous control tasks. Code is available at\n\\url{https://github.com/manantomar/Mirror-Descent-Policy-Optimization}.",
          "link": "http://arxiv.org/abs/2005.09814",
          "publishedOn": "2021-06-08T02:20:24.895Z",
          "wordCount": 722,
          "title": "Mirror Descent Policy Optimization. (arXiv:2005.09814v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.10224",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Nelsen_N/0/1/0/all/0/1\">Nicholas H. Nelsen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Stuart_A/0/1/0/all/0/1\">Andrew M. Stuart</a>",
          "description": "Well known to the machine learning community, the random feature model is a\nparametric approximation to kernel interpolation or regression methods. It is\ntypically used to approximate functions mapping a finite-dimensional input\nspace to the real line. In this paper, we instead propose a methodology for use\nof the random feature model as a data-driven surrogate for operators that map\nan input Banach space to an output Banach space. Although the methodology is\nquite general, we consider operators defined by partial differential equations\n(PDEs); here, the inputs and outputs are themselves functions, with the input\nparameters being functions required to specify the problem, such as initial\ndata or coefficients, and the outputs being solutions of the problem. Upon\ndiscretization, the model inherits several desirable attributes from this\ninfinite-dimensional viewpoint, including mesh-invariant approximation error\nwith respect to the true PDE solution map and the capability to be trained at\none mesh resolution and then deployed at different mesh resolutions. We view\nthe random feature model as a non-intrusive data-driven emulator, provide a\nmathematical framework for its interpretation, and demonstrate its ability to\nefficiently and accurately approximate the nonlinear parameter-to-solution maps\nof two prototypical PDEs arising in physical science and engineering\napplications: viscous Burgers' equation and a variable coefficient elliptic\nequation.",
          "link": "http://arxiv.org/abs/2005.10224",
          "publishedOn": "2021-06-08T02:20:24.886Z",
          "wordCount": 687,
          "title": "The Random Feature Model for Input-Output Maps between Banach Spaces. (arXiv:2005.10224v2 [math.NA] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.13228",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xingyu Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qiuhao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1\">Zenan Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yisen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guangcan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhouchen Lin</a>",
          "description": "Implicit equilibrium models, i.e., deep neural networks (DNNs) defined by\nimplicit equations, have been becoming more and more attractive recently. In\nthis paper, we investigate an emerging question: can an implicit equilibrium\nmodel's equilibrium point be regarded as the solution of an optimization\nproblem? To this end, we first decompose DNNs into a new class of unit layer\nthat is the proximal operator of an implicit convex function while keeping its\noutput unchanged. Then, the equilibrium model of the unit layer can be derived,\nnamed Optimization Induced Equilibrium Networks (OptEq), which can be easily\nextended to deep layers. The equilibrium point of OptEq can be theoretically\nconnected to the solution of its corresponding convex optimization problem with\nexplicit objectives. Based on this, we can flexibly introduce prior properties\nto the equilibrium points: 1) modifying the underlying convex problems\nexplicitly so as to change the architectures of OptEq; and 2) merging the\ninformation into the fixed point iteration, which guarantees to choose the\ndesired equilibrium point when the fixed point set is non-singleton. We show\nthat deep OptEq outperforms previous implicit models even with fewer\nparameters. This work establishes the first step towards the\noptimization-guided design of deep models.",
          "link": "http://arxiv.org/abs/2105.13228",
          "publishedOn": "2021-06-08T02:20:24.875Z",
          "wordCount": 667,
          "title": "Optimization Induced Equilibrium Networks. (arXiv:2105.13228v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.06429",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lukina_A/0/1/0/all/0/1\">Anna Lukina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schilling_C/0/1/0/all/0/1\">Christian Schilling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henzinger_T/0/1/0/all/0/1\">Thomas A. Henzinger</a>",
          "description": "Neural-network classifiers achieve high accuracy when predicting the class of\nan input that they were trained to identify. Maintaining this accuracy in\ndynamic environments, where inputs frequently fall outside the fixed set of\ninitially known classes, remains a challenge. The typical approach is to detect\ninputs from novel classes and retrain the classifier on an augmented dataset.\nHowever, not only the classifier but also the detection mechanism needs to\nadapt in order to distinguish between newly learned and yet unknown input\nclasses. To address this challenge, we introduce an algorithmic framework for\nactive monitoring of a neural network. A monitor wrapped in our framework\noperates in parallel with the neural network and interacts with a human user\nvia a series of interpretable labeling queries for incremental adaptation. In\naddition, we propose an adaptive quantitative monitor to improve precision. An\nexperimental evaluation on a diverse set of benchmarks with varying numbers of\nclasses confirms the benefits of our active monitoring framework in dynamic\nscenarios.",
          "link": "http://arxiv.org/abs/2009.06429",
          "publishedOn": "2021-06-08T02:20:24.869Z",
          "wordCount": 625,
          "title": "Into the Unknown: Active Monitoring of Neural Networks. (arXiv:2009.06429v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.00777",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hou_Y/0/1/0/all/0/1\">Yimin Hou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jia_S/0/1/0/all/0/1\">Shuyue Jia</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lun_X/0/1/0/all/0/1\">Xiangmin Lun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_Y/0/1/0/all/0/1\">Yan Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>",
          "description": "Recognition accuracy and response time are both critically essential ahead of\nbuilding practical electroencephalography (EEG) based brain-computer interface\n(BCI). Recent approaches, however, have either compromised in the\nclassification accuracy or responding time. This paper presents a novel deep\nlearning approach designed towards remarkably accurate and responsive motor\nimagery (MI) recognition based on scalp EEG. Bidirectional Long Short-term\nMemory (BiLSTM) with the Attention mechanism manages to derive relevant\nfeatures from raw EEG signals. The connected graph convolutional neural network\n(GCN) promotes the decoding performance by cooperating with the topological\nstructure of features, which are estimated from the overall data. The\n0.4-second detection framework has shown effective and efficient prediction\nbased on individual and group-wise training, with 98.81% and 94.64% accuracy,\nrespectively, which outperformed all the state-of-the-art studies. The\nintroduced deep feature mining approach can precisely recognize human motion\nintents from raw EEG signals, which paves the road to translate the EEG based\nMI recognition to practical BCI systems.",
          "link": "http://arxiv.org/abs/2005.00777",
          "publishedOn": "2021-06-08T02:20:24.848Z",
          "wordCount": 624,
          "title": "Deep Feature Mining via Attention-based BiLSTM-GCN for Human Motor Imagery Recognition. (arXiv:2005.00777v2 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.10085",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenrui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Peng Li</a>",
          "description": "Spiking neural networks (SNNs) are well suited for spatio-temporal learning\nand implementations on energy-efficient event-driven neuromorphic processors.\nHowever, existing SNN error backpropagation (BP) methods lack proper handling\nof spiking discontinuities and suffer from low performance compared with the BP\nmethods for traditional artificial neural networks. In addition, a large number\nof time steps are typically required to achieve decent performance, leading to\nhigh latency and rendering spike-based computation unscalable to deep\narchitectures. We present a novel Temporal Spike Sequence Learning\nBackpropagation (TSSL-BP) method for training deep SNNs, which breaks down\nerror backpropagation across two types of inter-neuron and intra-neuron\ndependencies and leads to improved temporal learning precision. It captures\ninter-neuron dependencies through presynaptic firing times by considering the\nall-or-none characteristics of firing activities and captures intra-neuron\ndependencies by handling the internal evolution of each neuronal state in time.\nTSSL-BP efficiently trains deep SNNs within a much shortened temporal window of\na few steps while improving the accuracy for various image classification\ndatasets including CIFAR10.",
          "link": "http://arxiv.org/abs/2002.10085",
          "publishedOn": "2021-06-08T02:20:24.819Z",
          "wordCount": 658,
          "title": "Temporal Spike Sequence Learning via Backpropagation for Deep Spiking Neural Networks. (arXiv:2002.10085v4 [cs.NE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02869",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1\">Yao-Hung Hubert Tsai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tianqin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Weixin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_P/0/1/0/all/0/1\">Peiyuan Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1\">Ruslan Salakhutdinov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morency_L/0/1/0/all/0/1\">Louis-Philippe Morency</a>",
          "description": "This paper presents to integrate the auxiliary information (e.g., additional\nattributes for data such as the hashtags for Instagram images) in the\nself-supervised learning process. We first observe that the auxiliary\ninformation may bring us useful information about data structures: for\ninstance, the Instagram images with the same hashtags can be semantically\nsimilar. Hence, to leverage the structural information from the auxiliary\ninformation, we present to construct data clusters according to the auxiliary\ninformation. Then, we introduce the Clustering InfoNCE (Cl-InfoNCE) objective\nthat learns similar representations for augmented variants of data from the\nsame cluster and dissimilar representations for data from different clusters.\nOur approach contributes as follows: 1) Comparing to conventional\nself-supervised representations, the auxiliary-information-infused\nself-supervised representations bring the performance closer to the supervised\nrepresentations; 2) The presented Cl-InfoNCE can also work with unsupervised\nconstructed clusters (e.g., k-means clusters) and outperform strong\nclustering-based self-supervised learning approaches, such as the Prototypical\nContrastive Learning (PCL) method; 3) We show that Cl-InfoNCE may be a better\napproach to leverage the data clustering information, by comparing it to the\nbaseline approach - learning to predict the clustering assignments with\ncross-entropy loss. For analysis, we connect the goodness of the learned\nrepresentations with the statistical relationships: i) the mutual information\nbetween the labels and the clusters and ii) the conditional entropy of the\nclusters given the labels.",
          "link": "http://arxiv.org/abs/2106.02869",
          "publishedOn": "2021-06-08T02:20:24.807Z",
          "wordCount": 648,
          "title": "Integrating Auxiliary Information in Self-supervised Learning. (arXiv:2106.02869v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.05973",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Agrawal_R/0/1/0/all/0/1\">Rohit Agrawal</a>, <a href=\"http://arxiv.org/find/math/1/au:+Horel_T/0/1/0/all/0/1\">Thibaut Horel</a>",
          "description": "The families of $f$-divergences (e.g. the Kullback-Leibler divergence) and\nIntegral Probability Metrics (e.g. total variation distance or maximum mean\ndiscrepancies) are widely used to quantify the similarity between probability\ndistributions. In this work, we systematically study the relationship between\nthese two families from the perspective of convex duality. Starting from a\ntight variational representation of the $f$-divergence, we derive a\ngeneralization of the moment-generating function, which we show exactly\ncharacterizes the best lower bound of the $f$-divergence as a function of a\ngiven IPM. Using this characterization, we obtain new bounds while also\nrecovering in a unified manner well-known results, such as Hoeffding's lemma,\nPinsker's inequality and its extension to subgaussian functions, and the\nHammersley-Chapman-Robbins bound. This characterization also allows us to prove\nnew results on topological properties of the divergence which may be of\nindependent interest.",
          "link": "http://arxiv.org/abs/2006.05973",
          "publishedOn": "2021-06-08T02:20:24.801Z",
          "wordCount": 615,
          "title": "Optimal Bounds between $f$-Divergences and Integral Probability Metrics. (arXiv:2006.05973v3 [math.ST] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02713",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bordelon_B/0/1/0/all/0/1\">Blake Bordelon</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pehlevan_C/0/1/0/all/0/1\">Cengiz Pehlevan</a>",
          "description": "The generalization performance of a machine learning algorithm such as a\nneural network depends in a non-trivial way on the structure of the data\ndistribution. Models of generalization in machine learning theory often ignore\nthe low-dimensional structure of natural signals, either by considering\ndata-agnostic bounds or by studying the performance of the algorithm when\ntrained on uncorrelated features. To analyze the influence of data structure on\ntest loss dynamics, we study an exactly solveable model of stochastic gradient\ndescent (SGD) which predicts test loss when training on features with arbitrary\ncovariance structure. We solve the theory exactly for both Gaussian features\nand arbitrary features and we show that the simpler Gaussian model accurately\npredicts test loss of nonlinear random-feature models and deep neural networks\ntrained with SGD on real datasets such as MNIST and CIFAR-10. We show that\nmodeling the geometry of the data in the induced feature space is indeed\ncrucial to accurately predict the test error throughout learning.",
          "link": "http://arxiv.org/abs/2106.02713",
          "publishedOn": "2021-06-08T02:20:24.795Z",
          "wordCount": 581,
          "title": "Learning Curves for SGD on Structured Features. (arXiv:2106.02713v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2004.04690",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Weiyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_R/0/1/0/all/0/1\">Rongmei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rehg_J/0/1/0/all/0/1\">James M. Rehg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paull_L/0/1/0/all/0/1\">Liam Paull</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1\">Li Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1\">Le Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1\">Adrian Weller</a>",
          "description": "The inductive bias of a neural network is largely determined by the\narchitecture and the training algorithm. To achieve good generalization, how to\neffectively train a neural network is of great importance. We propose a novel\northogonal over-parameterized training (OPT) framework that can provably\nminimize the hyperspherical energy which characterizes the diversity of neurons\non a hypersphere. By maintaining the minimum hyperspherical energy during\ntraining, OPT can greatly improve the empirical generalization. Specifically,\nOPT fixes the randomly initialized weights of the neurons and learns an\northogonal transformation that applies to these neurons. We consider multiple\nways to learn such an orthogonal transformation, including unrolling\northogonalization algorithms, applying orthogonal parameterization, and\ndesigning orthogonality-preserving gradient descent. For better scalability, we\npropose the stochastic OPT which performs orthogonal transformation\nstochastically for partial dimensions of neurons. Interestingly, OPT reveals\nthat learning a proper coordinate system for neurons is crucial to\ngeneralization. We provide some insights on why OPT yields better\ngeneralization. Extensive experiments validate the superiority of OPT over the\nstandard training.",
          "link": "http://arxiv.org/abs/2004.04690",
          "publishedOn": "2021-06-08T02:20:24.778Z",
          "wordCount": 685,
          "title": "Orthogonal Over-Parameterized Training. (arXiv:2004.04690v6 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.15646",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Azizian_W/0/1/0/all/0/1\">Wa&#xef;ss Azizian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lelarge_M/0/1/0/all/0/1\">Marc Lelarge</a>",
          "description": "Various classes of Graph Neural Networks (GNN) have been proposed and shown\nto be successful in a wide range of applications with graph structured data. In\nthis paper, we propose a theoretical framework able to compare the expressive\npower of these GNN architectures. The current universality theorems only apply\nto intractable classes of GNNs. Here, we prove the first approximation\nguarantees for practical GNNs, paving the way for a better understanding of\ntheir generalization. Our theoretical results are proved for invariant GNNs\ncomputing a graph embedding (permutation of the nodes of the input graph does\nnot affect the output) and equivariant GNNs computing an embedding of the nodes\n(permutation of the input permutes the output). We show that Folklore Graph\nNeural Networks (FGNN), which are tensor based GNNs augmented with matrix\nmultiplication are the most expressive architectures proposed so far for a\ngiven tensor order. We illustrate our results on the Quadratic Assignment\nProblem (a NP-Hard combinatorial problem) by showing that FGNNs are able to\nlearn how to solve the problem, leading to much better average performances\nthan existing algorithms (based on spectral, SDP or other GNNs architectures).\nOn a practical side, we also implement masked tensors to handle batches of\ngraphs of varying sizes.",
          "link": "http://arxiv.org/abs/2006.15646",
          "publishedOn": "2021-06-08T02:20:24.771Z",
          "wordCount": 692,
          "title": "Expressive Power of Invariant and Equivariant Graph Neural Networks. (arXiv:2006.15646v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.03631",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Likhosherstov_V/0/1/0/all/0/1\">Valerii Likhosherstov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xingyou Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choromanski_K/0/1/0/all/0/1\">Krzysztof Choromanski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1\">Jared Davis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1\">Adrian Weller</a>",
          "description": "Bilevel optimization (BLO) is a popular approach with many applications\nincluding hyperparameter optimization, neural architecture search, adversarial\nrobustness and model-agnostic meta-learning. However, the approach suffers from\ntime and memory complexity proportional to the length $r$ of its inner\noptimization loop, which has led to several modifications being proposed. One\nsuch modification is \\textit{first-order} BLO (FO-BLO) which approximates\nouter-level gradients by zeroing out second derivative terms, yielding\nsignificant speed gains and requiring only constant memory as $r$ varies.\nDespite FO-BLO's popularity, there is a lack of theoretical understanding of\nits convergence properties. We make progress by demonstrating a rich family of\nexamples where FO-BLO-based stochastic optimization does not converge to a\nstationary point of the BLO objective. We address this concern by proposing a\nnew FO-BLO-based unbiased estimate of outer-level gradients, enabling us to\ntheoretically guarantee this convergence, with no harm to memory and expected\ntime complexity. Our findings are supported by experimental results on Omniglot\nand Mini-ImageNet, popular few-shot meta-learning benchmarks.",
          "link": "http://arxiv.org/abs/2006.03631",
          "publishedOn": "2021-06-08T02:20:24.763Z",
          "wordCount": 622,
          "title": "UFO-BLO: Unbiased First-Order Bilevel Optimization. (arXiv:2006.03631v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02654",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Heinrich Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narasimhan_H/0/1/0/all/0/1\">Harikrishna Narasimhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bahri_D/0/1/0/all/0/1\">Dara Bahri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotter_A/0/1/0/all/0/1\">Andrew Cotter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rostamizadeh_A/0/1/0/all/0/1\">Afshin Rostamizadeh</a>",
          "description": "In real-world systems, models are frequently updated as more data becomes\navailable, and in addition to achieving high accuracy, the goal is to also\nmaintain a low difference in predictions compared to the base model (i.e.\npredictive ``churn''). If model retraining results in vastly different\nbehavior, then it could cause negative effects in downstream systems,\nespecially if this churn can be avoided with limited impact on model accuracy.\nIn this paper, we show an equivalence between training with distillation using\nthe base model as the teacher and training with an explicit constraint on the\npredictive churn. We then show that distillation performs strongly for low\nchurn training against a number of recent baselines on a wide range of datasets\nand model architectures, including fully-connected networks, convolutional\nnetworks, and transformers.",
          "link": "http://arxiv.org/abs/2106.02654",
          "publishedOn": "2021-06-08T02:20:24.754Z",
          "wordCount": null,
          "title": "Churn Reduction via Distillation. (arXiv:2106.02654v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2008.12315",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Amiridi_M/0/1/0/all/0/1\">Magda Amiridi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kargas_N/0/1/0/all/0/1\">Nikos Kargas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sidiropoulos_N/0/1/0/all/0/1\">Nicholas D. Sidiropoulos</a>",
          "description": "Effective non-parametric density estimation is a key challenge in\nhigh-dimensional multivariate data analysis. In this paper,we propose a novel\napproach that builds upon tensor factorization tools. Any multivariate density\ncan be represented by its characteristic function, via the Fourier transform.\nIf the sought density is compactly supported, then its characteristic function\ncan be approximated, within controllable error, by a finite tensor of leading\nFourier coefficients, whose size de-pends on the smoothness of the underlying\ndensity. This tensor can be naturally estimated from observed realizations of\nthe random vector of interest, via sample averaging. In order to circumvent the\ncurse of dimensionality, we introduce a low-rank model of this characteristic\ntensor, which significantly improves the density estimate especially for\nhigh-dimensional data and/or in the sample-starved regime. By virtue of\nuniqueness of low-rank tensor decomposition, under certain conditions, our\nmethod enables learning the true data-generating distribution. We demonstrate\nthe very promising performance of the proposed method using several measured\ndatasets.",
          "link": "http://arxiv.org/abs/2008.12315",
          "publishedOn": "2021-06-08T02:20:24.737Z",
          "wordCount": null,
          "title": "Low-rank Characteristic Tensor Density Estimation Part I: Foundations. (arXiv:2008.12315v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.08258",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bao_F/0/1/0/all/0/1\">Fan Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Kun Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chongxuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_L/0/1/0/all/0/1\">Lanqing Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bo Zhang</a>",
          "description": "The learning and evaluation of energy-based latent variable models (EBLVMs)\nwithout any structural assumptions are highly challenging, because the true\nposteriors and the partition functions in such models are generally\nintractable. This paper presents variational estimates of the score function\nand its gradient with respect to the model parameters in a general EBLVM,\nreferred to as VaES and VaGES respectively. The variational posterior is\ntrained to minimize a certain divergence to the true model posterior and the\nbias in both estimates can be bounded by the divergence theoretically. With a\nminimal model assumption, VaES and VaGES can be applied to the kernelized Stein\ndiscrepancy (KSD) and score matching (SM)-based methods to learn EBLVMs.\nBesides, VaES can also be used to estimate the exact Fisher divergence between\nthe data and general EBLVMs.",
          "link": "http://arxiv.org/abs/2010.08258",
          "publishedOn": "2021-06-08T02:20:24.735Z",
          "wordCount": 611,
          "title": "Variational (Gradient) Estimate of the Score Function in Energy-based Latent Variable Models. (arXiv:2010.08258v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02820",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zaixi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhenya Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Chengqiang Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chuanren Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1\">Enhong Chen</a>",
          "description": "As machine learning becomes more widely used for critical applications, the\nneed to study its implications in privacy turns to be urgent. Given access to\nthe target model and auxiliary information, the model inversion attack aims to\ninfer sensitive features of the training dataset, which leads to great privacy\nconcerns. Despite its success in grid-like domains, directly applying model\ninversion techniques on non-grid domains such as graph achieves poor attack\nperformance due to the difficulty to fully exploit the intrinsic properties of\ngraphs and attributes of nodes used in Graph Neural Networks (GNN). To bridge\nthis gap, we present \\textbf{Graph} \\textbf{M}odel \\textbf{I}nversion attack\n(GraphMI), which aims to extract private graph data of the training graph by\ninverting GNN, one of the state-of-the-art graph analysis tools. Specifically,\nwe firstly propose a projected gradient module to tackle the discreteness of\ngraph edges while preserving the sparsity and smoothness of graph features.\nThen we design a graph auto-encoder module to efficiently exploit graph\ntopology, node attributes, and target model parameters for edge inference. With\nthe proposed methods, we study the connection between model inversion risk and\nedge influence and show that edges with greater influence are more likely to be\nrecovered. Extensive experiments over several public datasets demonstrate the\neffectiveness of our method. We also show that differential privacy in its\ncanonical form can hardly defend our attack while preserving decent utility.",
          "link": "http://arxiv.org/abs/2106.02820",
          "publishedOn": "2021-06-08T02:20:24.729Z",
          "wordCount": 673,
          "title": "GraphMI: Extracting Private Graph Data from Graph Neural Networks. (arXiv:2106.02820v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.01618",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun-Kun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chi-Heng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abernethy_J/0/1/0/all/0/1\">Jacob Abernethy</a>",
          "description": "Incorporating a so-called \"momentum\" dynamic in gradient descent methods is\nwidely used in neural net training as it has been broadly observed that, at\nleast empirically, it often leads to significantly faster convergence. At the\nsame time, there are very few theoretical guarantees in the literature to\nexplain this apparent acceleration effect. Even for the classical strongly\nconvex quadratic problems, several existing results only show Polyak's momentum\nhas an accelerated linear rate asymptotically. In this paper, we first revisit\nthe quadratic problems and show a non-asymptotic accelerated linear rate of\nPolyak's momentum. Then, we provably show that Polyak's momentum achieves\nacceleration for training a one-layer wide ReLU network and a deep linear\nnetwork, which are perhaps the two most popular canonical models for studying\noptimization and deep learning in the literature. Prior work Du at al. 2019 and\nWu et al. 2019 showed that using vanilla gradient descent, and with an use of\nover-parameterization, the error decays as $(1- \\Theta(\\frac{1}{ \\kappa'}))^t$\nafter $t$ iterations, where $\\kappa'$ is the condition number of a Gram Matrix.\nOur result shows that with the appropriate choice of parameters Polyak's\nmomentum has a rate of $(1-\\Theta(\\frac{1}{\\sqrt{\\kappa'}}))^t$. For the deep\nlinear network, prior work Hu et al. 2020 showed that vanilla gradient descent\nhas a rate of $(1-\\Theta(\\frac{1}{\\kappa}))^t$, where $\\kappa$ is the condition\nnumber of a data matrix. Our result shows an acceleration rate $(1-\n\\Theta(\\frac{1}{\\sqrt{\\kappa}}))^t$ is achievable by Polyak's momentum. All the\nresults in this work are obtained from a modular analysis, which can be of\nindependent interest. This work establishes that momentum does indeed speed up\nneural net training.",
          "link": "http://arxiv.org/abs/2010.01618",
          "publishedOn": "2021-06-08T02:20:24.710Z",
          "wordCount": null,
          "title": "A Modular Analysis of Provable Acceleration via Polyak's Momentum: Training a Wide ReLU Network and a Deep Linear Network. (arXiv:2010.01618v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.05419",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nair_H/0/1/0/all/0/1\">Harideep Nair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vellaisamy_P/0/1/0/all/0/1\">Prabhu Vellaisamy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhasuthkar_S/0/1/0/all/0/1\">Santha Bhasuthkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">John Paul Shen</a>",
          "description": "A set of highly-optimized custom macro extensions is developed for a 7nm CMOS\ncell library for implementing Temporal Neural Networks (TNNs) that can mimic\nbrain-like sensory processing with extreme energy efficiency. A TNN prototype\n(13,750 neurons and 315,000 synapses) for MNIST requires only 1.56mm2 die area\nand consumes only 1.69mW.",
          "link": "http://arxiv.org/abs/2012.05419",
          "publishedOn": "2021-06-08T02:20:24.710Z",
          "wordCount": null,
          "title": "A Custom 7nm CMOS Standard Cell Library for Implementing TNN-based Neuromorphic Processors. (arXiv:2012.05419v2 [cs.AR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.08548",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Schiff_Y/0/1/0/all/0/1\">Yair Schiff</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chenthamarakshan_V/0/1/0/all/0/1\">Vijil Chenthamarakshan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ramamurthy_K/0/1/0/all/0/1\">Karthikeyan Natesan Ramamurthy</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Das_P/0/1/0/all/0/1\">Payel Das</a>",
          "description": "Deep generative models are increasingly becoming integral parts of the in\nsilico molecule design pipeline and have dual goals of learning the chemical\nand structural features that render candidate molecules viable while also being\nflexible enough to generate novel designs. Specifically, Variational Auto\nEncoders (VAEs) are generative models in which encoder-decoder network pairs\nare trained to reconstruct training data distributions in such a way that the\nlatent space of the encoder network is smooth. Therefore, novel candidates can\nbe found by sampling from this latent space. However, the scope of\narchitectures and hyperparameters is vast and choosing the best combination for\nin silico discovery has important implications for downstream success.\nTherefore, it is important to develop a principled methodology for\ndistinguishing how well a given generative model is able to learn salient\nmolecular features. In this work, we propose a method for measuring how well\nthe latent space of deep generative models is able to encode structural and\nchemical features of molecular datasets by correlating latent space metrics\nwith metrics from the field of topological data analysis (TDA). We apply our\nevaluation methodology to a VAE trained on SMILES strings and show that 3D\ntopology information is consistently encoded throughout the latent space of the\nmodel.",
          "link": "http://arxiv.org/abs/2010.08548",
          "publishedOn": "2021-06-08T02:20:24.709Z",
          "wordCount": null,
          "title": "Characterizing the Latent Space of Molecular Deep Generative Models with Persistent Homology Metrics. (arXiv:2010.08548v2 [q-bio.BM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Allen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moitra_A/0/1/0/all/0/1\">Ankur Moitra</a>",
          "description": "In this work we study the orbit recovery problem, which is a natural\nabstraction for the problem of recovering a planted signal from noisy\nmeasurements under unknown group actions. Many important inverse problems in\nstatistics, engineering and the sciences fit into this framework. Prior work\nhas studied cases when the group is discrete and/or abelian. However\nfundamentally new techniques are needed in order to handle more complex group\nactions.\n\nOur main result is a quasi-polynomial time algorithm to solve orbit recovery\nover $SO(3)$ - i.e. the cryo-electron tomography problem which asks to recover\nthe three-dimensional structure of a molecule from noisy measurements of\nrandomly rotated copies of it. We analyze a variant of the frequency marching\nheuristic in the framework of smoothed analysis. Our approach exploits the\nlayered structure of the invariant polynomials, and simultaneously yields a new\nclass of tensor decomposition algorithms that work in settings when the tensor\nis not low-rank but rather where the factors are algebraically related to each\nother by a group action.",
          "link": "http://arxiv.org/abs/2106.02680",
          "publishedOn": "2021-06-08T02:20:24.708Z",
          "wordCount": 602,
          "title": "How to Decompose a Tensor with Group Structure. (arXiv:2106.02680v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/1802.04064",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bietti_A/0/1/0/all/0/1\">Alberto Bietti</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Agarwal_A/0/1/0/all/0/1\">Alekh Agarwal</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Langford_J/0/1/0/all/0/1\">John Langford</a>",
          "description": "Contextual bandit algorithms are essential for solving many real-world\ninteractive machine learning problems. Despite multiple recent successes on\nstatistically and computationally efficient methods, the practical behavior of\nthese algorithms is still poorly understood. We leverage the availability of\nlarge numbers of supervised learning datasets to empirically evaluate\ncontextual bandit algorithms, focusing on practical methods that learn by\nrelying on optimization oracles from supervised learning. We find that a recent\nmethod (Foster et al., 2018) using optimism under uncertainty works the best\noverall. A surprisingly close second is a simple greedy baseline that only\nexplores implicitly through the diversity of contexts, followed by a variant of\nOnline Cover (Agarwal et al., 2014) which tends to be more conservative but\nrobust to problem specification by design. Along the way, we also evaluate\nvarious components of contextual bandit algorithm design such as loss\nestimators. Overall, this is a thorough study and review of contextual bandit\nmethodology.",
          "link": "http://arxiv.org/abs/1802.04064",
          "publishedOn": "2021-06-08T02:20:24.699Z",
          "wordCount": 617,
          "title": "A Contextual Bandit Bake-off. (arXiv:1802.04064v5 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02679",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lamy_Poirier_J/0/1/0/all/0/1\">Joel Lamy-Poirier</a>",
          "description": "The advent of the transformer has sparked a quick growth in the size of\nlanguage models, far outpacing hardware improvements. (Dense) transformers are\nexpected to reach the trillion-parameter scale in the near future, for which\ntraining requires thousands or even tens of thousands of GPUs. We investigate\nthe challenges of training at this scale and beyond on commercially available\nhardware. In particular, we analyse the shortest possible training time for\ndifferent configurations of distributed training, leveraging empirical scaling\nlaws for language models to estimate the optimal (critical) batch size.\nContrary to popular belief, we find no evidence for a memory wall, and instead\nargue that the real limitation -- other than the cost -- lies in the training\nduration.\n\nIn addition to this analysis, we introduce two new methods, \\textit{layered\ngradient accumulation} and \\textit{modular pipeline parallelism}, which\ntogether cut the shortest training time by half. The methods also reduce data\nmovement, lowering the network requirement to a point where a fast InfiniBand\nconnection is not necessary. This increased network efficiency also improve on\nthe methods introduced with the ZeRO optimizer, reducing the memory usage to a\ntiny fraction of the available GPU memory.",
          "link": "http://arxiv.org/abs/2106.02679",
          "publishedOn": "2021-06-08T02:20:24.693Z",
          "wordCount": 646,
          "title": "Layered gradient accumulation and modular pipeline parallelism: fast and efficient training of large language models. (arXiv:2106.02679v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.06522",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wiqvist_S/0/1/0/all/0/1\">Samuel Wiqvist</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Frellsen_J/0/1/0/all/0/1\">Jes Frellsen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Picchini_U/0/1/0/all/0/1\">Umberto Picchini</a>",
          "description": "We introduce the sequential neural posterior and likelihood approximation\n(SNPLA) algorithm. SNPLA is a normalizing flows-based algorithm for inference\nin implicit models, and therefore is a simulation-based inference method that\nonly requires simulations from a generative model. SNPLA avoids Markov chain\nMonte Carlo sampling and correction-steps of the parameter proposal function\nthat are introduced in similar methods, but that can be numerically unstable or\nrestrictive. By utilizing the reverse KL divergence, SNPLA manages to learn\nboth the likelihood and the posterior in a sequential manner. Over four\nexperiments, we show that SNPLA performs competitively when utilizing the same\nnumber of model simulations as used in other methods, even though the inference\nproblem for SNPLA is more complex due to the joint learning of posterior and\nlikelihood function. Due to utilizing normalizing flows SNPLA generates\nposterior draws much faster (4 orders of magnitude) than MCMC-based methods.",
          "link": "http://arxiv.org/abs/2102.06522",
          "publishedOn": "2021-06-08T02:20:24.668Z",
          "wordCount": null,
          "title": "Sequential Neural Posterior and Likelihood Approximation. (arXiv:2102.06522v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.00694",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huynh_N/0/1/0/all/0/1\">Nguyen Van Huynh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1\">Diep N. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoang_D/0/1/0/all/0/1\">Dinh Thai Hoang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dutkiewicz_E/0/1/0/all/0/1\">Eryk Dutkiewicz</a>",
          "description": "In intelligent transportation systems (ITS), vehicles are expected to feature\nwith advanced applications and services which demand ultra-high data rates and\nlow-latency communications. For that, the millimeter wave (mmWave)\ncommunication has been emerging as a very promising solution. However,\nincorporating the mmWave into ITS is particularly challenging due to the high\nmobility of vehicles and the inherent sensitivity of mmWave beams to dynamic\nblockages. This article addresses these problems by developing an optimal beam\nassociation framework for mmWave vehicular networks under high mobility.\nSpecifically, we use the semi-Markov decision process to capture the dynamics\nand uncertainty of the environment. The Q-learning algorithm is then often used\nto find the optimal policy. However, Q-learning is notorious for its\nslow-convergence. Instead of adopting deep reinforcement learning structures\n(like most works in the literature), we leverage the fact that there are\nusually multiple vehicles on the road to speed up the learning process. To that\nend, we develop a lightweight yet very effective parallel Q-learning algorithm\nto quickly obtain the optimal policy by simultaneously learning from various\nvehicles. Extensive simulations demonstrate that our proposed solution can\nincrease the data rate by 47% and reduce the disconnection probability by 29%\ncompared to other solutions.",
          "link": "http://arxiv.org/abs/2005.00694",
          "publishedOn": "2021-06-08T02:20:24.658Z",
          "wordCount": null,
          "title": "Optimal Beam Association for High Mobility mmWave Vehicular Networks: Lightweight Parallel Reinforcement Learning Approach. (arXiv:2005.00694v2 [cs.NI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.07550",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Soh_Y/0/1/0/all/0/1\">Yong Sheng Soh</a>",
          "description": "The dictionary learning problem concerns the task of representing data as\nsparse linear sums drawn from a smaller collection of basic building blocks. In\napplication domains where such techniques are deployed, we frequently encounter\ndatasets where some form of symmetry or invariance is present. Motivated by\nthis observation, we develop a framework for learning dictionaries for data\nunder the constraint that the collection of basic building blocks remains\ninvariant under such symmetries. Our procedure for learning such dictionaries\nrelies on representing the symmetry as the action of a matrix group acting on\nthe data, and subsequently introducing a convex penalty function so as to\ninduce sparsity with respect to the collection of matrix group elements. Our\nframework specializes to the convolutional dictionary learning problem when we\nconsider integer shifts. Using properties of positive semidefinite Hermitian\nToeplitz matrices, we develop an extension that learns dictionaries that are\ninvariant under continuous shifts. Our numerical experiments on synthetic data\nand ECG data show that the incorporation of such symmetries as priors are most\nvaluable when the dataset has few data-points, or when the full range of\nsymmetries is inadequately expressed in the dataset.",
          "link": "http://arxiv.org/abs/2007.07550",
          "publishedOn": "2021-06-08T02:20:24.657Z",
          "wordCount": 643,
          "title": "Group Invariant Dictionary Learning. (arXiv:2007.07550v2 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.00742",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+El_Mhamdi_E/0/1/0/all/0/1\">El-Mahdi El-Mhamdi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farhadkhani_S/0/1/0/all/0/1\">Sadegh Farhadkhani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guerraoui_R/0/1/0/all/0/1\">Rachid Guerraoui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guirguis_A/0/1/0/all/0/1\">Arsany Guirguis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoang_L/0/1/0/all/0/1\">L&#xea; Nguy&#xea;n Hoang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rouault_S/0/1/0/all/0/1\">S&#xe9;bastien Rouault</a>",
          "description": "We study Byzantine collaborative learning, where $n$ nodes seek to\ncollectively learn from each others' local data. The data distribution may vary\nfrom one node to another. No node is trusted, and $f < n$ nodes can behave\narbitrarily. We prove that collaborative learning is equivalent to a new form\nof agreement, which we call averaging agreement. In this problem, nodes start\neach with an initial vector and seek to approximately agree on a common vector,\nwhich is close to the average of honest nodes' initial vectors. We present two\nasynchronous solutions to averaging agreement, each we prove optimal according\nto some dimension. The first, based on the minimum-diameter averaging, requires\n$ n \\geq 6f+1$, but achieves asymptotically the best-possible averaging\nconstant up to a multiplicative constant. The second, based on reliable\nbroadcast and coordinate-wise trimmed mean, achieves optimal Byzantine\nresilience, i.e., $n \\geq 3f+1$. Each of these algorithms induces an optimal\nByzantine collaborative learning protocol. In particular, our equivalence\nyields new impossibility theorems on what any collaborative learning algorithm\ncan achieve in adversarial and heterogeneous environments.",
          "link": "http://arxiv.org/abs/2008.00742",
          "publishedOn": "2021-06-08T02:20:24.643Z",
          "wordCount": null,
          "title": "Collaborative Learning in the Jungle. (arXiv:2008.00742v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.09500",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sapir_M/0/1/0/all/0/1\">Marina Sapir</a>",
          "description": "ML is approached from logic point of view as a problem of maximizing\nconsistency of a hypothesis in a context of a given training set. Nonjudgmental\nlogic (NjL) with modalities ``It appears that'', ``Assume that'' is introduced\nto formalize and quantify the concepts of inconsistency. Two conjectures are\nformulated. First, there are only 5 types of steps for all learners. Second,\nany learner minimizes a criterion, which can be represented as a measure of\ninconsistency in a semantic of NjL. Many popular ML algorithms (from\nhierarchical clustering to k-NN and SVM) are shown to corroborate both\nconjectures. In addition, it is demonstrated that NjL allows to formalize and\nsolve several general learning problems which are not considered as ML usually.",
          "link": "http://arxiv.org/abs/2006.09500",
          "publishedOn": "2021-06-08T02:20:24.635Z",
          "wordCount": null,
          "title": "Logic of Machine Learning. (arXiv:2006.09500v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02639",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Rosenfeld_J/0/1/0/all/0/1\">Joel A. Rosenfeld</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kamalapurkar_R/0/1/0/all/0/1\">Rushikesh Kamalapurkar</a>",
          "description": "This manuscript is aimed at addressing several long standing limitations of\ndynamic mode decompositions in the application of Koopman analysis. Principle\namong these limitations are the convergence of associated Dynamic Mode\nDecomposition algorithms and the existence of Koopman modes. To address these\nlimitations, two major modifications are made, where Koopman operators are\nremoved from the analysis in light of Liouville operators (known as Koopman\ngenerators in special cases), and these operators are shown to be compact for\ncertain pairs of Hilbert spaces selected separately as the domain and range of\nthe operator. While eigenfunctions are discarded in this analysis, a viable\nreconstruction algorithm is still demonstrated, and the sacrifice of\neigenfunctions realizes the theoretical goals of DMD analysis that have yet to\nbe achieved in other contexts. The manuscript concludes with the description of\na Dynamic Mode Decomposition algorithm that converges when a dense collection\nof occupation kernels, arising from the data, are leveraged in the analysis.",
          "link": "http://arxiv.org/abs/2106.02639",
          "publishedOn": "2021-06-08T02:20:24.615Z",
          "wordCount": 611,
          "title": "Singular Dynamic Mode Decompositions. (arXiv:2106.02639v1 [eess.SY])"
        },
        {
          "id": "http://arxiv.org/abs/2104.02822",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baykal_C/0/1/0/all/0/1\">Cenk Baykal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liebenwein_L/0/1/0/all/0/1\">Lucas Liebenwein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feldman_D/0/1/0/all/0/1\">Dan Feldman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rus_D/0/1/0/all/0/1\">Daniela Rus</a>",
          "description": "We develop an online learning algorithm for identifying unlabeled data points\nthat are most informative for training (i.e., active learning). By formulating\nthe active learning problem as the prediction with sleeping experts problem, we\nprovide a framework for identifying informative data with respect to any given\ndefinition of informativeness. At the core of our work is an efficient\nalgorithm for sleeping experts that is tailored to achieve low regret on\npredictable (easy) instances while remaining resilient to adversarial ones.\nThis stands in contrast to state-of-the-art active learning methods that are\noverwhelmingly based on greedy selection, and hence cannot ensure good\nperformance across varying problem instances. We present empirical results\ndemonstrating that our method (i) instantiated with an informativeness measure\nconsistently outperforms its greedy counterpart and (ii) reliably outperforms\nuniform sampling on real-world data sets and models.",
          "link": "http://arxiv.org/abs/2104.02822",
          "publishedOn": "2021-06-08T02:20:24.601Z",
          "wordCount": null,
          "title": "Low-Regret Active learning. (arXiv:2104.02822v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.04050",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hess_T/0/1/0/all/0/1\">Tom Hess</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moshkovitz_M/0/1/0/all/0/1\">Michal Moshkovitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabato_S/0/1/0/all/0/1\">Sivan Sabato</a>",
          "description": "We study k-median clustering under the sequential no-substitution setting. In\nthis setting, a data stream is sequentially observed, and some of the points\nare selected by the algorithm as cluster centers. However, a point can be\nselected as a center only immediately after it is observed, before observing\nthe next point. In addition, a selected center cannot be substituted later. We\ngive the first algorithm for this setting that obtains a constant approximation\nfactor on the optimal risk under a random arrival order, an exponential\nimprovement over previous work. This is also the first constant approximation\nguarantee that holds without any structural assumptions on the input data.\nMoreover, the number of selected centers is only quasi-linear in k. Our\nalgorithm and analysis are based on a careful risk estimation that avoids\noutliers, a new concept of a linear bin division, and a multiscale approach to\ncenter selection.",
          "link": "http://arxiv.org/abs/2102.04050",
          "publishedOn": "2021-06-08T02:20:24.598Z",
          "wordCount": null,
          "title": "A Constant Approximation Algorithm for Sequential Random-Order No-Substitution k-Median Clustering. (arXiv:2102.04050v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02780",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Farias_V/0/1/0/all/0/1\">Vivek F. Farias</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_A/0/1/0/all/0/1\">Andrew A. Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Peng_T/0/1/0/all/0/1\">Tianyi Peng</a>",
          "description": "The problem of causal inference with panel data is a central econometric\nquestion. The following is a fundamental version of this problem: Let $M^*$ be\na low rank matrix and $E$ be a zero-mean noise matrix. For a `treatment' matrix\n$Z$ with entries in $\\{0,1\\}$ we observe the matrix $O$ with entries $O_{ij} :=\nM^*_{ij} + E_{ij} + \\mathcal{T}_{ij} Z_{ij}$ where $\\mathcal{T}_{ij} $ are\nunknown, heterogenous treatment effects. The problem requires we estimate the\naverage treatment effect $\\tau^* := \\sum_{ij} \\mathcal{T}_{ij} Z_{ij} /\n\\sum_{ij} Z_{ij}$. The synthetic control paradigm provides an approach to\nestimating $\\tau^*$ when $Z$ places support on a single row. This paper extends\nthat framework to allow rate-optimal recovery of $\\tau^*$ for general $Z$, thus\nbroadly expanding its applicability. Our guarantees are the first of their type\nin this general setting. Computational experiments on synthetic and real-world\ndata show a substantial advantage over competing estimators.",
          "link": "http://arxiv.org/abs/2106.02780",
          "publishedOn": "2021-06-08T02:20:24.597Z",
          "wordCount": 582,
          "title": "Learning Treatment Effects in Panels with General Intervention Patterns. (arXiv:2106.02780v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2007.05975",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Edwards_T/0/1/0/all/0/1\">Tobias Edwards</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubinstein_B/0/1/0/all/0/1\">Benjamin I. P. Rubinstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zuhe Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Sanming Zhou</a>",
          "description": "Blowfish privacy is a recent generalisation of differential privacy that\nenables improved utility while maintaining privacy policies with semantic\nguarantees, a factor that has driven the popularity of differential privacy in\ncomputer science. This paper relates Blowfish privacy to an important measure\nof privacy loss of information channels from the communications theory\ncommunity: min-entropy leakage. Symmetry in an input data neighbouring relation\nis central to known connections between differential privacy and min-entropy\nleakage. But while differential privacy exhibits strong symmetry, Blowfish\nneighbouring relations correspond to arbitrary simple graphs owing to the\nframework's flexible privacy policies. To bound the min-entropy leakage of\nBlowfish-private mechanisms we organise our analysis over symmetrical\npartitions corresponding to orbits of graph automorphism groups. A construction\nmeeting our bound with asymptotic equality demonstrates tightness.",
          "link": "http://arxiv.org/abs/2007.05975",
          "publishedOn": "2021-06-08T02:20:24.589Z",
          "wordCount": null,
          "title": "A Graph Symmetrisation Bound on Channel Information Leakage under Blowfish Privacy. (arXiv:2007.05975v2 [cs.IT] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02734",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zifeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jian_T/0/1/0/all/0/1\">Tong Jian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Masoomi_A/0/1/0/all/0/1\">Aria Masoomi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ioannidis_S/0/1/0/all/0/1\">Stratis Ioannidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dy_J/0/1/0/all/0/1\">Jennifer Dy</a>",
          "description": "We investigate the HSIC (Hilbert-Schmidt independence criterion) bottleneck\nas a regularizer for learning an adversarially robust deep neural network\nclassifier. We show that the HSIC bottleneck enhances robustness to adversarial\nattacks both theoretically and experimentally. Our experiments on multiple\nbenchmark datasets and architectures demonstrate that incorporating an HSIC\nbottleneck regularizer attains competitive natural accuracy and improves\nadversarial robustness, both with and without adversarial examples during\ntraining.",
          "link": "http://arxiv.org/abs/2106.02734",
          "publishedOn": "2021-06-08T02:20:24.576Z",
          "wordCount": 490,
          "title": "Revisiting Hilbert-Schmidt Information Bottleneck for Adversarial Robustness. (arXiv:2106.02734v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02888",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaoyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johansson_M/0/1/0/all/0/1\">Mikael Johansson</a>",
          "description": "Many popular learning-rate schedules for deep neural networks combine a\ndecaying trend with local perturbations that attempt to escape saddle points\nand bad local minima. We derive convergence guarantees for bandwidth-based\nstep-sizes, a general class of learning-rates that are allowed to vary in a\nbanded region. This framework includes cyclic and non-monotonic step-sizes for\nwhich no theoretical guarantees were previously known. We provide worst-case\nguarantees for SGD on smooth non-convex problems under several bandwidth-based\nstep sizes, including stagewise $1/\\sqrt{t}$ and the popular step-decay\n(constant and then drop by a constant), which is also shown to be optimal.\nMoreover, we show that its momentum variant (SGDM) converges as fast as SGD\nwith the bandwidth-based step-decay step-size. Finally, we propose some novel\nstep-size schemes in the bandwidth-based family and verify their efficiency on\nseveral deep neural network training tasks.",
          "link": "http://arxiv.org/abs/2106.02888",
          "publishedOn": "2021-06-08T02:20:24.569Z",
          "wordCount": 559,
          "title": "Bandwidth-based Step-Sizes for Non-Convex Stochastic Optimization. (arXiv:2106.02888v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/1905.11824",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deshmukh_S/0/1/0/all/0/1\">Soham Deshmukh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rade_R/0/1/0/all/0/1\">Rahul Rade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kazi_D/0/1/0/all/0/1\">Dr. Faruk Kazi</a>",
          "description": "Cyber threat intelligence is one of the emerging areas of focus in\ninformation security. Much of the recent work has focused on rule-based methods\nand detection of network attacks using Intrusion Detection algorithms. In this\npaper we propose a framework for inspecting and modelling the behavioural\naspect of an attacker to obtain better insight predictive power on his future\nactions. For modelling we propose a novel semi-supervised algorithm called\nFusion Hidden Markov Model (FHMM) which is more robust to noise, requires\ncomparatively less training time, and utilizes the benefits of ensemble\nlearning to better model temporal relationships in data. This paper evaluates\nthe performances of FHMM and compares it with both traditional algorithms like\nMarkov Chain, Hidden Markov Model (HMM) and recently developed Deep Recurrent\nNeural Network (Deep RNN) architectures. We conduct the experiments on dataset\nconsisting of real data attacks on a Cowrie honeypot system. FHMM provides\naccuracy comparable to deep RNN architectures at significant lower training\ntime. Given these experimental results, we recommend using FHMM for modelling\ndiscrete temporal data for significantly faster training and better performance\nthan existing methods.",
          "link": "http://arxiv.org/abs/1905.11824",
          "publishedOn": "2021-06-08T02:20:24.551Z",
          "wordCount": 650,
          "title": "Attacker Behaviour Profiling using Stochastic Ensemble of Hidden Markov Models. (arXiv:1905.11824v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02969",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Safaryan_M/0/1/0/all/0/1\">Mher Safaryan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Islamov_R/0/1/0/all/0/1\">Rustem Islamov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_X/0/1/0/all/0/1\">Xun Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richtarik_P/0/1/0/all/0/1\">Peter Richt&#xe1;rik</a>",
          "description": "Inspired by recent work of Islamov et al (2021), we propose a family of\nFederated Newton Learn (FedNL) methods, which we believe is a marked step in\nthe direction of making second-order methods applicable to FL. In contrast to\nthe aforementioned work, FedNL employs a different Hessian learning technique\nwhich i) enhances privacy as it does not rely on the training data to be\nrevealed to the coordinating server, ii) makes it applicable beyond generalized\nlinear models, and iii) provably works with general contractive compression\noperators for compressing the local Hessians, such as Top-$K$ or Rank-$R$,\nwhich are vastly superior in practice. Notably, we do not need to rely on error\nfeedback for our methods to work with contractive compressors. Moreover, we\ndevelop FedNL-PP, FedNL-CR and FedNL-LS, which are variants of FedNL that\nsupport partial participation, and globalization via cubic regularization and\nline search, respectively, and FedNL-BC, which is a variant that can further\nbenefit from bidirectional compression of gradients and models, i.e., smart\nuplink gradient and smart downlink model compression. We prove local\nconvergence rates that are independent of the condition number, the number of\ntraining data points, and compression variance. Our communication efficient\nHessian learning technique provably learns the Hessian at the optimum. Finally,\nwe perform a variety of numerical experiments that show that our FedNL methods\nhave state-of-the-art communication complexity when compared to key baselines.",
          "link": "http://arxiv.org/abs/2106.02969",
          "publishedOn": "2021-06-08T02:20:24.536Z",
          "wordCount": 672,
          "title": "FedNL: Making Newton-Type Methods Applicable to Federated Learning. (arXiv:2106.02969v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2002.03513",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Shaojun Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zha_H/0/1/0/all/0/1\">Hongyuan Zha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Haomin Zhou</a>",
          "description": "Learning nonlinear dynamics from aggregate data is a challenging problem\nbecause the full trajectory of each individual is not available, namely, the\nindividual observed at one time may not be observed at the next time point, or\nthe identity of individual is unavailable. This is in sharp contrast to\nlearning dynamics with full trajectory data, on which the majority of existing\nmethods are based. We propose a novel method using the weak form of Fokker\nPlanck Equation (FPE) -- a partial differential equation -- to describe the\ndensity evolution of data in a sampled form, which is then combined with\nWasserstein generative adversarial network (WGAN) in the training process. In\nsuch a sample-based framework we are able to learn the nonlinear dynamics from\naggregate data without explicitly solving the partial differential equation\n(PDE) FPE. We demonstrate our approach in the context of a series of synthetic\nand real-world data sets.",
          "link": "http://arxiv.org/abs/2002.03513",
          "publishedOn": "2021-06-08T02:20:24.529Z",
          "wordCount": null,
          "title": "Learning Stochastic Behaviour from Aggregate Data. (arXiv:2002.03513v7 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.16664",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Perekrestenko_D/0/1/0/all/0/1\">Dmytro Perekrestenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_S/0/1/0/all/0/1\">Stephan M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bolcskei_H/0/1/0/all/0/1\">Helmut B&#xf6;lcskei</a>",
          "description": "We present an explicit deep neural network construction that transforms\nuniformly distributed one-dimensional noise into an arbitrarily close\napproximation of any two-dimensional Lipschitz-continuous target distribution.\nThe key ingredient of our design is a generalization of the \"space-filling\"\nproperty of sawtooth functions discovered in (Bailey & Telgarsky, 2018). We\nelicit the importance of depth - in our neural network construction - in\ndriving the Wasserstein distance between the target distribution and the\napproximation realized by the network to zero. An extension to output\ndistributions of arbitrary dimension is outlined. Finally, we show that the\nproposed construction does not incur a cost - in terms of error measured in\nWasserstein-distance - relative to generating $d$-dimensional target\ndistributions from $d$ independent random variables.",
          "link": "http://arxiv.org/abs/2006.16664",
          "publishedOn": "2021-06-08T02:20:24.525Z",
          "wordCount": 577,
          "title": "Constructive Universal High-Dimensional Distribution Generation through Deep ReLU Networks. (arXiv:2006.16664v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2003.12725",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1\">Chence Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Minkai Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1\">Hongyu Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Ming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jian Tang</a>",
          "description": "A fundamental problem in computational chemistry is to find a set of\nreactants to synthesize a target molecule, a.k.a. retrosynthesis prediction.\nExisting state-of-the-art methods rely on matching the target molecule with a\nlarge set of reaction templates, which are very computationally expensive and\nalso suffer from the problem of coverage. In this paper, we propose a novel\ntemplate-free approach called G2Gs by transforming a target molecular graph\ninto a set of reactant molecular graphs. G2Gs first splits the target molecular\ngraph into a set of synthons by identifying the reaction centers, and then\ntranslates the synthons to the final reactant graphs via a variational graph\ntranslation framework. Experimental results show that G2Gs significantly\noutperforms existing template-free approaches by up to 63% in terms of the\ntop-1 accuracy and achieves a performance close to that of state-of-the-art\ntemplate based approaches, but does not require domain knowledge and is much\nmore scalable.",
          "link": "http://arxiv.org/abs/2003.12725",
          "publishedOn": "2021-06-08T02:20:24.516Z",
          "wordCount": null,
          "title": "A Graph to Graphs Framework for Retrosynthesis Prediction. (arXiv:2003.12725v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02933",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Greenewald_K/0/1/0/all/0/1\">Kristjan Greenewald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_A/0/1/0/all/0/1\">Anming Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yurochkin_M/0/1/0/all/0/1\">Mikhail Yurochkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Solomon_J/0/1/0/all/0/1\">Justin Solomon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chien_E/0/1/0/all/0/1\">Edward Chien</a>",
          "description": "Mixup is a popular regularization technique for training deep neural networks\nthat can improve generalization and increase adversarial robustness. It\nperturbs input training data in the direction of other randomly-chosen\ninstances in the training set. To better leverage the structure of the data, we\nextend mixup to \\emph{$k$-mixup} by perturbing $k$-batches of training points\nin the direction of other $k$-batches using displacement interpolation,\ninterpolation under the Wasserstein metric. We demonstrate theoretically and in\nsimulations that $k$-mixup preserves cluster and manifold structures, and we\nextend theory studying efficacy of standard mixup. Our empirical results show\nthat training with $k$-mixup further improves generalization and robustness on\nbenchmark datasets.",
          "link": "http://arxiv.org/abs/2106.02933",
          "publishedOn": "2021-06-08T02:20:24.485Z",
          "wordCount": 531,
          "title": "k-Mixup Regularization for Deep Learning via Optimal Transport. (arXiv:2106.02933v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02658",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huber_P/0/1/0/all/0/1\">Patrick Huber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_W/0/1/0/all/0/1\">Wen Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carenini_G/0/1/0/all/0/1\">Giuseppe Carenini</a>",
          "description": "Aiming for a better integration of data-driven and linguistically-inspired\napproaches, we explore whether RST Nuclearity, assigning a binary assessment of\nimportance between text segments, can be replaced by automatically generated,\nreal-valued scores, in what we call a Weighted-RST framework. In particular, we\nfind that weighted discourse trees from auxiliary tasks can benefit key NLP\ndownstream applications, compared to nuclearity-centered approaches. We further\nshow that real-valued importance distributions partially and interestingly\nalign with the assessment and uncertainty of human annotators.",
          "link": "http://arxiv.org/abs/2106.02658",
          "publishedOn": "2021-06-08T02:20:24.469Z",
          "wordCount": 516,
          "title": "W-RST: Towards a Weighted RST-style Discourse Framework. (arXiv:2106.02658v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02993",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Daw_A/0/1/0/all/0/1\">Arka Daw</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maruf_M/0/1/0/all/0/1\">M. Maruf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karpatne_A/0/1/0/all/0/1\">Anuj Karpatne</a>",
          "description": "As applications of deep learning (DL) continue to seep into critical\nscientific use-cases, the importance of performing uncertainty quantification\n(UQ) with DL has become more pressing than ever before. In scientific\napplications, it is also important to inform the learning of DL models with\nknowledge of physics of the problem to produce physically consistent and\ngeneralized solutions. This is referred to as the emerging field of\nphysics-informed deep learning (PIDL). We consider the problem of developing\nPIDL formulations that can also perform UQ. To this end, we propose a novel\nphysics-informed GAN architecture, termed PID-GAN, where the knowledge of\nphysics is used to inform the learning of both the generator and discriminator\nmodels, making ample use of unlabeled data instances. We show that our proposed\nPID-GAN framework does not suffer from imbalance of generator gradients from\nmultiple loss terms as compared to state-of-the-art. We also empirically\ndemonstrate the efficacy of our proposed framework on a variety of case studies\ninvolving benchmark physics-based PDEs as well as imperfect physics. All the\ncode and datasets used in this study have been made available on this link :\nhttps://github.com/arkadaw9/PID-GAN.",
          "link": "http://arxiv.org/abs/2106.02993",
          "publishedOn": "2021-06-08T02:20:24.456Z",
          "wordCount": 640,
          "title": "PID-GAN: A GAN Framework based on a Physics-informed Discriminator for Uncertainty Quantification with Physics. (arXiv:2106.02993v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02881",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chu_Z/0/1/0/all/0/1\">Zhixuan Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rathbun_S/0/1/0/all/0/1\">Stephen L. Rathbun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sheng Li</a>",
          "description": "Treatment effect estimation from observational data is a critical research\ntopic across many domains. The foremost challenge in treatment effect\nestimation is how to capture hidden confounders. Recently, the growing\navailability of networked observational data offers a new opportunity to deal\nwith the issue of hidden confounders. Unlike networked data in traditional\ngraph learning tasks, such as node classification and link detection, the\nnetworked data under the causal inference problem has its particularity, i.e.,\nimbalanced network structure. In this paper, we propose a Graph Infomax\nAdversarial Learning (GIAL) model for treatment effect estimation, which makes\nfull use of the network structure to capture more information by recognizing\nthe imbalance in network structure. We evaluate the performance of our GIAL\nmodel on two benchmark datasets, and the results demonstrate superiority over\nthe state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2106.02881",
          "publishedOn": "2021-06-08T02:20:24.434Z",
          "wordCount": 596,
          "title": "Graph Infomax Adversarial Learning for Treatment Effect Estimation with Networked Observational Data. (arXiv:2106.02881v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02810",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Huang_Y/0/1/0/all/0/1\">Yu-Lin Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Su_B/0/1/0/all/0/1\">Bo-Hao Su</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hong_Y/0/1/0/all/0/1\">Y.-W. Peter Hong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_C/0/1/0/all/0/1\">Chi-Chun Lee</a>",
          "description": "Advancement in speech technology has brought convenience to our life.\nHowever, the concern is on the rise as speech signal contains multiple personal\nattributes, which would lead to either sensitive information leakage or bias\ntoward decision. In this work, we propose an attribute-aligned learning\nstrategy to derive speech representation that can flexibly address these issues\nby attribute-selection mechanism. Specifically, we propose a\nlayered-representation variational autoencoder (LR-VAE), which factorizes\nspeech representation into attribute-sensitive nodes, to derive an\nidentity-free representation for speech emotion recognition (SER), and an\nemotionless representation for speaker verification (SV). Our proposed method\nachieves competitive performances on identity-free SER and a better performance\non emotionless SV, comparing to the current state-of-the-art method of using\nadversarial learning applied on a large emotion corpora, the MSP-Podcast. Also,\nour proposed learning strategy reduces the model and training process needed to\nachieve multiple privacy-preserving tasks.",
          "link": "http://arxiv.org/abs/2106.02810",
          "publishedOn": "2021-06-08T02:20:24.391Z",
          "wordCount": 581,
          "title": "An Attribute-Aligned Strategy for Learning Speech Representation. (arXiv:2106.02810v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2101.10318",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shukla_S/0/1/0/all/0/1\">Satya Narayan Shukla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marlin_B/0/1/0/all/0/1\">Benjamin M. Marlin</a>",
          "description": "Irregular sampling occurs in many time series modeling applications where it\npresents a significant challenge to standard deep learning models. This work is\nmotivated by the analysis of physiological time series data in electronic\nhealth records, which are sparse, irregularly sampled, and multivariate. In\nthis paper, we propose a new deep learning framework for this setting that we\ncall Multi-Time Attention Networks. Multi-Time Attention Networks learn an\nembedding of continuous-time values and use an attention mechanism to produce a\nfixed-length representation of a time series containing a variable number of\nobservations. We investigate the performance of this framework on interpolation\nand classification tasks using multiple datasets. Our results show that the\nproposed approach performs as well or better than a range of baseline and\nrecently proposed models while offering significantly faster training times\nthan current state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2101.10318",
          "publishedOn": "2021-06-08T02:20:24.112Z",
          "wordCount": 603,
          "title": "Multi-Time Attention Networks for Irregularly Sampled Time Series. (arXiv:2101.10318v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.04238",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1\">Yun Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiangfeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_B/0/1/0/all/0/1\">Bo Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenhao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Junchi Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiaofeng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zha_H/0/1/0/all/0/1\">Hongyuan Zha</a>",
          "description": "In spite of the success of existing meta reinforcement learning methods, they\nstill have difficulty in learning a meta policy effectively for RL problems\nwith sparse reward. In this respect, we develop a novel meta reinforcement\nlearning framework called Hyper-Meta RL(HMRL), for sparse reward RL problems.\nIt is consisted with three modules including the cross-environment meta state\nembedding module which constructs a common meta state space to adapt to\ndifferent environments; the meta state based environment-specific meta reward\nshaping which effectively extends the original sparse reward trajectory by\ncross-environmental knowledge complementarity and as a consequence the meta\npolicy achieves better generalization and efficiency with the shaped meta\nreward. Experiments with sparse-reward environments show the superiority of\nHMRL on both transferability and policy learning efficiency.",
          "link": "http://arxiv.org/abs/2002.04238",
          "publishedOn": "2021-06-08T02:20:24.070Z",
          "wordCount": 615,
          "title": "HMRL: Hyper-Meta Learning for Sparse Reward Reinforcement Learning Problem. (arXiv:2002.04238v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02818",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Atashin_A/0/1/0/all/0/1\">Amir Ahooye Atashin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Razeghi_B/0/1/0/all/0/1\">Behrooz Razeghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunduz_D/0/1/0/all/0/1\">Deniz G&#xfc;nd&#xfc;z</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Voloshynovskiy_S/0/1/0/all/0/1\">Slava Voloshynovskiy</a>",
          "description": "We study the role of information complexity in privacy leakage about an\nattribute of an adversary's interest, which is not known a priori to the system\ndesigner. Considering the supervised representation learning setup and using\nneural networks to parameterize the variational bounds of information\nquantities, we study the impact of the following factors on the amount of\ninformation leakage: information complexity regularizer weight, latent space\ndimension, the cardinalities of the known utility and unknown sensitive\nattribute sets, the correlation between utility and sensitive attributes, and a\npotential bias in a sensitive attribute of adversary's interest. We conduct\nextensive experiments on Colored-MNIST and CelebA datasets to evaluate the\neffect of information complexity on the amount of intrinsic leakage.",
          "link": "http://arxiv.org/abs/2106.02818",
          "publishedOn": "2021-06-08T02:20:24.063Z",
          "wordCount": 555,
          "title": "Variational Leakage: The Role of Information Complexity in Privacy Leakage. (arXiv:2106.02818v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02988",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lu_Y/0/1/0/all/0/1\">Yangyi Lu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Meisami_A/0/1/0/all/0/1\">Amirhossein Meisami</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tewari_A/0/1/0/all/0/1\">Ambuj Tewari</a>",
          "description": "In causal bandit problems, the action set consists of interventions on\nvariables of a causal graph. Several researchers have recently studied such\nbandit problems and pointed out their practical applications. However, all\nexisting works rely on a restrictive and impractical assumption that the\nlearner is given full knowledge of the causal graph structure upfront. In this\npaper, we develop novel causal bandit algorithms without knowing the causal\ngraph. Our algorithms work well for causal trees, causal forests and a general\nclass of causal graphs. The regret guarantees of our algorithms greatly improve\nupon those of standard multi-armed bandit (MAB) algorithms under mild\nconditions. Lastly, we prove our mild conditions are necessary: without them\none cannot do better than standard MAB bandit algorithms.",
          "link": "http://arxiv.org/abs/2106.02988",
          "publishedOn": "2021-06-08T02:20:24.056Z",
          "wordCount": 544,
          "title": "Causal Bandits with Unknown Graph Structure. (arXiv:2106.02988v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02848",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gopi_S/0/1/0/all/0/1\">Sivakanth Gopi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Yin Tat Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wutschitz_L/0/1/0/all/0/1\">Lukas Wutschitz</a>",
          "description": "We give a fast algorithm to optimally compose privacy guarantees of\ndifferentially private (DP) algorithms to arbitrary accuracy. Our method is\nbased on the notion of privacy loss random variables to quantify the privacy\nloss of DP algorithms. The running time and memory needed for our algorithm to\napproximate the privacy curve of a DP algorithm composed with itself $k$ times\nis $\\tilde{O}(\\sqrt{k})$. This improves over the best prior method by Koskela\net al. (2020) which requires $\\tilde{\\Omega}(k^{1.5})$ running time. We\ndemonstrate the utility of our algorithm by accurately computing the privacy\nloss of DP-SGD algorithm of Abadi et al. (2016) and showing that our algorithm\nspeeds up the privacy computations by a few orders of magnitude compared to\nprior work, while maintaining similar accuracy.",
          "link": "http://arxiv.org/abs/2106.02848",
          "publishedOn": "2021-06-08T02:20:24.051Z",
          "wordCount": 555,
          "title": "Numerical Composition of Differential Privacy. (arXiv:2106.02848v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02795",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_S/0/1/0/all/0/1\">Si Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Gang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1\">Cho-Jui Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_S/0/1/0/all/0/1\">Samy Bengio</a>",
          "description": "Attentional mechanisms are order-invariant. Positional encoding is a crucial\ncomponent to allow attention-based deep model architectures such as Transformer\nto address sequences or images where the position of information matters. In\nthis paper, we propose a novel positional encoding method based on learnable\nFourier features. Instead of hard-coding each position as a token or a vector,\nwe represent each position, which can be multi-dimensional, as a trainable\nencoding based on learnable Fourier feature mapping, modulated with a\nmulti-layer perceptron. The representation is particularly advantageous for a\nspatial multi-dimensional position, e.g., pixel positions on an image, where\n$L_2$ distances or more complex positional relationships need to be captured.\nOur experiments based on several public benchmark tasks show that our learnable\nFourier feature representation for multi-dimensional positional encoding\noutperforms existing methods by both improving the accuracy and allowing faster\nconvergence.",
          "link": "http://arxiv.org/abs/2106.02795",
          "publishedOn": "2021-06-08T02:20:24.044Z",
          "wordCount": 573,
          "title": "Learnable Fourier Features for Multi-DimensionalSpatial Positional Encoding. (arXiv:2106.02795v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2005.01529",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Gaudio_J/0/1/0/all/0/1\">Joseph E. Gaudio</a>, <a href=\"http://arxiv.org/find/math/1/au:+Annaswamy_A/0/1/0/all/0/1\">Anuradha M. Annaswamy</a>, <a href=\"http://arxiv.org/find/math/1/au:+Moreu_J/0/1/0/all/0/1\">Jos&#xe9; M. Moreu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Bolender_M/0/1/0/all/0/1\">Michael A. Bolender</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gibson_T/0/1/0/all/0/1\">Travis E. Gibson</a>",
          "description": "High order momentum-based parameter update algorithms have seen widespread\napplications in training machine learning models. Recently, connections with\nvariational approaches have led to the derivation of new learning algorithms\nwith accelerated learning guarantees. Such methods however, have only\nconsidered the case of static regressors. There is a significant need for\nparameter update algorithms which can be proven stable in the presence of\nadversarial time-varying regressors, as is commonplace in control theory. In\nthis paper, we propose a new discrete time algorithm which 1) provides\nstability and asymptotic convergence guarantees in the presence of adversarial\nregressors by leveraging insights from adaptive control theory and 2) provides\nnon-asymptotic accelerated learning guarantees leveraging insights from convex\noptimization. In particular, our algorithm reaches an $\\epsilon$ sub-optimal\npoint in at most $\\tilde{\\mathcal{O}}(1/\\sqrt{\\epsilon})$ iterations when\nregressors are constant - matching lower bounds due to Nesterov of\n$\\Omega(1/\\sqrt{\\epsilon})$, up to a $\\log(1/\\epsilon)$ factor and provides\nguaranteed bounds for stability when regressors are time-varying. We provide\nnumerical experiments for a variant of Nesterov's provably hard convex\noptimization problem with time-varying regressors, as well as the problem of\nrecovering an image with a time-varying blur and noise using streaming data.",
          "link": "http://arxiv.org/abs/2005.01529",
          "publishedOn": "2021-06-08T02:20:24.038Z",
          "wordCount": 664,
          "title": "Accelerated Learning with Robustness to Adversarial Regressors. (arXiv:2005.01529v3 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02940",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kessler_S/0/1/0/all/0/1\">Samuel Kessler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parker_Holder_J/0/1/0/all/0/1\">Jack Parker-Holder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ball_P/0/1/0/all/0/1\">Philip Ball</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zohren_S/0/1/0/all/0/1\">Stefan Zohren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_S/0/1/0/all/0/1\">Stephen J. Roberts</a>",
          "description": "Continual Learning (CL) considers the problem of training an agent\nsequentially on a set of tasks while seeking to retain performance on all\nprevious tasks. A key challenge in CL is catastrophic forgetting, which arises\nwhen performance on a previously mastered task is reduced when learning a new\ntask. While a variety of methods exist to combat forgetting, in some cases\ntasks are fundamentally incompatible with each other and thus cannot be learnt\nby a single policy. This can occur, in reinforcement learning (RL) when an\nagent may be rewarded for achieving different goals from the same observation.\nIn this paper we formalize this ``interference'' as distinct from the problem\nof forgetting. We show that existing CL methods based on single neural network\npredictors with shared replay buffers fail in the presence of interference.\nInstead, we propose a simple method, OWL, to address this challenge. OWL learns\na factorized policy, using shared feature extraction layers, but separate\nheads, each specializing on a new task. The separate heads in OWL are used to\nprevent interference. At test time, we formulate policy selection as a\nmulti-armed bandit problem, and show it is possible to select the best policy\nfor an unknown task using feedback from the environment. The use of bandit\nalgorithms allows the OWL agent to constructively re-use different continually\nlearnt policies at different times during an episode. We show in multiple RL\nenvironments that existing replay based CL methods fail, while OWL is able to\nachieve close to optimal performance when training sequentially.",
          "link": "http://arxiv.org/abs/2106.02940",
          "publishedOn": "2021-06-08T02:20:24.032Z",
          "wordCount": 690,
          "title": "Same State, Different Task: Continual Reinforcement Learning without Interference. (arXiv:2106.02940v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02978",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ding_Q/0/1/0/all/0/1\">Qin Ding</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hsieh_C/0/1/0/all/0/1\">Cho-Jui Hsieh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sharpnack_J/0/1/0/all/0/1\">James Sharpnack</a>",
          "description": "Stochastic linear contextual bandit algorithms have substantial applications\nin practice, such as recommender systems, online advertising, clinical trials,\netc. Recent works show that optimal bandit algorithms are vulnerable to\nadversarial attacks and can fail completely in the presence of attacks.\nExisting robust bandit algorithms only work for the non-contextual setting\nunder the attack of rewards and cannot improve the robustness in the general\nand popular contextual bandit environment. In addition, none of the existing\nmethods can defend against attacked context. In this work, we provide the first\nrobust bandit algorithm for stochastic linear contextual bandit setting under a\nfully adaptive and omniscient attack. Our algorithm not only works under the\nattack of rewards, but also under attacked context. Moreover, it does not need\nany information about the attack budget or the particular form of the attack.\nWe provide theoretical guarantees for our proposed algorithm and show by\nextensive experiments that our proposed algorithm significantly improves the\nrobustness against various kinds of popular attacks.",
          "link": "http://arxiv.org/abs/2106.02978",
          "publishedOn": "2021-06-08T02:20:24.025Z",
          "wordCount": 590,
          "title": "Robust Stochastic Linear Contextual Bandits Under Adversarial Attacks. (arXiv:2106.02978v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02954",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Caciularu_A/0/1/0/all/0/1\">Avi Caciularu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dagan_I/0/1/0/all/0/1\">Ido Dagan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberger_J/0/1/0/all/0/1\">Jacob Goldberger</a>",
          "description": "We introduce a new approach for smoothing and improving the quality of word\nembeddings. We consider a method of fusing word embeddings that were trained on\nthe same corpus but with different initializations. We project all the models\nto a shared vector space using an efficient implementation of the Generalized\nProcrustes Analysis (GPA) procedure, previously used in multilingual word\ntranslation. Our word representation demonstrates consistent improvements over\nthe raw models as well as their simplistic average, on a range of tasks. As the\nnew representations are more stable and reliable, there is a noticeable\nimprovement in rare word evaluations.",
          "link": "http://arxiv.org/abs/2106.02954",
          "publishedOn": "2021-06-08T02:20:24.001Z",
          "wordCount": 533,
          "title": "Denoising Word Embeddings by Averaging in a Shared Space. (arXiv:2106.02954v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02948",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Takagi_Y/0/1/0/all/0/1\">Yu Takagi</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Hunt_L/0/1/0/all/0/1\">Laurence T. Hunt</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ohata_R/0/1/0/all/0/1\">Ryu Ohata</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Imamizu_H/0/1/0/all/0/1\">Hiroshi Imamizu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Hirayama_J/0/1/0/all/0/1\">Jun-ichiro Hirayama</a>",
          "description": "Multi-regional interaction among neuronal populations underlies the brain's\nprocessing of rich sensory information in our daily lives. Recent neuroscience\nand neuroimaging studies have increasingly used naturalistic stimuli and\nexperimental design to identify such realistic sensory computation in the\nbrain. However, existing methods for cross-areal interaction analysis with\ndimensionality reduction, such as reduced-rank regression and canonical\ncorrelation analysis, have limited applicability and interpretability in\nnaturalistic settings because they usually do not appropriately 'demix' neural\ninteractions into those associated with different types of task parameters or\nstimulus features (e.g., visual or audio). In this paper, we develop a new\nmethod for cross-areal interaction analysis that uses the rich task or stimulus\nparameters to reveal how and what types of information are shared by different\nneural populations. The proposed neural demixed shared component analysis\ncombines existing dimensionality reduction methods with a practical neural\nnetwork implementation of functional analysis of variance with latent\nvariables, thereby efficiently demixing nonlinear effects of continuous and\nmultimodal stimuli. We also propose a simplifying alternative under the\nassumptions of linear effects and unimodal stimuli. To demonstrate our methods,\nwe analyzed two human neuroimaging datasets of participants watching\nnaturalistic videos of movies and dance movements. The results demonstrate that\nour methods provide new insights into multi-regional interaction in the brain\nduring naturalistic sensory inputs, which cannot be captured by conventional\ntechniques.",
          "link": "http://arxiv.org/abs/2106.02948",
          "publishedOn": "2021-06-08T02:20:23.981Z",
          "wordCount": 664,
          "title": "Neural dSCA: demixing multimodal interaction among brain areas during naturalistic experiments. (arXiv:2106.02948v1 [q-bio.NC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02930",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_D/0/1/0/all/0/1\">Defu Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiachen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1\">Hengbo Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomizuka_M/0/1/0/all/0/1\">Masayoshi Tomizuka</a>",
          "description": "An effective understanding of the contextual environment and accurate motion\nforecasting of surrounding agents is crucial for the development of autonomous\nvehicles and social mobile robots. This task is challenging since the behavior\nof an autonomous agent is not only affected by its own intention, but also by\nthe static environment and surrounding dynamically interacting agents. Previous\nworks focused on utilizing the spatial and temporal information in time domain\nwhile not sufficiently taking advantage of the cues in frequency domain. To\nthis end, we propose a Spectral Temporal Graph Neural Network (SpecTGNN), which\ncan capture inter-agent correlations and temporal dependency simultaneously in\nfrequency domain in addition to time domain. SpecTGNN operates on both an agent\ngraph with dynamic state information and an environment graph with the features\nextracted from context images in two streams. The model integrates graph\nFourier transform, spectral graph convolution and temporal gated convolution to\nencode history information and forecast future trajectories. Moreover, we\nincorporate a multi-head spatio-temporal attention mechanism to mitigate the\neffect of error propagation in a long time horizon. We demonstrate the\nperformance of SpecTGNN on two public trajectory prediction benchmark datasets,\nwhich achieves state-of-the-art performance in terms of prediction accuracy.",
          "link": "http://arxiv.org/abs/2106.02930",
          "publishedOn": "2021-06-08T02:20:23.942Z",
          "wordCount": 641,
          "title": "Spectral Temporal Graph Neural Network for Trajectory Prediction. (arXiv:2106.02930v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2103.11804",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mazzeo_V/0/1/0/all/0/1\">V. Mazzeo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rapisarda_A/0/1/0/all/0/1\">A. Rapisarda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giuffrida_G/0/1/0/all/0/1\">G. Giuffrida</a>",
          "description": "In early January 2020, after China reported the first cases of the new\ncoronavirus (SARS-CoV-2) in the city of Wuhan, unreliable and not fully\naccurate information has started spreading faster than the virus itself.\nAlongside this pandemic, people have experienced a parallel infodemic, i.e., an\noverabundance of information, some of which misleading or even harmful, that\nhas widely spread around the globe. Although Social Media are increasingly\nbeing used as information source, Web Search Engines, like Google or Yahoo!,\nstill represent a powerful and trustworthy resource for finding information on\nthe Web. This is due to their capability to capture the largest amount of\ninformation, helping users quickly identify the most relevant, useful, although\nnot always the most reliable, results for their search queries. This study aims\nto detect potential misleading and fake contents by capturing and analysing\ntextual information, which flow through Search Engines. By using a real-world\ndataset associated with recent CoViD-19 pandemic, we first apply re-sampling\ntechniques for class imbalance, then we use existing Machine Learning\nalgorithms for classification of not reliable news. By extracting lexical and\nhost-based features of associated Uniform Resource Locators (URLs) for news\narticles, we show that the proposed methods, so common in phishing and\nmalicious URLs detection, can improve the efficiency and performance of\nclassifiers. Based on these findings, we suggest that the use of both textual\nand URLs features can improve the effectiveness of fake news detection methods.",
          "link": "http://arxiv.org/abs/2103.11804",
          "publishedOn": "2021-06-08T02:20:23.924Z",
          "wordCount": 740,
          "title": "Detection of fake news on CoViD-19 on Web Search Engines. (arXiv:2103.11804v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.00520",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Paltun_B/0/1/0/all/0/1\">Bet&#xfc;l G&#xfc;ven&#xe7; Paltun</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Kaski_S/0/1/0/all/0/1\">Samuel Kaski</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Mamitsuka_H/0/1/0/all/0/1\">Hiroshi Mamitsuka</a>",
          "description": "Detecting predictive biomarkers from multi-omics data is important for\nprecision medicine, to improve diagnostics of complex diseases and for better\ntreatments. This needs substantial experimental efforts that are made difficult\nby the heterogeneity of cell lines and huge cost. An effective solution is to\nbuild a computational model over the diverse omics data, including genomic,\nmolecular, and environmental information. However, choosing informative and\nreliable data sources from among the different types of data is a challenging\nproblem. We propose DIVERSE, a framework of Bayesian importance-weighted tri-\nand bi-matrix factorization(DIVERSE3 or DIVERSE2) to predict drug responses\nfrom data of cell lines, drugs, and gene interactions. DIVERSE integrates the\ndata sources systematically, in a step-wise manner, examining the importance of\neach added data set in turn. More specifically, we sequentially integrate five\ndifferent data sets, which have not all been combined in earlier bioinformatic\nmethods for predicting drug responses. Empirical experiments show that DIVERSE\nclearly outperformed five other methods including three state-of-the-art\napproaches, under cross-validation, particularly in out-of-matrix prediction,\nwhich is closer to the setting of real use cases and more challenging than\nsimpler in-matrix prediction. Additionally, case studies for discovering new\ndrugs further confirmed the performance advantage of DIVERSE.",
          "link": "http://arxiv.org/abs/2104.00520",
          "publishedOn": "2021-06-08T02:20:23.913Z",
          "wordCount": 681,
          "title": "DIVERSE: Bayesian Data IntegratiVE learning for precise drug ResponSE prediction. (arXiv:2104.00520v2 [q-bio.QM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02979",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ding_Q/0/1/0/all/0/1\">Qin Ding</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_Y/0/1/0/all/0/1\">Yi-Wei Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hsieh_C/0/1/0/all/0/1\">Cho-Jui Hsieh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sharpnack_J/0/1/0/all/0/1\">James Sharpnack</a>",
          "description": "The stochastic contextual bandit problem, which models the trade-off between\nexploration and exploitation, has many real applications, including recommender\nsystems, online advertising and clinical trials. As many other machine learning\nalgorithms, contextual bandit algorithms often have one or more\nhyper-parameters. As an example, in most optimal stochastic contextual bandit\nalgorithms, there is an unknown exploration parameter which controls the\ntrade-off between exploration and exploitation. A proper choice of the\nhyper-parameters is essential for contextual bandit algorithms to perform well.\nHowever, it is infeasible to use offline tuning methods to select\nhyper-parameters in contextual bandit environment since there is no\npre-collected dataset and the decisions have to be made in real time. To tackle\nthis problem, we first propose a two-layer bandit structure for auto tuning the\nexploration parameter and further generalize it to the Syndicated Bandits\nframework which can learn multiple hyper-parameters dynamically in contextual\nbandit environment. We show our Syndicated Bandits framework can achieve the\noptimal regret upper bounds and is general enough to handle the tuning tasks in\nmany popular contextual bandit algorithms, such as LinUCB, LinTS, UCB-GLM, etc.\nExperiments on both synthetic and real datasets validate the effectiveness of\nour proposed framework.",
          "link": "http://arxiv.org/abs/2106.02979",
          "publishedOn": "2021-06-08T02:20:23.906Z",
          "wordCount": 632,
          "title": "Syndicated Bandits: A Framework for Auto Tuning Hyper-parameters in Contextual Bandit Algorithms. (arXiv:2106.02979v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2103.01379",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lecuyer_M/0/1/0/all/0/1\">Mathias L&#xe9;cuyer</a>",
          "description": "Differential Privacy (DP) is the leading approach to privacy preserving deep\nlearning. As such, there are multiple efforts to provide drop-in integration of\nDP into popular frameworks. These efforts, which add noise to each gradient\ncomputation to make it DP, rely on composition theorems to bound the total\nprivacy loss incurred over this sequence of DP computations.\n\nHowever, existing composition theorems present a tension between efficiency\nand flexibility. Most theorems require all computations in the sequence to have\na predefined DP parameter, called the privacy budget. This prevents the design\nof training algorithms that adapt the privacy budget on the fly, or that\nterminate early to reduce the total privacy loss. Alternatively, the few\nexisting composition results for adaptive privacy budgets provide complex\nbounds on the privacy loss, with constants too large to be practical.\n\nIn this paper, we study DP composition under adaptive privacy budgets through\nthe lens of R\\'enyi Differential Privacy, proving a simpler composition theorem\nwith smaller constants, making it practical enough to use in algorithm design.\nWe demonstrate two applications of this theorem for DP deep learning: adapting\nthe noise or batch size online to improve a model's accuracy within a fixed\ntotal privacy loss, and stopping early when fine-tuning a model to reduce total\nprivacy loss.",
          "link": "http://arxiv.org/abs/2103.01379",
          "publishedOn": "2021-06-08T02:20:23.899Z",
          "wordCount": 665,
          "title": "Practical Privacy Filters and Odometers with R\\'enyi Differential Privacy and Applications to Differentially Private Deep Learning. (arXiv:2103.01379v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02926",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tran_C/0/1/0/all/0/1\">Cong Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_W/0/1/0/all/0/1\">Won-Yong Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spitz_A/0/1/0/all/0/1\">Andreas Spitz</a>",
          "description": "In real-world applications of influence maximization (IM), the network\nstructure is often unknown. In this case, we may identify the most influential\nseed nodes by exploring only a part of the underlying network given a small\nbudget for node queries. Motivated by the fact that collecting node metadata is\nmore cost-effective than investigating the relationship between nodes via\nqueried nodes, we develop IM-META, an end-to-end solution to IM in networks\nwith unknown topology by retrieving information from both queries and node\nmetadata. However, using such metadata to aid the IM process is not without\nrisk due to the noisy nature of metadata and uncertainties in connectivity\ninference. To tackle these challenges, we formulate an IM problem that aims to\nfind two sets, i.e., seed nodes and queried nodes. We propose an effective\nmethod that iteratively performs three steps: 1) we learn the relationship\nbetween collected metadata and edges via a Siamese neural network model, 2) we\nselect a number of inferred influential edges to construct a reinforced graph\nused for discovering an optimal seed set, and 3) we identify the next node to\nquery by maximizing the inferred influence spread using a topology-aware\nranking strategy. By querying only 5% of nodes, IM-META reaches 93% of the\nupper bound performance.",
          "link": "http://arxiv.org/abs/2106.02926",
          "publishedOn": "2021-06-08T02:20:23.893Z",
          "wordCount": 667,
          "title": "IM-META: Influence Maximization Using Node Metadata in Networks With Unknown Topology. (arXiv:2106.02926v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2105.04544",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mastouri_A/0/1/0/all/0/1\">Afsaneh Mastouri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yuchen Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gultchin_L/0/1/0/all/0/1\">Limor Gultchin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korba_A/0/1/0/all/0/1\">Anna Korba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_R/0/1/0/all/0/1\">Ricardo Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kusner_M/0/1/0/all/0/1\">Matt J. Kusner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gretton_A/0/1/0/all/0/1\">Arthur Gretton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muandet_K/0/1/0/all/0/1\">Krikamol Muandet</a>",
          "description": "We address the problem of causal effect estimation in the presence of\nunobserved confounding, but where proxies for the latent confounder(s) are\nobserved. We propose two kernel-based methods for nonlinear causal effect\nestimation in this setting: (a) a two-stage regression approach, and (b) a\nmaximum moment restriction approach. We focus on the proximal causal learning\nsetting, but our methods can be used to solve a wider class of inverse problems\ncharacterised by a Fredholm integral equation. In particular, we provide a\nunifying view of two-stage and moment restriction approaches for solving this\nproblem in a nonlinear setting. We provide consistency guarantees for each\nalgorithm, and we demonstrate these approaches achieve competitive results on\nsynthetic data and data simulating a real-world task. In particular, our\napproach outperforms earlier methods that are not suited to leveraging proxy\nvariables.",
          "link": "http://arxiv.org/abs/2105.04544",
          "publishedOn": "2021-06-08T02:20:23.873Z",
          "wordCount": 613,
          "title": "Proximal Causal Learning with Kernels: Two-Stage Estimation and Moment Restriction. (arXiv:2105.04544v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02855",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Santosh_S/0/1/0/all/0/1\">S. V. Sai Santosh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Darak_S/0/1/0/all/0/1\">Sumit J. Darak</a>",
          "description": "Multi-armed Bandit (MAB) algorithms identify the best arm among multiple arms\nvia exploration-exploitation trade-off without prior knowledge of arm\nstatistics. Their usefulness in wireless radio, IoT, and robotics demand\ndeployment on edge devices, and hence, a mapping on system-on-chip (SoC) is\ndesired. Theoretically, the Bayesian approach-based Thompson Sampling (TS)\nalgorithm offers better performance than the frequentist approach-based Upper\nConfidence Bound (UCB) algorithm. However, TS is not synthesizable due to Beta\nfunction. We address this problem by approximating it via a pseudo-random\nnumber generator-based approach and efficiently realize the TS algorithm on\nZynq SoC. In practice, the type of arms distribution (e.g., Bernoulli,\nGaussian, etc.) is unknown and hence, a single algorithm may not be optimal. We\npropose a reconfigurable and intelligent MAB (RI-MAB) framework. Here,\nintelligence enables the identification of appropriate MAB algorithms for a\ngiven environment, and reconfigurability allows on-the-fly switching between\nalgorithms on the SoC. This eliminates the need for parallel implementation of\nalgorithms resulting in huge savings in resources and power consumption. We\nanalyze the functional correctness, area, power, and execution time of the\nproposed and existing architectures for various arm distributions, word-length,\nand hardware-software co-design approaches. We demonstrate the superiority of\nthe RI-MAB over TS and UCB only architectures.",
          "link": "http://arxiv.org/abs/2106.02855",
          "publishedOn": "2021-06-08T02:20:23.867Z",
          "wordCount": 644,
          "title": "Multi-armed Bandit Algorithms on System-on-Chip: Go Frequentist or Bayesian?. (arXiv:2106.02855v1 [eess.SY])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02982",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dasgupta_S/0/1/0/all/0/1\">Sagar Dasgupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1\">Mizanur Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1\">Mhafuzul Islam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_M/0/1/0/all/0/1\">Mashrur Chowdhury</a>",
          "description": "In this study, a sensor fusion based GNSS spoofing attack detection framework\nis presented that consists of three concurrent strategies for an autonomous\nvehicle (AV): (i) prediction of location shift, (ii) detection of turns (left\nor right), and (iii) recognition of motion state (including standstill state).\nData from multiple low-cost in-vehicle sensors (i.e., accelerometer, steering\nangle sensor, speed sensor, and GNSS) are fused and fed into a recurrent neural\nnetwork model, which is a long short-term memory (LSTM) network for predicting\nthe location shift, i.e., the distance that an AV travels between two\nconsecutive timestamps. We have then combined k-Nearest Neighbors (k-NN) and\nDynamic Time Warping (DTW) algorithms to detect turns using data from the\nsteering angle sensor. In addition, data from an AV's speed sensor is used to\nrecognize the AV's motion state including the standstill state. To prove the\nefficacy of the sensor fusion-based attack detection framework, attack datasets\nare created for three unique and sophisticated spoofing attacks turn by turn,\novershoot, and stop using the publicly available real-world Honda Research\nInstitute Driving Dataset (HDD). Our analysis reveals that the sensor\nfusion-based detection framework successfully detects all three types of\nspoofing attacks within the required computational latency threshold.",
          "link": "http://arxiv.org/abs/2106.02982",
          "publishedOn": "2021-06-08T02:20:23.860Z",
          "wordCount": 635,
          "title": "Sensor Fusion-based GNSS Spoofing Attack Detection Framework for Autonomous Vehicles. (arXiv:2106.02982v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2105.02468",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Petrini_L/0/1/0/all/0/1\">Leonardo Petrini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Favero_A/0/1/0/all/0/1\">Alessandro Favero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geiger_M/0/1/0/all/0/1\">Mario Geiger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wyart_M/0/1/0/all/0/1\">Matthieu Wyart</a>",
          "description": "Understanding why deep nets can classify data in large dimensions remains a\nchallenge. It has been proposed that they do so by becoming stable to\ndiffeomorphisms, yet existing empirical measurements support that it is often\nnot the case. We revisit this question by defining a maximum-entropy\ndistribution on diffeomorphisms, that allows to study typical diffeomorphisms\nof a given norm. We confirm that stability toward diffeomorphisms does not\nstrongly correlate to performance on benchmark data sets of images. By\ncontrast, we find that the stability toward diffeomorphisms relative to that of\ngeneric transformations $R_f$ correlates remarkably with the test error\n$\\epsilon_t$. It is of order unity at initialization but decreases by several\ndecades during training for state-of-the-art architectures. For CIFAR10 and 15\nknown architectures, we find $\\epsilon_t\\approx 0.2\\sqrt{R_f}$, suggesting that\nobtaining a small $R_f$ is important to achieve good performance. We study how\n$R_f$ depends on the size of the training set and compare it to a simple model\nof invariant learning.",
          "link": "http://arxiv.org/abs/2105.02468",
          "publishedOn": "2021-06-08T02:20:23.854Z",
          "wordCount": 621,
          "title": "Relative stability toward diffeomorphisms indicates performance in deep nets. (arXiv:2105.02468v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02736",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goyal_K/0/1/0/all/0/1\">Kartik Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dyer_C/0/1/0/all/0/1\">Chris Dyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berg_Kirkpatrick_T/0/1/0/all/0/1\">Taylor Berg-Kirkpatrick</a>",
          "description": "While recent work has shown that scores from models trained by the ubiquitous\nmasked language modeling (MLM) objective effectively discriminate probable and\nimprobable sequences, it is still an open question if these MLMs specify a\nprincipled probability distribution over the space of possible sequences. In\nthis paper, we interpret MLMs as energy-based sequence models and propose two\nenergy parametrizations derivable from the trained MLMs. In order to draw\nsamples correctly from these models, we develop a tractable \\emph{sampling}\nscheme based on the Metropolis--Hastings Monte Carlo algorithm. In our\napproach, samples are proposed from the same masked conditionals used for\ntraining the masked language models, and they are accepted or rejected based on\ntheir energy values according to the target distribution. We validate the\neffectiveness of the proposed parametrizations by exploring the quality of\nsamples drawn from these energy-based models on the conditional generation task\nof machine translation. We theoretically and empirically justify our sampling\nalgorithm by showing that the masked conditionals on their own do not yield a\nMarkov chain whose stationary distribution is that of our target distribution,\nand our approach generates higher quality samples than other recently proposed\nundirected generation approaches (Wang et al., 2019, Ghazvininejad et al.,\n2019).",
          "link": "http://arxiv.org/abs/2106.02736",
          "publishedOn": "2021-06-08T02:20:23.846Z",
          "wordCount": 634,
          "title": "Exposing the Implicit Energy Networks behind Masked Language Models via Metropolis--Hastings. (arXiv:2106.02736v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.04373",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qiaosheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suh_G/0/1/0/all/0/1\">Geewon Suh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suh_C/0/1/0/all/0/1\">Changho Suh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_V/0/1/0/all/0/1\">Vincent Y. F. Tan</a>",
          "description": "In this paper, we design and analyze MC2G (Matrix Completion with 2 Graphs),\nan algorithm that performs matrix completion in the presence of social and item\nsimilarity graphs. MC2G runs in quasilinear time and is parameter free. It is\nbased on spectral clustering and local refinement steps. The expected number of\nsampled entries required for MC2G to succeed (i.e., recover the clusters in the\ngraphs and complete the matrix) matches an information-theoretic lower bound up\nto a constant factor for a wide range of parameters. We show via extensive\nexperiments on both synthetic and real datasets that MC2G outperforms other\nstate-of-the-art matrix completion algorithms that leverage graph side\ninformation.",
          "link": "http://arxiv.org/abs/2006.04373",
          "publishedOn": "2021-06-08T02:20:23.828Z",
          "wordCount": 594,
          "title": "MC2G: An Efficient Algorithm for Matrix Completion with Social and Item Similarity Graphs. (arXiv:2006.04373v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03358",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Datta_S/0/1/0/all/0/1\">Soumyya Kanti Datta</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shaikh_M/0/1/0/all/0/1\">Mohammad Abuzar Shaikh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Srihari_S/0/1/0/all/0/1\">Sargur N. Srihari</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gao_M/0/1/0/all/0/1\">Mingchen Gao</a>",
          "description": "In clinical applications, neural networks must focus on and highlight the\nmost important parts of an input image. Soft-Attention mechanism enables a\nneural network toachieve this goal. This paper investigates the effectiveness\nof Soft-Attention in deep neural architectures. The central aim of\nSoft-Attention is to boost the value of important features and suppress the\nnoise-inducing features. We compare the performance of VGG, ResNet,\nInceptionResNetv2 and DenseNet architectures with and without the\nSoft-Attention mechanism, while classifying skin lesions. The original network\nwhen coupled with Soft-Attention outperforms the baseline[16] by 4.7% while\nachieving a precision of 93.7% on HAM10000 dataset [25]. Additionally,\nSoft-Attention coupling improves the sensitivity score by 3.8% compared to\nbaseline[31] and achieves 91.6% on ISIC-2017 dataset [2]. The code is publicly\navailable at github.",
          "link": "http://arxiv.org/abs/2105.03358",
          "publishedOn": "2021-06-08T02:20:23.821Z",
          "wordCount": 600,
          "title": "Soft-Attention Improves Skin Cancer Classification Performance. (arXiv:2105.03358v3 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.08776",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hosseini_H/0/1/0/all/0/1\">Hossein Hosseini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_H/0/1/0/all/0/1\">Hyunsin Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1\">Sungrack Yun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Louizos_C/0/1/0/all/0/1\">Christos Louizos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soriaga_J/0/1/0/all/0/1\">Joseph Soriaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1\">Max Welling</a>",
          "description": "We consider the problem of training User Verification (UV) models in\nfederated setting, where each user has access to the data of only one class and\nuser embeddings cannot be shared with the server or other users. To address\nthis problem, we propose Federated User Verification (FedUV), a framework in\nwhich users jointly learn a set of vectors and maximize the correlation of\ntheir instance embeddings with a secret linear combination of those vectors. We\nshow that choosing the linear combinations from the codewords of an\nerror-correcting code allows users to collaboratively train the model without\nrevealing their embedding vectors. We present the experimental results for user\nverification with voice, face, and handwriting data and show that FedUV is on\npar with existing approaches, while not sharing the embeddings with other users\nor the server.",
          "link": "http://arxiv.org/abs/2104.08776",
          "publishedOn": "2021-06-08T02:20:23.815Z",
          "wordCount": 598,
          "title": "Federated Learning of User Verification Models Without Sharing Embeddings. (arXiv:2104.08776v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.06387",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Paul_W/0/1/0/all/0/1\">William Paul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hadzic_A/0/1/0/all/0/1\">Armin Hadzic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_N/0/1/0/all/0/1\">Neil Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alajaji_F/0/1/0/all/0/1\">Fady Alajaji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burlina_P/0/1/0/all/0/1\">Phil Burlina</a>",
          "description": "We propose a novel method for enforcing AI fairness with respect to protected\nor sensitive factors. This method uses a dual strategy performing training and\nrepresentation alteration (TARA) for the mitigation of prominent causes of AI\nbias by including: a) the use of representation learning alteration via\nadversarial independence to suppress the bias-inducing dependence of the data\nrepresentation from protected factors; and b) training set alteration via\nintelligent augmentation to address bias-causing data imbalance, by using\ngenerative models that allow the fine control of sensitive factors related to\nunderrepresented populations via domain adaptation and latent space\nmanipulation. When testing our methods on image analytics, experiments\ndemonstrate that TARA significantly or fully debiases baseline models while\noutperforming competing debiasing methods that have the same amount of\ninformation, e.g., with (% overall accuracy, % accuracy gap) = (78.8, 0.5) vs.\nthe baseline method's score of (71.8, 10.5) for EyePACS, and (73.7, 11.8) vs.\n(69.1, 21.7) for CelebA. Furthermore, recognizing certain limitations in\ncurrent metrics used for assessing debiasing performance, we propose novel\nconjunctive debiasing metrics. Our experiments also demonstrate the ability of\nthese novel metrics in assessing the Pareto efficiency of the proposed methods.",
          "link": "http://arxiv.org/abs/2012.06387",
          "publishedOn": "2021-06-08T02:20:23.807Z",
          "wordCount": 675,
          "title": "TARA: Training and Representation Alteration for AI Fairness and Domain Generalization. (arXiv:2012.06387v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02973",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Havens_A/0/1/0/all/0/1\">Aaron Havens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhary_G/0/1/0/all/0/1\">Girish Chowdhary</a>",
          "description": "As deep learning becomes more prevalent for prediction and control of real\nphysical systems, it is important that these overparameterized models are\nconsistent with physically plausible dynamics. This elicits a problem with how\nmuch inductive bias to impose on the model through known physical parameters\nand principles to reduce complexity of the learning problem to give us more\nreliable predictions. Recent work employs discrete variational integrators\nparameterized as a neural network architecture to learn conservative Lagrangian\nsystems. The learned model captures and enforces global energy preserving\nproperties of the system from very few trajectories. However, most real systems\nare inherently non-conservative and, in practice, we would also like to apply\nactuation. In this paper we extend this paradigm to account for general forcing\n(e.g. control input and damping) via discrete d'Alembert's principle which may\nultimately be used for control applications. We show that this forced\nvariational integrator networks (FVIN) architecture allows us to accurately\naccount for energy dissipation and external forcing while still capturing the\ntrue underlying energy-based passive dynamics. We show that in application this\ncan result in highly-data efficient model-based control and can predict on real\nnon-conservative systems.",
          "link": "http://arxiv.org/abs/2106.02973",
          "publishedOn": "2021-06-08T02:20:23.782Z",
          "wordCount": 622,
          "title": "Forced Variational Integrator Networks for Prediction and Control of Mechanical Systems. (arXiv:2106.02973v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.08868",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Faghri_F/0/1/0/all/0/1\">Fartash Faghri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gowal_S/0/1/0/all/0/1\">Sven Gowal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasconcelos_C/0/1/0/all/0/1\">Cristina Vasconcelos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fleet_D/0/1/0/all/0/1\">David J. Fleet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pedregosa_F/0/1/0/all/0/1\">Fabian Pedregosa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roux_N/0/1/0/all/0/1\">Nicolas Le Roux</a>",
          "description": "We demonstrate that the choice of optimizer, neural network architecture, and\nregularizer significantly affect the adversarial robustness of linear neural\nnetworks, providing guarantees without the need for adversarial training. To\nthis end, we revisit a known result linking maximally robust classifiers and\nminimum norm solutions, and combine it with recent results on the implicit bias\nof optimizers. First, we show that, under certain conditions, it is possible to\nachieve both perfect standard accuracy and a certain degree of robustness,\nsimply by training an overparametrized model using the implicit bias of the\noptimization. In that regime, there is a direct relationship between the type\nof the optimizer and the attack to which the model is robust. To the best of\nour knowledge, this work is the first to study the impact of optimization\nmethods such as sign gradient descent and proximal methods on adversarial\nrobustness. Second, we characterize the robustness of linear convolutional\nmodels, showing that they resist attacks subject to a constraint on the\nFourier-$\\ell_\\infty$ norm. To illustrate these findings we design a novel\nFourier-$\\ell_\\infty$ attack that finds adversarial examples with controllable\nfrequencies. We evaluate Fourier-$\\ell_\\infty$ robustness of\nadversarially-trained deep CIFAR-10 models from the standard RobustBench\nbenchmark and visualize adversarial perturbations.",
          "link": "http://arxiv.org/abs/2102.08868",
          "publishedOn": "2021-06-08T02:20:23.761Z",
          "wordCount": 685,
          "title": "Bridging the Gap Between Adversarial Robustness and Optimization Bias. (arXiv:2102.08868v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.04250",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gan_K/0/1/0/all/0/1\">Kyra Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_S/0/1/0/all/0/1\">Su Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Andrew Li</a>",
          "description": "In the problem of active sequential hypotheses testing (ASHT), a learner\nseeks to identify the true hypothesis from among a known set of hypotheses. The\nlearner is given a set of actions and knows the random distribution of the\noutcome of any action under any true hypothesis. Given a target error\n$\\delta>0$, the goal is to sequentially select the fewest number of actions so\nas to identify the true hypothesis with probability at least $1 - \\delta$.\nMotivated by applications in which the number of hypotheses or actions is\nmassive (e.g. genomics-based cancer detection), we propose efficient (greedy,\nin fact) algorithms and provide the first approximation guarantees for ASHT,\nunder two types of adaptivity. Both of our guarantees are independent of the\nnumber of actions and logarithmic in the number of hypotheses. We numerically\nevaluate the performance of our algorithms using both synthetic and real DNA\nmutation data, demonstrating that our algorithms outperform previous heuristic\npolicies by large margins.",
          "link": "http://arxiv.org/abs/2103.04250",
          "publishedOn": "2021-06-08T02:20:23.753Z",
          "wordCount": 612,
          "title": "Greedy Approximation Algorithms for Active Sequential Hypothesis Testing. (arXiv:2103.04250v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02856",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pathan_S/0/1/0/all/0/1\">Sharmin Pathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shrivastava_V/0/1/0/all/0/1\">Vyom Shrivastava</a>",
          "description": "We present an end-to-end framework for the Assignment Problem with multiple\ntasks mapped to a group of workers, using reinforcement learning while\npreserving many constraints. Tasks and workers have time constraints and there\nis a cost associated with assigning a worker to a task. Each worker can perform\nmultiple tasks until it exhausts its allowed time units (capacity). We train a\nreinforcement learning agent to find near optimal solutions to the problem by\nminimizing total cost associated with the assignments while maintaining hard\nconstraints. We use proximal policy optimization to optimize model parameters.\nThe model generates a sequence of actions in real-time which correspond to task\nassignment to workers, without having to retrain for changes in the dynamic\nstate of the environment. In our problem setting reward is computed as negative\nof the assignment cost. We also demonstrate our results on bin packing and\ncapacitated vehicle routing problem, using the same framework. Our results\noutperform Google OR-Tools using MIP and CP-SAT solvers with large problem\ninstances, in terms of solution quality and computation time.",
          "link": "http://arxiv.org/abs/2106.02856",
          "publishedOn": "2021-06-08T02:20:23.721Z",
          "wordCount": 598,
          "title": "Reinforcement Learning for Assignment Problem with Time Constraints. (arXiv:2106.02856v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02800",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhang_Q/0/1/0/all/0/1\">Qian Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sampani_K/0/1/0/all/0/1\">Konstantina Sampani</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_M/0/1/0/all/0/1\">Mengjia Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cai_S/0/1/0/all/0/1\">Shengze Cai</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Deng_Y/0/1/0/all/0/1\">Yixiang Deng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_H/0/1/0/all/0/1\">He Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sun_J/0/1/0/all/0/1\">Jennifer K. Sun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Karniadakis_G/0/1/0/all/0/1\">George Em Karniadakis</a>",
          "description": "Adaptive optics scanning laser ophthalmoscopy (AOSLO) provides real-time\nretinal images with high resolution down to 2 $\\mu m$. This technique enables\ndetection of the morphologies of individual microaneurysms (MAs), which are one\nof the earliest signs of diabetic retinopathy (DR), a frequent complication of\ndiabetes that can lead to visual impairment and blindness. In contrast to\nprevious automatic models developed for MA detection on standard fundus\nphotographs, currently there is no high throughput image protocol available for\nautomatic analysis of AOSLO photographs. To address this urgency, we introduce\nAOSLO-net, a deep neural network framework with customized training policy,\nincluding preprocessing, data augmentation and transfer learning, to\nautomatically segment MAs from AOSLO images. We evaluate the performance of\nAOSLO-net using 87 DR AOSLO images demonstrating very accurate MA detection and\nsegmentation, leading to correct MA morphological classification, while\noutperforming the state-of-the-art both in accuracy and cost.",
          "link": "http://arxiv.org/abs/2106.02800",
          "publishedOn": "2021-06-08T02:20:23.696Z",
          "wordCount": 617,
          "title": "AOSLO-net: A deep learning-based method for automatic segmentation of retinal microaneurysms from adaptive optics scanning laser ophthalmoscope images. (arXiv:2106.02800v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.03150",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schutt_K/0/1/0/all/0/1\">Kristof T. Sch&#xfc;tt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Unke_O/0/1/0/all/0/1\">Oliver T. Unke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gastegger_M/0/1/0/all/0/1\">Michael Gastegger</a>",
          "description": "Message passing neural networks have become a method of choice for learning\non graphs, in particular the prediction of chemical properties and the\nacceleration of molecular dynamics studies. While they readily scale to large\ntraining data sets, previous approaches have proven to be less data efficient\nthan kernel methods. We identify limitations of invariant representations as a\nmajor reason and extend the message passing formulation to rotationally\nequivariant representations. On this basis, we propose the polarizable atom\ninteraction neural network (PaiNN) and improve on common molecule benchmarks\nover previous networks, while reducing model size and inference time. We\nleverage the equivariant atomwise representations obtained by PaiNN for the\nprediction of tensorial properties. Finally, we apply this to the simulation of\nmolecular spectra, achieving speedups of 4-5 orders of magnitude compared to\nthe electronic structure reference.",
          "link": "http://arxiv.org/abs/2102.03150",
          "publishedOn": "2021-06-08T02:20:23.689Z",
          "wordCount": 623,
          "title": "Equivariant message passing for the prediction of tensorial properties and molecular spectra. (arXiv:2102.03150v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.01302",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Mitra_A/0/1/0/all/0/1\">Aritra Mitra</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Richards_J/0/1/0/all/0/1\">John A. Richards</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bagchi_S/0/1/0/all/0/1\">Saurabh Bagchi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sundaram_S/0/1/0/all/0/1\">Shreyas Sundaram</a>",
          "description": "We consider the problem of distributed inference where agents in a network\nobserve a stream of private signals generated by an unknown state, and aim to\nuniquely identify this state from a finite set of hypotheses. We focus on\nscenarios where communication between agents is costly, and takes place over\nchannels with finite bandwidth. To reduce the frequency of communication, we\ndevelop a novel event-triggered distributed learning rule that is based on the\nprinciple of diffusing low beliefs on each false hypothesis. Building on this\nprinciple, we design a trigger condition under which an agent broadcasts only\nthose components of its belief vector that have adequate innovation, to only\nthose neighbors that require such information. We prove that our rule\nguarantees convergence to the true state exponentially fast almost surely\ndespite sparse communication, and that it has the potential to significantly\nreduce information flow from uninformative agents to informative agents. Next,\nto deal with finite-precision communication channels, we propose a distributed\nlearning rule that leverages the idea of adaptive quantization. We show that by\nsequentially refining the range of the quantizers, every agent can learn the\ntruth exponentially fast almost surely, while using just $1$ bit to encode its\nbelief on each hypothesis. For both our proposed algorithms, we rigorously\ncharacterize the trade-offs between communication-efficiency and the learning\nrate.",
          "link": "http://arxiv.org/abs/2004.01302",
          "publishedOn": "2021-06-08T02:20:23.670Z",
          "wordCount": 717,
          "title": "Distributed Inference with Sparse and Quantized Communication. (arXiv:2004.01302v4 [eess.SY] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.09593",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1\">Samson Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1\">Shafiq Joty</a>",
          "description": "Multilingual models have demonstrated impressive cross-lingual transfer\nperformance. However, test sets like XNLI are monolingual at the example level.\nIn multilingual communities, it is common for polyglots to code-mix when\nconversing with each other. Inspired by this phenomenon, we present two strong\nblack-box adversarial attacks (one word-level, one phrase-level) for\nmultilingual models that push their ability to handle code-mixed sentences to\nthe limit. The former uses bilingual dictionaries to propose perturbations and\ntranslations of the clean example for sense disambiguation. The latter directly\naligns the clean example with its translations before extracting phrases as\nperturbations. Our phrase-level attack has a success rate of 89.75% against\nXLM-R-large, bringing its average accuracy of 79.85 down to 8.18 on XNLI.\nFinally, we propose an efficient adversarial training scheme that trains in the\nsame number of steps as the original model and show that it improves model\naccuracy.",
          "link": "http://arxiv.org/abs/2103.09593",
          "publishedOn": "2021-06-08T02:20:23.663Z",
          "wordCount": 652,
          "title": "Code-Mixing on Sesame Street: Dawn of the Adversarial Polyglots. (arXiv:2103.09593v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02693",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Turner_R/0/1/0/all/0/1\">Rosanne Turner</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ly_A/0/1/0/all/0/1\">Alexander Ly</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Grunwald_P/0/1/0/all/0/1\">Peter Gr&#xfc;nwald</a>",
          "description": "We develop E variables for testing whether two data streams come from the\nsame source or not, and more generally, whether the difference between the\nsources is larger than some minimal effect size. These E variables lead to\ntests that remain safe, i.e. keep their Type-I error guarantees, under flexible\nsampling scenarios such as optional stopping and continuation. We also develop\nthe corresponding always-valid confidence intervals. In special cases our E\nvariables also have an optimal `growth' property under the alternative. We\nillustrate the generic construction through the special case of 2x2 contingency\ntables, where we also allow for the incorporation of different restrictions on\na composite alternative. Comparison to p-value analysis in simulations and a\nreal-world example show that E variables, through their flexibility, often\nallow for early stopping of data collection, thereby retaining similar power as\nclassical methods.",
          "link": "http://arxiv.org/abs/2106.02693",
          "publishedOn": "2021-06-08T02:20:23.657Z",
          "wordCount": 575,
          "title": "Safe Tests and Always-Valid Confidence Intervals for contingency tables and beyond. (arXiv:2106.02693v1 [stat.ME])"
        },
        {
          "id": "http://arxiv.org/abs/2005.01757",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shabat_E/0/1/0/all/0/1\">Eliran Shabat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_L/0/1/0/all/0/1\">Lee Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansour_Y/0/1/0/all/0/1\">Yishay Mansour</a>",
          "description": "There is a growing interest in societal concerns in machine learning systems,\nespecially in fairness. Multicalibration gives a comprehensive methodology to\naddress group fairness. In this work, we address the multicalibration error and\ndecouple it from the prediction error. The importance of decoupling the\nfairness metric (multicalibration) and the accuracy (prediction error) is due\nto the inherent trade-off between the two, and the societal decision regarding\nthe \"right tradeoff\" (as imposed many times by regulators). Our work gives\nsample complexity bounds for uniform convergence guarantees of multicalibration\nerror, which implies that regardless of the accuracy, we can guarantee that the\nempirical and (true) multicalibration errors are close. We emphasize that our\nresults: (1) are more general than previous bounds, as they apply to both\nagnostic and realizable settings, and do not rely on a specific type of\nalgorithm (such as deferentially private), (2) improve over previous\nmulticalibration sample complexity bounds and (3) implies uniform convergence\nguarantees for the classical calibration error.",
          "link": "http://arxiv.org/abs/2005.01757",
          "publishedOn": "2021-06-08T02:20:23.634Z",
          "wordCount": 629,
          "title": "Sample Complexity of Uniform Convergence for Multicalibration. (arXiv:2005.01757v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05640",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1\">Yutong Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Scott_C/0/1/0/all/0/1\">Clayton D. Scott</a>",
          "description": "Recent empirical evidence suggests that the Weston-Watkins support vector\nmachine is among the best performing multiclass extensions of the binary SVM.\nCurrent state-of-the-art solvers repeatedly solve a particular subproblem\napproximately using an iterative strategy. In this work, we propose an\nalgorithm that solves the subproblem exactly using a novel reparametrization of\nthe Weston-Watkins dual problem. For linear WW-SVMs, our solver shows\nsignificant speed-up over the state-of-the-art solver when the number of\nclasses is large. Our exact subproblem solver also allows us to prove linear\nconvergence of the overall solver.",
          "link": "http://arxiv.org/abs/2102.05640",
          "publishedOn": "2021-06-08T02:20:23.627Z",
          "wordCount": 533,
          "title": "An Exact Solver for the Weston-Watkins SVM Subproblem. (arXiv:2102.05640v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02900",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Jay Tenenbaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaplan_H/0/1/0/all/0/1\">Haim Kaplan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansour_Y/0/1/0/all/0/1\">Yishay Mansour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stemmer_U/0/1/0/all/0/1\">Uri Stemmer</a>",
          "description": "We give an $(\\varepsilon,\\delta)$-differentially private algorithm for the\nmulti-armed bandit (MAB) problem in the shuffle model with a\ndistribution-dependent regret of $O\\left(\\left(\\sum_{a\\in\n[k]:\\Delta_a>0}\\frac{\\log\nT}{\\Delta_a}\\right)+\\frac{k\\sqrt{\\log\\frac{1}{\\delta}}\\log\nT}{\\varepsilon}\\right)$, and a distribution-independent regret of\n$O\\left(\\sqrt{kT\\log T}+\\frac{k\\sqrt{\\log\\frac{1}{\\delta}}\\log\nT}{\\varepsilon}\\right)$, where $T$ is the number of rounds, $\\Delta_a$ is the\nsuboptimality gap of the arm $a$, and $k$ is the total number of arms. Our\nupper bound almost matches the regret of the best known algorithms for the\ncentralized model, and significantly outperforms the best known algorithm in\nthe local model.",
          "link": "http://arxiv.org/abs/2106.02900",
          "publishedOn": "2021-06-08T02:20:23.618Z",
          "wordCount": 514,
          "title": "Differentially Private Multi-Armed Bandits in the Shuffle Model. (arXiv:2106.02900v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2004.09764",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1\">Xianghong Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_H/0/1/0/all/0/1\">Haoli Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zenglin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1\">Michael Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1\">Irwin King</a>",
          "description": "Variational autoencoders (VAEs) have been widely applied for text modeling.\nIn practice, however, they are troubled by two challenges: information\nunderrepresentation and posterior collapse. The former arises as only the last\nhidden state of LSTM encoder is transformed into the latent space, which is\ngenerally insufficient to summarize the data. The latter is a long-standing\nproblem during the training of VAEs as the optimization is trapped to a\ndisastrous local optimum. In this paper, we propose Discrete Auto-regressive\nVariational Attention Model (DAVAM) to address the challenges. Specifically, we\nintroduce an auto-regressive variational attention approach to enrich the\nlatent space by effectively capturing the semantic dependency from the input.\nWe further design discrete latent space for the variational attention and\nmathematically show that our model is free from posterior collapse. Extensive\nexperiments on language modeling tasks demonstrate the superiority of DAVAM\nagainst several VAE counterparts.",
          "link": "http://arxiv.org/abs/2004.09764",
          "publishedOn": "2021-06-08T02:20:23.611Z",
          "wordCount": 624,
          "title": "Discrete Auto-regressive Variational Attention Models for Text Modeling. (arXiv:2004.09764v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1907.06022",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1\">Yantao Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Shujian Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giraldo_L/0/1/0/all/0/1\">Luis Sanchez Giraldo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Principe_J/0/1/0/all/0/1\">Jose C. Principe</a>",
          "description": "This paper proposes a novel architecture, termed multiscale principle of\nrelevant information (MPRI), to learn discriminative spectral-spatial features\nfor hyperspectral image (HSI) classification. MPRI inherits the merits of the\nprinciple of relevant information (PRI) to effectively extract multiscale\ninformation embedded in the given data, and also takes advantage of the\nmultilayer structure to learn representations in a coarse-to-fine manner.\nSpecifically, MPRI performs spectral-spatial pixel characterization (using PRI)\nand feature dimensionality reduction (using regularized linear discriminant\nanalysis) iteratively and successively. Extensive experiments on three\nbenchmark data sets demonstrate that MPRI outperforms existing state-of-the-art\nmethods (including deep learning based ones) qualitatively and quantitatively,\nespecially in the scenario of limited training samples. Code of MPRI is\navailable at \\url{this http URL}.",
          "link": "http://arxiv.org/abs/1907.06022",
          "publishedOn": "2021-06-08T02:20:23.549Z",
          "wordCount": 612,
          "title": "Multiscale Principle of Relevant Information for Hyperspectral Image Classification. (arXiv:1907.06022v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02997",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Geiger_A/0/1/0/all/0/1\">Atticus Geiger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Hanson Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Icard_T/0/1/0/all/0/1\">Thomas Icard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1\">Christopher Potts</a>",
          "description": "Structural analysis methods (e.g., probing and feature attribution) are\nincreasingly important tools for neural network analysis. We propose a new\nstructural analysis method grounded in a formal theory of \\textit{causal\nabstraction} that provides rich characterizations of model-internal\nrepresentations and their roles in input/output behavior. In this method,\nneural representations are aligned with variables in interpretable causal\nmodels, and then \\textit{interchange interventions} are used to experimentally\nverify that the neural representations have the causal properties of their\naligned variables. We apply this method in a case study to analyze neural\nmodels trained on Multiply Quantified Natural Language Inference (MQNLI)\ncorpus, a highly complex NLI dataset that was constructed with a\ntree-structured natural logic causal model. We discover that a BERT-based model\nwith state-of-the-art performance successfully realizes the approximate causal\nstructure of the natural logic causal model, whereas a simpler baseline model\nfails to show any such structure, demonstrating that neural representations\nencode the compositional structure of MQNLI examples.",
          "link": "http://arxiv.org/abs/2106.02997",
          "publishedOn": "2021-06-08T02:20:23.542Z",
          "wordCount": 578,
          "title": "Causal Abstractions of Neural Networks. (arXiv:2106.02997v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02777",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hyfte_Z/0/1/0/all/0/1\">Zach Van Hyfte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zakhor_A/0/1/0/all/0/1\">Avideh Zakhor</a>",
          "description": "Smartphone apps for exposure notification and contact tracing have been shown\nto be effective in controlling the COVID-19 pandemic. However, Bluetooth Low\nEnergy tokens similar to those broadcast by existing apps can still be picked\nup far away from the transmitting device. In this paper, we present a new class\nof methods for detecting whether or not two Wi-Fi-enabled devices are in\nimmediate physical proximity, i.e. 2 or fewer meters apart, as established by\nthe U.S. Centers for Disease Control and Prevention (CDC). Our goal is to\nenhance the accuracy of smartphone-based exposure notification and contact\ntracing systems. We present a set of binary machine learning classifiers that\ntake as input pairs of Wi-Fi RSSI fingerprints. We empirically verify that a\nsingle classifier cannot generalize well to a range of different environments\nwith vastly different numbers of detectable Wi-Fi Access Points (APs). However,\nspecialized classifiers, tailored to situations where the number of detectable\nAPs falls within a certain range, are able to detect immediate physical\nproximity significantly more accurately. As such, we design three classifiers\nfor situations with low, medium, and high numbers of detectable APs. These\nclassifiers distinguish between pairs of RSSI fingerprints recorded 2 or fewer\nmeters apart and pairs recorded further apart but still in Bluetooth range. We\ncharacterize their balanced accuracy for this task to be between 66.8% and\n77.8%.",
          "link": "http://arxiv.org/abs/2106.02777",
          "publishedOn": "2021-06-08T02:20:23.534Z",
          "wordCount": 704,
          "title": "Immediate Proximity Detection Using Wi-Fi-Enabled Smartphones. (arXiv:2106.02777v1 [cs.NI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02850",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Koti_N/0/1/0/all/0/1\">Nishat Koti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patra_A/0/1/0/all/0/1\">Arpita Patra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rachuri_R/0/1/0/all/0/1\">Rahul Rachuri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suresh_A/0/1/0/all/0/1\">Ajith Suresh</a>",
          "description": "In this work, we design an efficient mixed-protocol framework, Tetrad, with\napplications to privacy-preserving machine learning. It is designed for the\nfour-party setting with at most one active corruption and supports rings.\n\nOur fair multiplication protocol requires communicating only 5 ring elements\nimproving over the state-of-the-art protocol of Trident (Chaudhari et al.\nNDSS'20). The technical highlights of Tetrad include efficient (a) truncation\nwithout any overhead, (b) multi-input multiplication protocols for arithmetic\nand boolean worlds, (c) garbled-world, tailor-made for the mixed-protocol\nframework, and (d) conversion mechanisms to switch between the computation\nstyles. The fair framework is also extended to provide robustness without\ninflating the costs.\n\nThe competence of Tetrad is tested with benchmarks for deep neural networks\nsuch as LeNet and VGG16 and support vector machines. One variant of our\nframework aims at minimizing the execution time, while the other focuses on the\nmonetary cost. We observe improvements up to 6x over Trident across these\nparameters.",
          "link": "http://arxiv.org/abs/2106.02850",
          "publishedOn": "2021-06-08T02:20:23.469Z",
          "wordCount": 586,
          "title": "Tetrad: Actively Secure 4PC for Secure Training and Inference. (arXiv:2106.02850v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02742",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cimolino_G/0/1/0/all/0/1\">Gabriele Cimolino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rivest_F/0/1/0/all/0/1\">Francois Rivest</a>",
          "description": "Animals can quickly learn the timing of events with fixed intervals and their\nrate of acquisition does not depend on the length of the interval. In contrast,\nrecurrent neural networks that use gradient based learning have difficulty\npredicting the timing of events that depend on stimulus that occurred long ago.\nWe present the latent time-adaptive drift-diffusion model (LTDDM), an extension\nto the time-adaptive drift-diffusion model (TDDM), a model for animal learning\nof timing that exhibits behavioural properties consistent with experimental\ndata from animals. The performance of LTDDM is compared to that of a state of\nthe art long short-term memory (LSTM) recurrent neural network across three\ntiming tasks. Differences in the relative performance of these two models is\ndiscussed and it is shown how LTDDM can learn these events time series orders\nof magnitude faster than recurrent neural networks.",
          "link": "http://arxiv.org/abs/2106.02742",
          "publishedOn": "2021-06-08T02:20:23.458Z",
          "wordCount": 553,
          "title": "Latent Time-Adaptive Drift-Diffusion Model. (arXiv:2106.02742v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02681",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schmidgall_S/0/1/0/all/0/1\">Samuel Schmidgall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ashkanazy_J/0/1/0/all/0/1\">Julia Ashkanazy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lawson_W/0/1/0/all/0/1\">Wallace Lawson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hays_J/0/1/0/all/0/1\">Joe Hays</a>",
          "description": "The adaptive changes in synaptic efficacy that occur between spiking neurons\nhave been demonstrated to play a critical role in learning for biological\nneural networks. Despite this source of inspiration, many learning focused\napplications using Spiking Neural Networks (SNNs) retain static synaptic\nconnections, preventing additional learning after the initial training period.\nHere, we introduce a framework for simultaneously learning the underlying\nfixed-weights and the rules governing the dynamics of synaptic plasticity and\nneuromodulated synaptic plasticity in SNNs through gradient descent. We further\ndemonstrate the capabilities of this framework on a series of challenging\nbenchmarks, learning the parameters of several plasticity rules including BCM,\nOja's, and their respective set of neuromodulatory variants. The experimental\nresults display that SNNs augmented with differentiable plasticity are\nsufficient for solving a set of challenging temporal learning tasks that a\ntraditional SNN fails to solve, even in the presence of significant noise.\nThese networks are also shown to be capable of producing locomotion on a\nhigh-dimensional robotic learning task, where near-minimal degradation in\nperformance is observed in the presence of novel conditions not seen during the\ninitial training period.",
          "link": "http://arxiv.org/abs/2106.02681",
          "publishedOn": "2021-06-08T02:20:23.220Z",
          "wordCount": 615,
          "title": "SpikePropamine: Differentiable Plasticity in Spiking Neural Networks. (arXiv:2106.02681v1 [cs.NE])"
        },
        {
          "id": "http://arxiv.org/abs/2104.09435",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_H/0/1/0/all/0/1\">Hyoungjun Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Na_M/0/1/0/all/0/1\">Myeongsu Na</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1\">Bumju Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Soohyun Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1\">Ki Hean Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Sunghoe Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jong Chul Ye</a>",
          "description": "Volumetric imaging by fluorescence microscopy is often limited by anisotropic\nspatial resolution from inferior axial resolution compared to the lateral\nresolution. To address this problem, here we present a deep-learning-enabled\nunsupervised super-resolution technique that enhances anisotropic images in\nvolumetric fluorescence microscopy. In contrast to the existing deep learning\napproaches that require matched high-resolution target volume images, our\nmethod greatly reduces the effort to put into practice as the training of a\nnetwork requires as little as a single 3D image stack, without a priori\nknowledge of the image formation process, registration of training data, or\nseparate acquisition of target data. This is achieved based on the optimal\ntransport driven cycle-consistent generative adversarial network that learns\nfrom an unpaired matching between high-resolution 2D images in lateral image\nplane and low-resolution 2D images in the other planes. Using fluorescence\nconfocal microscopy and light-sheet microscopy, we demonstrate that the trained\nnetwork not only enhances axial resolution, but also restores suppressed visual\ndetails between the imaging planes and removes imaging artifacts.",
          "link": "http://arxiv.org/abs/2104.09435",
          "publishedOn": "2021-06-08T02:20:23.214Z",
          "wordCount": 651,
          "title": "Deep learning enables reference-free isotropic super-resolution for volumetric fluorescence microscopy. (arXiv:2104.09435v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.11070",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shenoy_A/0/1/0/all/0/1\">Ashish Shenoy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bodapati_S/0/1/0/all/0/1\">Sravan Bodapati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sunkara_M/0/1/0/all/0/1\">Monica Sunkara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ronanki_S/0/1/0/all/0/1\">Srikanth Ronanki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirchhoff_K/0/1/0/all/0/1\">Katrin Kirchhoff</a>",
          "description": "Neural Language Models (NLM), when trained and evaluated with context\nspanning multiple utterances, have been shown to consistently outperform both\nconventional n-gram language models and NLMs that use limited context. In this\npaper, we investigate various techniques to incorporate turn based context\nhistory into both recurrent (LSTM) and Transformer-XL based NLMs. For recurrent\nbased NLMs, we explore context carry over mechanism and feature based\naugmentation, where we incorporate other forms of contextual information such\nas bot response and system dialogue acts as classified by a Natural Language\nUnderstanding (NLU) model. To mitigate the sharp nearby, fuzzy far away problem\nwith contextual NLM, we propose the use of attention layer over lexical\nmetadata to improve feature based augmentation. Additionally, we adapt our\ncontextual NLM towards user provided on-the-fly speech patterns by leveraging\nencodings from a large pre-trained masked language model and performing fusion\nwith a Transformer-XL based NLM. We test our proposed models using N-best\nrescoring of ASR hypotheses of task-oriented dialogues and also evaluate on\ndownstream NLU tasks such as intent classification and slot labeling. The best\nperforming model shows a relative WER between 1.6% and 9.1% and a slot labeling\nF1 score improvement of 4% over non-contextual baselines.",
          "link": "http://arxiv.org/abs/2104.11070",
          "publishedOn": "2021-06-08T02:20:23.207Z",
          "wordCount": 676,
          "title": "Adapting Long Context NLM for ASR Rescoring in Conversational Agents. (arXiv:2104.11070v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.08911",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Toreini_E/0/1/0/all/0/1\">Ehsan Toreini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aitken_M/0/1/0/all/0/1\">Mhairi Aitken</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coopamootoo_K/0/1/0/all/0/1\">Kovila P. L. Coopamootoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elliott_K/0/1/0/all/0/1\">Karen Elliott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zelaya_V/0/1/0/all/0/1\">Vladimiro Gonzalez Zelaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Missier_P/0/1/0/all/0/1\">Paolo Missier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_M/0/1/0/all/0/1\">Magdalene Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moorsel_A/0/1/0/all/0/1\">Aad van Moorsel</a>",
          "description": "Concerns about the societal impact of AI-based services and systems has\nencouraged governments and other organisations around the world to propose AI\npolicy frameworks to address fairness, accountability, transparency and related\ntopics. To achieve the objectives of these frameworks, the data and software\nengineers who build machine-learning systems require knowledge about a variety\nof relevant supporting tools and techniques. In this paper we provide an\noverview of technologies that support building trustworthy machine learning\nsystems, i.e., systems whose properties justify that people place trust in\nthem. We argue that four categories of system properties are instrumental in\nachieving the policy objectives, namely fairness, explainability, auditability\nand safety & security (FEAS). We discuss how these properties need to be\nconsidered across all stages of the machine learning life cycle, from data\ncollection through run-time model inference. As a consequence, we survey in\nthis paper the main technologies with respect to all four of the FEAS\nproperties, for data-centric as well as model-centric stages of the machine\nlearning system life cycle. We conclude with an identification of open research\nproblems, with a particular focus on the connection between trustworthy machine\nlearning technologies and their implications for individuals and society.",
          "link": "http://arxiv.org/abs/2007.08911",
          "publishedOn": "2021-06-08T02:20:23.184Z",
          "wordCount": 702,
          "title": "Technologies for Trustworthy Machine Learning: A Survey in a Socio-Technical Context. (arXiv:2007.08911v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.11455",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1\">Heng Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tonghan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiayuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1\">Chi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chongjie Zhang</a>",
          "description": "How cooperation emerges is a long-standing and interdisciplinary problem.\nGame-theoretical studies on social dilemmas reveal that altruistic incentives\nare critical to the emergence of cooperation but their analyses are limited to\nstateless games. For more realistic scenarios, multi-agent reinforcement\nlearning has been used to study sequential social dilemmas (SSDs). Recent works\nshow that learning to incentivize other agents can promote cooperation in SSDs.\nHowever, we find that, with these incentivizing mechanisms, the team\ncooperation level does not converge and regularly oscillates between\ncooperation and defection during learning. We show that a second-order social\ndilemma resulting from the incentive mechanisms is the main reason for such\nfragile cooperation. We formally analyze the dynamics of second-order social\ndilemmas and find that a typical tendency of humans, called homophily, provides\na promising solution. We propose a novel learning framework to encourage\nhomophilic incentives and show that it achieves stable cooperation in both SSDs\nof public goods and tragedy of the commons.",
          "link": "http://arxiv.org/abs/2104.11455",
          "publishedOn": "2021-06-08T02:20:23.178Z",
          "wordCount": 634,
          "title": "Birds of a Feather Flock Together: A Close Look at Cooperation Emergence via Multi-Agent RL. (arXiv:2104.11455v2 [cs.MA] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1911.07255",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Boyarski_A/0/1/0/all/0/1\">Amit Boyarski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vedula_S/0/1/0/all/0/1\">Sanketh Vedula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bronstein_A/0/1/0/all/0/1\">Alex Bronstein</a>",
          "description": "Deep Matrix Factorization (DMF) is an emerging approach to the problem of\nmatrix completion. Recent works have established that gradient descent applied\nto a DMF model induces an implicit regularization on the rank of the recovered\nmatrix. In this work we interpret the DMF model through the lens of spectral\ngeometry. This allows us to incorporate explicit regularization without\nbreaking the DMF structure, thus enjoying the best of both worlds. In\nparticular, we focus on matrix completion problems with underlying geometric or\ntopological relations between the rows and/or columns. Such relations are\nprevalent in matrix completion problems that arise in many applications, such\nas recommender systems and drug-target interaction. Our contributions enable\nDMF models to exploit these relations, and make them competitive on real\nbenchmarks, while exhibiting one of the first successful applications of deep\nlinear networks.",
          "link": "http://arxiv.org/abs/1911.07255",
          "publishedOn": "2021-06-08T02:20:23.171Z",
          "wordCount": 615,
          "title": "Spectral Geometric Matrix Completion. (arXiv:1911.07255v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02757",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1\">Ching-An Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolobov_A/0/1/0/all/0/1\">Andrey Kolobov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swaminathan_A/0/1/0/all/0/1\">Adith Swaminathan</a>",
          "description": "We provide a framework for accelerating reinforcement learning (RL)\nalgorithms by heuristics constructed from domain knowledge or offline data.\nTabula rasa RL algorithms require environment interactions or computation that\nscales with the horizon of the sequential decision-making task. Using our\nframework, we show how heuristic-guided RL induces a much shorter-horizon\nsubproblem that provably solves the original task. Our framework can be viewed\nas a horizon-based regularization for controlling bias and variance in RL under\na finite interaction budget. On the theoretical side, we characterize\nproperties of a good heuristic and its impact on RL acceleration. In\nparticular, we introduce the novel concept of an \"improvable heuristic\" -- a\nheuristic that allows an RL agent to extrapolate beyond its prior knowledge. On\nthe empirical side, we instantiate our framework to accelerate several\nstate-of-the-art algorithms in simulated robotic control tasks and procedurally\ngenerated games. Our framework complements the rich literature on warm-starting\nRL with expert demonstrations or exploratory datasets, and introduces a\nprincipled method for injecting prior knowledge into RL.",
          "link": "http://arxiv.org/abs/2106.02757",
          "publishedOn": "2021-06-08T02:20:23.164Z",
          "wordCount": 584,
          "title": "Heuristic-Guided Reinforcement Learning. (arXiv:2106.02757v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.09050",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Strypsteen_T/0/1/0/all/0/1\">Thomas Strypsteen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bertrand_A/0/1/0/all/0/1\">Alexander Bertrand</a>",
          "description": "Many electroencephalography (EEG) applications rely on channel selection\nmethods to remove the least informative channels, e.g., to reduce the amount of\nelectrodes to be mounted, to decrease the computational load, or to reduce\noverfitting effects and improve performance. Wrapper-based channel selection\nmethods aim to match the channel selection step to the target model, yet they\nrequire to re-train the model multiple times on different candidate channel\nsubsets, which often leads to an unacceptably high computational cost,\nespecially when said model is a (deep) neural network. To alleviate this, we\npropose a framework to embed the EEG channel selection in the neural network\nitself to jointly learn the network weights and optimal channels in an\nend-to-end manner by traditional backpropagation algorithms. We deal with the\ndiscrete nature of this new optimization problem by employing continuous\nrelaxations of the discrete channel selection parameters based on the\nGumbel-softmax trick. We also propose a regularization method that discourages\nselecting channels more than once. This generic approach is evaluated on two\ndifferent EEG tasks: motor imagery brain-computer interfaces and auditory\nattention decoding. The results demonstrate that our framework is generally\napplicable, while being competitive with state-of-the art EEG channel selection\nmethods, tailored to these tasks.",
          "link": "http://arxiv.org/abs/2102.09050",
          "publishedOn": "2021-06-08T02:20:23.158Z",
          "wordCount": 664,
          "title": "End-to-end learnable EEG channel selection for deep neural networks with Gumbel-softmax. (arXiv:2102.09050v3 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02892",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1\">Zhan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_S/0/1/0/all/0/1\">Subhrajit Bhattacharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Leiming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blum_R/0/1/0/all/0/1\">Rick S. Blum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1\">Alejandro Ribeiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sadler_B/0/1/0/all/0/1\">Brian M. Sadler</a>",
          "description": "Graph neural networks (GNNs) are processing architectures that exploit graph\nstructural information to model representations from network data. Despite\ntheir success, GNNs suffer from sub-optimal generalization performance given\nlimited training data, referred to as over-fitting. This paper proposes\nTopology Adaptive Edge Dropping (TADropEdge) method as an adaptive data\naugmentation technique to improve generalization performance and learn robust\nGNN models. We start by explicitly analyzing how random edge dropping increases\nthe data diversity during training, while indicating i.i.d. edge dropping does\nnot account for graph structural information and could result in noisy\naugmented data degrading performance. To overcome this issue, we consider graph\nconnectivity as the key property that captures graph topology. TADropEdge\nincorporates this factor into random edge dropping such that the edge-dropped\nsubgraphs maintain similar topology as the underlying graph, yielding more\nsatisfactory data augmentation. In particular, TADropEdge first leverages the\ngraph spectrum to assign proper weights to graph edges, which represent their\ncriticality for establishing the graph connectivity. It then normalizes the\nedge weights and drops graph edges adaptively based on their normalized\nweights. Besides improving generalization performance, TADropEdge reduces\nvariance for efficient training and can be applied as a generic method modular\nto different GNN models. Intensive experiments on real-life and synthetic\ndatasets corroborate theory and verify the effectiveness of the proposed\nmethod.",
          "link": "http://arxiv.org/abs/2106.02892",
          "publishedOn": "2021-06-08T02:20:23.139Z",
          "wordCount": 655,
          "title": "Training Robust Graph Neural Networks with Topology Adaptive Edge Dropping. (arXiv:2106.02892v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.03584",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Scheinker_A/0/1/0/all/0/1\">Alexander Scheinker</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cropp_F/0/1/0/all/0/1\">Frederick Cropp</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Paiagua_S/0/1/0/all/0/1\">Sergio Paiagua</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Filippetto_D/0/1/0/all/0/1\">Daniele Filippetto</a>",
          "description": "Powerful deep learning tools, such as convolutional neural networks (CNN),\nare able to learn the input-output relationships of large complicated systems\ndirectly from data. Encoder-decoder deep CNNs are able to extract features\ndirectly from images, mix them with scalar inputs within a general\nlow-dimensional latent space, and then generate new complex 2D outputs which\nrepresent complex physical phenomenon. One important challenge faced by deep\nlearning methods is large non-stationary systems whose characteristics change\nquickly with time for which re-training is not feasible. In this paper we\npresent a method for adaptive tuning of the low-dimensional latent space of\ndeep encoder-decoder style CNNs based on real-time feedback to quickly\ncompensate for unknown and fast distribution shifts. We demonstrate our\napproach for predicting the properties of a time-varying charged particle beam\nin a particle accelerator whose components (accelerating electric fields and\nfocusing magnetic fields) are also quickly changing with time.",
          "link": "http://arxiv.org/abs/2105.03584",
          "publishedOn": "2021-06-08T02:20:23.132Z",
          "wordCount": 616,
          "title": "Adaptive Latent Space Tuning for Non-Stationary Distributions. (arXiv:2105.03584v4 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02768",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Pan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhichao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Que_M/0/1/0/all/0/1\">Maofei Que</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yao Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuzhilin_A/0/1/0/all/0/1\">Alexander Tuzhilin</a>",
          "description": "Cross domain recommender system constitutes a powerful method to tackle the\ncold-start and sparsity problem by aggregating and transferring user\npreferences across multiple category domains. Therefore, it has great potential\nto improve click-through-rate prediction performance in online commerce\nplatforms having many domains of products. While several cross domain\nsequential recommendation models have been proposed to leverage information\nfrom a source domain to improve CTR predictions in a target domain, they did\nnot take into account bidirectional latent relations of user preferences across\nsource-target domain pairs. As such, they cannot provide enhanced cross-domain\nCTR predictions for both domains simultaneously. In this paper, we propose a\nnovel approach to cross-domain sequential recommendations based on the dual\nlearning mechanism that simultaneously transfers information between two\nrelated domains in an iterative manner until the learning process stabilizes.\nIn particular, the proposed Dual Attentive Sequential Learning (DASL) model\nconsists of two novel components Dual Embedding and Dual Attention, which\njointly establish the two-stage learning process: we first construct dual\nlatent embeddings that extract user preferences in both domains simultaneously,\nand subsequently provide cross-domain recommendations by matching the extracted\nlatent embeddings with candidate items through dual-attention learning\nmechanism. We conduct extensive offline experiments on three real-world\ndatasets to demonstrate the superiority of our proposed model, which\nsignificantly and consistently outperforms several state-of-the-art baselines\nacross all experimental settings. We also conduct an online A/B test at a major\nvideo streaming platform Alibaba-Youku, where our proposed model significantly\nimproves business performance over the latest production system in the company.",
          "link": "http://arxiv.org/abs/2106.02768",
          "publishedOn": "2021-06-08T02:20:23.125Z",
          "wordCount": 686,
          "title": "Dual Attentive Sequential Learning for Cross-Domain Click-Through Rate Prediction. (arXiv:2106.02768v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02923",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rhodes_T/0/1/0/all/0/1\">Travers Rhodes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Daniel D. Lee</a>",
          "description": "There have been many recent advances in representation learning; however,\nunsupervised representation learning can still struggle with model\nidentification issues. Variational Auto-Encoders (VAEs) and their extensions\nsuch as $\\beta$-VAEs have been shown to locally align latent variables with PCA\ndirections, which can help to improve model disentanglement under some\nconditions. Borrowing inspiration from Independent Component Analysis (ICA) and\nsparse coding, we propose applying an $L_1$ loss to the VAE's generative\nJacobian during training to encourage local latent variable alignment with\nindependent factors of variation in the data. We demonstrate our results on a\nvariety of datasets, giving qualitative and quantitative results using\ninformation theoretic and modularity measures that show our added $L_1$ cost\nencourages local axis alignment of the latent representation with individual\nfactors of variation.",
          "link": "http://arxiv.org/abs/2106.02923",
          "publishedOn": "2021-06-08T02:20:23.112Z",
          "wordCount": 560,
          "title": "Local Disentanglement in Variational Auto-Encoders Using Jacobian $L_1$ Regularization. (arXiv:2106.02923v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02901",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Si_J/0/1/0/all/0/1\">Jingjing Si</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_G/0/1/0/all/0/1\">Guoliang Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheng_Y/0/1/0/all/0/1\">Yinbo Cheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Enemali_G/0/1/0/all/0/1\">Godwin Enemali</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_C/0/1/0/all/0/1\">Chang Liu</a>",
          "description": "As an in situ combustion diagnostic tool, Tunable Diode Laser Absorption\nSpectroscopy (TDLAS) tomography has been widely used for imaging of\ntwo-dimensional temperature distributions in reactive flows. Compared with the\ncomputational tomographic algorithms, Convolutional Neural Networks (CNNs) have\nbeen proofed to be more robust and accurate for image reconstruction,\nparticularly in case of limited access of laser beams in the Region of Interest\n(RoI). In practice, flame in the RoI that requires to be reconstructed with\ngood spatial resolution is commonly surrounded by low-temperature background.\nAlthough the background is not of high interest, spectroscopic absorption still\nexists due to heat dissipation and gas convection. Therefore, we propose a\nPseudo-Inversed CNN (PI-CNN) for hierarchical temperature imaging that (a) uses\nefficiently the training and learning resources for temperature imaging in the\nRoI with good spatial resolution, and (b) reconstructs the less spatially\nresolved background temperature by adequately addressing the integrity of the\nspectroscopic absorption model. In comparison with the traditional CNN, the\nnewly introduced pseudo inversion of the RoI sensitivity matrix is more\npenetrating for revealing the inherent correlation between the projection data\nand the RoI to be reconstructed, thus prioritising the temperature imaging in\nthe RoI with high accuracy and high computational efficiency. In this paper,\nthe proposed algorithm was validated by both numerical simulation and lab-scale\nexperiment, indicating good agreement between the phantoms and the\nhigh-fidelity reconstructions.",
          "link": "http://arxiv.org/abs/2106.02901",
          "publishedOn": "2021-06-08T02:20:23.105Z",
          "wordCount": 686,
          "title": "Hierarchical Temperature Imaging Using Pseudo-Inversed Convolutional Neural Network Aided TDLAS Tomography. (arXiv:2106.02901v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02676",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Berlyand_L/0/1/0/all/0/1\">Leonid Berlyand</a>, <a href=\"http://arxiv.org/find/math/1/au:+Creese_R/0/1/0/all/0/1\">Robert Creese</a>, <a href=\"http://arxiv.org/find/math/1/au:+Jabin_P/0/1/0/all/0/1\">Pierre-Emmanuel Jabin</a>",
          "description": "We introduce two-scale loss functions for use in various gradient descent\nalgorithms applied to classification problems via deep neural networks. This\nnew method is generic in the sense that it can be applied to a wide range of\nmachine learning architectures, from deep neural networks to support vector\nmachines for example. These two-scale loss functions allow to focus the\ntraining onto objects in the training set which are not well classified. This\nleads to an increase in several measures of performance for\nappropriately-defined two-scale loss functions with respect to the more\nclassical cross-entropy when tested on traditional deep neural networks on the\nMNIST, CIFAR10, and CIFAR100 data-sets.",
          "link": "http://arxiv.org/abs/2106.02676",
          "publishedOn": "2021-06-08T02:20:23.083Z",
          "wordCount": 549,
          "title": "A novel multi-scale loss function for classification problems in machine learning. (arXiv:2106.02676v1 [math.NA])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02755",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Altschuler_J/0/1/0/all/0/1\">Jason M. Altschuler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parrilo_P/0/1/0/all/0/1\">Pablo A. Parrilo</a>",
          "description": "Low-rank approximation of kernels is a fundamental mathematical problem with\nwidespread algorithmic applications. Often the kernel is restricted to an\nalgebraic variety, e.g., in problems involving sparse or low-rank data. We show\nthat significantly better approximations are obtainable in this setting: the\nrank required to achieve a given error depends on the variety's dimension\nrather than the ambient dimension, which is typically much larger. This is true\nin both high-precision and high-dimensional regimes. Our results are presented\nfor smooth isotropic kernels, the predominant class of kernels used in\napplications. Our main technical insight is to approximate smooth kernels by\npolynomial kernels, and leverage two key properties of polynomial kernels that\nhold when they are restricted to a variety. First, their ranks decrease\nexponentially in the variety's co-dimension. Second, their maximum values are\ngoverned by their values over a small set of points. Together, our results\nprovide a general approach for exploiting (approximate) \"algebraic structure\"\nin datasets in order to efficiently solve large-scale data science problems.",
          "link": "http://arxiv.org/abs/2106.02755",
          "publishedOn": "2021-06-08T02:20:23.077Z",
          "wordCount": 592,
          "title": "Kernel approximation on algebraic varieties. (arXiv:2106.02755v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2011.10115",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stelzer_F/0/1/0/all/0/1\">Florian Stelzer</a> (1, 2 and 4), <a href=\"http://arxiv.org/find/cs/1/au:+Rohm_A/0/1/0/all/0/1\">Andr&#xe9; R&#xf6;hm</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Vicente_R/0/1/0/all/0/1\">Raul Vicente</a> (4), <a href=\"http://arxiv.org/find/cs/1/au:+Fischer_I/0/1/0/all/0/1\">Ingo Fischer</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Yanchuk_S/0/1/0/all/0/1\">Serhiy Yanchuk</a> (1) ((1) Institute of Mathematics, Technische Universit&#xe4;t Berlin, Germany, (2) Department of Mathematics, Humboldt-Universit&#xe4;t zu Berlin, Germany, (3) Instituto de F&#xed;sica Interdisciplinar y Sistemas Complejos, IFISC (UIB-CSIC), Spain, (4) Institute of Computer Science, University of Tartu, Estonia)",
          "description": "Deep neural networks are among the most widely applied machine learning tools\nshowing outstanding performance in a broad range of tasks. We present a method\nfor folding a deep neural network of arbitrary size into a single neuron with\nmultiple time-delayed feedback loops. This single-neuron deep neural network\ncomprises only a single nonlinearity and appropriately adjusted modulations of\nthe feedback signals. The network states emerge in time as a temporal unfolding\nof the neuron's dynamics. By adjusting the feedback-modulation within the\nloops, we adapt the network's connection weights. These connection weights are\ndetermined via a back-propagation algorithm, where both the delay-induced and\nlocal network connections must be taken into account. Our approach can fully\nrepresent standard Deep Neural Networks (DNN), encompasses sparse DNNs, and\nextends the DNN concept toward dynamical systems implementations. The new\nmethod, which we call Folded-in-time DNN (Fit-DNN), exhibits promising\nperformance in a set of benchmark tasks.",
          "link": "http://arxiv.org/abs/2011.10115",
          "publishedOn": "2021-06-08T02:20:23.071Z",
          "wordCount": 666,
          "title": "Deep Neural Networks using a Single Neuron: Folded-in-Time Architecture using Feedback-Modulated Delay Loops. (arXiv:2011.10115v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02890",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dinghuai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahuja_K/0/1/0/all/0/1\">Kartik Ahuja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yilun Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yisen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Courville_A/0/1/0/all/0/1\">Aaron Courville</a>",
          "description": "Can models with particular structure avoid being biased towards spurious\ncorrelation in out-of-distribution (OOD) generalization? Peters et al. (2016)\nprovides a positive answer for linear cases. In this paper, we use a functional\nmodular probing method to analyze deep model structures under OOD setting. We\ndemonstrate that even in biased models (which focus on spurious correlation)\nthere still exist unbiased functional subnetworks. Furthermore, we articulate\nand demonstrate the functional lottery ticket hypothesis: full network contains\na subnetwork that can achieve better OOD performance. We then propose Modular\nRisk Minimization to solve the subnetwork selection problem. Our algorithm\nlearns the subnetwork structure from a given dataset, and can be combined with\nany other OOD regularization methods. Experiments on various OOD generalization\ntasks corroborate the effectiveness of our method.",
          "link": "http://arxiv.org/abs/2106.02890",
          "publishedOn": "2021-06-08T02:20:23.061Z",
          "wordCount": 567,
          "title": "Can Subnetwork Structure be the Key to Out-of-Distribution Generalization?. (arXiv:2106.02890v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02867",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Renjue Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hanwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_P/0/1/0/all/0/1\">Pengfei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Cheng-Chao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1\">Aimin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_B/0/1/0/all/0/1\">Bai Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lijun Zhang</a>",
          "description": "In this paper, we propose a framework of filter-based ensemble of deep\nneuralnetworks (DNNs) to defend against adversarial attacks. The framework\nbuilds an ensemble of sub-models -- DNNs with differentiated preprocessing\nfilters. From the theoretical perspective of DNN robustness, we argue that\nunder the assumption of high quality of the filters, the weaker the\ncorrelations of the sensitivity of the filters are, the more robust the\nensemble model tends to be, and this is corroborated by the experiments of\ntransfer-based attacks. Correspondingly, we propose a principle that chooses\nthe specific filters with smaller Pearson correlation coefficients, which\nensures the diversity of the inputs received by DNNs, as well as the\neffectiveness of the entire framework against attacks. Our ensemble models are\nmore robust than those constructed by previous defense methods like adversarial\ntraining, and even competitive with the classical ensemble of adversarial\ntrained DNNs under adversarial attacks when the attacking radius is large.",
          "link": "http://arxiv.org/abs/2106.02867",
          "publishedOn": "2021-06-08T02:20:23.056Z",
          "wordCount": 588,
          "title": "Ensemble Defense with Data Diversity: Weak Correlation Implies Strong Robustness. (arXiv:2106.02867v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02748",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sayin_M/0/1/0/all/0/1\">Muhammed O. Sayin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaiqing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leslie_D/0/1/0/all/0/1\">David S. Leslie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basar_T/0/1/0/all/0/1\">Tamer Basar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozdaglar_A/0/1/0/all/0/1\">Asuman Ozdaglar</a>",
          "description": "We study multi-agent reinforcement learning (MARL) in infinite-horizon\ndiscounted zero-sum Markov games. We focus on the practical but challenging\nsetting of decentralized MARL, where agents make decisions without coordination\nby a centralized controller, but only based on their own payoffs and local\nactions executed. The agents need not observe the opponent's actions or\npayoffs, possibly being even oblivious to the presence of the opponent, nor be\naware of the zero-sum structure of the underlying game, a setting also referred\nto as radically uncoupled in the literature of learning in games. In this\npaper, we develop for the first time a radically uncoupled Q-learning dynamics\nthat is both rational and convergent: the learning dynamics converges to the\nbest response to the opponent's strategy when the opponent follows an\nasymptotically stationary strategy; the value function estimates converge to\nthe payoffs at a Nash equilibrium when both agents adopt the dynamics. The key\nchallenge in this decentralized setting is the non-stationarity of the learning\nenvironment from an agent's perspective, since both her own payoffs and the\nsystem evolution depend on the actions of other agents, and each agent adapts\ntheir policies simultaneously and independently. To address this issue, we\ndevelop a two-timescale learning dynamics where each agent updates her local\nQ-function and value function estimates concurrently, with the latter happening\nat a slower timescale.",
          "link": "http://arxiv.org/abs/2106.02748",
          "publishedOn": "2021-06-08T02:20:23.040Z",
          "wordCount": 665,
          "title": "Decentralized Q-Learning in Zero-sum Markov Games. (arXiv:2106.02748v1 [cs.GT])"
        },
        {
          "id": "http://arxiv.org/abs/2102.06790",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianlong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_Y/0/1/0/all/0/1\">Yongduo Sui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xuxi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Aston Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>",
          "description": "With graphs rapidly growing in size and deeper graph neural networks (GNNs)\nemerging, the training and inference of GNNs become increasingly expensive.\nExisting network weight pruning algorithms cannot address the main space and\ncomputational bottleneck in GNNs, caused by the size and connectivity of the\ngraph. To this end, this paper first presents a unified GNN sparsification\n(UGS) framework that simultaneously prunes the graph adjacency matrix and the\nmodel weights, for effectively accelerating GNN inference on large-scale\ngraphs. Leveraging this new tool, we further generalize the recently popular\nlottery ticket hypothesis to GNNs for the first time, by defining a graph\nlottery ticket (GLT) as a pair of core sub-dataset and sparse sub-network,\nwhich can be jointly identified from the original GNN and the full dense graph\nby iteratively applying UGS. Like its counterpart in convolutional neural\nnetworks, GLT can be trained in isolation to match the performance of training\nwith the full model and graph, and can be drawn from both randomly initialized\nand self-supervised pre-trained GNNs. Our proposal has been experimentally\nverified across various GNN architectures and diverse tasks, on both\nsmall-scale graph datasets (Cora, Citeseer and PubMed), and large-scale\ndatasets from the challenging Open Graph Benchmark (OGB). Specifically, for\nnode classification, our found GLTs achieve the same accuracies with 20%~98%\nMACs saving on small graphs and 25%~85% MACs saving on large ones. For link\nprediction, GLTs lead to 48%~97% and 70% MACs saving on small and large graph\ndatasets, respectively, without compromising predictive performance. Codes\navailable at https://github.com/VITA-Group/Unified-LTH-GNN.",
          "link": "http://arxiv.org/abs/2102.06790",
          "publishedOn": "2021-06-08T02:20:23.033Z",
          "wordCount": 718,
          "title": "A Unified Lottery Ticket Hypothesis for Graph Neural Networks. (arXiv:2102.06790v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02796",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhadane_S/0/1/0/all/0/1\">Sourbh Bhadane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wagner_A/0/1/0/all/0/1\">Aaron B. Wagner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Acharya_J/0/1/0/all/0/1\">Jayadev Acharya</a>",
          "description": "We consider a linear autoencoder in which the latent variables are quantized,\nor corrupted by noise, and the constraint is Schur-concave in the set of latent\nvariances. Although finding the optimal encoder/decoder pair for this setup is\na nonconvex optimization problem, we show that decomposing the source into its\nprincipal components is optimal. If the constraint is strictly Schur-concave\nand the empirical covariance matrix has only simple eigenvalues, then any\noptimal encoder/decoder must decompose the source in this way. As one\napplication, we consider a strictly Schur-concave constraint that estimates the\nnumber of bits needed to represent the latent variables under fixed-rate\nencoding, a setup that we call \\emph{Principal Bit Analysis (PBA)}. This yields\na practical, general-purpose, fixed-rate compressor that outperforms existing\nalgorithms. As a second application, we show that a prototypical\nautoencoder-based variable-rate compressor is guaranteed to decompose the\nsource into its principal components.",
          "link": "http://arxiv.org/abs/2106.02796",
          "publishedOn": "2021-06-08T02:20:23.025Z",
          "wordCount": 581,
          "title": "Principle Bit Analysis: Autoencoding with Schur-Concave Loss. (arXiv:2106.02796v1 [cs.IT])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02743",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_C/0/1/0/all/0/1\">Chaoyang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ceyani_E/0/1/0/all/0/1\">Emir Ceyani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balasubramanian_K/0/1/0/all/0/1\">Keshav Balasubramanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Annavaram_M/0/1/0/all/0/1\">Murali Annavaram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avestimehr_S/0/1/0/all/0/1\">Salman Avestimehr</a>",
          "description": "Graph Neural Networks (GNNs) are the first choice methods for graph machine\nlearning problems thanks to their ability to learn state-of-the-art level\nrepresentations from graph-structured data. However, centralizing a massive\namount of real-world graph data for GNN training is prohibitive due to\nuser-side privacy concerns, regulation restrictions, and commercial\ncompetition. Federated Learning is the de-facto standard for collaborative\ntraining of machine learning models over many distributed edge devices without\nthe need for centralization. Nevertheless, training graph neural networks in a\nfederated setting is vaguely defined and brings statistical and systems\nchallenges. This work proposes SpreadGNN, a novel multi-task federated training\nframework capable of operating in the presence of partial labels and absence of\na central server for the first time in the literature. SpreadGNN extends\nfederated multi-task learning to realistic serverless settings for GNNs, and\nutilizes a novel optimization algorithm with a convergence guarantee,\nDecentralized Periodic Averaging SGD (DPA-SGD), to solve decentralized\nmulti-task learning problems. We empirically demonstrate the efficacy of our\nframework on a variety of non-I.I.D. distributed graph-level molecular property\nprediction datasets with partial labels. Our results show that SpreadGNN\noutperforms GNN models trained over a central server-dependent federated\nlearning system, even in constrained topologies. The source code is publicly\navailable at https://github.com/FedML-AI/SpreadGNN",
          "link": "http://arxiv.org/abs/2106.02743",
          "publishedOn": "2021-06-08T02:20:23.019Z",
          "wordCount": 643,
          "title": "SpreadGNN: Serverless Multi-task Federated Learning for Graph Neural Networks. (arXiv:2106.02743v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.04230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grathwohl_W/0/1/0/all/0/1\">Will Grathwohl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kelly_J/0/1/0/all/0/1\">Jacob Kelly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashemi_M/0/1/0/all/0/1\">Milad Hashemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Norouzi_M/0/1/0/all/0/1\">Mohammad Norouzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swersky_K/0/1/0/all/0/1\">Kevin Swersky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duvenaud_D/0/1/0/all/0/1\">David Duvenaud</a>",
          "description": "Energy-Based Models (EBMs) present a flexible and appealing way to represent\nuncertainty. Despite recent advances, training EBMs on high-dimensional data\nremains a challenging problem as the state-of-the-art approaches are costly,\nunstable, and require considerable tuning and domain expertise to apply\nsuccessfully. In this work, we present a simple method for training EBMs at\nscale which uses an entropy-regularized generator to amortize the MCMC sampling\ntypically used in EBM training. We improve upon prior MCMC-based entropy\nregularization methods with a fast variational approximation. We demonstrate\nthe effectiveness of our approach by using it to train tractable likelihood\nmodels. Next, we apply our estimator to the recently proposed Joint Energy\nModel (JEM), where we match the original performance with faster and stable\ntraining. This allows us to extend JEM models to semi-supervised classification\non tabular data from a variety of continuous domains.",
          "link": "http://arxiv.org/abs/2010.04230",
          "publishedOn": "2021-06-08T02:20:23.012Z",
          "wordCount": 623,
          "title": "No MCMC for me: Amortized sampling for fast and stable training of energy-based models. (arXiv:2010.04230v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02803",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Li_T/0/1/0/all/0/1\">Tianxi Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Le_C/0/1/0/all/0/1\">Can M. Le</a>",
          "description": "Networks analysis has been commonly used to study the interactions between\nunits of complex systems. One problem of particular interest is learning the\nnetwork's underlying connection pattern given a single and noisy instantiation.\nWhile many methods have been proposed to address this problem in recent years,\nthey usually assume that the true model belongs to a known class, which is not\nverifiable in most real-world applications. Consequently, network modeling\nbased on these methods either suffers from model misspecification or relies on\nadditional model selection procedures that are not well understood in theory\nand can potentially be unstable in practice. To address this difficulty, we\npropose a mixing strategy that leverages available arbitrary models to improve\ntheir individual performances. The proposed method is computationally efficient\nand almost tuning-free; thus, it can be used as an off-the-shelf method for\nnetwork modeling. We show that the proposed method performs equally well as the\noracle estimate when the true model is included as individual candidates. More\nimportantly, the method remains robust and outperforms all current estimates\neven when the models are misspecified. Extensive simulation examples are used\nto verify the advantage of the proposed mixing method. Evaluation of link\nprediction performance on 385 real-world networks from six domains also\ndemonstrates the universal competitiveness of the mixing method across multiple\ndomains.",
          "link": "http://arxiv.org/abs/2106.02803",
          "publishedOn": "2021-06-08T02:20:22.994Z",
          "wordCount": 648,
          "title": "Network Estimation by Mixing: Adaptivity and More. (arXiv:2106.02803v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2010.09610",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nichani_E/0/1/0/all/0/1\">Eshaan Nichani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radhakrishnan_A/0/1/0/all/0/1\">Adityanarayanan Radhakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uhler_C/0/1/0/all/0/1\">Caroline Uhler</a>",
          "description": "Recent works have demonstrated that increasing model capacity through width\nin over-parameterized neural networks leads to a decrease in test risk. For\nneural networks, however, model capacity can also be increased through depth,\nyet understanding the impact of increasing depth on test risk remains an open\nquestion. In this work, we demonstrate that the test risk of over-parameterized\nconvolutional networks is a U-shaped curve (i.e. monotonically decreasing, then\nincreasing) with increasing depth. We first provide empirical evidence for this\nphenomenon via image classification experiments using both ResNets and the\nconvolutional neural tangent kernel (CNTK). We then present a novel linear\nregression framework for characterizing the impact of depth on test risk, and\nshow that increasing depth leads to a U-shaped test risk for the linear CNTK.\nIn particular, we prove that the linear CNTK corresponds to a depth-dependent\nlinear transformation on the original space and characterize properties of this\ntransformation. We then analyze over-parameterized linear regression under\narbitrary linear transformations and, in simplified settings, provably identify\nthe depths which minimize each of the bias and variance terms of the test risk.",
          "link": "http://arxiv.org/abs/2010.09610",
          "publishedOn": "2021-06-08T02:20:22.987Z",
          "wordCount": 646,
          "title": "Increasing Depth Leads to U-Shaped Test Risk in Over-parameterized Convolutional Networks. (arXiv:2010.09610v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02852",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1\">Yehui Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1\">Kai Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yunhe Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jianyuan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>",
          "description": "This paper studies the efficiency problem for visual transformers by\nexcavating redundant calculation in given networks. The recent transformer\narchitecture has demonstrated its effectiveness for achieving excellent\nperformance on a series of computer vision tasks. However, similar to that of\nconvolutional neural networks, the huge computational cost of vision\ntransformers is still a severe issue. Considering that the attention mechanism\naggregates different patches layer-by-layer, we present a novel patch slimming\napproach that discards useless patches in a top-down paradigm. We first\nidentify the effective patches in the last layer and then use them to guide the\npatch selection process of previous layers. For each layer, the impact of a\npatch on the final output feature is approximated and patches with less impact\nwill be removed. Experimental results on benchmark datasets demonstrate that\nthe proposed method can significantly reduce the computational costs of vision\ntransformers without affecting their performances. For example, over 45% FLOPs\nof the ViT-Ti model can be reduced with only 0.2% top-1 accuracy drop on the\nImageNet dataset.",
          "link": "http://arxiv.org/abs/2106.02852",
          "publishedOn": "2021-06-08T02:20:22.975Z",
          "wordCount": 606,
          "title": "Patch Slimming for Efficient Vision Transformers. (arXiv:2106.02852v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02808",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Chin-Wei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_J/0/1/0/all/0/1\">Jae Hyun Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Courville_A/0/1/0/all/0/1\">Aaron Courville</a>",
          "description": "Discrete-time diffusion-based generative models and score matching methods\nhave shown promising results in modeling high-dimensional image data. Recently,\nSong et al. (2021) show that diffusion processes that transform data into noise\ncan be reversed via learning the score function, i.e. the gradient of the\nlog-density of the perturbed data. They propose to plug the learned score\nfunction into an inverse formula to define a generative diffusion process.\nDespite the empirical success, a theoretical underpinning of this procedure is\nstill lacking. In this work, we approach the (continuous-time) generative\ndiffusion directly and derive a variational framework for likelihood\nestimation, which includes continuous-time normalizing flows as a special case,\nand can be seen as an infinitely deep variational autoencoder. Under this\nframework, we show that minimizing the score-matching loss is equivalent to\nmaximizing a lower bound of the likelihood of the plug-in reverse SDE proposed\nby Song et al. (2021), bridging the theoretical gap.",
          "link": "http://arxiv.org/abs/2106.02808",
          "publishedOn": "2021-06-08T02:20:22.968Z",
          "wordCount": 579,
          "title": "A Variational Perspective on Diffusion-Based Generative Models and Score Matching. (arXiv:2106.02808v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02720",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Woodworth_B/0/1/0/all/0/1\">Blake Woodworth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srebro_N/0/1/0/all/0/1\">Nathan Srebro</a>",
          "description": "We present and analyze an algorithm for optimizing smooth and convex or\nstrongly convex objectives using minibatch stochastic gradient estimates. The\nalgorithm is optimal with respect to its dependence on both the minibatch size\nand minimum expected loss simultaneously. This improves over the optimal method\nof Lan (2012), which is insensitive to the minimum expected loss; over the\noptimistic acceleration of Cotter et al. (2011), which has suboptimal\ndependence on the minibatch size; and over the algorithm of Liu and Belkin\n(2018), which is limited to least squares problems and is also similarly\nsuboptimal with respect to the minibatch size. Applied to interpolation\nlearning, the improvement over Cotter et al. and Liu and Belkin translates to a\nlinear, rather than square-root, parallelization speedup.",
          "link": "http://arxiv.org/abs/2106.02720",
          "publishedOn": "2021-06-08T02:20:22.953Z",
          "wordCount": 559,
          "title": "An Even More Optimal Stochastic Optimization Algorithm: Minibatching and Interpolation Learning. (arXiv:2106.02720v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.02507",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1\">Damai Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1\">Jing Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_S/0/1/0/all/0/1\">Shuang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1\">Baobao Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_Z/0/1/0/all/0/1\">Zhifang Sui</a>",
          "description": "Document-level Relation Extraction (RE) requires extracting relations\nexpressed within and across sentences. Recent works show that graph-based\nmethods, usually constructing a document-level graph that captures\ndocument-aware interactions, can obtain useful entity representations thus\nhelping tackle document-level RE. These methods either focus more on the entire\ngraph, or pay more attention to a part of the graph, e.g., paths between the\ntarget entity pair. However, we find that document-level RE may benefit from\nfocusing on both of them simultaneously. Therefore, to obtain more\ncomprehensive entity representations, we propose the Coarse-to-Fine Entity\nRepresentation model (CFER) that adopts a coarse-to-fine strategy involving two\nphases. First, CFER uses graph neural networks to integrate global information\nin the entire graph at a coarse level. Next, CFER utilizes the global\ninformation as a guidance to selectively aggregate path information between the\ntarget entity pair at a fine level. In classification, we combine the entity\nrepresentations from both two levels into more comprehensive representations\nfor relation extraction. Experimental results on two document-level RE\ndatasets, DocRED and CDR, show that CFER outperforms existing models and is\nrobust to the uneven label distribution.",
          "link": "http://arxiv.org/abs/2012.02507",
          "publishedOn": "2021-06-08T02:20:22.946Z",
          "wordCount": 647,
          "title": "Coarse-to-Fine Entity Representations for Document-level Relation Extraction. (arXiv:2012.02507v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.08115",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sonbhadra_S/0/1/0/all/0/1\">Sanjay Kumar Sonbhadra</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Agarwal_S/0/1/0/all/0/1\">Sonali Agarwal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nagabhushan_P/0/1/0/all/0/1\">P. Nagabhushan</a>",
          "description": "The infection of respiratory coronavirus disease 2019 (COVID-19) starts with\nthe upper respiratory tract and as the virus grows, the infection can progress\nto lungs and develop pneumonia. The conventional way of COVID-19 diagnosis is\nreverse transcription polymerase chain reaction (RT-PCR), which is less\nsensitive during early stages; especially if the patient is asymptomatic, which\nmay further cause more severe pneumonia. In this context, several deep learning\nmodels have been proposed to identify pulmonary infections using publicly\navailable chest X-ray (CXR) image datasets for early diagnosis, better\ntreatment and quick cure. In these datasets, presence of less number of\nCOVID-19 positive samples compared to other classes (normal, pneumonia and\nTuberculosis) raises the challenge for unbiased learning of deep learning\nmodels. All deep learning models opted class balancing techniques to solve this\nissue; which however should be avoided in any medical diagnosis process.\nMoreover, the deep learning models are also data hungry and need massive\ncomputation resources. Therefore for quicker diagnosis, this research proposes\na novel pinball loss function based one-class support vector machine\n(PB-OCSVM), that can work in presence of limited COVID-19 positive CXR samples\nwith objectives to maximize the learning efficiency and to minimize the false\npredictions. The performance of the proposed model is compared with\nconventional OCSVM and existing deep learning models, and the experimental\nresults prove that the proposed model outperformed over state-of-the-art\nmethods. To validate the robustness of the proposed model, experiments are also\nperformed with noisy CXR images and UCI benchmark datasets.",
          "link": "http://arxiv.org/abs/2010.08115",
          "publishedOn": "2021-06-08T02:20:22.935Z",
          "wordCount": 759,
          "title": "Pinball-OCSVM for early-stage COVID-19 diagnosis with limited posteroanterior chest X-ray images. (arXiv:2010.08115v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.07999",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yanlin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pu_G/0/1/0/all/0/1\">George Pu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiyao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaolin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">Dapeng Wu</a>",
          "description": "Current federated learning algorithms take tens of communication rounds\ntransmitting unwieldy model weights under ideal circumstances and hundreds when\ndata is poorly distributed. Inspired by recent work on dataset distillation and\ndistributed one-shot learning, we propose Distilled One-Shot Federated Learning\n(DOSFL) to significantly reduce the communication cost while achieving\ncomparable performance. In just one round, each client distills their private\ndataset, sends the synthetic data (e.g. images or sentences) to the server, and\ncollectively trains a global model. The distilled data look like noise and are\nonly useful to the specific model weights, i.e., become useless after the model\nupdates. With this weight-less and gradient-less design, the total\ncommunication cost of DOSFL is up to three orders of magnitude less than FedAvg\nwhile preserving between 93% to 99% performance of a centralized counterpart.\nAfterwards, clients could switch to traditional methods such as FedAvg to\nfinetune the last few percent to fit personalized local models with local\ndatasets. Through comprehensive experiments, we show the accuracy and\ncommunication performance of DOSFL on both vision and language tasks with\ndifferent models including CNN, LSTM, Transformer, etc. We demonstrate that an\neavesdropping attacker cannot properly train a good model using the leaked\ndistilled data, without knowing the initial model weights. DOSFL serves as an\ninexpensive method to quickly converge on a performant pre-trained model with\nless than 0.1% communication cost of traditional methods.",
          "link": "http://arxiv.org/abs/2009.07999",
          "publishedOn": "2021-06-08T02:20:22.918Z",
          "wordCount": 693,
          "title": "Distilled One-Shot Federated Learning. (arXiv:2009.07999v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02925",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1\">Yi Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldfarb_D/0/1/0/all/0/1\">Donald Goldfarb</a>",
          "description": "Despite the predominant use of first-order methods for training deep learning\nmodels, second-order methods, and in particular, natural gradient methods,\nremain of interest because of their potential for accelerating training through\nthe use of curvature information. Several methods with non-diagonal\npreconditioning matrices, including KFAC and Shampoo, have been proposed and\nshown to be effective. Based on the so-called tensor normal (TN) distribution,\nwe propose and analyze a brand new approximate natural gradient method, Tensor\nNormal Training (TNT), which like Shampoo, only requires knowledge on the shape\nof the training parameters. By approximating the probabilistically based Fisher\nmatrix, as opposed to the empirical Fisher matrix, our method uses the\nlayer-wise covariance of the sampling based gradient as the pre-conditioning\nmatrix. Moreover, the assumption that the sampling-based (tensor) gradient\nfollows a TN distribution, ensures that its covariance has a Kronecker\nseparable structure, which leads to a tractable approximation to the Fisher\nmatrix. Consequently, TNT's memory requirements and per-iteration computational\ncosts are only slightly higher than those for first-order methods. In our\nexperiments, TNT exhibited superior optimization performance to KFAC and\nShampoo, and to state-of-the-art first-order methods. Moreover, TNT\ndemonstrated its ability to generalize as well as these first-order methods,\nusing fewer epochs.",
          "link": "http://arxiv.org/abs/2106.02925",
          "publishedOn": "2021-06-08T02:20:22.909Z",
          "wordCount": 618,
          "title": "Tensor Normal Training for Deep Learning Models. (arXiv:2106.02925v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.14605",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bronzino_F/0/1/0/all/0/1\">Francesco Bronzino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmitt_P/0/1/0/all/0/1\">Paul Schmitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ayoubi_S/0/1/0/all/0/1\">Sara Ayoubi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyojoon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teixeira_R/0/1/0/all/0/1\">Renata Teixeira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feamster_N/0/1/0/all/0/1\">Nick Feamster</a>",
          "description": "Network management often relies on machine learning to make predictions about\nperformance and security from network traffic. Often, the representation of the\ntraffic is as important as the choice of the model. The features that the model\nrelies on, and the representation of those features, ultimately determine model\naccuracy, as well as where and whether the model can be deployed in practice.\nThus, the design and evaluation of these models ultimately requires\nunderstanding not only model accuracy but also the systems costs associated\nwith deploying the model in an operational network. Towards this goal, this\npaper develops a new framework and system that enables a joint evaluation of\nboth the conventional notions of machine learning performance (e.g., model\naccuracy) and the systems-level costs of different representations of network\ntraffic. We highlight these two dimensions for two practical network management\ntasks, video streaming quality inference and malware detection, to demonstrate\nthe importance of exploring different representations to find the appropriate\noperating point. We demonstrate the benefit of exploring a range of\nrepresentations of network traffic and present Traffic Refinery, a\nproof-of-concept implementation that both monitors network traffic at 10 Gbps\nand transforms traffic in real time to produce a variety of feature\nrepresentations for machine learning. Traffic Refinery both highlights this\ndesign space and makes it possible to explore different representations for\nlearning, balancing systems costs related to feature extraction and model\ntraining against model accuracy.",
          "link": "http://arxiv.org/abs/2010.14605",
          "publishedOn": "2021-06-08T02:20:22.898Z",
          "wordCount": 716,
          "title": "Traffic Refinery: Cost-Aware Data Representation for Machine Learning on Network Traffic. (arXiv:2010.14605v3 [cs.NI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.08924",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lun_X/0/1/0/all/0/1\">Xiangmin Lun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jia_S/0/1/0/all/0/1\">Shuyue Jia</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hou_Y/0/1/0/all/0/1\">Yimin Hou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_Y/0/1/0/all/0/1\">Yan Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>",
          "description": "Towards developing effective and efficient brain-computer interface (BCI)\nsystems, precise decoding of brain activity measured by electroencephalogram\n(EEG), is highly demanded. Traditional works classify EEG signals without\nconsidering the topological relationship among electrodes. However,\nneuroscience research has increasingly emphasized network patterns of brain\ndynamics. Thus, the Euclidean structure of electrodes might not adequately\nreflect the interaction between signals. To fill the gap, a novel deep learning\nframework based on the graph convolutional neural networks (GCNs) was presented\nto enhance the decoding performance of raw EEG signals during different types\nof motor imagery (MI) tasks while cooperating with the functional topological\nrelationship of electrodes. Based on the absolute Pearson's matrix of overall\nsignals, the graph Laplacian of EEG electrodes was built up. The GCNs-Net\nconstructed by graph convolutional layers learns the generalized features. The\nfollowed pooling layers reduce dimensionality, and the fully-connected softmax\nlayer derives the final prediction. The introduced approach has been shown to\nconverge for both personalized and group-wise predictions. It has achieved the\nhighest averaged accuracy, 93.056% and 88.57% (PhysioNet Dataset), 96.24% and\n80.89% (High Gamma Dataset), at the subject and group level, respectively,\ncompared with existing studies, which suggests adaptability and robustness to\nindividual variability. Moreover, the performance was stably reproducible among\nrepetitive experiments for cross-validation. To conclude, the GCNs-Net filters\nEEG signals based on the functional topological relationship, which manages to\ndecode relevant features for brain motor imagery.",
          "link": "http://arxiv.org/abs/2006.08924",
          "publishedOn": "2021-06-08T02:20:22.781Z",
          "wordCount": 700,
          "title": "GCNs-Net: A Graph Convolutional Neural Network Approach for Decoding Time-resolved EEG Motor Imagery Signals. (arXiv:2006.08924v2 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.14268",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_L/0/1/0/all/0/1\">Lei Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Granmo_O/0/1/0/all/0/1\">Ole-Christoffer Granmo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodwin_M/0/1/0/all/0/1\">Morten Goodwin</a>",
          "description": "The Tsetlin Machine (TM) is a recent machine learning algorithm with several\ndistinct properties, such as interpretability, simplicity, and\nhardware-friendliness. Although numerous empirical evaluations report on its\nperformance, the mathematical analysis of its convergence is still open. In\nthis article, we analyze the convergence of the TM with only one clause\ninvolved for classification. More specifically, we examine two basic logical\noperators, namely, the \"IDENTITY\"- and \"NOT\" operators. Our analysis reveals\nthat the TM, with just one clause, can converge correctly to the intended\nlogical operator, learning from training data over an infinite time horizon.\nBesides, it can capture arbitrarily rare patterns and select the most accurate\none when two candidate patterns are incompatible, by configuring a granularity\nparameter. The analysis of the convergence of the two basic operators lays the\nfoundation for analyzing other logical operators. These analyses altogether,\nfrom a mathematical perspective, provide new insights on why TMs have obtained\nstate-of-the-art performance on several pattern recognition problems.",
          "link": "http://arxiv.org/abs/2007.14268",
          "publishedOn": "2021-06-08T02:20:22.770Z",
          "wordCount": 632,
          "title": "On the Convergence of Tsetlin Machines for the IDENTITY- and NOT Operators. (arXiv:2007.14268v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02994",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1\">Alex Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cicek_S/0/1/0/all/0/1\">Safa Cicek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1\">Stefano Soatto</a>",
          "description": "We present a method for inferring dense depth maps from images and sparse\ndepth measurements by leveraging synthetic data to learn the association of\nsparse point clouds with dense natural shapes, and using the image as evidence\nto validate the predicted depth map. Our learned prior for natural shapes uses\nonly sparse depth as input, not images, so the method is not affected by the\ncovariate shift when attempting to transfer learned models from synthetic data\nto real ones. This allows us to use abundant synthetic data with ground truth\nto learn the most difficult component of the reconstruction process, which is\ntopology estimation, and use the image to refine the prediction based on\nphotometric evidence. Our approach uses fewer parameters than previous methods,\nyet, achieves the state of the art on both indoor and outdoor benchmark\ndatasets. Code available at:\nhttps://github.com/alexklwong/learning-topology-synthetic-data.",
          "link": "http://arxiv.org/abs/2106.02994",
          "publishedOn": "2021-06-08T02:20:22.729Z",
          "wordCount": 580,
          "title": "Learning Topology from Synthetic Data for Unsupervised Depth Completion. (arXiv:2106.02994v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02914",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yue Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1\">Yuan Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Luchan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1\">Yang Xiang</a>",
          "description": "Pruning is a model compression method that removes redundant parameters in\ndeep neural networks (DNNs) while maintaining accuracy. Most available filter\npruning methods require complex treatments such as iterative pruning, features\nstatistics/ranking, or additional optimization designs in the training process.\nIn this paper, we propose a simple and effective regularization strategy from a\nnew perspective of evolution of features, which we call feature flow\nregularization (FFR), for improving structured sparsity and filter pruning in\nDNNs. Specifically, FFR imposes controls on the gradient and curvature of\nfeature flow along the neural network, which implicitly increases the sparsity\nof the parameters. The principle behind FFR is that coherent and smooth\nevolution of features will lead to an efficient network that avoids redundant\nparameters. The high structured sparsity obtained from FFR enables us to prune\nfilters effectively. Experiments with VGGNets, ResNets on CIFAR-10/100, and\nTiny ImageNet datasets demonstrate that FFR can significantly improve both\nunstructured and structured sparsity. Our pruning results in terms of reduction\nof parameters and FLOPs are comparable to or even better than those of\nstate-of-the-art pruning methods.",
          "link": "http://arxiv.org/abs/2106.02914",
          "publishedOn": "2021-06-08T02:20:22.703Z",
          "wordCount": 616,
          "title": "Feature Flow Regularization: Improving Structured Sparsity in Deep Neural Networks. (arXiv:2106.02914v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02943",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cetin_E/0/1/0/all/0/1\">Edoardo Cetin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celiktutan_O/0/1/0/all/0/1\">Oya Celiktutan</a>",
          "description": "The performance of reinforcement learning depends upon designing an\nappropriate action space, where the effect of each action is measurable, yet,\ngranular enough to permit flexible behavior. So far, this process involved\nnon-trivial user choices in terms of the available actions and their execution\nfrequency. We propose a novel framework for reinforcement learning that\neffectively lifts such constraints. Within our framework, agents learn\neffective behavior over a routine space: a new, higher-level action space,\nwhere each routine represents a set of 'equivalent' sequences of granular\nactions with arbitrary length. Our routine space is learned end-to-end to\nfacilitate the accomplishment of underlying off-policy reinforcement learning\nobjectives. We apply our framework to two state-of-the-art off-policy\nalgorithms and show that the resulting agents obtain relevant performance\nimprovements while requiring fewer interactions with the environment per\nepisode, improving computational efficiency.",
          "link": "http://arxiv.org/abs/2106.02943",
          "publishedOn": "2021-06-08T02:20:22.697Z",
          "wordCount": 557,
          "title": "Learning Routines for Effective Off-Policy Reinforcement Learning. (arXiv:2106.02943v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02965",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lacroce_C/0/1/0/all/0/1\">Clara Lacroce</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panangaden_P/0/1/0/all/0/1\">Prakash Panangaden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabusseau_G/0/1/0/all/0/1\">Guillaume Rabusseau</a>",
          "description": "In this paper we study the approximate minimization problem for language\nmodelling. We assume we are given some language model as a black box. The\nobjective is to obtain a weighted finite automaton (WFA) that fits within a\ngiven size constraint and which mimics the behaviour of the original model\nwhile minimizing some notion of distance between the black box and the\nextracted WFA. We provide an algorithm for the approximate minimization of\nblack boxes trained for language modelling of sequential data over a one-letter\nalphabet. By reformulating the problem in terms of Hankel matrices, we leverage\nclassical results on the approximation of Hankel operators, namely the\ncelebrated Adamyan-Arov-Krein (AAK) theory. This allows us to use the spectral\nnorm to measure the distance between the black box and the WFA. We provide\ntheoretical guarantees to study the potentially infinite-rank Hankel matrix of\nthe black box, without accessing the training data, and we prove that our\nmethod returns an asymptotically-optimal approximation.",
          "link": "http://arxiv.org/abs/2106.02965",
          "publishedOn": "2021-06-08T02:20:22.691Z",
          "wordCount": 602,
          "title": "Extracting Weighted Automata for Approximate Minimization in Language Modelling. (arXiv:2106.02965v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02705",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuyan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xuezhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beutel_A/0/1/0/all/0/1\">Alex Beutel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prost_F/0/1/0/all/0/1\">Flavien Prost</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jilin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chi_E/0/1/0/all/0/1\">Ed H. Chi</a>",
          "description": "As multi-task models gain popularity in a wider range of machine learning\napplications, it is becoming increasingly important for practitioners to\nunderstand the fairness implications associated with those models. Most\nexisting fairness literature focuses on learning a single task more fairly,\nwhile how ML fairness interacts with multiple tasks in the joint learning\nsetting is largely under-explored. In this paper, we are concerned with how\ngroup fairness (e.g., equal opportunity, equalized odds) as an ML fairness\nconcept plays out in the multi-task scenario. In multi-task learning, several\ntasks are learned jointly to exploit task correlations for a more efficient\ninductive transfer. This presents a multi-dimensional Pareto frontier on (1)\nthe trade-off between group fairness and accuracy with respect to each task, as\nwell as (2) the trade-offs across multiple tasks. We aim to provide a deeper\nunderstanding on how group fairness interacts with accuracy in multi-task\nlearning, and we show that traditional approaches that mainly focus on\noptimizing the Pareto frontier of multi-task accuracy might not perform well on\nfairness goals. We propose a new set of metrics to better capture the\nmulti-dimensional Pareto frontier of fairness-accuracy trade-offs uniquely\npresented in a multi-task learning setting. We further propose a\nMulti-Task-Aware Fairness (MTA-F) approach to improve fairness in multi-task\nlearning. Experiments on several real-world datasets demonstrate the\neffectiveness of our proposed approach.",
          "link": "http://arxiv.org/abs/2106.02705",
          "publishedOn": "2021-06-08T02:20:22.670Z",
          "wordCount": 651,
          "title": "Understanding and Improving Fairness-Accuracy Trade-offs in Multi-Task Learning. (arXiv:2106.02705v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.13553",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Siemenn_A/0/1/0/all/0/1\">Alexander E. Siemenn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaulsky_E/0/1/0/all/0/1\">Evyatar Shaulsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beveridge_M/0/1/0/all/0/1\">Matthew Beveridge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buonassisi_T/0/1/0/all/0/1\">Tonio Buonassisi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashmi_S/0/1/0/all/0/1\">Sara M. Hashmi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drori_I/0/1/0/all/0/1\">Iddo Drori</a>",
          "description": "Autonomous optimization is a process by which hardware conditions are\ndiscovered that generate an optimized experimental product without the guidance\nof a domain expert. We design an autonomous optimization framework to discover\nthe experimental conditions within fluid systems that generate discrete and\nuniform droplet patterns. Generating discrete and uniform droplets requires\nhigh-precision control over the experimental conditions of a fluid system.\nFluid stream instabilities, such as Rayleigh-Plateau instability and capillary\ninstability, drive the separation of a flow into individual droplets. However,\nbecause this phenomenon leverages an instability, by nature the hardware must\nbe precisely tuned to achieve uniform, repeatable droplets. Typically this\nrequires a domain expert in the loop and constant re-tuning depending on the\nhardware configuration and liquid precursor selection. Herein, we propose a\ncomputer vision-driven Bayesian optimization framework to discover the precise\nhardware conditions that generate uniform, reproducible droplets with the\ndesired features, leveraging flow instability without a domain expert in the\nloop. This framework is validated on two fluid systems, at the micrometer and\nmillimeter length scales, using microfluidic and inkjet systems, respectively,\nindicating the application breadth of this approach.",
          "link": "http://arxiv.org/abs/2105.13553",
          "publishedOn": "2021-06-08T02:20:22.664Z",
          "wordCount": 654,
          "title": "Autonomous Optimization of Fluid Systems at Varying Length Scales. (arXiv:2105.13553v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.09667",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shumailov_I/0/1/0/all/0/1\">Ilia Shumailov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shumaylov_Z/0/1/0/all/0/1\">Zakhar Shumaylov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kazhdan_D/0/1/0/all/0/1\">Dmitry Kazhdan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yiren Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papernot_N/0/1/0/all/0/1\">Nicolas Papernot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erdogdu_M/0/1/0/all/0/1\">Murat A. Erdogdu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anderson_R/0/1/0/all/0/1\">Ross Anderson</a>",
          "description": "Machine learning is vulnerable to a wide variety of attacks. It is now well\nunderstood that by changing the underlying data distribution, an adversary can\npoison the model trained with it or introduce backdoors. In this paper we\npresent a novel class of training-time attacks that require no changes to the\nunderlying dataset or model architecture, but instead only change the order in\nwhich data are supplied to the model. In particular, we find that the attacker\ncan either prevent the model from learning, or poison it to learn behaviours\nspecified by the attacker. Furthermore, we find that even a single\nadversarially-ordered epoch can be enough to slow down model learning, or even\nto reset all of the learning progress. Indeed, the attacks presented here are\nnot specific to the model or dataset, but rather target the stochastic nature\nof modern learning procedures. We extensively evaluate our attacks on computer\nvision and natural language benchmarks to find that the adversary can disrupt\nmodel training and even introduce backdoors.",
          "link": "http://arxiv.org/abs/2104.09667",
          "publishedOn": "2021-06-08T02:20:22.657Z",
          "wordCount": 642,
          "title": "Manipulating SGD with Data Ordering Attacks. (arXiv:2104.09667v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02875",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qian_Z/0/1/0/all/0/1\">Zhaozhi Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zame_W/0/1/0/all/0/1\">William R. Zame</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1\">Mihaela van der Schaar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fleuren_L/0/1/0/all/0/1\">Lucas M. Fleuren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elbers_P/0/1/0/all/0/1\">Paul Elbers</a>",
          "description": "Modeling a system's temporal behaviour in reaction to external stimuli is a\nfundamental problem in many areas. Pure Machine Learning (ML) approaches often\nfail in the small sample regime and cannot provide actionable insights beyond\npredictions. A promising modification has been to incorporate expert domain\nknowledge into ML models. The application we consider is predicting the\nprogression of disease under medications, where a plethora of domain knowledge\nis available from pharmacology. Pharmacological models describe the dynamics of\ncarefully-chosen medically meaningful variables in terms of systems of Ordinary\nDifferential Equations (ODEs). However, these models only describe a limited\ncollection of variables, and these variables are often not observable in\nclinical environments. To close this gap, we propose the latent hybridisation\nmodel (LHM) that integrates a system of expert-designed ODEs with\nmachine-learned Neural ODEs to fully describe the dynamics of the system and to\nlink the expert and latent variables to observable quantities. We evaluated LHM\non synthetic data as well as real-world intensive care data of COVID-19\npatients. LHM consistently outperforms previous works, especially when few\ntraining samples are available such as at the beginning of the pandemic.",
          "link": "http://arxiv.org/abs/2106.02875",
          "publishedOn": "2021-06-08T02:20:22.623Z",
          "wordCount": 670,
          "title": "Integrating Expert ODEs into Neural ODEs: Pharmacology and Disease Progression. (arXiv:2106.02875v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2104.08382",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhagoji_A/0/1/0/all/0/1\">Arjun Nitin Bhagoji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cullina_D/0/1/0/all/0/1\">Daniel Cullina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sehwag_V/0/1/0/all/0/1\">Vikash Sehwag</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_P/0/1/0/all/0/1\">Prateek Mittal</a>",
          "description": "Understanding the fundamental limits of robust supervised learning has\nemerged as a problem of immense interest, from both practical and theoretical\nstandpoints. In particular, it is critical to determine classifier-agnostic\nbounds on the training loss to establish when learning is possible. In this\npaper, we determine optimal lower bounds on the cross-entropy loss in the\npresence of test-time adversaries, along with the corresponding optimal\nclassification outputs. Our formulation of the bound as a solution to an\noptimization problem is general enough to encompass any loss function depending\non soft classifier outputs. We also propose and provide a proof of correctness\nfor a bespoke algorithm to compute this lower bound efficiently, allowing us to\ndetermine lower bounds for multiple practical datasets of interest. We use our\nlower bounds as a diagnostic tool to determine the effectiveness of current\nrobust training methods and find a gap from optimality at larger budgets.\nFinally, we investigate the possibility of using of optimal classification\noutputs as soft labels to empirically improve robust training.",
          "link": "http://arxiv.org/abs/2104.08382",
          "publishedOn": "2021-06-08T02:20:22.603Z",
          "wordCount": 648,
          "title": "Lower Bounds on Cross-Entropy Loss in the Presence of Test-time Adversaries. (arXiv:2104.08382v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02835",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_R/0/1/0/all/0/1\">Ruichu Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weilin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_J/0/1/0/all/0/1\">Jie Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_Z/0/1/0/all/0/1\">Zhifeng Hao</a>",
          "description": "Causal discovery from observational data is an important but challenging task\nin many scientific fields. Recently, NOTEARS [Zheng et al., 2018] formulates\nthe causal structure learning problem as a continuous optimization problem\nusing least-square loss with an acyclicity constraint. Though the least-square\nloss function is well justified under the standard Gaussian noise assumption,\nit is limited if the assumption does not hold. In this work, we theoretically\nshow that the violation of the Gaussian noise assumption will hinder the causal\ndirection identification, making the causal orientation fully determined by the\ncausal strength as well as the variances of noises in the linear case and the\nnoises of strong non-Gaussianity in the nonlinear case. Consequently, we\npropose a more general entropy-based loss that is theoretically consistent with\nthe likelihood score under any noise distribution. We run extensive empirical\nevaluations on both synthetic data and real-world data to validate the\neffectiveness of the proposed method and show that our method achieves the best\nin Structure Hamming Distance, False Discovery Rate, and True Positive Rate\nmatrices.",
          "link": "http://arxiv.org/abs/2106.02835",
          "publishedOn": "2021-06-08T02:20:22.589Z",
          "wordCount": 610,
          "title": "On the Role of Entropy-based Loss for Learning Causal Structures with Continuous Optimization. (arXiv:2106.02835v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.11152",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Okawa_M/0/1/0/all/0/1\">Maya Okawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iwata_T/0/1/0/all/0/1\">Tomoharu Iwata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanaka_Y/0/1/0/all/0/1\">Yusuke Tanaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toda_H/0/1/0/all/0/1\">Hiroyuki Toda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurashima_T/0/1/0/all/0/1\">Takeshi Kurashima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kashima_H/0/1/0/all/0/1\">Hisashi Kashima</a>",
          "description": "Sequences of events including infectious disease outbreaks, social network\nactivities, and crimes are ubiquitous and the data on such events carry\nessential information about the underlying diffusion processes between\ncommunities (e.g., regions, online user groups). Modeling diffusion processes\nand predicting future events are crucial in many applications including\nepidemic control, viral marketing, and predictive policing. Hawkes processes\noffer a central tool for modeling the diffusion processes, in which the\ninfluence from the past events is described by the triggering kernel. However,\nthe triggering kernel parameters, which govern how each community is influenced\nby the past events, are assumed to be static over time. In the real world, the\ndiffusion processes depend not only on the influences from the past, but also\nthe current (time-evolving) states of the communities, e.g., people's awareness\nof the disease and people's current interests. In this paper, we propose a\nnovel Hawkes process model that is able to capture the underlying dynamics of\ncommunity states behind the diffusion processes and predict the occurrences of\nevents based on the dynamics. Specifically, we model the latent dynamic\nfunction that encodes these hidden dynamics by a mixture of neural networks.\nThen we design the triggering kernel using the latent dynamic function and its\nintegral. The proposed method, termed DHP (Dynamic Hawkes Processes), offers a\nflexible way to learn complex representations of the time-evolving communities'\nstates, while at the same time it allows to computing the exact likelihood,\nwhich makes parameter learning tractable. Extensive experiments on four\nreal-world event datasets show that DHP outperforms five widely adopted methods\nfor event prediction.",
          "link": "http://arxiv.org/abs/2105.11152",
          "publishedOn": "2021-06-08T02:20:22.582Z",
          "wordCount": 758,
          "title": "Dynamic Hawkes Processes for Discovering Time-evolving Communities' States behind Diffusion Processes. (arXiv:2105.11152v2 [cs.SI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.06643",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1\">Wanyu Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_H/0/1/0/all/0/1\">Hao Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Baochun Li</a>",
          "description": "This paper presents Gem, a model-agnostic approach for providing\ninterpretable explanations for any GNNs on various graph learning tasks.\nSpecifically, we formulate the problem of providing explanations for the\ndecisions of GNNs as a causal learning task. Then we train a causal explanation\nmodel equipped with a loss function based on Granger causality. Different from\nexisting explainers for GNNs, Gem explains GNNs on graph-structured data from a\ncausal perspective. It has better generalization ability as it has no\nrequirements on the internal structure of the GNNs or prior knowledge on the\ngraph learning tasks. In addition, Gem, once trained, can be used to explain\nthe target GNN very quickly. Our theoretical analysis shows that several recent\nexplainers fall into a unified framework of additive feature attribution\nmethods. Experimental results on synthetic and real-world datasets show that\nGem achieves a relative increase of the explanation accuracy by up to $30\\%$\nand speeds up the explanation process by up to $110\\times$ as compared to its\nstate-of-the-art alternatives.",
          "link": "http://arxiv.org/abs/2104.06643",
          "publishedOn": "2021-06-08T02:20:22.575Z",
          "wordCount": 628,
          "title": "Generative Causal Explanations for Graph Neural Networks. (arXiv:2104.06643v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02769",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Adams_S/0/1/0/all/0/1\">Samuel Adams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choudhary_C/0/1/0/all/0/1\">Chaitali Choudhary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cock_M/0/1/0/all/0/1\">Martine De Cock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dowsley_R/0/1/0/all/0/1\">Rafael Dowsley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melanson_D/0/1/0/all/0/1\">David Melanson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nascimento_A/0/1/0/all/0/1\">Anderson C. A. Nascimento</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Railsback_D/0/1/0/all/0/1\">Davis Railsback</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Jianwei Shen</a>",
          "description": "Most existing Secure Multi-Party Computation (MPC) protocols for\nprivacy-preserving training of decision trees over distributed data assume that\nthe features are categorical. In real-life applications, features are often\nnumerical. The standard ``in the clear'' algorithm to grow decision trees on\ndata with continuous values requires sorting of training examples for each\nfeature in the quest for an optimal cut-point in the range of feature values in\neach node. Sorting is an expensive operation in MPC, hence finding secure\nprotocols that avoid such an expensive step is a relevant problem in\nprivacy-preserving machine learning. In this paper we propose three more\nefficient alternatives for secure training of decision tree based models on\ndata with continuous features, namely: (1) secure discretization of the data,\nfollowed by secure training of a decision tree over the discretized data; (2)\nsecure discretization of the data, followed by secure training of a random\nforest over the discretized data; and (3) secure training of extremely\nrandomized trees (``extra-trees'') on the original data. Approaches (2) and (3)\nboth involve randomizing feature choices. In addition, in approach (3)\ncut-points are chosen randomly as well, thereby alleviating the need to sort or\nto discretize the data up front. We implemented all proposed solutions in the\nsemi-honest setting with additive secret sharing based MPC. In addition to\nmathematically proving that all proposed approaches are correct and secure, we\nexperimentally evaluated and compared them in terms of classification accuracy\nand runtime. We privately train tree ensembles over data sets with 1000s of\ninstances or features in a few minutes, with accuracies that are at par with\nthose obtained in the clear. This makes our solution orders of magnitude more\nefficient than the existing approaches, which are based on oblivious sorting.",
          "link": "http://arxiv.org/abs/2106.02769",
          "publishedOn": "2021-06-08T02:20:22.556Z",
          "wordCount": 729,
          "title": "Privacy-Preserving Training of Tree Ensembles over Continuous Data. (arXiv:2106.02769v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02738",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mo_T/0/1/0/all/0/1\">Tong Mo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bang Liu</a>",
          "description": "Keyword spotting aims to identify specific keyword audio utterances. In\nrecent years, deep convolutional neural networks have been widely utilized in\nkeyword spotting systems. However, their model architectures are mainly based\non off-the shelfbackbones such as VGG-Net or ResNet, instead of specially\ndesigned for the task. In this paper, we utilize neural architecture search to\ndesign convolutional neural network models that can boost the performance of\nkeyword spotting while maintaining an acceptable memory footprint.\nSpecifically, we search the model operators and their connections in a specific\nsearch space with Encoder-Decoder neural architecture optimization. Extensive\nevaluations on Google's Speech Commands Dataset show that the model\narchitecture searched by our approach achieves a state-of-the-art accuracy of\nover 97%.",
          "link": "http://arxiv.org/abs/2106.02738",
          "publishedOn": "2021-06-08T02:20:22.549Z",
          "wordCount": 540,
          "title": "Encoder-Decoder Neural Architecture Optimization for Keyword Spotting. (arXiv:2106.02738v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02938",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bian_Y/0/1/0/all/0/1\">Yatao Bian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rong_Y/0/1/0/all/0/1\">Yu Rong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1\">Tingyang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jiaxiang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1\">Andreas Krause</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Junzhou Huang</a>",
          "description": "Valuation problems, such as attribution-based feature interpretation, data\nvaluation and model valuation for ensembles, become increasingly more important\nin many machine learning applications. Such problems are commonly solved by\nwell-known game-theoretic criteria, such as Shapley value or Banzhaf index. In\nthis work, we present a novel energy-based treatment for cooperative games,\nwith a theoretical justification by the maximum entropy framework.\nSurprisingly, by conducting variational inference of the energy-based model, we\nrecover various game-theoretic valuation criteria, such as Shapley value and\nBanzhaf index, through conducting one-step gradient ascent for maximizing the\nmean-field ELBO objective. This observation also verifies the rationality of\nexisting criteria, as they are all trying to decouple the correlations among\nthe players through the mean-field approach. By running gradient ascent for\nmultiple steps, we achieve a trajectory of the valuations, among which we\ndefine the valuation with the best conceivable decoupling error as the\nVariational Index. We experimentally demonstrate that the proposed Variational\nIndex enjoys intriguing properties on certain synthetic and real-world\nvaluation problems.",
          "link": "http://arxiv.org/abs/2106.02938",
          "publishedOn": "2021-06-08T02:20:22.543Z",
          "wordCount": 598,
          "title": "Energy-Based Learning for Cooperative Games, with Applications to Feature/Data/Model Valuations. (arXiv:2106.02938v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02700",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Campos_C/0/1/0/all/0/1\">C&#xe9;dric M. Campos</a>, <a href=\"http://arxiv.org/find/math/1/au:+Mahillo_A/0/1/0/all/0/1\">Alejandro Mahillo</a>, <a href=\"http://arxiv.org/find/math/1/au:+Diego_D/0/1/0/all/0/1\">David Mart&#xed;n de Diego</a>",
          "description": "Many of the new developments in machine learning are connected with\ngradient-based optimization methods. Recently, these methods have been studied\nusing a variational perspective. This has opened up the possibility of\nintroducing variational and symplectic integration methods using geometric\nintegrators. In particular, in this paper, we introduce variational integrators\nwhich allow us to derive different methods for optimization. Using both,\nHamilton's principle and Lagrange-d'Alembert's, we derive two families of\noptimization methods in one-to-one correspondence that generalize Polyak's\nheavy ball and the well known Nesterov accelerated gradient method, mimicking\nthe behavior of the latter which reduces the oscillations of typical momentum\nmethods. However, since the systems considered are explicitly time-dependent,\nthe preservation of symplecticity of autonomous systems occurs here solely on\nthe fibers. Several experiments exemplify the result.",
          "link": "http://arxiv.org/abs/2106.02700",
          "publishedOn": "2021-06-08T02:20:22.537Z",
          "wordCount": 574,
          "title": "A Discrete Variational Derivation of Accelerated Methods in Optimization. (arXiv:2106.02700v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2104.10972",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ridnik_T/0/1/0/all/0/1\">Tal Ridnik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ben_Baruch_E/0/1/0/all/0/1\">Emanuel Ben-Baruch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noy_A/0/1/0/all/0/1\">Asaf Noy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zelnik_Manor_L/0/1/0/all/0/1\">Lihi Zelnik-Manor</a>",
          "description": "ImageNet-1K serves as the primary dataset for pretraining deep learning\nmodels for computer vision tasks. ImageNet-21K dataset, which is bigger and\nmore diverse, is used less frequently for pretraining, mainly due to its\ncomplexity, low accessibility, and underestimation of its added value. This\npaper aims to close this gap, and make high-quality efficient pretraining on\nImageNet-21K available for everyone. Via a dedicated preprocessing stage,\nutilization of WordNet hierarchical structure, and a novel training scheme\ncalled semantic softmax, we show that various models significantly benefit from\nImageNet-21K pretraining on numerous datasets and tasks, including small\nmobile-oriented models. We also show that we outperform previous ImageNet-21K\npretraining schemes for prominent new models like ViT and Mixer. Our proposed\npretraining pipeline is efficient, accessible, and leads to SoTA reproducible\nresults, from a publicly available dataset. The training code and pretrained\nmodels are available at: https://github.com/Alibaba-MIIL/ImageNet21K",
          "link": "http://arxiv.org/abs/2104.10972",
          "publishedOn": "2021-06-08T02:20:22.512Z",
          "wordCount": 609,
          "title": "ImageNet-21K Pretraining for the Masses. (arXiv:2104.10972v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02674",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tran_C/0/1/0/all/0/1\">Cuong Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dinh_M/0/1/0/all/0/1\">My H. Dinh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fioretto_F/0/1/0/all/0/1\">Ferdinando Fioretto</a>",
          "description": "Differential Privacy (DP) is an important privacy-enhancing technology for\nprivate machine learning systems. It allows to measure and bound the risk\nassociated with an individual participation in a computation. However, it was\nrecently observed that DP learning systems may exacerbate bias and unfairness\nfor different groups of individuals. This paper builds on these important\nobservations and sheds light on the causes of the disparate impacts arising in\nthe problem of differentially private empirical risk minimization. It focuses\non the accuracy disparity arising among groups of individuals in two\nwell-studied DP learning methods: output perturbation and differentially\nprivate stochastic gradient descent. The paper analyzes which data and model\nproperties are responsible for the disproportionate impacts, why these aspects\nare affecting different groups disproportionately and proposes guidelines to\nmitigate these effects. The proposed approach is evaluated on several datasets\nand settings.",
          "link": "http://arxiv.org/abs/2106.02674",
          "publishedOn": "2021-06-08T02:20:22.505Z",
          "wordCount": 571,
          "title": "Differentially Private Deep Learning under the Fairness Lens. (arXiv:2106.02674v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02972",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1\">Prasoon Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mooney_R/0/1/0/all/0/1\">Raymond J. Mooney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niekum_S/0/1/0/all/0/1\">Scott Niekum</a>",
          "description": "Imitation learning and instruction-following are two common approaches to\ncommunicate a user's intent to a learning agent. However, as the complexity of\ntasks grows, it could be beneficial to use both demonstrations and language to\ncommunicate with an agent. In this work, we propose a novel setting where an\nagent is given both a demonstration and a description, and must combine\ninformation from both the modalities. Specifically, given a demonstration for a\ntask (the source task), and a natural language description of the differences\nbetween the demonstrated task and a related but different task (the target\ntask), our goal is to train an agent to complete the target task in a zero-shot\nsetting, that is, without any demonstrations for the target task. To this end,\nwe introduce Language-Aided Reward and Value Adaptation (LARVA) which, given a\nsource demonstration and a linguistic description of how the target task\ndiffers, learns to output a reward / value function that accurately describes\nthe target task. Our experiments show that on a diverse set of adaptations, our\napproach is able to complete more than 95% of target tasks when using\ntemplate-based descriptions, and more than 70% when using free-form natural\nlanguage.",
          "link": "http://arxiv.org/abs/2106.02972",
          "publishedOn": "2021-06-08T02:20:22.499Z",
          "wordCount": 625,
          "title": "Zero-shot Task Adaptation using Natural Language. (arXiv:2106.02972v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02735",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Feng_J/0/1/0/all/0/1\">Jinchao Feng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ren_Y/0/1/0/all/0/1\">Yunxiang Ren</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tang_S/0/1/0/all/0/1\">Sui Tang</a>",
          "description": "Interacting particle or agent systems that display a rich variety of\ncollection motions are ubiquitous in science and engineering. A fundamental and\nchallenging goal is to understand the link between individual interaction rules\nand collective behaviors. In this paper, we study the data-driven discovery of\ndistance-based interaction laws in second-order interacting particle systems.\nWe propose a learning approach that models the latent interaction kernel\nfunctions as Gaussian processes, which can simultaneously fulfill two inference\ngoals: one is the nonparametric inference of interaction kernel function with\nthe pointwise uncertainty quantification, and the other one is the inference of\nunknown parameters in the non-collective forces of the system. We formulate\nlearning interaction kernel functions as a statistical inverse problem and\nprovide a detailed analysis of recoverability conditions, establishing that a\ncoercivity condition is sufficient for recoverability. We provide a\nfinite-sample analysis, showing that our posterior mean estimator converges at\nan optimal rate equal to the one in the classical 1-dimensional Kernel Ridge\nregression. Numerical results on systems that exhibit different collective\nbehaviors demonstrate efficient learning of our approach from scarce noisy\ntrajectory data.",
          "link": "http://arxiv.org/abs/2106.02735",
          "publishedOn": "2021-06-08T02:20:22.491Z",
          "wordCount": 625,
          "title": "Data-driven discovery of interacting particle systems using Gaussian processes. (arXiv:2106.02735v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2104.06249",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Ntumba_M/0/1/0/all/0/1\">Manuel Ntumba</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Gore_S/0/1/0/all/0/1\">Saurabh Gore</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Awanyo_J/0/1/0/all/0/1\">Jean-Baptiste Awanyo</a>",
          "description": "In recent years, understanding asteroids has shifted from light worlds to\ngeological worlds by exploring modern spacecraft and advanced radar and\ntelescopic surveys. However, flyby in 2029 will be an opportunity to conduct an\ninternal geophysical study and test the current hypothesis on the effects of\ntidal forces on asteroids. The Earth-Apophis mission is driven by additional\nfactors and scientific goals beyond the unique opportunity for natural\nexperimentation. However, the internal geophysical structures remain largely\nunknown. Understanding the strength and internal integrity of asteroids is not\njust a matter of scientific curiosity. It is a practical imperative to advance\nknowledge for planetary defense against the possibility of an asteroid impact.\nThis paper presents a conceptual robotics system required for efficiency at\nevery stage from entry to post-landing and for asteroid monitoring. In short,\nasteroid surveillance missions are futuristic frontiers, with the potential for\ntechnological growth that could revolutionize space exploration. Advanced space\ntechnologies and robotic systems are needed to minimize risk and prepare these\ntechnologies for future missions. A neural network model is implemented to\ntrack and predict asteroids' orbits. Advanced algorithms are also needed to\nnumerically predict orbital events to minimize error",
          "link": "http://arxiv.org/abs/2104.06249",
          "publishedOn": "2021-06-08T02:20:22.483Z",
          "wordCount": 679,
          "title": "Prediction of Apophis Asteroid Flyby Optimal Trajectories and Data Fusion of Earth-Apophis Mission Launch Windows using Deep Neural Networks. (arXiv:2104.06249v2 [astro-ph.IM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02694",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kong_F/0/1/0/all/0/1\">Fanjie Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henao_R/0/1/0/all/0/1\">Ricardo Henao</a>",
          "description": "An increasing number of applications in the computer vision domain,\nspecially, in medical imaging and remote sensing, are challenging when the goal\nis to classify very large images with tiny objects. More specifically, these\ntype of classification tasks face two key challenges: $i$) the size of the\ninput image in the target dataset is usually in the order of megapixels,\nhowever, existing deep architectures do not easily operate on such big images\ndue to memory constraints, consequently, we seek a memory-efficient method to\nprocess these images; and $ii$) only a small fraction of the input images are\ninformative of the label of interest, resulting in low region of interest (ROI)\nto image ratio. However, most of the current convolutional neural networks\n(CNNs) are designed for image classification datasets that have relatively\nlarge ROIs and small image size (sub-megapixel). Existing approaches have\naddressed these two challenges in isolation. We present an end-to-end CNN model\ntermed Zoom-In network that leverages hierarchical attention sampling for\nclassification of large images with tiny objects using a single GPU. We\nevaluate our method on two large-image datasets and one gigapixel dataset.\nExperimental results show that our model achieves higher accuracy than existing\nmethods while requiring less computing resources.",
          "link": "http://arxiv.org/abs/2106.02694",
          "publishedOn": "2021-06-08T02:20:22.464Z",
          "wordCount": 634,
          "title": "Efficient Classification of Very Large Images with Tiny Objects. (arXiv:2106.02694v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.03902",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1\">Chence Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1\">Shitong Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Minkai Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jian Tang</a>",
          "description": "We study a fundamental problem in computational chemistry known as molecular\nconformation generation, trying to predict stable 3D structures from 2D\nmolecular graphs. Existing machine learning approaches usually first predict\ndistances between atoms and then generate a 3D structure satisfying the\ndistances, where noise in predicted distances may induce extra errors during 3D\ncoordinate generation. Inspired by the traditional force field methods for\nmolecular dynamics simulation, in this paper, we propose a novel approach\ncalled ConfGF by directly estimating the gradient fields of the log density of\natomic coordinates. The estimated gradient fields allow directly generating\nstable conformations via Langevin dynamics. However, the problem is very\nchallenging as the gradient fields are roto-translation equivariant. We notice\nthat estimating the gradient fields of atomic coordinates can be translated to\nestimating the gradient fields of interatomic distances, and hence develop a\nnovel algorithm based on recent score-based generative models to effectively\nestimate these gradients. Experimental results across multiple tasks show that\nConfGF outperforms previous state-of-the-art baselines by a significant margin.",
          "link": "http://arxiv.org/abs/2105.03902",
          "publishedOn": "2021-06-08T02:20:22.457Z",
          "wordCount": 631,
          "title": "Learning Gradient Fields for Molecular Conformation Generation. (arXiv:2105.03902v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.07365",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bellet_A/0/1/0/all/0/1\">Aur&#xe9;lien Bellet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kermarrec_A/0/1/0/all/0/1\">Anne-Marie Kermarrec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lavoie_E/0/1/0/all/0/1\">Erick Lavoie</a>",
          "description": "The convergence speed of machine learning models trained with Federated\nLearning is significantly affected by non-independent and identically\ndistributed (non-IID) data partitions, even more so in a fully decentralized\nsetting without a central server. In this paper, we show that the impact of\nlocal class bias, an important type of data non-IIDness, can be significantly\nreduced by carefully designing the underlying communication topology. We\npresent D-Cliques, a novel topology that reduces gradient bias by grouping\nnodes in interconnected cliques such that the local joint distribution in a\nclique is representative of the global class distribution. We also show how to\nadapt the updates of decentralized SGD to obtain unbiased gradients and\nimplement an effective momentum with D-Cliques. Our empirical evaluation on\nMNIST and CIFAR10 demonstrates that our approach provides similar convergence\nspeed as a fully-connected topology with a significant reduction in the number\nof edges and messages. In a 1000-node topology, D-Cliques requires 98% less\nedges and 96% less total messages, with further possible gains using a\nsmall-world topology across cliques.",
          "link": "http://arxiv.org/abs/2104.07365",
          "publishedOn": "2021-06-08T02:20:22.450Z",
          "wordCount": 634,
          "title": "D-Cliques: Compensating NonIIDness in Decentralized Federated Learning with Topology. (arXiv:2104.07365v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02684",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_R/0/1/0/all/0/1\">Ruida Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalathil_D/0/1/0/all/0/1\">Dileep Kalathil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1\">P. R. Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_C/0/1/0/all/0/1\">Chao Tian</a>",
          "description": "We address the issue of safety in reinforcement learning. We pose the problem\nin an episodic framework of a constrained Markov decision process. Existing\nresults have shown that it is possible to achieve a reward regret of\n$\\tilde{\\mathcal{O}}(\\sqrt{K})$ while allowing an\n$\\tilde{\\mathcal{O}}(\\sqrt{K})$ constraint violation in $K$ episodes. A\ncritical question that arises is whether it is possible to keep the constraint\nviolation even smaller. We show that when a strictly safe policy is known, then\none can confine the system to zero constraint violation with arbitrarily high\nprobability while keeping the reward regret of order\n$\\tilde{\\mathcal{O}}(\\sqrt{K})$. The algorithm which does so employs the\nprinciple of optimistic pessimism in the face of uncertainty to achieve safe\nexploration. When no strictly safe policy is known, though one is known to\nexist, then it is possible to restrict the system to bounded constraint\nviolation with arbitrarily high probability. This is shown to be realized by a\nprimal-dual algorithm with an optimistic primal estimate and a pessimistic dual\nupdate.",
          "link": "http://arxiv.org/abs/2106.02684",
          "publishedOn": "2021-06-08T02:20:22.407Z",
          "wordCount": 598,
          "title": "Learning Policies with Zero or Bounded Constraint Violation for Constrained MDPs. (arXiv:2106.02684v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02732",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhuosheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Shucheng Yu</a>",
          "description": "Decision-based attacks (DBA), wherein attackers perturb inputs to spoof\nlearning algorithms by observing solely the output labels, are a type of severe\nadversarial attacks against Deep Neural Networks (DNNs) requiring minimal\nknowledge of attackers. State-of-the-art DBA attacks relying on zeroth-order\ngradient estimation require an excessive number of queries. Recently, Bayesian\noptimization (BO) has shown promising in reducing the number of queries in\nscore-based attacks (SBA), in which attackers need to observe real-valued\nprobability scores as outputs. However, extending BO to the setting of DBA is\nnontrivial because in DBA only output labels instead of real-valued scores, as\nneeded by BO, are available to attackers. In this paper, we close this gap by\nproposing an efficient DBA attack, namely BO-DBA. Different from existing\napproaches, BO-DBA generates adversarial examples by searching so-called\n\\emph{directions of perturbations}. It then formulates the problem as a BO\nproblem that minimizes the real-valued distortion of perturbations. With the\noptimized perturbation generation process, BO-DBA converges much faster than\nthe state-of-the-art DBA techniques. Experimental results on pre-trained\nImageNet classifiers show that BO-DBA converges within 200 queries while the\nstate-of-the-art DBA techniques need over 15,000 queries to achieve the same\nlevel of perturbation distortion. BO-DBA also shows similar attack success\nrates even as compared to BO-based SBA attacks but with less distortion.",
          "link": "http://arxiv.org/abs/2106.02732",
          "publishedOn": "2021-06-08T02:20:22.400Z",
          "wordCount": 644,
          "title": "BO-DBA: Query-Efficient Decision-Based Adversarial Attacks via Bayesian Optimization. (arXiv:2106.02732v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02669",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Pourbemany_J/0/1/0/all/0/1\">Jafar Pourbemany</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Essa_A/0/1/0/all/0/1\">Almabrok Essa</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhu_Y/0/1/0/all/0/1\">Ye Zhu</a>",
          "description": "In recent years, research about monitoring vital signs by smartphones grows\nsignificantly. There are some special sensors like Electrocardiogram (ECG) and\nPhotoplethysmographic (PPG) to detect heart rate (HR) and respiration rate\n(RR). Smartphone cameras also can measure HR by detecting and processing\nimaging Photoplethysmographic (iPPG) signals from the video of a user's face.\nIndeed, the variation in the intensity of the green channel can be measured by\nthe iPPG signals of the video. This study aimed to provide a method to extract\nheart rate and respiration rate using the video of individuals' faces. The\nproposed method is based on measuring fluctuations in the Hue, and can\ntherefore extract both HR and RR from the video of a user's face. The proposed\nmethod is evaluated by performing on 25 healthy individuals. For each subject,\n20 seconds video of his/her face is recorded. Results show that the proposed\napproach of measuring iPPG using Hue gives more accurate rates than the Green\nchannel.",
          "link": "http://arxiv.org/abs/2106.02669",
          "publishedOn": "2021-06-08T02:20:22.368Z",
          "wordCount": 606,
          "title": "Real Time Video based Heart and Respiration Rate Monitoring. (arXiv:2106.02669v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.11558",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1\">Prateek Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kowshik_S/0/1/0/all/0/1\">Suhas S Kowshik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagaraj_D/0/1/0/all/0/1\">Dheeraj Nagaraj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Netrapalli_P/0/1/0/all/0/1\">Praneeth Netrapalli</a>",
          "description": "We consider the setting of vector valued non-linear dynamical systems\n$X_{t+1} = \\phi(A^* X_t) + \\eta_t$, where $\\eta_t$ is unbiased noise and $\\phi\n: \\mathbb{R} \\to \\mathbb{R}$ is a known link function that satisfies certain\n{\\em expansivity property}. The goal is to learn $A^*$ from a single trajectory\n$X_1,\\cdots,X_T$ of {\\em dependent or correlated} samples. While the problem is\nwell-studied in the linear case, where $\\phi$ is identity, with optimal error\nrates even for non-mixing systems, existing results in the non-linear case hold\nonly for mixing systems. In this work, we improve existing results for learning\nnonlinear systems in a number of ways: a) we provide the first offline\nalgorithm that can learn non-linear dynamical systems without the mixing\nassumption, b) we significantly improve upon the sample complexity of existing\nresults for mixing systems, c) in the much harder one-pass, streaming setting\nwe study a SGD with Reverse Experience Replay ($\\mathsf{SGD-RER}$) method, and\ndemonstrate that for mixing systems, it achieves the same sample complexity as\nour offline algorithm, d) we justify the expansivity assumption by showing that\nfor the popular ReLU link function -- a non-expansive but easy to learn link\nfunction with i.i.d. samples -- any method would require exponentially many\nsamples (with respect to dimension of $X_t$) from the dynamical system. We\nvalidate our results via. simulations and demonstrate that a naive application\nof SGD can be highly sub-optimal. Indeed, our work demonstrates that for\ncorrelated data, specialized methods designed for the dependency structure in\ndata can significantly outperform standard SGD based methods.",
          "link": "http://arxiv.org/abs/2105.11558",
          "publishedOn": "2021-06-07T22:33:05.470Z",
          "wordCount": 726,
          "title": "Near-optimal Offline and Streaming Algorithms for Learning Non-Linear Dynamical Systems. (arXiv:2105.11558v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.13889",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Decelle_A/0/1/0/all/0/1\">Aur&#xe9;lien Decelle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Furtlehner_C/0/1/0/all/0/1\">Cyril Furtlehner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seoane_B/0/1/0/all/0/1\">Beatriz Seoane</a>",
          "description": "Training Restricted Boltzmann Machines (RBMs) has been challenging for a long\ntime due to the difficulty of computing precisely the log-likelihood gradient.\nOver the past decades, many works have proposed more or less successful\ntraining recipes but without studying the crucial quantity of the problem: the\nmixing time i.e. the number of Monte Carlo iterations needed to sample new\nconfigurations from a model. In this work, we show that this mixing time plays\na crucial role in the dynamics and stability of the trained model, and that\nRBMs operate in two well-defined regimes, namely equilibrium and\nout-of-equilibrium, depending on the interplay between this mixing time of the\nmodel and the number of steps, $k$, used to approximate the gradient. We\nfurther show empirically that this mixing time increases with the learning,\nwhich often implies a transition from one regime to another as soon as $k$\nbecomes smaller than this time. In particular, we show that using the popular\n$k$ (persistent) contrastive divergence approaches, with $k$ small, the\ndynamics of the learned model are extremely slow and often dominated by strong\nout-of-equilibrium effects. On the contrary, RBMs trained in equilibrium\ndisplay faster dynamics, and a smooth convergence to dataset-like\nconfigurations during the sampling. Finally we discuss how to exploit in\npractice both regimes depending on the task one aims to fulfill: (i) short $k$s\ncan be used to generate convincing samples in short times, (ii) large $k$ (or\nincreasingly large) must be used to learn the correct equilibrium distribution\nof the RBM.",
          "link": "http://arxiv.org/abs/2105.13889",
          "publishedOn": "2021-06-07T22:33:05.420Z",
          "wordCount": 730,
          "title": "Equilibrium and non-Equilibrium regimes in the learning of Restricted Boltzmann Machines. (arXiv:2105.13889v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.13939",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roux_C/0/1/0/all/0/1\">Christophe Roux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wirth_E/0/1/0/all/0/1\">Elias Wirth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pokutta_S/0/1/0/all/0/1\">Sebastian Pokutta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kerdreux_T/0/1/0/all/0/1\">Thomas Kerdreux</a>",
          "description": "Several learning problems involve solving min-max problems, e.g., empirical\ndistributional robust learning or learning with non-standard aggregated losses.\nMore specifically, these problems are convex-linear problems where the\nminimization is carried out over the model parameters $w\\in\\mathcal{W}$ and the\nmaximization over the empirical distribution $p\\in\\mathcal{K}$ of the training\nset indexes, where $\\mathcal{K}$ is the simplex or a subset of it. To design\nefficient methods, we let an online learning algorithm play against a\n(combinatorial) bandit algorithm. We argue that the efficiency of such\napproaches critically depends on the structure of $\\mathcal{K}$ and propose two\nproperties of $\\mathcal{K}$ that facilitate designing efficient algorithms. We\nfocus on a specific family of sets $\\mathcal{S}_{n,k}$ encompassing various\nlearning applications and provide high-probability convergence guarantees to\nthe minimax values.",
          "link": "http://arxiv.org/abs/2105.13939",
          "publishedOn": "2021-06-07T22:33:05.409Z",
          "wordCount": 583,
          "title": "Efficient Online-Bandit Strategies for Minimax Learning Problems. (arXiv:2105.13939v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.13609",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dewanto_V/0/1/0/all/0/1\">Vektor Dewanto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gallagher_M/0/1/0/all/0/1\">Marcus Gallagher</a>",
          "description": "For continuing environments, reinforcement learning methods commonly maximize\na discounted reward criterion with discount factor close to 1 in order to\napproximate the steady-state reward (the gain). However, such a criterion only\nconsiders the long-run performance, ignoring the transient behaviour. In this\nwork, we develop a policy gradient method that optimizes the gain, then the\nbias (which indicates the transient performance and is important to capably\nselect from policies with equal gain). We derive expressions that enable\nsampling for the gradient of the bias, and its preconditioning Fisher matrix.\nWe further propose an algorithm that solves the corresponding bi-level\noptimization using a logarithmic barrier. Experimental results provide insights\ninto the fundamental mechanisms of our proposal.",
          "link": "http://arxiv.org/abs/2105.13609",
          "publishedOn": "2021-06-07T22:33:05.399Z",
          "wordCount": 576,
          "title": "A nearly Blackwell-optimal policy gradient method. (arXiv:2105.13609v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.11126",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1\">Jing Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Baoxiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_S/0/1/0/all/0/1\">Shuo Shao</a>",
          "description": "This paper studies \\emph{differential privacy (DP)} and \\emph{local\ndifferential privacy (LDP)} in cascading bandits. Under DP, we propose an\nalgorithm which guarantees $\\epsilon$-indistinguishability and a regret of\n$\\mathcal{O}((\\frac{\\log T}{\\epsilon})^{1+\\xi})$ for an arbitrarily small\n$\\xi$. This is a significant improvement from the previous work of\n$\\mathcal{O}(\\frac{\\log^3 T}{\\epsilon})$ regret. Under\n($\\epsilon$,$\\delta$)-LDP, we relax the $K^2$ dependence through the tradeoff\nbetween privacy budget $\\epsilon$ and error probability $\\delta$, and obtain a\nregret of $\\mathcal{O}(\\frac{K\\log (1/\\delta) \\log T}{\\epsilon^2})$, where $K$\nis the size of the arm subset. This result holds for both Gaussian mechanism\nand Laplace mechanism by analyses on the composition. Our results extend to\ncombinatorial semi-bandit. We show respective lower bounds for DP and LDP\ncascading bandits. Extensive experiments corroborate our theoretic findings.",
          "link": "http://arxiv.org/abs/2105.11126",
          "publishedOn": "2021-06-07T22:33:05.386Z",
          "wordCount": 570,
          "title": "Cascading Bandit under Differential Privacy. (arXiv:2105.11126v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2001.03108",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fang_S/0/1/0/all/0/1\">Song Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1\">Quanyan Zhu</a>",
          "description": "In this paper, we relate a feedback channel with any finite-order\nautoregressive moving-average (ARMA) Gaussian noises to a variant of the Kalman\nfilter. In light of this, we obtain relatively explicit lower bounds on the\nfeedback capacity for such colored Gaussian noises, and the bounds are seen to\nbe consistent with various existing results in the literature. Meanwhile, this\nvariant of the Kalman filter also leads to explicit recursive coding schemes\nwith clear structures to achieve the lower bounds. In general, our results\nprovide an alternative perspective while pointing to potentially tighter bounds\nfor the feedback capacity problem.",
          "link": "http://arxiv.org/abs/2001.03108",
          "publishedOn": "2021-06-07T22:33:05.322Z",
          "wordCount": 649,
          "title": "Feedback Capacity and a Variant of the Kalman Filter with ARMA Gaussian Noises: Explicit Bounds and Feedback Coding Design. (arXiv:2001.03108v6 [cs.IT] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08791",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xiaocheng Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1\">Zhiwei Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yansheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_D/0/1/0/all/0/1\">Dingyuan Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_B/0/1/0/all/0/1\">Bingchen Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_Y/0/1/0/all/0/1\">Yongxin Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hongtu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jieping Ye</a>",
          "description": "Large ride-hailing platforms, such as DiDi, Uber and Lyft, connect tens of\nthousands of vehicles in a city to millions of ride demands throughout the day,\nproviding great promises for improving transportation efficiency through the\ntasks of order dispatching and vehicle repositioning. Existing studies,\nhowever, usually consider the two tasks in simplified settings that hardly\naddress the complex interactions between the two, the real-time fluctuations\nbetween supply and demand, and the necessary coordinations due to the\nlarge-scale nature of the problem. In this paper we propose a unified\nvalue-based dynamic learning framework (V1D3) for tackling both tasks. At the\ncenter of the framework is a globally shared value function that is updated\ncontinuously using online experiences generated from real-time platform\ntransactions. To improve the sample-efficiency and the robustness, we further\npropose a novel periodic ensemble method combining the fast online learning\nwith a large-scale offline training scheme that leverages the abundant\nhistorical driver trajectory data. This allows the proposed framework to adapt\nquickly to the highly dynamic environment, to generalize robustly to recurrent\npatterns and to drive implicit coordinations among the population of managed\nvehicles. Extensive experiments based on real-world datasets show considerably\nimprovements over other recently proposed methods on both tasks. Particularly,\nV1D3 outperforms the first prize winners of both dispatching and repositioning\ntracks in the KDD Cup 2020 RL competition, achieving state-of-the-art results\non improving both total driver income and user experience related metrics.",
          "link": "http://arxiv.org/abs/2105.08791",
          "publishedOn": "2021-06-07T22:33:05.308Z",
          "wordCount": 736,
          "title": "Value Function is All You Need: A Unified Learning Framework for Ride Hailing Platforms. (arXiv:2105.08791v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02614",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinjie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cloninger_A/0/1/0/all/0/1\">Alexander Cloninger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saab_R/0/1/0/all/0/1\">Rayan Saab</a>",
          "description": "We propose the use of low bit-depth Sigma-Delta and distributed noise-shaping\nmethods for quantizing the Random Fourier features (RFFs) associated with\nshift-invariant kernels. We prove that our quantized RFFs -- even in the case\nof $1$-bit quantization -- allow a high accuracy approximation of the\nunderlying kernels, and the approximation error decays at least polynomially\nfast as the dimension of the RFFs increases. We also show that the quantized\nRFFs can be further compressed, yielding an excellent trade-off between memory\nuse and accuracy. Namely, the approximation error now decays exponentially as a\nfunction of the bits used. Moreover, we empirically show by testing the\nperformance of our methods on several machine learning tasks that our method\ncompares favorably to other state of the art quantization methods in this\ncontext.",
          "link": "http://arxiv.org/abs/2106.02614",
          "publishedOn": "2021-06-07T03:06:17.007Z",
          "wordCount": 566,
          "title": "Sigma-Delta and Distributed Noise-Shaping Quantization Methods for Random Fourier Features. (arXiv:2106.02614v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2101.07415",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xingyou Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choromanski_K/0/1/0/all/0/1\">Krzysztof Choromanski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parker_Holder_J/0/1/0/all/0/1\">Jack Parker-Holder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1\">Yunhao Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_D/0/1/0/all/0/1\">Daiyi Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_D/0/1/0/all/0/1\">Deepali Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1\">Wenbo Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pacchiano_A/0/1/0/all/0/1\">Aldo Pacchiano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarlos_T/0/1/0/all/0/1\">Tamas Sarlos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yuxiang Yang</a>",
          "description": "We introduce ES-ENAS, a simple yet general evolutionary joint optimization\nprocedure by combining continuous optimization via Evolutionary Strategies (ES)\nand combinatorial optimization via Efficient NAS (ENAS) in a highly scalable\nand intuitive way. Our main insight is noticing that ES is already a highly\ndistributed algorithm involving hundreds of forward passes which can not only\nbe used for training neural network weights, but also for jointly training a\nNAS controller, both in a blackbox fashion. By doing so, we also bridge the gap\nfrom NAS research in supervised learning settings to the reinforcement learning\nscenario through this relatively simple marriage between two different yet\ncommon lines of research. We demonstrate the utility and effectiveness of our\nmethod over a large search space by training highly combinatorial neural\nnetwork architectures for RL problems in continuous control, via edge pruning\nand quantization. We also incorporate a wide variety of popular techniques from\nmodern NAS literature including multiobjective optimization along with various\ncontroller methods, to showcase their promise in the RL field and discuss\npossible extensions.",
          "link": "http://arxiv.org/abs/2101.07415",
          "publishedOn": "2021-06-07T03:06:17.000Z",
          "wordCount": 674,
          "title": "ES-ENAS: Controller-Based Architecture Search for Evolutionary Reinforcement Learning. (arXiv:2101.07415v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.00749",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Luo_Y/0/1/0/all/0/1\">Yubo Luo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nirjon_S/0/1/0/all/0/1\">Shahriar Nirjon</a>",
          "description": "We propose SmartON, a batteryless system that learns to wake up proactively\nat the right moment in order to detect events of interest. It does so by\nadapting the duty cycle to match the distribution of event arrival times under\nthe constraints of harvested energy. While existing energy harvesting systems\neither wake up periodically at a fixed rate to sense and process the data, or\nwake up only in accordance with the availability of the energy source, SmartON\nemploys a three-phase learning framework to learn the energy harvesting pattern\nas well as the pattern of events at run-time, and uses that knowledge to wake\nitself up when events are most likely to occur. The three-phase learning\nframework enables rapid adaptation to environmental changes in both short and\nlong terms. Being able to remain asleep more often than a CTID\n(charging-then-immediate-discharging) wake-up system and adapt to the event\npattern, SmartON is able to reduce energy waste, increase energy efficiency,\nand capture more events. To realize SmartON we have developed a dedicated\nhardware platform whose power management module activates capacitors on-the-fly\nto dynamically increase its storage capacitance. We conduct both\nsimulation-driven and real-system experiments to demonstrate that SmartON\ncaptures 1X--7X more events and is 8X--17X more energy-efficient than a CTID\nsystem.",
          "link": "http://arxiv.org/abs/2103.00749",
          "publishedOn": "2021-06-07T03:06:16.993Z",
          "wordCount": 677,
          "title": "SmartON: Just-in-Time Active Event Detection on Energy Harvesting Systems. (arXiv:2103.00749v2 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.12376",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Keswani_V/0/1/0/all/0/1\">Vijay Keswani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mangoubi_O/0/1/0/all/0/1\">Oren Mangoubi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sachdeva_S/0/1/0/all/0/1\">Sushant Sachdeva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vishnoi_N/0/1/0/all/0/1\">Nisheeth K. Vishnoi</a>",
          "description": "Motivated by the recent work of Mangoubi and Vishnoi (STOC 2021), we propose\na variant of the min-max optimization framework where the max-player is\nconstrained to update the maximization variable in a greedy manner until it\nreaches a *first-order* stationary point. We present an algorithm that provably\nconverges to an approximate local equilibrium for our framework from any\ninitialization and for nonconvex-nonconcave loss functions. Compared to the\nsecond-order algorithm of Mangoubi and Vishnoi, whose iteration bound is\npolynomial in the dimension, our algorithm is first-order and its iteration\nbound is independent of dimension. We empirically evaluate our algorithm on\nchallenging nonconvex-nonconcave test-functions and loss functions that arise\nin GAN training. Our algorithm converges on these test functions and, when used\nto train GANs on synthetic and real-world datasets, trains stably and avoids\nmode collapse.",
          "link": "http://arxiv.org/abs/2006.12376",
          "publishedOn": "2021-06-07T03:06:16.987Z",
          "wordCount": 634,
          "title": "A Convergent and Dimension-Independent First-Order Algorithm for Min-Max Optimization. (arXiv:2006.12376v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.03034",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cooper_A/0/1/0/all/0/1\">A. Feder Cooper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yucheng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forde_J/0/1/0/all/0/1\">Jessica Zosa Forde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sa_C/0/1/0/all/0/1\">Christopher De Sa</a>",
          "description": "Recent empirical work shows that inconsistent results, based on choice of\nhyperparameter optimization (HPO) configuration, are a widespread problem in ML\nresearch. When comparing two algorithms J and K, searching one subspace can\nyield the conclusion that J outperforms K, whereas searching another can entail\nthe opposite. In short, the way we choose hyperparameters can deceive us. We\nprovide a theoretical complement to this prior work, arguing that, to avoid\nsuch deception, the process of drawing conclusions from HPO should be made more\nrigorous. We call this process epistemic hyperparameter optimization (EHPO),\nand put forth a logical framework to capture its semantics and how it can lead\nto inconsistent conclusions about performance. Our framework enables us to\nprove EHPO methods that are guaranteed to be defended against deception. We\ndemonstrate its utility by proving and empirically validating a defended\nvariant of random search.",
          "link": "http://arxiv.org/abs/2102.03034",
          "publishedOn": "2021-06-07T03:06:16.981Z",
          "wordCount": 617,
          "title": "Hyperparameter Optimization Is Deceiving Us, and How to Stop It. (arXiv:2102.03034v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02553",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baek_J/0/1/0/all/0/1\">Jackie Baek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farias_V/0/1/0/all/0/1\">Vivek F. Farias</a>",
          "description": "Motivated by the consideration of fairly sharing the cost of exploration\nbetween multiple groups in learning problems, we develop the Nash bargaining\nsolution in the context of multi-armed bandits. Specifically, the 'grouped'\nbandit associated with any multi-armed bandit problem associates, with each\ntime step, a single group from some finite set of groups. The utility gained by\na given group under some learning policy is naturally viewed as the reduction\nin that group's regret relative to the regret that group would have incurred\n'on its own'. We derive policies that yield the Nash bargaining solution\nrelative to the set of incremental utilities possible under any policy. We show\nthat on the one hand, the 'price of fairness' under such policies is limited,\nwhile on the other hand, regret optimal policies are arbitrarily unfair under\ngeneric conditions. Our theoretical development is complemented by a case study\non contextual bandits for warfarin dosing where we are concerned with the cost\nof exploration across multiple races and age groups.",
          "link": "http://arxiv.org/abs/2106.02553",
          "publishedOn": "2021-06-07T03:06:16.974Z",
          "wordCount": 587,
          "title": "Fair Exploration via Axiomatic Bargaining. (arXiv:2106.02553v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02608",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1\">Shushan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zha_H/0/1/0/all/0/1\">Hongyuan Zha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1\">Xiaojing Ye</a>",
          "description": "We propose a novel learning framework using neural mean-field (NMF) dynamics\nfor inference and estimation problems on heterogeneous diffusion networks. Our\nnew framework leverages the Mori-Zwanzig formalism to obtain an exact evolution\nequation of the individual node infection probabilities, which renders a delay\ndifferential equation with memory integral approximated by learnable time\nconvolution operators. Directly using information diffusion cascade data, our\nframework can simultaneously learn the structure of the diffusion network and\nthe evolution of node infection probabilities. Connections between parameter\nlearning and optimal control are also established, leading to a rigorous and\nimplementable algorithm for training NMF. Moreover, we show that the projected\ngradient descent method can be employed to solve the challenging influence\nmaximization problem, where the gradient is computed extremely fast by\nintegrating NMF forward in time just once in each iteration. Extensive\nempirical studies show that our approach is versatile and robust to variations\nof the underlying diffusion network models, and significantly outperform\nexisting approaches in accuracy and efficiency on both synthetic and real-world\ndata.",
          "link": "http://arxiv.org/abs/2106.02608",
          "publishedOn": "2021-06-07T03:06:16.956Z",
          "wordCount": 631,
          "title": "Influence Estimation and Maximization via Neural Mean-Field Dynamics. (arXiv:2106.02608v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.07038",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Somnath_V/0/1/0/all/0/1\">Vignesh Ram Somnath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bunne_C/0/1/0/all/0/1\">Charlotte Bunne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coley_C/0/1/0/all/0/1\">Connor W. Coley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1\">Andreas Krause</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barzilay_R/0/1/0/all/0/1\">Regina Barzilay</a>",
          "description": "Retrosynthesis prediction is a fundamental problem in organic synthesis,\nwhere the task is to identify precursor molecules that can be used to\nsynthesize a target molecule. A key consideration in building neural models for\nthis task is aligning model design with strategies adopted by chemists.\nBuilding on this viewpoint, this paper introduces a graph-based approach that\ncapitalizes on the idea that the graph topology of precursor molecules is\nlargely unaltered during a chemical reaction. The model first predicts the set\nof graph edits transforming the target into incomplete molecules called\nsynthons. Next, the model learns to expand synthons into complete molecules by\nattaching relevant leaving groups. This decomposition simplifies the\narchitecture, making its predictions more interpretable, and also amenable to\nmanual correction. Our model achieves a top-1 accuracy of $53.7\\%$,\noutperforming previous template-free and semi-template-based methods.",
          "link": "http://arxiv.org/abs/2006.07038",
          "publishedOn": "2021-06-07T03:06:16.949Z",
          "wordCount": 596,
          "title": "Learning Graph Models for Retrosynthesis Prediction. (arXiv:2006.07038v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02585",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hess_T/0/1/0/all/0/1\">Timm Hess</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mundt_M/0/1/0/all/0/1\">Martin Mundt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pliushch_I/0/1/0/all/0/1\">Iuliia Pliushch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramesh_V/0/1/0/all/0/1\">Visvanathan Ramesh</a>",
          "description": "Several families of continual learning techniques have been proposed to\nalleviate catastrophic interference in deep neural network training on\nnon-stationary data. However, a comprehensive comparison and analysis of\nlimitations remains largely open due to the inaccessibility to suitable\ndatasets. Empirical examination not only varies immensely between individual\nworks, it further currently relies on contrived composition of benchmarks\nthrough subdivision and concatenation of various prevalent static vision\ndatasets. In this work, our goal is to bridge this gap by introducing a\ncomputer graphics simulation framework that repeatedly renders only upcoming\nurban scene fragments in an endless real-time procedural world generation\nprocess. At its core lies a modular parametric generative model with adaptable\ngenerative factors. The latter can be used to flexibly compose data streams,\nwhich significantly facilitates a detailed analysis and allows for effortless\ninvestigation of various continual learning schemes.",
          "link": "http://arxiv.org/abs/2106.02585",
          "publishedOn": "2021-06-07T03:06:16.942Z",
          "wordCount": 576,
          "title": "A Procedural World Generation Framework for Systematic Evaluation of Continual Learning. (arXiv:2106.02585v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.06422",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Makar_M/0/1/0/all/0/1\">Maggie Makar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Packer_B/0/1/0/all/0/1\">Ben Packer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moldovan_D/0/1/0/all/0/1\">Dan Moldovan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blalock_D/0/1/0/all/0/1\">Davis Blalock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Halpern_Y/0/1/0/all/0/1\">Yoni Halpern</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DAmour_A/0/1/0/all/0/1\">Alexander D&#x27;Amour</a>",
          "description": "Robustness to certain forms of distribution shift is a key concern in many ML\napplications. Often, robustness can be formulated as enforcing invariances to\nparticular interventions on the data generating process. Here, we study a\nflexible, causally-motivated approach to enforcing such invariances, paying\nspecial attention to shortcut learning, where a robust predictor can achieve\noptimal i.i.d generalization in principle, but instead it relies on spurious\ncorrelations or shortcuts in practice. Our approach uses auxiliary labels,\ntypically available at training time, to enforce conditional independences\nbetween the latent factors that determine these labels. We show both\ntheoretically and empirically that causally-motivated regularization schemes\n(a) lead to more robust estimators that generalize well under distribution\nshift, and (b) have better finite sample efficiency compared to usual\nregularization schemes, even in the absence of distribution shifts. Our\nanalysis highlights important theoretical properties of training techniques\ncommonly used in causal inference, fairness, and disentanglement literature.",
          "link": "http://arxiv.org/abs/2105.06422",
          "publishedOn": "2021-06-07T03:06:16.936Z",
          "wordCount": 604,
          "title": "Causally-motivated Shortcut Removal Using Auxiliary Labels. (arXiv:2105.06422v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.08737",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sudhakaran_S/0/1/0/all/0/1\">Shyam Sudhakaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grbic_D/0/1/0/all/0/1\">Djordje Grbic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Siyan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katona_A/0/1/0/all/0/1\">Adam Katona</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Najarro_E/0/1/0/all/0/1\">Elias Najarro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glanois_C/0/1/0/all/0/1\">Claire Glanois</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Risi_S/0/1/0/all/0/1\">Sebastian Risi</a>",
          "description": "Neural Cellular Automata (NCAs) have been proven effective in simulating\nmorphogenetic processes, the continuous construction of complex structures from\nvery few starting cells. Recent developments in NCAs lie in the 2D domain,\nnamely reconstructing target images from a single pixel or infinitely growing\n2D textures. In this work, we propose an extension of NCAs to 3D, utilizing 3D\nconvolutions in the proposed neural network architecture. Minecraft is selected\nas the environment for our automaton since it allows the generation of both\nstatic structures and moving machines. We show that despite their simplicity,\nNCAs are capable of growing complex entities such as castles, apartment blocks,\nand trees, some of which are composed of over 3,000 blocks. Additionally, when\ntrained for regeneration, the system is able to regrow parts of simple\nfunctional machines, significantly expanding the capabilities of simulated\nmorphogenetic systems. The code for the experiment in this paper can be found\nat: https://github.com/real-itu/3d-artefacts-nca.",
          "link": "http://arxiv.org/abs/2103.08737",
          "publishedOn": "2021-06-07T03:06:16.920Z",
          "wordCount": 628,
          "title": "Growing 3D Artefacts and Functional Machines with Neural Cellular Automata. (arXiv:2103.08737v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.02805",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lubana_E/0/1/0/all/0/1\">Ekdeep Singh Lubana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trivedi_P/0/1/0/all/0/1\">Puja Trivedi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koutra_D/0/1/0/all/0/1\">Danai Koutra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dick_R/0/1/0/all/0/1\">Robert P. Dick</a>",
          "description": "Catastrophic forgetting undermines the effectiveness of deep neural networks\n(DNNs) in scenarios such as continual learning and lifelong learning. While\nseveral methods have been proposed to tackle this problem, there is limited\nwork explaining why these methods work well. This paper has the goal of better\nexplaining a popularly used technique for avoiding catastrophic forgetting:\nquadratic regularization. We show that quadratic regularizers prevent\nforgetting of past tasks by interpolating current and previous values of model\nparameters at every training iteration. Over multiple training iterations, this\ninterpolation operation reduces the learning rates of more important model\nparameters, thereby minimizing their movement. Our analysis also reveals two\ndrawbacks of quadratic regularization: (a) dependence of parameter\ninterpolation on training hyperparameters, which often leads to training\ninstability and (b) assignment of lower importance to deeper layers, which are\ngenerally the place forgetting occurs in DNNs. Via a simple modification to the\norder of operations, we show these drawbacks can be easily avoided, resulting\nin 6.2% higher average accuracy at 4.5% lower average forgetting. Code\navailable at \\url{https://github.com/EkdeepSLubana/QRforgetting}",
          "link": "http://arxiv.org/abs/2102.02805",
          "publishedOn": "2021-06-07T03:06:16.914Z",
          "wordCount": 643,
          "title": "How do Quadratic Regularizers Prevent Catastrophic Forgetting: The Role of Interpolation. (arXiv:2102.02805v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1905.09997",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vaswani_S/0/1/0/all/0/1\">Sharan Vaswani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishkin_A/0/1/0/all/0/1\">Aaron Mishkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laradji_I/0/1/0/all/0/1\">Issam Laradji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_M/0/1/0/all/0/1\">Mark Schmidt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gidel_G/0/1/0/all/0/1\">Gauthier Gidel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lacoste_Julien_S/0/1/0/all/0/1\">Simon Lacoste-Julien</a>",
          "description": "Recent works have shown that stochastic gradient descent (SGD) achieves the\nfast convergence rates of full-batch gradient descent for over-parameterized\nmodels satisfying certain interpolation conditions. However, the step-size used\nin these works depends on unknown quantities and SGD's practical performance\nheavily relies on the choice of this step-size. We propose to use line-search\ntechniques to automatically set the step-size when training models that can\ninterpolate the data. In the interpolation setting, we prove that SGD with a\nstochastic variant of the classic Armijo line-search attains the deterministic\nconvergence rates for both convex and strongly-convex functions. Under\nadditional assumptions, SGD with Armijo line-search is shown to achieve fast\nconvergence for non-convex functions. Furthermore, we show that stochastic\nextra-gradient with a Lipschitz line-search attains linear convergence for an\nimportant class of non-convex functions and saddle-point problems satisfying\ninterpolation. To improve the proposed methods' practical performance, we give\nheuristics to use larger step-sizes and acceleration. We compare the proposed\nalgorithms against numerous optimization methods on standard classification\ntasks using both kernel methods and deep networks. The proposed methods result\nin competitive performance across all models and datasets, while being robust\nto the precise choices of hyper-parameters. For multi-class classification\nusing deep networks, SGD with Armijo line-search results in both faster\nconvergence and better generalization.",
          "link": "http://arxiv.org/abs/1905.09997",
          "publishedOn": "2021-06-07T03:06:16.908Z",
          "wordCount": 734,
          "title": "Painless Stochastic Gradient: Interpolation, Line-Search, and Convergence Rates. (arXiv:1905.09997v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11062",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ferianc_M/0/1/0/all/0/1\">Martin Ferianc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maji_P/0/1/0/all/0/1\">Partha Maji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mattina_M/0/1/0/all/0/1\">Matthew Mattina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodrigues_M/0/1/0/all/0/1\">Miguel Rodrigues</a>",
          "description": "Bayesian neural networks (BNNs) are making significant progress in many\nresearch areas where decision-making needs to be accompanied by uncertainty\nestimation. Being able to quantify uncertainty while making decisions is\nessential for understanding when the model is over-/under-confident, and hence\nBNNs are attracting interest in safety-critical applications, such as\nautonomous driving, healthcare, and robotics. Nevertheless, BNNs have not been\nas widely used in industrial practice, mainly because of their increased memory\nand compute costs. In this work, we investigate quantisation of BNNs by\ncompressing 32-bit floating-point weights and activations to their integer\ncounterparts, that has already been successful in reducing the compute demand\nin standard pointwise neural networks. We study three types of quantised BNNs,\nwe evaluate them under a wide range of different settings, and we empirically\ndemonstrate that a uniform quantisation scheme applied to BNNs does not\nsubstantially decrease their quality of uncertainty estimation.",
          "link": "http://arxiv.org/abs/2102.11062",
          "publishedOn": "2021-06-07T03:06:16.902Z",
          "wordCount": 620,
          "title": "On the Effects of Quantisation on Model Uncertainty in Bayesian Neural Networks. (arXiv:2102.11062v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02612",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Diotalevi_T/0/1/0/all/0/1\">Tommaso Diotalevi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Falabella_A/0/1/0/all/0/1\">Antonio Falabella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martelli_B/0/1/0/all/0/1\">Barbara Martelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michelotto_D/0/1/0/all/0/1\">Diego Michelotto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morganti_L/0/1/0/all/0/1\">Lucia Morganti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bonacorsi_D/0/1/0/all/0/1\">Daniele Bonacorsi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giommi_L/0/1/0/all/0/1\">Luca Giommi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tisbeni_S/0/1/0/all/0/1\">Simone Rossi Tisbeni</a>",
          "description": "The distributed Grid infrastructure for High Energy Physics experiments at\nthe Large Hadron Collider (LHC) in Geneva comprises a set of computing centres,\nspread all over the world, as part of the Worldwide LHC Computing Grid (WLCG).\nIn Italy, the Tier-1 functionalities are served by the INFN-CNAF data center,\nwhich provides also computing and storage resources to more than twenty non-LHC\nexperiments. For this reason, a high amount of logs are collected each day from\nvarious sources, which are highly heterogeneous and difficult to harmonize. In\nthis contribution, a working implementation of a system that collects, parses\nand displays the log information from CNAF data sources and the investigation\nof a Machine Learning based predictive maintenance system, is presented.",
          "link": "http://arxiv.org/abs/2106.02612",
          "publishedOn": "2021-06-07T03:06:16.895Z",
          "wordCount": 608,
          "title": "Collection and harmonization of system logs and prototypal Analytics services with the Elastic (ELK) suite at the INFN-CNAF computing centre. (arXiv:2106.02612v1 [cs.DC])"
        },
        {
          "id": "http://arxiv.org/abs/2005.04310",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdali_S/0/1/0/all/0/1\">Sara Abdali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1\">Neil Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papalexakis_E/0/1/0/all/0/1\">Evangelos E. Papalexakis</a>",
          "description": "Distinguishing between misinformation and real information is one of the most\nchallenging problems in today's interconnected world. The vast majority of the\nstate-of-the-art in detecting misinformation is fully supervised, requiring a\nlarge number of high-quality human annotations. However, the availability of\nsuch annotations cannot be taken for granted, since it is very costly,\ntime-consuming, and challenging to do so in a way that keeps up with the\nproliferation of misinformation. In this work, we are interested in exploring\nscenarios where the number of annotations is limited. In such scenarios, we\ninvestigate how tapping on a diverse number of resources that characterize a\nnews article, henceforth referred to as \"aspects\" can compensate for the lack\nof labels. In particular, our contributions in this paper are twofold: 1) We\npropose the use of three different aspects: article content, context of social\nsharing behaviors, and host website/domain features, and 2) We introduce a\nprincipled tensor based embedding framework that combines all those aspects\neffectively. We propose HiJoD a 2-level decomposition pipeline which not only\noutperforms state-of-the-art methods with F1-scores of 74% and 81% on Twitter\nand Politifact datasets respectively but also is an order of magnitude faster\nthan similar ensemble approaches.",
          "link": "http://arxiv.org/abs/2005.04310",
          "publishedOn": "2021-06-07T03:06:16.886Z",
          "wordCount": 665,
          "title": "Semi-Supervised Multi-aspect Detection of Misinformation using Hierarchical Joint Decomposition. (arXiv:2005.04310v2 [cs.SI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02630",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Dohmatob_E/0/1/0/all/0/1\">Elvis Dohmatob</a>",
          "description": "This work studies the (non)robustness of two-layer neural networks in various\nhigh-dimensional linearized regimes. We establish fundamental trade-offs\nbetween memorization and robustness, as measured by the Sobolev-seminorm of the\nmodel w.r.t the data distribution, i.e the square root of the average squared\n$L_2$-norm of the gradients of the model w.r.t the its input. More precisely,\nif $n$ is the number of training examples, $d$ is the input dimension, and $k$\nis the number of hidden neurons in a two-layer neural network, we prove for a\nlarge class of activation functions that, if the model memorizes even a\nfraction of the training, then its Sobolev-seminorm is lower-bounded by (i)\n$\\sqrt{n}$ in case of infinite-width random features (RF) or neural tangent\nkernel (NTK) with $d \\gtrsim n$; (ii) $\\sqrt{n}$ in case of finite-width RF\nwith proportionate scaling of $d$ and $k$; and (iii) $\\sqrt{n/k}$ in case of\nfinite-width NTK with proportionate scaling of $d$ and $k$. Moreover, all of\nthese lower-bounds are tight: they are attained by the min-norm / least-squares\ninterpolator (when $n$, $d$, and $k$ are in the appropriate interpolating\nregime). All our results hold as soon as data is log-concave isotropic, and\nthere is label-noise, i.e the target variable is not a deterministic function\nof the data / features. We empirically validate our theoretical results with\nexperiments. Accidentally, these experiments also reveal for the first time,\n(iv) a multiple-descent phenomenon in the robustness of the min-norm\ninterpolator.",
          "link": "http://arxiv.org/abs/2106.02630",
          "publishedOn": "2021-06-07T03:06:16.878Z",
          "wordCount": 670,
          "title": "Fundamental tradeoffs between memorization and robustness in random features and neural tangent regimes. (arXiv:2106.02630v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2103.09603",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bach_P/0/1/0/all/0/1\">Philipp Bach</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chernozhukov_V/0/1/0/all/0/1\">Victor Chernozhukov</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kurz_M/0/1/0/all/0/1\">Malte S. Kurz</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Spindler_M/0/1/0/all/0/1\">Martin Spindler</a>",
          "description": "The R package DoubleML implements the double/debiased machine learning\nframework of Chernozhukov et al. (2018). It provides functionalities to\nestimate parameters in causal models based on machine learning methods. The\ndouble machine learning framework consist of three key ingredients: Neyman\northogonality, high-quality machine learning estimation and sample splitting.\nEstimation of nuisance components can be performed by various state-of-the-art\nmachine learning methods that are available in the mlr3 ecosystem. DoubleML\nmakes it possible to perform inference in a variety of causal models, including\npartially linear and interactive regression models and their extensions to\ninstrumental variable estimation. The object-oriented implementation of\nDoubleML enables a high flexibility for the model specification and makes it\neasily extendable. This paper serves as an introduction to the double machine\nlearning framework and the R package DoubleML. In reproducible code examples\nwith simulated and real data sets, we demonstrate how DoubleML users can\nperform valid inference based on machine learning methods.",
          "link": "http://arxiv.org/abs/2103.09603",
          "publishedOn": "2021-06-07T03:06:16.871Z",
          "wordCount": 618,
          "title": "DoubleML -- An Object-Oriented Implementation of Double Machine Learning in R. (arXiv:2103.09603v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.13565",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bjorck_J/0/1/0/all/0/1\">Johan Bjorck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiangyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sa_C/0/1/0/all/0/1\">Christopher De Sa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomes_C/0/1/0/all/0/1\">Carla P. Gomes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weinberger_K/0/1/0/all/0/1\">Kilian Q. Weinberger</a>",
          "description": "Low-precision training has become a popular approach to reduce compute\nrequirements, memory footprint, and energy consumption in supervised learning.\nIn contrast, this promising approach has not yet enjoyed similarly widespread\nadoption within the reinforcement learning (RL) community, partly because RL\nagents can be notoriously hard to train even in full precision. In this paper\nwe consider continuous control with the state-of-the-art SAC agent and\ndemonstrate that a na\\\"ive adaptation of low-precision methods from supervised\nlearning fails. We propose a set of six modifications, all straightforward to\nimplement, that leaves the underlying agent and its hyperparameters unchanged\nbut improves the numerical stability dramatically. The resulting modified SAC\nagent has lower memory and compute requirements while matching full-precision\nrewards, demonstrating that low-precision training can substantially accelerate\nstate-of-the-art RL without parameter tuning.",
          "link": "http://arxiv.org/abs/2102.13565",
          "publishedOn": "2021-06-07T03:06:16.840Z",
          "wordCount": 593,
          "title": "Low-Precision Reinforcement Learning: Running Soft Actor-Critic in Half Precision. (arXiv:2102.13565v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.07107",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kutalev_A/0/1/0/all/0/1\">Alexey Kutalev</a>",
          "description": "Not so long ago, a method was discovered that successfully overcomes the\ncatastrophic forgetting in neural networks. Although we know about the cases of\nusing this method to preserve skills when adapting pre-trained networks to\nparticular tasks, it has not obtained widespread distribution yet. In this\npaper, we would like to propose an alternative method of overcoming\ncatastrophic forgetting based on the total absolute signal passing through each\nconnection in the network. This method has a simple implementation and seems to\nus essentially close to the processes occurring in the brain of animals to\npreserve previously learned skills during subsequent learning. We hope that the\nease of implementation of this method will serve its wide application.",
          "link": "http://arxiv.org/abs/2005.07107",
          "publishedOn": "2021-06-07T03:06:16.822Z",
          "wordCount": 574,
          "title": "Natural Way to Overcome the Catastrophic Forgetting in Neural Networks. (arXiv:2005.07107v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2003.01384",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agnew_W/0/1/0/all/0/1\">William Agnew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Domingos_P/0/1/0/all/0/1\">Pedro Domingos</a>",
          "description": "Current deep reinforcement learning (RL) approaches incorporate minimal prior\nknowledge about the environment, limiting computational and sample efficiency.\n\\textit{Objects} provide a succinct and causal description of the world, and\nmany recent works have proposed unsupervised object representation learning\nusing priors and losses over static object properties like visual consistency.\nHowever, object dynamics and interactions are also critical cues for\nobjectness. In this paper we propose a framework for reasoning about object\ndynamics and behavior to rapidly determine minimal and task-specific object\nrepresentations. To demonstrate the need to reason over object behavior and\ndynamics, we introduce a suite of RGBD MuJoCo object collection and avoidance\ntasks that, while intuitive and visually simple, confound state-of-the-art\nunsupervised object representation learning algorithms. We also highlight the\npotential of this framework on several Atari games, using our object\nrepresentation and standard RL and planning algorithms to learn dramatically\nfaster than existing deep RL algorithms.",
          "link": "http://arxiv.org/abs/2003.01384",
          "publishedOn": "2021-06-07T03:06:16.801Z",
          "wordCount": 613,
          "title": "Relevance-Guided Modeling of Object Dynamics for Reinforcement Learning. (arXiv:2003.01384v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.12174",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Fang_S/0/1/0/all/0/1\">Song Fang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhu_Q/0/1/0/all/0/1\">Quanyan Zhu</a>",
          "description": "In this paper, we examine the fundamental performance limitations in the\ncontrol of stochastic dynamical systems; more specifically, we derive generic\n$\\mathcal{L}_p$ bounds that hold for any causal (stabilizing) controllers and\nany stochastic disturbances, by an information-theoretic analysis. We first\nconsider the scenario where the plant (i.e., the dynamical system to be\ncontrolled) is linear time-invariant, and it is seen in general that the lower\nbounds are characterized by the unstable poles (or nonminimum-phase zeros) of\nthe plant as well as the conditional entropy of the disturbance. We then\nanalyze the setting where the plant is assumed to be (strictly) causal, for\nwhich case the lower bounds are determined by the conditional entropy of the\ndisturbance. We also discuss the special cases of $p = 2$ and $p = \\infty$,\nwhich correspond to minimum-variance control and controlling the maximum\ndeviations, respectively. In addition, we investigate the power-spectral\ncharacterization of the lower bounds as well as its relation to the\nKolmogorov-Szeg\\\"o formula.",
          "link": "http://arxiv.org/abs/2012.12174",
          "publishedOn": "2021-06-07T03:06:16.779Z",
          "wordCount": 700,
          "title": "Fundamental Limits of Controlled Stochastic Dynamical Systems: An Information-Theoretic Approach. (arXiv:2012.12174v6 [eess.SY] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11448",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Su_D/0/1/0/all/0/1\">DiJia Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jason D. Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mulvey_J/0/1/0/all/0/1\">John M. Mulvey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poor_H/0/1/0/all/0/1\">H. Vincent Poor</a>",
          "description": "In many contemporary applications such as healthcare, finance, robotics, and\nrecommendation systems, continuous deployment of new policies for data\ncollection and online learning is either cost ineffective or impractical. We\nconsider a setting that lies between pure offline reinforcement learning (RL)\nand pure online RL called deployment constrained RL in which the number of\npolicy deployments for data sampling is limited. To solve this challenging\ntask, we propose a new algorithmic learning framework called Model-based\nUncertainty regularized and Sample Efficient Batch Optimization (MUSBO). Our\nframework discovers novel and high quality samples for each deployment to\nenable efficient data collection. During each offline training session, we\nbootstrap the policy update by quantifying the amount of uncertainty within our\ncollected data. In the high support region (low uncertainty), we encourage our\npolicy by taking an aggressive update. In the low support region (high\nuncertainty) when the policy bootstraps into the out-of-distribution region, we\ndownweight it by our estimated uncertainty quantification. Experimental results\nshow that MUSBO achieves state-of-the-art performance in the deployment\nconstrained RL setting.",
          "link": "http://arxiv.org/abs/2102.11448",
          "publishedOn": "2021-06-07T03:06:16.770Z",
          "wordCount": 644,
          "title": "MUSBO: Model-based Uncertainty Regularized and Sample Efficient Batch Optimization for Deployment Constrained Reinforcement Learning. (arXiv:2102.11448v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.13451",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Horvath_S/0/1/0/all/0/1\">Samuel Horvath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laskaridis_S/0/1/0/all/0/1\">Stefanos Laskaridis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Almeida_M/0/1/0/all/0/1\">Mario Almeida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leontiadis_I/0/1/0/all/0/1\">Ilias Leontiadis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venieris_S/0/1/0/all/0/1\">Stylianos I. Venieris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lane_N/0/1/0/all/0/1\">Nicholas D. Lane</a>",
          "description": "Federated Learning (FL) has been gaining significant traction across\ndifferent ML tasks, ranging from vision to keyboard predictions. In large-scale\ndeployments, client heterogeneity is a fact, and constitutes a primary problem\nfor fairness, training performance and accuracy. Although significant efforts\nhave been made into tackling statistical data heterogeneity, the diversity in\nthe processing capabilities and network bandwidth of clients, termed as system\nheterogeneity, has remained largely unexplored. Current solutions either\ndisregard a large portion of available devices or set a uniform limit on the\nmodel's capacity, restricted by the least capable participants. In this work,\nwe introduce Ordered Dropout, a mechanism that achieves an ordered, nested\nrepresentation of knowledge in Neural Networks and enables the extraction of\nlower footprint submodels without the need of retraining. We further show that\nfor linear maps our Ordered Dropout is equivalent to SVD. We employ this\ntechnique, along with a self-distillation methodology, in the realm of FL in a\nframework called FjORD. FjORD alleviates the problem of client system\nheterogeneity by tailoring the model width to the client's capabilities.\nExtensive evaluation on both CNNs and RNNs across diverse modalities shows that\nFjORD consistently leads to significant performance gains over state-of-the-art\nbaselines, while maintaining its nested structure.",
          "link": "http://arxiv.org/abs/2102.13451",
          "publishedOn": "2021-06-07T03:06:16.751Z",
          "wordCount": 703,
          "title": "FjORD: Fair and Accurate Federated Learning under heterogeneous targets with Ordered Dropout. (arXiv:2102.13451v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.13631",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Shengding Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_X/0/1/0/all/0/1\">Xin Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Cheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jie Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Juanzi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>",
          "description": "A comprehensive knowledge graph (KG) contains an instance-level entity graph\nand an ontology-level concept graph. The two-view KG provides a testbed for\nmodels to \"simulate\" human's abilities on knowledge abstraction,\nconcretization, and completion (KACC), which are crucial for human to recognize\nthe world and manage learned knowledge. Existing studies mainly focus on\npartial aspects of KACC. In order to promote thorough analyses for KACC\nabilities of models, we propose a unified KG benchmark by improving existing\nbenchmarks in terms of dataset scale, task coverage, and difficulty.\nSpecifically, we collect new datasets that contain larger concept graphs,\nabundant cross-view links as well as dense entity graphs. Based on the\ndatasets, we propose novel tasks such as multi-hop knowledge abstraction (MKA),\nmulti-hop knowledge concretization (MKC) and then design a comprehensive\nbenchmark. For MKA and MKC tasks, we further annotate multi-hop hierarchical\ntriples as harder samples. The experimental results of existing methods\ndemonstrate the challenges of our benchmark. The resource is available at\nhttps://github.com/thunlp/KACC.",
          "link": "http://arxiv.org/abs/2004.13631",
          "publishedOn": "2021-06-07T03:06:16.744Z",
          "wordCount": 647,
          "title": "KACC: A Multi-task Benchmark for Knowledge Abstraction, Concretization and Completion. (arXiv:2004.13631v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.07945",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Touati_A/0/1/0/all/0/1\">Ahmed Touati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ollivier_Y/0/1/0/all/0/1\">Yann Ollivier</a>",
          "description": "We introduce the forward-backward (FB) representation of the dynamics of a\nreward-free Markov decision process. It provides explicit near-optimal policies\nfor any reward specified a posteriori. During an unsupervised phase, we use\nreward-free interactions with the environment to learn two representations via\noff-the-shelf deep learning methods and temporal difference (TD) learning. In\nthe test phase, a reward representation is estimated either from observations\nor an explicit reward description (e.g., a target state). The optimal policy\nfor that reward is directly obtained from these representations, with no\nplanning. We assume access to an exploration scheme or replay buffer for the\nfirst phase.\n\nThe unsupervised FB loss is well-principled: if training is perfect, the\npolicies obtained are provably optimal for any reward function. With imperfect\ntraining, the sub-optimality is proportional to the unsupervised approximation\nerror. The FB representation learns long-range relationships between states and\nactions, via a predictive occupancy map, without having to synthesize states as\nin model-based approaches.\n\nThis is a step towards learning controllable agents in arbitrary black-box\nstochastic environments. This approach compares well to goal-oriented RL\nalgorithms on discrete and continuous mazes, pixel-based MsPacman, and the\nFetchReach virtual robot arm. We also illustrate how the agent can immediately\nadapt to new tasks beyond goal-oriented RL.",
          "link": "http://arxiv.org/abs/2103.07945",
          "publishedOn": "2021-06-07T03:06:16.728Z",
          "wordCount": 661,
          "title": "Learning One Representation to Optimize All Rewards. (arXiv:2103.07945v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.12964",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jianxin Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jianwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hongxia Yang</a>",
          "description": "Deep candidate generation (DCG) that narrows down the collection of relevant\nitems from billions to hundreds via representation learning has become\nprevalent in industrial recommender systems. Standard approaches approximate\nmaximum likelihood estimation (MLE) through sampling for better scalability and\naddress the problem of DCG in a way similar to language modeling. However, live\nrecommender systems face severe exposure bias and have a vocabulary several\norders of magnitude larger than that of natural language, implying that MLE\nwill preserve and even exacerbate the exposure bias in the long run in order to\nfaithfully fit the observed samples. In this paper, we theoretically prove that\na popular choice of contrastive loss is equivalent to reducing the exposure\nbias via inverse propensity weighting, which provides a new perspective for\nunderstanding the effectiveness of contrastive learning. Based on the\ntheoretical discovery, we design CLRec, a contrastive learning method to\nimprove DCG in terms of fairness, effectiveness and efficiency in recommender\nsystems with extremely large candidate size. We further improve upon CLRec and\npropose Multi-CLRec, for accurate multi-intention aware bias reduction. Our\nmethods have been successfully deployed in Taobao, where at least four-month\nonline A/B tests and offline analyses demonstrate its substantial improvements,\nincluding a dramatic reduction in the Matthew effect.",
          "link": "http://arxiv.org/abs/2005.12964",
          "publishedOn": "2021-06-07T03:06:16.706Z",
          "wordCount": 759,
          "title": "Contrastive Learning for Debiased Candidate Generation in Large-Scale Recommender Systems. (arXiv:2005.12964v9 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.10460",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Chen_V/0/1/0/all/0/1\">Violet Xinying Chen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kilinc_Karzan_F/0/1/0/all/0/1\">Fatma K&#x131;l&#x131;n&#xe7;-Karzan</a>",
          "description": "We study the problem of online learning (OL) from revealed preferences: a\nlearner wishes to learn a non-strategic agent's private utility function\nthrough observing the agent's utility-maximizing actions in a changing\nenvironment. We adopt an online inverse optimization setup, where the learner\nobserves a stream of agent's actions in an online fashion and the learning\nperformance is measured by regret associated with a loss function. We first\ncharacterize a special but broad class of agent's utility functions, then\nutilize this structure in designing a new convex loss function. We establish\nthat the regret with respect to our new loss function also bounds the regret\nwith respect to all other usual loss functions in the literature. This allows\nus to design a flexible OL framework that enables a unified treatment of loss\nfunctions and supports a variety of online convex optimization algorithms. We\ndemonstrate with theoretical and empirical evidence that our framework based on\nthe new loss function (in particular online Mirror Descent) has significant\nadvantages in terms of regret performance and solution time over other OL\nalgorithms from the literature and bypasses the previous technical assumptions\nas well.",
          "link": "http://arxiv.org/abs/2008.10460",
          "publishedOn": "2021-06-07T03:06:16.665Z",
          "wordCount": 651,
          "title": "Online Convex Optimization Perspective for Learning from Dynamically Revealed Preferences. (arXiv:2008.10460v3 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02552",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Heinrich Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rostamizadeh_A/0/1/0/all/0/1\">Afshin Rostamizadeh</a>",
          "description": "We analyze the problem of active covering, where the learner is given an\nunlabeled dataset and can sequentially label query examples. The objective is\nto label query all of the positive examples in the fewest number of total label\nqueries. We show under standard non-parametric assumptions that a classical\nsupport estimator can be repurposed as an offline algorithm attaining an excess\nquery cost of $\\widetilde{\\Theta}(n^{D/(D+1)})$ compared to the optimal\nlearner, where $n$ is the number of datapoints and $D$ is the dimension. We\nthen provide a simple active learning method that attains an improved excess\nquery cost of $\\widetilde{O}(n^{(D-1)/D})$. Furthermore, the proposed\nalgorithms only require access to the positive labeled examples, which in\ncertain settings provides additional computational and privacy benefits.\nFinally, we show that the active learning method consistently outperforms\noffline methods as well as a variety of baselines on a wide range of benchmark\nimage-based datasets.",
          "link": "http://arxiv.org/abs/2106.02552",
          "publishedOn": "2021-06-07T03:06:16.658Z",
          "wordCount": 567,
          "title": "Active Covering. (arXiv:2106.02552v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2002.06799",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kommrusch_S/0/1/0/all/0/1\">Steve Kommrusch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barollet_T/0/1/0/all/0/1\">Th&#xe9;o Barollet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pouchet_L/0/1/0/all/0/1\">Louis-No&#xeb;l Pouchet</a>",
          "description": "In this work we target the problem of provably computing the equivalence\nbetween two programs represented as dataflow graphs. To this end, we formalize\nthe problem of equivalence between two programs as finding a set of\nsemantics-preserving rewrite rules from one into the other, such that after the\nrewrite the two programs are structurally identical, and therefore trivially\nequivalent. We then develop the first graph-to-sequence neural network system\nfor program equivalence, trained to produce such rewrite sequences from a\ncarefully crafted automatic example generation algorithm. We extensively\nevaluate our system on a rich multi-type linear algebra expression language,\nusing arbitrary combinations of 100+ graph-rewriting axioms of equivalence. Our\nsystem outputs via inference a correct rewrite sequence for 96% of the 10,000\nprogram pairs isolated for testing, using 30-term programs. And in all cases,\nthe validity of the sequence produced and therefore the provable assertion of\nprogram equivalence is computable, in negligible time.",
          "link": "http://arxiv.org/abs/2002.06799",
          "publishedOn": "2021-06-07T03:06:16.651Z",
          "wordCount": 634,
          "title": "Equivalence of Dataflow Graphs via Rewrite Rules Using a Graph-to-Sequence Neural Model. (arXiv:2002.06799v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02636",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zellers_R/0/1/0/all/0/1\">Rowan Zellers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Ximing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hessel_J/0/1/0/all/0/1\">Jack Hessel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Youngjae Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jae Sung Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1\">Jize Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farhadi_A/0/1/0/all/0/1\">Ali Farhadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>",
          "description": "As humans, we understand events in the visual world contextually, performing\nmultimodal reasoning across time to make inferences about the past, present,\nand future. We introduce MERLOT, a model that learns multimodal script\nknowledge by watching millions of YouTube videos with transcribed speech -- in\nan entirely label-free, self-supervised manner. By pretraining with a mix of\nboth frame-level (spatial) and video-level (temporal) objectives, our model not\nonly learns to match images to temporally corresponding words, but also to\ncontextualize what is happening globally over time. As a result, MERLOT\nexhibits strong out-of-the-box representations of temporal commonsense, and\nachieves state-of-the-art performance on 12 different video QA datasets when\nfinetuned. It also transfers well to the world of static images, allowing\nmodels to reason about the dynamic context behind visual scenes. On Visual\nCommonsense Reasoning, MERLOT answers questions correctly with 80.6% accuracy,\noutperforming state-of-the-art models of similar size by over 3%, even those\nthat make heavy use of auxiliary supervised data (like object bounding boxes).\n\nAblation analyses demonstrate the complementary importance of: 1) training on\nvideos versus static images; 2) scaling the magnitude and diversity of the\npretraining video corpus; and 3) using diverse objectives that encourage\nfull-stack multimodal reasoning, from the recognition to cognition level.",
          "link": "http://arxiv.org/abs/2106.02636",
          "publishedOn": "2021-06-07T03:06:16.634Z",
          "wordCount": 655,
          "title": "MERLOT: Multimodal Neural Script Knowledge Models. (arXiv:2106.02636v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2006.01350",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Liu_Z/0/1/0/all/0/1\">Zejian Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_M/0/1/0/all/0/1\">Meng Li</a>",
          "description": "We study the problem of estimating the derivatives of the regression\nfunction, which has a wide range of applications as a key nonparametric\nfunctional of unknown functions. Standard analysis may be tailored to specific\nderivative orders, and parameter tuning remains a daunting challenge\nparticularly for high-order derivatives. In this article, we propose a simple\nplug-in kernel ridge regression (KRR) estimator in nonparametric regression\nwith random design that is broadly applicable for multi-dimensional support and\narbitrary mixed-partial derivatives. We provide a non-asymptotic analysis to\nstudy the behavior of the proposed estimator, leading to two error bounds for a\ngeneral class of kernels under the strong $L_\\infty$ norm. In a concrete\nexample specialized to kernels with polynomially decaying eigenvalues, the\nproposed estimator recovers the minimax optimal rate up to a logarithmic factor\nfor estimating derivatives of functions in H\\\"older class. Interestingly, the\nproposed estimator achieves the optimal rate of convergence with the same\nchoice of tuning parameter for any order of derivatives. Hence, the proposed\nestimator enjoys a remarkable \\textit{plug-in property} for derivatives in that\nit automatically adapts to the order of derivatives to be estimated, enabling\neasy tuning in practice. Our simulation studies show favorable finite sample\nperformance of the proposed method relative to several existing methods.",
          "link": "http://arxiv.org/abs/2006.01350",
          "publishedOn": "2021-06-07T03:06:16.624Z",
          "wordCount": 655,
          "title": "On the Estimation of Derivatives Using Plug-in KRR Estimators. (arXiv:2006.01350v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.08482",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pellegrini_G/0/1/0/all/0/1\">Giovanni Pellegrini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tibo_A/0/1/0/all/0/1\">Alessandro Tibo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frasconi_P/0/1/0/all/0/1\">Paolo Frasconi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Passerini_A/0/1/0/all/0/1\">Andrea Passerini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaeger_M/0/1/0/all/0/1\">Manfred Jaeger</a>",
          "description": "Learning on sets is increasingly gaining attention in the machine learning\ncommunity, due to its widespread applicability. Typically, representations over\nsets are computed by using fixed aggregation functions such as sum or maximum.\nHowever, recent results showed that universal function representation by sum-\n(or max-) decomposition requires either highly discontinuous (and thus poorly\nlearnable) mappings, or a latent dimension equal to the maximum number of\nelements in the set. To mitigate this problem, we introduce a learnable\naggregation function (LAF) for sets of arbitrary cardinality. LAF can\napproximate several extensively used aggregators (such as average, sum,\nmaximum) as well as more complex functions (e.g., variance and skewness). We\nreport experiments on semi-synthetic and real data showing that LAF outperforms\nstate-of-the-art sum- (max-) decomposition architectures such as DeepSets and\nlibrary-based architectures like Principal Neighborhood Aggregation, and can be\neffectively combined with attention-based architectures.",
          "link": "http://arxiv.org/abs/2012.08482",
          "publishedOn": "2021-06-07T03:06:16.611Z",
          "wordCount": 604,
          "title": "Learning Aggregation Functions. (arXiv:2012.08482v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.06466",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Steven Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiuming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhoutong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Richard Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun-Yan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Russell_B/0/1/0/all/0/1\">Bryan Russell</a>",
          "description": "A neural radiance field (NeRF) is a scene model supporting high-quality view\nsynthesis, optimized per scene. In this paper, we explore enabling user editing\nof a category-level NeRF - also known as a conditional radiance field - trained\non a shape category. Specifically, we introduce a method for propagating coarse\n2D user scribbles to the 3D space, to modify the color or shape of a local\nregion. First, we propose a conditional radiance field that incorporates new\nmodular network components, including a shape branch that is shared across\nobject instances. Observing multiple instances of the same category, our model\nlearns underlying part semantics without any supervision, thereby allowing the\npropagation of coarse 2D user scribbles to the entire 3D region (e.g., chair\nseat). Next, we propose a hybrid network update strategy that targets specific\nnetwork components, which balances efficiency and accuracy. During user\ninteraction, we formulate an optimization problem that both satisfies the\nuser's constraints and preserves the original object structure. We demonstrate\nour approach on various editing tasks over three shape datasets and show that\nit outperforms prior neural editing approaches. Finally, we edit the appearance\nand shape of a real photograph and show that the edit propagates to\nextrapolated novel views.",
          "link": "http://arxiv.org/abs/2105.06466",
          "publishedOn": "2021-06-07T03:06:16.515Z",
          "wordCount": 682,
          "title": "Editing Conditional Radiance Fields. (arXiv:2105.06466v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.04875",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Galashov_A/0/1/0/all/0/1\">Alexandre Galashov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sygnowski_J/0/1/0/all/0/1\">Jakub Sygnowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Desjardins_G/0/1/0/all/0/1\">Guillaume Desjardins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Humplik_J/0/1/0/all/0/1\">Jan Humplik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasenclever_L/0/1/0/all/0/1\">Leonard Hasenclever</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_R/0/1/0/all/0/1\">Rae Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teh_Y/0/1/0/all/0/1\">Yee Whye Teh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heess_N/0/1/0/all/0/1\">Nicolas Heess</a>",
          "description": "The ability to exploit prior experience to solve novel problems rapidly is a\nhallmark of biological learning systems and of great practical importance for\nartificial ones. In the meta reinforcement learning literature much recent work\nhas focused on the problem of optimizing the learning process itself. In this\npaper we study a complementary approach which is conceptually simple, general,\nmodular and built on top of recent improvements in off-policy learning. The\nframework is inspired by ideas from the probabilistic inference literature and\ncombines robust off-policy learning with a behavior prior, or default behavior\nthat constrains the space of solutions and serves as a bias for exploration; as\nwell as a representation for the value function, both of which are easily\nlearned from a number of training tasks in a multi-task scenario. Our approach\nachieves competitive adaptation performance on hold-out tasks compared to meta\nreinforcement learning baselines and can scale to complex sparse-reward\nscenarios.",
          "link": "http://arxiv.org/abs/2009.04875",
          "publishedOn": "2021-06-07T03:06:16.506Z",
          "wordCount": 622,
          "title": "Importance Weighted Policy Learning and Adaptation. (arXiv:2009.04875v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.01484",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+E_W/0/1/0/all/0/1\">Weinan E</a>, <a href=\"http://arxiv.org/find/math/1/au:+Wojtowytsch_S/0/1/0/all/0/1\">Stephan Wojtowytsch</a>",
          "description": "We use explicit representation formulas to show that solutions to certain\npartial differential equations lie in Barron spaces or multilayer spaces if the\nPDE data lie in such function spaces. Consequently, these solutions can be\nrepresented efficiently using artificial neural networks, even in high\ndimension. Conversely, we present examples in which the solution fails to lie\nin the function space associated to a neural network under consideration.",
          "link": "http://arxiv.org/abs/2012.01484",
          "publishedOn": "2021-06-07T03:06:16.243Z",
          "wordCount": null,
          "title": "Some observations on high-dimensional partial differential equations with Barron data. (arXiv:2012.01484v3 [math.AP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14849",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeyer_A/0/1/0/all/0/1\">Albert Zeyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schluter_R/0/1/0/all/0/1\">Ralf Schl&#xfc;ter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ney_H/0/1/0/all/0/1\">Hermann Ney</a>",
          "description": "The peaky behavior of CTC models is well known experimentally. However, an\nunderstanding about why peaky behavior occurs is missing, and whether this is a\ngood property. We provide a formal analysis of the peaky behavior and gradient\ndescent convergence properties of the CTC loss and related training criteria.\nOur analysis provides a deep understanding why peaky behavior occurs and when\nit is suboptimal. On a simple example which should be trivial to learn for any\nmodel, we prove that a feed-forward neural network trained with CTC from\nuniform initialization converges towards peaky behavior with a 100% error rate.\nOur analysis further explains why CTC only works well together with the blank\nlabel. We further demonstrate that peaky behavior does not occur on other\nrelated losses including a label prior model, and that this improves\nconvergence.",
          "link": "http://arxiv.org/abs/2105.14849",
          "publishedOn": "2021-06-07T03:06:16.242Z",
          "wordCount": null,
          "title": "Why does CTC result in peaky behavior?. (arXiv:2105.14849v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.09507",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Markov_I/0/1/0/all/0/1\">Igor L. Markov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jacqueline Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vagner_A/0/1/0/all/0/1\">Adam Vagner</a>",
          "description": "Text classifiers are at the core of many NLP applications and use a variety\nof algorithmic approaches and software. This paper introduces infrastructure\nand methodologies for text classifiers based on large-scale regular\nexpressions. In particular, we describe how Facebook determines if a given\npiece of text - anything from a hashtag to a post - belongs to a narrow topic\nsuch as COVID-19. To fully define a topic and evaluate classifier performance\nwe employ human-guided iterations of keyword discovery, but do not require\nlabeled data. For COVID-19, we build two sets of regular expressions: (1) for\n66 languages, with 99% precision and recall >50%, (2) for the 11 most common\nlanguages, with precision >90% and recall >90%. Regular expressions enable\nlow-latency queries from multiple platforms. Response to challenges like\nCOVID-19 is fast and so are revisions. Comparisons to a DNN classifier show\nexplainable results, higher precision and recall, and less overfitting. Our\nlearnings can be applied to other narrow-topic classifiers.",
          "link": "http://arxiv.org/abs/2102.09507",
          "publishedOn": "2021-06-07T03:06:16.231Z",
          "wordCount": null,
          "title": "Regular Expressions for Fast-response COVID-19 Text Classification. (arXiv:2102.09507v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02597",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Samoilescu_R/0/1/0/all/0/1\">Robert-Florian Samoilescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Looveren_A/0/1/0/all/0/1\">Arnaud Van Looveren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klaise_J/0/1/0/all/0/1\">Janis Klaise</a>",
          "description": "Counterfactual instances are a powerful tool to obtain valuable insights into\nautomated decision processes, describing the necessary minimal changes in the\ninput space to alter the prediction towards a desired target. Most previous\napproaches require a separate, computationally expensive optimization procedure\nper instance, making them impractical for both large amounts of data and\nhigh-dimensional data. Moreover, these methods are often restricted to certain\nsubclasses of machine learning models (e.g. differentiable or tree-based\nmodels). In this work, we propose a deep reinforcement learning approach that\ntransforms the optimization procedure into an end-to-end learnable process,\nallowing us to generate batches of counterfactual instances in a single forward\npass. Our experiments on real-world data show that our method i) is\nmodel-agnostic (does not assume differentiability), relying only on feedback\nfrom model predictions; ii) allows for generating target-conditional\ncounterfactual instances; iii) allows for flexible feature range constraints\nfor numerical and categorical attributes, including the immutability of\nprotected features (e.g. gender, race); iv) is easily extended to other data\nmodalities such as images.",
          "link": "http://arxiv.org/abs/2106.02597",
          "publishedOn": "2021-06-07T03:06:16.230Z",
          "wordCount": 599,
          "title": "Model-agnostic and Scalable Counterfactual Explanations via Reinforcement Learning. (arXiv:2106.02597v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.03939",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Busch_J/0/1/0/all/0/1\">Julian Busch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kocheturov_A/0/1/0/all/0/1\">Anton Kocheturov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tresp_V/0/1/0/all/0/1\">Volker Tresp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seidl_T/0/1/0/all/0/1\">Thomas Seidl</a>",
          "description": "Malicious software (malware) poses an increasing threat to the security of\ncommunication systems as the number of interconnected mobile devices increases\nexponentially. While some existing malware detection and classification\napproaches successfully leverage network traffic data, they treat network flows\nbetween pairs of endpoints independently and thus fail to leverage rich\ncommunication patterns present in the complete network. Our approach first\nextracts flow graphs and subsequently classifies them using a novel edge\nfeature-based graph neural network model. We present three variants of our base\nmodel, which support malware detection and classification in supervised and\nunsupervised settings. We evaluate our approach on flow graphs that we extract\nfrom a recently published dataset for mobile malware detection that addresses\nseveral issues with previously available datasets. Experiments on four\ndifferent prediction tasks consistently demonstrate the advantages of our\napproach and show that our graph neural network model can boost detection\nperformance by a significant margin.",
          "link": "http://arxiv.org/abs/2103.03939",
          "publishedOn": "2021-06-07T03:06:16.224Z",
          "wordCount": 639,
          "title": "NF-GNN: Network Flow Graph Neural Networks for Malware Detection and Classification. (arXiv:2103.03939v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.09258",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Song_Y/0/1/0/all/0/1\">Yang Song</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Durkan_C/0/1/0/all/0/1\">Conor Durkan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Murray_I/0/1/0/all/0/1\">Iain Murray</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ermon_S/0/1/0/all/0/1\">Stefano Ermon</a>",
          "description": "Score-based diffusion models synthesize samples by reversing a stochastic\nprocess that diffuses data to noise, and are trained by minimizing a weighted\ncombination of score matching losses. The log-likelihood of score-based models\ncan be tractably computed through a connection to continuous normalizing flows,\nbut log-likelihood is not directly optimized by the weighted combination of\nscore matching losses. We show that for a specific weighting scheme, the\nobjective upper bounds the negative log-likelihood, thus enabling approximate\nmaximum likelihood training of score-based models. We empirically observe that\nmaximum likelihood training consistently improves the likelihood of score-based\nmodels across multiple datasets, stochastic processes, and model architectures.\nOur best models achieve negative log-likelihoods of 2.74 and 3.76 bits/dim on\nCIFAR-10 and down-sampled ImageNet, outperforming all existing likelihood-based\nmodels.",
          "link": "http://arxiv.org/abs/2101.09258",
          "publishedOn": "2021-06-07T03:06:16.211Z",
          "wordCount": 567,
          "title": "Maximum Likelihood Training of Score-Based Diffusion Models. (arXiv:2101.09258v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.03309",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Carrasco_Davis_R/0/1/0/all/0/1\">Rodrigo Carrasco-Davis</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Reyes_E/0/1/0/all/0/1\">Esteban Reyes</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Valenzuela_C/0/1/0/all/0/1\">Camilo Valenzuela</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Forster_F/0/1/0/all/0/1\">Francisco F&#xf6;rster</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Estevez_P/0/1/0/all/0/1\">Pablo A. Est&#xe9;vez</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Pignata_G/0/1/0/all/0/1\">Giuliano Pignata</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Bauer_F/0/1/0/all/0/1\">Franz E. Bauer</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Reyes_I/0/1/0/all/0/1\">Ignacio Reyes</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Sanchez_Saez_P/0/1/0/all/0/1\">Paula S&#xe1;nchez-S&#xe1;ez</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Cabrera_Vives_G/0/1/0/all/0/1\">Guillermo Cabrera-Vives</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Eyheramendy_S/0/1/0/all/0/1\">Susana Eyheramendy</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Catelan_M/0/1/0/all/0/1\">M&#xe1;rcio Catelan</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Arredondo_J/0/1/0/all/0/1\">Javier Arredondo</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Castillo_Navarrete_E/0/1/0/all/0/1\">Ernesto Castillo-Navarrete</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Rodriguez_Mancini_D/0/1/0/all/0/1\">Diego Rodr&#xed;guez-Mancini</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Ruz_Mieres_D/0/1/0/all/0/1\">Daniela Ruz-Mieres</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Moya_A/0/1/0/all/0/1\">Alberto Moya</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Sabatini_Gacitua_L/0/1/0/all/0/1\">Luis Sabatini-Gacit&#xfa;a</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Sepulveda_Cobo_C/0/1/0/all/0/1\">Crist&#xf3;bal Sep&#xfa;lveda-Cobo</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Mahabal_A/0/1/0/all/0/1\">Ashish A. Mahabal</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Silva_Farfan_J/0/1/0/all/0/1\">Javier Silva-Farf&#xe1;n</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Camacho_Iniquez_E/0/1/0/all/0/1\">Ernesto Camacho-I&#xf1;iquez</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Galbany_L/0/1/0/all/0/1\">Llu&#xed;s Galbany</a>",
          "description": "We present a real-time stamp classifier of astronomical events for the ALeRCE\n(Automatic Learning for the Rapid Classification of Events) broker. The\nclassifier is based on a convolutional neural network, trained on alerts\ningested from the Zwicky Transient Facility (ZTF). Using only the\n\\textit{science, reference} and \\textit{difference} images of the first\ndetection as inputs, along with the metadata of the alert as features, the\nclassifier is able to correctly classify alerts from active galactic nuclei,\nsupernovae (SNe), variable stars, asteroids and bogus classes, with high\naccuracy ($\\sim$94\\%) in a balanced test set. In order to find and analyze SN\ncandidates selected by our classifier from the ZTF alert stream, we designed\nand deployed a visualization tool called SN Hunter, where relevant information\nabout each possible SN is displayed for the experts to choose among candidates\nto report to the Transient Name Server database. From June 26th 2019 to\nFebruary 28th 2021, we have reported 6846 SN candidates to date (11.8\ncandidates per day on average), of which 971 have been confirmed\nspectroscopically. Our ability to report objects using only a single detection\nmeans that 70\\% of the reported SNe occurred within one day after the first\ndetection. ALeRCE has only reported candidates not otherwise detected or\nselected by other groups, therefore adding new early transients to the bulk of\nobjects available for early follow-up. Our work represents an important\nmilestone toward rapid alert classifications with the next generation of large\netendue telescopes, such as the Vera C. Rubin Observatory.",
          "link": "http://arxiv.org/abs/2008.03309",
          "publishedOn": "2021-06-07T03:06:16.204Z",
          "wordCount": 764,
          "title": "Alert Classification for the ALeRCE Broker System: The Real-time Stamp Classifier. (arXiv:2008.03309v2 [astro-ph.IM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02607",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Trivedi_A/0/1/0/all/0/1\">Anusua Trivedi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suhm_A/0/1/0/all/0/1\">Alyssa Suhm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahankal_P/0/1/0/all/0/1\">Prathamesh Mahankal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukuntharaj_S/0/1/0/all/0/1\">Subhiksha Mukuntharaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parab_M/0/1/0/all/0/1\">Meghana D. Parab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohan_M/0/1/0/all/0/1\">Malvika Mohan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berger_M/0/1/0/all/0/1\">Meredith Berger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sethumadhavan_A/0/1/0/all/0/1\">Arathi Sethumadhavan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaiman_A/0/1/0/all/0/1\">Ashish Jaiman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dodhia_R/0/1/0/all/0/1\">Rahul Dodhia</a>",
          "description": "The rise in online misinformation in recent years threatens democracies by\ndistorting authentic public discourse and causing confusion, fear, and even, in\nextreme cases, violence. There is a need to understand the spread of false\ncontent through online networks for developing interventions that disrupt\nmisinformation before it achieves virality. Using a Deep Bidirectional\nTransformer for Language Understanding (BERT) and propagation graphs, this\nstudy classifies and visualizes the spread of misinformation on a social media\nnetwork using publicly available Twitter data. The results confirm prior\nresearch around user clusters and the virality of false content while improving\nthe precision of deep learning models for misinformation detection. The study\nfurther demonstrates the suitability of BERT for providing a scalable model for\nfalse information detection, which can contribute to the development of more\ntimely and accurate interventions to slow the spread of misinformation in\nonline environments.",
          "link": "http://arxiv.org/abs/2106.02607",
          "publishedOn": "2021-06-07T03:06:16.183Z",
          "wordCount": 600,
          "title": "Defending Democracy: Using Deep Learning to Identify and Prevent Misinformation. (arXiv:2106.02607v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/1912.11603",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Yamaguchi_S/0/1/0/all/0/1\">Shin&#x27;ya Yamaguchi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kanai_S/0/1/0/all/0/1\">Sekitoshi Kanai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shioda_T/0/1/0/all/0/1\">Tetsuya Shioda</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Takeda_S/0/1/0/all/0/1\">Shoichiro Takeda</a>",
          "description": "The rotation prediction (Rotation) is a simple pretext-task for\nself-supervised learning (SSL), where models learn useful representations for\ntarget vision tasks by solving pretext-tasks. Although Rotation captures\ninformation of object shapes, it hardly captures information of textures. To\ntackle this problem, we introduce a novel pretext-task called image enhanced\nrotation prediction (IE-Rot) for SSL. IE-Rot simultaneously solves Rotation and\nanother pretext-task based on image enhancement (e.g., sharpening and\nsolarizing) while maintaining simplicity. Through the simultaneous prediction\nof rotation and image enhancement, models learn representations to capture the\ninformation of not only object shapes but also textures. Our experimental\nresults show that IE-Rot models outperform Rotation on various standard\nbenchmarks including ImageNet classification, PASCAL-VOC detection, and COCO\ndetection/segmentation.",
          "link": "http://arxiv.org/abs/1912.11603",
          "publishedOn": "2021-06-07T03:06:16.176Z",
          "wordCount": 589,
          "title": "Image Enhanced Rotation Prediction for Self-Supervised Learning. (arXiv:1912.11603v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.10897",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1\">Simon S. Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1\">Sham M. Kakade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jason D. Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lovett_S/0/1/0/all/0/1\">Shachar Lovett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahajan_G/0/1/0/all/0/1\">Gaurav Mahajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Wen Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Ruosong Wang</a>",
          "description": "This work introduces Bilinear Classes, a new structural framework, which\npermit generalization in reinforcement learning in a wide variety of settings\nthrough the use of function approximation. The framework incorporates nearly\nall existing models in which a polynomial sample complexity is achievable, and,\nnotably, also includes new models, such as the Linear $Q^*/V^*$ model in which\nboth the optimal $Q$-function and the optimal $V$-function are linear in some\nknown feature space. Our main result provides an RL algorithm which has\npolynomial sample complexity for Bilinear Classes; notably, this sample\ncomplexity is stated in terms of a reduction to the generalization error of an\nunderlying supervised learning sub-problem. These bounds nearly match the best\nknown sample complexity bounds for existing models. Furthermore, this framework\nalso extends to the infinite dimensional (RKHS) setting: for the the Linear\n$Q^*/V^*$ model, linear MDPs, and linear mixture MDPs, we provide sample\ncomplexities that have no explicit dependence on the explicit feature dimension\n(which could be infinite), but instead depends only on information theoretic\nquantities.",
          "link": "http://arxiv.org/abs/2103.10897",
          "publishedOn": "2021-06-07T03:06:16.169Z",
          "wordCount": 674,
          "title": "Bilinear Classes: A Structural Framework for Provable Generalization in RL. (arXiv:2103.10897v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2001.03813",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fang_S/0/1/0/all/0/1\">Song Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1\">Quanyan Zhu</a>",
          "description": "In this paper, we examine the fundamental performance limits of prediction,\nwith or without side information. More specifically, we derive generic lower\nbounds on the $\\mathcal{L}_p$ norms of the prediction errors that are valid for\nany prediction algorithms and for any data distributions. Meanwhile, we combine\nthe entropic analysis from information theory and the innovations approach from\nprediction/estimation theory to characterize the conditions (in terms of, e.g.,\ndirected information or mutual information) to achieve the bounds. We also\ninvestigate the implications of the results in analyzing the fundamental limits\nof generalization in fitting (learning) problems from the perspective of\nprediction with side information, as well as the fundamental limits of\nrecursive algorithms by viewing them as generalized prediction problems.",
          "link": "http://arxiv.org/abs/2001.03813",
          "publishedOn": "2021-06-07T03:06:16.162Z",
          "wordCount": 628,
          "title": "Fundamental Limits of Prediction, Generalization, and Recursion: An Entropic-Innovations Perspective. (arXiv:2001.03813v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.12056",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Shi_C/0/1/0/all/0/1\">Changfa Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xian_M/0/1/0/all/0/1\">Min Xian</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_X/0/1/0/all/0/1\">Xiancheng Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1\">Haotian Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheng_H/0/1/0/all/0/1\">Heng-Da Cheng</a>",
          "description": "Liver segmentation from abdominal CT images is an essential step for liver\ncancer computer-aided diagnosis and surgical planning. However, both the\naccuracy and robustness of existing liver segmentation methods cannot meet the\nrequirements of clinical applications. In particular, for the common clinical\ncases where the liver tissue contains major pathology, current segmentation\nmethods show poor performance. In this paper, we propose a novel low-rank\ntensor decomposition (LRTD) based multi-atlas segmentation (MAS) framework that\nachieves accurate and robust pathological liver segmentation of CT images.\nFirstly, we propose a multi-slice LRTD scheme to recover the underlying\nlow-rank structure embedded in 3D medical images. It performs the LRTD on small\nimage segments consisting of multiple consecutive image slices. Then, we\npresent an LRTD-based atlas construction method to generate tumor-free liver\natlases that mitigates the performance degradation of liver segmentation due to\nthe presence of tumors. Finally, we introduce an LRTD-based MAS algorithm to\nderive patient-specific liver atlases for each test image, and to achieve\naccurate pairwise image registration and label propagation. Extensive\nexperiments on three public databases of pathological liver cases validate the\neffectiveness of the proposed method. Both qualitative and quantitative results\ndemonstrate that, in the presence of major pathology, the proposed method is\nmore accurate and robust than state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2102.12056",
          "publishedOn": "2021-06-07T03:06:16.150Z",
          "wordCount": 695,
          "title": "Multi-Slice Low-Rank Tensor Decomposition Based Multi-Atlas Segmentation: Application to Automatic Pathological Liver CT Segmentation. (arXiv:2102.12056v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.09541",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Geffner_T/0/1/0/all/0/1\">Tomas Geffner</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Domke_J/0/1/0/all/0/1\">Justin Domke</a>",
          "description": "Several approximate inference algorithms have been proposed to minimize an\nalpha-divergence between an approximating distribution and a target\ndistribution. Many of these algorithms introduce bias, the magnitude of which\nbecomes problematic in high dimensions. Other algorithms are unbiased. These\noften seem to suffer from high variance, but little is rigorously known. In\nthis work we study unbiased methods for alpha-divergence minimization through\nthe Signal-to-Noise Ratio (SNR) of the gradient estimator. We study several\nrepresentative scenarios where strong analytical results are possible, such as\nfully-factorized or Gaussian distributions. We find that when alpha is not\nzero, the SNR worsens exponentially in the dimensionality of the problem. This\ncasts doubt on the practicality of these methods. We empirically confirm these\ntheoretical results.",
          "link": "http://arxiv.org/abs/2010.09541",
          "publishedOn": "2021-06-07T03:06:16.132Z",
          "wordCount": 576,
          "title": "On the Difficulty of Unbiased Alpha Divergence Minimization. (arXiv:2010.09541v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02206",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Linfeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hughes_M/0/1/0/all/0/1\">Michael C. Hughes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassoun_S/0/1/0/all/0/1\">Soha Hassoun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Li-Ping Liu</a>",
          "description": "Recent works leveraging Graph Neural Networks to approach graph matching\ntasks have shown promising results. Recent progress in learning discrete\ndistributions poses new opportunities for learning graph matching models. In\nthis work, we propose a new model, Stochastic Iterative Graph MAtching (SIGMA),\nto address the graph matching problem. Our model defines a distribution of\nmatchings for a graph pair so the model can explore a wide range of possible\nmatchings. We further introduce a novel multi-step matching procedure, which\nlearns how to refine a graph pair's matching results incrementally. The model\nalso includes dummy nodes so that the model does not have to find matchings for\nnodes without correspondence. We fit this model to data via scalable stochastic\noptimization. We conduct extensive experiments across synthetic graph datasets\nas well as biochemistry and computer vision applications. Across all tasks, our\nresults show that SIGMA can produce significantly improved graph matching\nresults compared to state-of-the-art models. Ablation studies verify that each\nof our components (stochastic training, iterative matching, and dummy nodes)\noffers noticeable improvement.",
          "link": "http://arxiv.org/abs/2106.02206",
          "publishedOn": "2021-06-07T03:06:16.126Z",
          "wordCount": 603,
          "title": "Stochastic Iterative Graph Matching. (arXiv:2106.02206v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02549",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frank_T/0/1/0/all/0/1\">Thorben Frank</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chmiela_S/0/1/0/all/0/1\">Stefan Chmiela</a>",
          "description": "Attention mechanisms are developing into a viable alternative to\nconvolutional layers as elementary building block of NNs. Their main advantage\nis that they are not restricted to capture local dependencies in the input, but\ncan draw arbitrary connections. This unprecedented capability coincides with\nthe long-standing problem of modeling global atomic interactions in molecular\nforce fields and other many-body problems. In its original formulation,\nhowever, attention is not applicable to the continuous domains in which the\natoms live. For this purpose we propose a variant to describe geometric\nrelations for arbitrary atomic configurations in Euclidean space that also\nrespects all relevant physical symmetries. We furthermore demonstrate, how the\nsuccessive application of our learned attention matrices effectively translates\nthe molecular geometry into a set of individual atomic contributions\non-the-fly.",
          "link": "http://arxiv.org/abs/2106.02549",
          "publishedOn": "2021-06-07T03:06:16.120Z",
          "wordCount": 561,
          "title": "Detect the Interactions that Matter in Matter: Geometric Attention for Many-Body Systems. (arXiv:2106.02549v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02356",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Mondelli_M/0/1/0/all/0/1\">Marco Mondelli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Venkataramanan_R/0/1/0/all/0/1\">Ramji Venkataramanan</a>",
          "description": "We study the problem of estimating a rank-$1$ signal in the presence of\nrotationally invariant noise-a class of perturbations more general than\nGaussian noise. Principal Component Analysis (PCA) provides a natural\nestimator, and sharp results on its performance have been obtained in the\nhigh-dimensional regime. Recently, an Approximate Message Passing (AMP)\nalgorithm has been proposed as an alternative estimator with the potential to\nimprove the accuracy of PCA. However, the existing analysis of AMP requires an\ninitialization that is both correlated with the signal and independent of the\nnoise, which is often unrealistic in practice. In this work, we combine the two\nmethods, and propose to initialize AMP with PCA. Our main result is a rigorous\nasymptotic characterization of the performance of this estimator. Both the AMP\nalgorithm and its analysis differ from those previously derived in the Gaussian\nsetting: at every iteration, our AMP algorithm requires a specific term to\naccount for PCA initialization, while in the Gaussian case, PCA initialization\naffects only the first iteration of AMP. The proof is based on a two-phase\nartificial AMP that first approximates the PCA estimator and then mimics the\ntrue AMP. Our numerical simulations show an excellent agreement between AMP\nresults and theoretical predictions, and suggest an interesting open direction\non achieving Bayes-optimal performance.",
          "link": "http://arxiv.org/abs/2106.02356",
          "publishedOn": "2021-06-07T03:06:16.112Z",
          "wordCount": 658,
          "title": "PCA Initialization for Approximate Message Passing in Rotationally Invariant Models. (arXiv:2106.02356v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2103.05896",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1\">Prateek Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kowshik_S/0/1/0/all/0/1\">Suhas S Kowshik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagaraj_D/0/1/0/all/0/1\">Dheeraj Nagaraj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Netrapalli_P/0/1/0/all/0/1\">Praneeth Netrapalli</a>",
          "description": "We consider the problem of estimating a linear time-invariant (LTI) dynamical\nsystem from a single trajectory via streaming algorithms, which is encountered\nin several applications including reinforcement learning (RL) and time-series\nanalysis. While the LTI system estimation problem is well-studied in the {\\em\noffline} setting, the practically important streaming/online setting has\nreceived little attention. Standard streaming methods like stochastic gradient\ndescent (SGD) are unlikely to work since streaming points can be highly\ncorrelated. In this work, we propose a novel streaming algorithm, SGD with\nReverse Experience Replay ($\\mathsf{SGD}-\\mathsf{RER}$), that is inspired by\nthe experience replay (ER) technique popular in the RL literature.\n$\\mathsf{SGD}-\\mathsf{RER}$ divides data into small buffers and runs SGD\nbackwards on the data stored in the individual buffers. We show that this\nalgorithm exactly deconstructs the dependency structure and obtains information\ntheoretically optimal guarantees for both parameter error and prediction error.\nThus, we provide the first -- to the best of our knowledge -- optimal SGD-style\nalgorithm for the classical problem of linear system identification with a\nfirst order oracle. Furthermore, $\\mathsf{SGD}-\\mathsf{RER}$ can be applied to\nmore general settings like sparse LTI identification with known sparsity\npattern, and non-linear dynamical systems. Our work demonstrates that the\nknowledge of data dependency structure can aid us in designing statistically\nand computationally efficient algorithms which can \"decorrelate\" streaming\nsamples.",
          "link": "http://arxiv.org/abs/2103.05896",
          "publishedOn": "2021-06-07T03:06:16.106Z",
          "wordCount": 685,
          "title": "Streaming Linear System Identification with Reverse Experience Replay. (arXiv:2103.05896v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.11430",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wilson_B/0/1/0/all/0/1\">Benjamin Wilson</a>",
          "description": "We propose a novel method for the inference of phylogenetic trees that\nutilises point configurations on hyperbolic space as its optimisation\nlandscape. Each taxon corresponds to a point of the point configuration, while\nthe evolutionary distance between taxa is represented by the geodesic distance\nbetween their corresponding points. The point configuration is iteratively\nmodified to increase an objective function that additively combines pairwise\nlog-likelihood terms. After convergence, the final tree is derived from the\ninter-point distances using a standard distance-based method. The objective\nfunction, which is shown to mimic the log-likelihood on tree space, is a\ndifferentiable function on a Riemannian manifold. Thus gradient-based\noptimisation techniques can be applied, avoiding the need for combinatorial\nrearrangements of tree topology.",
          "link": "http://arxiv.org/abs/2104.11430",
          "publishedOn": "2021-06-07T03:06:16.086Z",
          "wordCount": 576,
          "title": "Learning phylogenetic trees as hyperbolic point configurations. (arXiv:2104.11430v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.07446",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Talwai_P/0/1/0/all/0/1\">Prem Talwai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shameli_A/0/1/0/all/0/1\">Ali Shameli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Simchi_Levi_D/0/1/0/all/0/1\">David Simchi-Levi</a>",
          "description": "We develop novel learning rates for conditional mean embeddings by applying\nthe theory of interpolation for reproducing kernel Hilbert spaces (RKHS). We\nderive explicit, adaptive convergence rates for the sample estimator under the\nmisspecifed setting, where the target operator is not Hilbert-Schmidt or\nbounded with respect to the input/output RKHSs. We demonstrate that in certain\nparameter regimes, we can achieve uniform convergence rates in the output RKHS.\nWe hope our analyses will allow the much broader application of conditional\nmean embeddings to more complex ML/RL settings involving infinite dimensional\nRKHSs and continuous state spaces.",
          "link": "http://arxiv.org/abs/2105.07446",
          "publishedOn": "2021-06-07T03:06:16.080Z",
          "wordCount": 537,
          "title": "Sobolev Norm Learning Rates for Conditional Mean Embeddings. (arXiv:2105.07446v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.05982",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+E_W/0/1/0/all/0/1\">Weinan E</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wojtowytsch_S/0/1/0/all/0/1\">Stephan Wojtowytsch</a>",
          "description": "We study the natural function space for infinitely wide two-layer neural\nnetworks with ReLU activation (Barron space) and establish different\nrepresentation formulae. In two cases, we describe the space explicitly up to\nisomorphism.\n\nUsing a convenient representation, we study the pointwise properties of\ntwo-layer networks and show that functions whose singular set is fractal or\ncurved (for example distance functions from smooth submanifolds) cannot be\nrepresented by infinitely wide two-layer networks with finite path-norm. We use\nthis structure theorem to show that the only $C^1$-diffeomorphisms which Barron\nspace are affine.\n\nFurthermore, we show that every Barron function can be decomposed as the sum\nof a bounded and a positively one-homogeneous function and that there exist\nBarron functions which decay rapidly at infinity and are globally\nLebesgue-integrable. This result suggests that two-layer neural networks may be\nable to approximate a greater variety of functions than commonly believed.",
          "link": "http://arxiv.org/abs/2006.05982",
          "publishedOn": "2021-06-07T03:06:16.074Z",
          "wordCount": 604,
          "title": "Representation formulas and pointwise properties for Barron functions. (arXiv:2006.05982v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02617",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alamdari_P/0/1/0/all/0/1\">Parand Alizadeh Alamdari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klassen_T/0/1/0/all/0/1\">Toryn Q. Klassen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Icarte_R/0/1/0/all/0/1\">Rodrigo Toro Icarte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McIlraith_S/0/1/0/all/0/1\">Sheila A. McIlraith</a>",
          "description": "Recent work in AI safety has highlighted that in sequential decision making,\nobjectives are often underspecified or incomplete. This gives discretion to the\nacting agent to realize the stated objective in ways that may result in\nundesirable outcomes. We contend that to learn to act safely, a reinforcement\nlearning (RL) agent should include contemplation of the impact of its actions\non the wellbeing and agency of others in the environment, including other\nacting agents and reactive processes. We endow RL agents with the ability to\ncontemplate such impact by augmenting their reward based on expectation of\nfuture return by others in the environment, providing different criteria for\ncharacterizing impact. We further endow these agents with the ability to\ndifferentially factor this impact into their decision making, manifesting\nbehavior that ranges from self-centred to self-less, as demonstrated by\nexperiments in gridworld environments.",
          "link": "http://arxiv.org/abs/2106.02617",
          "publishedOn": "2021-06-07T03:06:16.068Z",
          "wordCount": 578,
          "title": "Be Considerate: Objectives, Side Effects, and Deciding How to Act. (arXiv:2106.02617v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02205",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Peiyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1\">Ze-Feng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1\">Z.Y. Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhong-Yi Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>",
          "description": "This paper presents a novel pre-trained language models (PLM) compression\napproach based on the matrix product operator (short as MPO) from quantum\nmany-body physics. It can decompose an original matrix into central tensors\n(containing the core information) and auxiliary tensors (with only a small\nproportion of parameters). With the decomposed MPO structure, we propose a\nnovel fine-tuning strategy by only updating the parameters from the auxiliary\ntensors, and design an optimization algorithm for MPO-based approximation over\nstacked network architectures. Our approach can be applied to the original or\nthe compressed PLMs in a general way, which derives a lighter network and\nsignificantly reduces the parameters to be fine-tuned. Extensive experiments\nhave demonstrated the effectiveness of the proposed approach in model\ncompression, especially the reduction in finetuning parameters (91% reduction\non average).",
          "link": "http://arxiv.org/abs/2106.02205",
          "publishedOn": "2021-06-07T03:06:16.062Z",
          "wordCount": 586,
          "title": "Enabling Lightweight Fine-tuning for Pre-trained Language Model Compression based on Matrix Product Operators. (arXiv:2106.02205v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02566",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gomez_T/0/1/0/all/0/1\">Tristan Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_S/0/1/0/all/0/1\">Suiyi Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freour_T/0/1/0/all/0/1\">Thomas Fr&#xe9;our</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mouchere_H/0/1/0/all/0/1\">Harold Mouch&#xe8;re</a>",
          "description": "The prevalence of employing attention mechanisms has brought along concerns\non the interpretability of attention distributions. Although it provides\ninsights about how a model is operating, utilizing attention as the explanation\nof model predictions is still highly dubious. The community is still seeking\nmore interpretable strategies for better identifying local active regions that\ncontribute the most to the final decision. To improve the interpretability of\nexisting attention models, we propose a novel Bilinear Representative\nNon-Parametric Attention (BR-NPA) strategy that captures the task-relevant\nhuman-interpretable information. The target model is first distilled to have\nhigher-resolution intermediate feature maps. From which, representative\nfeatures are then grouped based on local pairwise feature similarity, to\nproduce finer-grained, more precise attention maps highlighting task-relevant\nparts of the input. The obtained attention maps are ranked according to the\n`active level' of the compound feature, which provides information regarding\nthe important level of the highlighted regions. The proposed model can be\neasily adapted in a wide variety of modern deep models, where classification is\ninvolved. It is also more accurate, faster, and with a smaller memory footprint\nthan usual neural attention modules. Extensive experiments showcase more\ncomprehensive visual explanations compared to the state-of-the-art\nvisualization model across multiple tasks including few-shot classification,\nperson re-identification, fine-grained image classification. The proposed\nvisualization model sheds imperative light on how neural networks `pay their\nattention' differently in different tasks.",
          "link": "http://arxiv.org/abs/2106.02566",
          "publishedOn": "2021-06-07T03:06:16.056Z",
          "wordCount": 669,
          "title": "Improve the Interpretability of Attention: A Fast, Accurate, and Interpretable High-Resolution Attention Model. (arXiv:2106.02566v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02567",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_R/0/1/0/all/0/1\">Ratnajit Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iqbal_H/0/1/0/all/0/1\">Haris Iqbal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marzban_S/0/1/0/all/0/1\">Shabbir Marzban</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Badar_A/0/1/0/all/0/1\">Ahmed Badar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brouns_T/0/1/0/all/0/1\">Terence Brouns</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gowda_S/0/1/0/all/0/1\">Shruthi Gowda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arani_E/0/1/0/all/0/1\">Elahe Arani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zonooz_B/0/1/0/all/0/1\">Bahram Zonooz</a>",
          "description": "Road infrastructure maintenance inspection is typically a labour-intensive\nand critical task to ensure the safety of all the road users. In this work, we\npropose a detailed methodology to use state-of-the-art techniques in artificial\nintelligence and computer vision to automate a sizeable portion of the\nmaintenance inspection subtasks and reduce the labour costs. The proposed\nmethodology uses state-of-the-art computer vision techniques such as object\ndetection and semantic segmentation to automate inspections on primary road\nstructures such as the road surface, markings, barriers (guardrails) and\ntraffic signs. The models are mostly trained on commercially viable datasets\nand augmented with proprietary data. We demonstrate that our AI models can not\nonly automate and scale maintenance inspections on primary road structures but\nalso result in higher recall compared to traditional manual inspections.",
          "link": "http://arxiv.org/abs/2106.02567",
          "publishedOn": "2021-06-07T03:06:16.030Z",
          "wordCount": 575,
          "title": "AI Driven Road Maintenance Inspection. (arXiv:2106.02567v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02543",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chevalier_S/0/1/0/all/0/1\">Samuel Chevalier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stiasny_J/0/1/0/all/0/1\">Jochen Stiasny</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatzivasileiadis_S/0/1/0/all/0/1\">Spyros Chatzivasileiadis</a>",
          "description": "Recent advances in deep learning have set the focus on neural networks (NNs)\nthat can successfully replace traditional numerical solvers in many\napplications, achieving impressive computing gains. One such application is\ntime domain simulation, which is indispensable for the design, analysis and\noperation of many engineering systems. Simulating dynamical systems with\nimplicit Newton-based solvers is a computationally heavy task, as it requires\nthe solution of a parameterized system of differential and algebraic equations\nat each time step. A variety of NN-based methodologies have been shown to\nsuccessfully approximate the dynamical trajectories computed by numerical time\ndomain solvers at a fraction of the time. However, so far no previous NN-based\nmodel has explicitly captured the fact that any predicted point on the time\ndomain trajectory also represents the fixed point of the numerical solver\nitself. As we show, explicitly capturing this property can lead to\nsignificantly increased NN accuracy and much smaller NN sizes. In this paper,\nwe model the Newton solver at the heart of an implicit Runge-Kutta integrator\nas a contracting map iteratively seeking this fixed point. Our primary\ncontribution is to develop a recurrent NN simulation tool, termed the\nContracting Neural-Newton Solver (CoNNS), which explicitly captures the\ncontracting nature of these Newton iterations. To build CoNNS, we train a\nfeedforward NN and mimic this contraction behavior by embedding a series of\ntraining constraints which guarantee the mapping provided by the NN satisfies\nthe Banach fixed-point theorem; thus, we are able to prove that successive\npasses through the NN are guaranteed to converge to a unique, fixed point.",
          "link": "http://arxiv.org/abs/2106.02543",
          "publishedOn": "2021-06-07T03:06:16.024Z",
          "wordCount": 678,
          "title": "Contracting Neural-Newton Solver. (arXiv:2106.02543v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02533",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1\">Weiwei Jiang</a>",
          "description": "Communication networks are important infrastructures in contemporary society.\nThere are still many challenges that are not fully solved and new solutions are\nproposed continuously in this active research area. In recent years, to model\nthe network topology, graph-based deep learning has achieved state-of-the-art\nperformance in a series of problems in communication networks. In this survey,\nwe review the rapidly growing body of research using different graph-based deep\nlearning models, e.g. graph convolutional and graph attention networks, in\nvarious problems from different communication networks, e.g. wireless networks,\nwired networks, and software-defined networks. We also present a well-organized\nlist of the problem and solution for each study and identify future research\ndirections. To the best of our knowledge, this paper is the first survey that\nfocuses on the application of graph-based deep learning methods in\ncommunication networks. To track the follow-up research, a public GitHub\nrepository is created, where the relevant papers will be updated continuously.",
          "link": "http://arxiv.org/abs/2106.02533",
          "publishedOn": "2021-06-07T03:06:16.018Z",
          "wordCount": 586,
          "title": "Graph-based Deep Learning for Communication Networks: A Survey. (arXiv:2106.02533v1 [cs.NI])"
        },
        {
          "id": "http://arxiv.org/abs/2102.02734",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Spadea_M/0/1/0/all/0/1\">Maria Francesca Spadea</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Maspero_M/0/1/0/all/0/1\">Matteo Maspero</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zaffino_P/0/1/0/all/0/1\">Paolo Zaffino</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Seco_J/0/1/0/all/0/1\">Joao Seco</a>",
          "description": "Recently, deep learning (DL)-based methods for the generation of synthetic\ncomputed tomography (sCT) have received significant research attention as an\nalternative to classical ones. We present here a systematic review of these\nmethods by grouping them into three categories, according to their clinical\napplications: I) To replace CT in magnetic resonance (MR)-based treatment\nplanning. II) Facilitate cone-beam computed tomography (CBCT)-based\nimage-guided adaptive radiotherapy. III) Derive attenuation maps for the\ncorrection of positron emission tomography (PET). Appropriate database\nsearching was performed on journal articles published between January 2014 and\nDecember 2020. The DL methods' key characteristics were extracted from each\neligible study, and a comprehensive comparison among network architectures and\nmetrics was reported. A detailed review of each category was given,\nhighlighting essential contributions, identifying specific challenges, and\nsummarising the achievements. Lastly, the statistics of all the cited works\nfrom various aspects were analysed, revealing the popularity and future trends,\nand the potential of DL-based sCT generation. The current status of DL-based\nsCT generation was evaluated, assessing the clinical readiness of the presented\nmethods.",
          "link": "http://arxiv.org/abs/2102.02734",
          "publishedOn": "2021-06-07T03:06:16.011Z",
          "wordCount": 653,
          "title": "Deep learning-based synthetic-CT generation in radiotherapy and PET: a review. (arXiv:2102.02734v2 [physics.med-ph] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.13355",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yangkun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1\">Jiarui Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weinan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wipf_D/0/1/0/all/0/1\">David Wipf</a>",
          "description": "Over the past few years, graph neural networks (GNN) and label\npropagation-based methods have made significant progress in addressing node\nclassification tasks on graphs. However, in addition to their reliance on\nelaborate architectures and algorithms, there are several key technical details\nthat are frequently overlooked, and yet nonetheless can play a vital role in\nachieving satisfactory performance. In this paper, we first summarize a series\nof existing tricks-of-the-trade, and then propose several new ones related to\nlabel usage, loss function formulation, and model design that can significantly\nimprove various GNN architectures. We empirically evaluate their impact on\nfinal node classification accuracy by conducting ablation studies and\ndemonstrate consistently-improved performance, often to an extent that\noutweighs the gains from more dramatic changes in the underlying GNN\narchitecture. Notably, many of the top-ranked models on the Open Graph\nBenchmark (OGB) leaderboard benefit from our techniques.",
          "link": "http://arxiv.org/abs/2103.13355",
          "publishedOn": "2021-06-07T03:06:16.001Z",
          "wordCount": 603,
          "title": "Bag of Tricks for Node Classification with Graph Neural Networks. (arXiv:2103.13355v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02216",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xing_X/0/1/0/all/0/1\">Xiaoying Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hongfu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jundong Li</a>",
          "description": "Feature selection is a prevalent data preprocessing paradigm for various\nlearning tasks. Due to the expensive cost of acquiring supervision information,\nunsupervised feature selection sparks great interests recently. However,\nexisting unsupervised feature selection algorithms do not have fairness\nconsiderations and suffer from a high risk of amplifying discrimination by\nselecting features that are over associated with protected attributes such as\ngender, race, and ethnicity. In this paper, we make an initial investigation of\nthe fairness-aware unsupervised feature selection problem and develop a\nprincipled framework, which leverages kernel alignment to find a subset of\nhigh-quality features that can best preserve the information in the original\nfeature space while being minimally correlated with protected attributes.\nSpecifically, different from the mainstream in-processing debiasing methods,\nour proposed framework can be regarded as a model-agnostic debiasing strategy\nthat eliminates biases and discrimination before downstream learning algorithms\nare involved. Experimental results on multiple real-world datasets demonstrate\nthat our framework achieves a good trade-off between utility maximization and\nfairness promotion.",
          "link": "http://arxiv.org/abs/2106.02216",
          "publishedOn": "2021-06-07T03:06:15.981Z",
          "wordCount": 583,
          "title": "Fairness-Aware Unsupervised Feature Selection. (arXiv:2106.02216v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.00628",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Wang_Z/0/1/0/all/0/1\">Zixuan Wang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Tang_S/0/1/0/all/0/1\">Shanjian Tang</a>",
          "description": "This paper is concerned with convergence of stochastic gradient algorithms\nwith momentum terms in the nonconvex setting. A class of stochastic momentum\nmethods, including stochastic gradient descent, heavy ball, and Nesterov's\naccelerated gradient, is analyzed in a general framework under mild\nassumptions. Based on the convergence result of expected gradients, we prove\nthe almost sure convergence by a detailed discussion of the effects of momentum\nand the number of upcrossings. It is worth noting that there are not additional\nrestrictions imposed on the objective function and stepsize. Another\nimprovement over previous results is that the existing Lipschitz condition of\nthe gradient is relaxed into the condition of Holder continuity. As a\nbyproduct, we apply a localization procedure to extend our results to\nstochastic stepsizes.",
          "link": "http://arxiv.org/abs/2012.00628",
          "publishedOn": "2021-06-07T03:06:15.975Z",
          "wordCount": 572,
          "title": "Convergence of Gradient Algorithms for Nonconvex C^{1+alpha} Cost Functions. (arXiv:2012.00628v2 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02600",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_S/0/1/0/all/0/1\">Song Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yao Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Josef_C/0/1/0/all/0/1\">Christopher S. Josef</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamaleswaran_R/0/1/0/all/0/1\">Rishikesan Kamaleswaran</a>",
          "description": "Continuous, automated surveillance systems that incorporate machine learning\nmodels are becoming increasingly more common in healthcare environments. These\nmodels can capture temporally dependent changes across multiple patient\nvariables and can enhance a clinician's situational awareness by providing an\nearly warning alarm of an impending adverse event such as sepsis. However, most\ncommonly used methods, e.g., XGBoost, fail to provide an interpretable\nmechanism for understanding why a model produced a sepsis alarm at a given\ntime. The black-box nature of many models is a severe limitation as it prevents\nclinicians from independently corroborating those physiologic features that\nhave contributed to the sepsis alarm. To overcome this limitation, we propose a\ngeneralized linear model (GLM) approach to fit a Granger causal graph based on\nthe physiology of several major sepsis-associated derangements (SADs). We adopt\na recently developed stochastic monotone variational inequality-based estimator\ncoupled with forwarding feature selection to learn the graph structure from\nboth continuous and discrete-valued as well as regularly and irregularly\nsampled time series. Most importantly, we develop a non-asymptotic upper bound\non the estimation error for any monotone link function in the GLM. We conduct\nreal-data experiments and demonstrate that our proposed method can achieve\ncomparable performance to popular and powerful prediction methods such as\nXGBoost while simultaneously maintaining a high level of interpretability.",
          "link": "http://arxiv.org/abs/2106.02600",
          "publishedOn": "2021-06-07T03:06:15.968Z",
          "wordCount": 660,
          "title": "Inferring Granger Causality from Irregularly Sampled Time Series. (arXiv:2106.02600v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02634",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sitzmann_V/0/1/0/all/0/1\">Vincent Sitzmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rezchikov_S/0/1/0/all/0/1\">Semon Rezchikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freeman_W/0/1/0/all/0/1\">William T. Freeman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua B. Tenenbaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durand_F/0/1/0/all/0/1\">Fredo Durand</a>",
          "description": "Inferring representations of 3D scenes from 2D observations is a fundamental\nproblem of computer graphics, computer vision, and artificial intelligence.\nEmerging 3D-structured neural scene representations are a promising approach to\n3D scene understanding. In this work, we propose a novel neural scene\nrepresentation, Light Field Networks or LFNs, which represent both geometry and\nappearance of the underlying 3D scene in a 360-degree, four-dimensional light\nfield parameterized via a neural implicit representation. Rendering a ray from\nan LFN requires only a *single* network evaluation, as opposed to hundreds of\nevaluations per ray for ray-marching or volumetric based renderers in\n3D-structured neural scene representations. In the setting of simple scenes, we\nleverage meta-learning to learn a prior over LFNs that enables multi-view\nconsistent light field reconstruction from as little as a single image\nobservation. This results in dramatic reductions in time and memory complexity,\nand enables real-time rendering. The cost of storing a 360-degree light field\nvia an LFN is two orders of magnitude lower than conventional methods such as\nthe Lumigraph. Utilizing the analytical differentiability of neural implicit\nrepresentations and a novel parameterization of light space, we further\ndemonstrate the extraction of sparse depth maps from LFNs.",
          "link": "http://arxiv.org/abs/2106.02634",
          "publishedOn": "2021-06-07T03:06:15.958Z",
          "wordCount": 657,
          "title": "Light Field Networks: Neural Scene Representations with Single-Evaluation Rendering. (arXiv:2106.02634v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02559",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maudslay_R/0/1/0/all/0/1\">Rowan Hall Maudslay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>",
          "description": "Analysing whether neural language models encode linguistic information has\nbecome popular in NLP. One method of doing so, which is frequently cited to\nsupport the claim that models like BERT encode syntax, is called probing;\nprobes are small supervised models trained to extract linguistic information\nfrom another model's output. If a probe is able to predict a particular\nstructure, it is argued that the model whose output it is trained on must have\nimplicitly learnt to encode it. However, drawing a generalisation about a\nmodel's linguistic knowledge about a specific phenomena based on what a probe\nis able to learn may be problematic: in this work, we show that semantic cues\nin training data means that syntactic probes do not properly isolate syntax. We\ngenerate a new corpus of semantically nonsensical but syntactically well-formed\nJabberwocky sentences, which we use to evaluate two probes trained on normal\ndata. We train the probes on several popular language models (BERT, GPT, and\nRoBERTa), and find that in all settings they perform worse when evaluated on\nthese data, for one probe by an average of 15.4 UUAS points absolute. Although\nin most cases they still outperform the baselines, their lead is reduced\nsubstantially, e.g. by 53% in the case of BERT for one probe. This begs the\nquestion: what empirical scores constitute knowing syntax?",
          "link": "http://arxiv.org/abs/2106.02559",
          "publishedOn": "2021-06-07T03:06:15.952Z",
          "wordCount": 649,
          "title": "Do Syntactic Probes Probe Syntax? Experiments with Jabberwocky Probing. (arXiv:2106.02559v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02624",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dangel_F/0/1/0/all/0/1\">Felix Dangel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tatzel_L/0/1/0/all/0/1\">Lukas Tatzel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hennig_P/0/1/0/all/0/1\">Philipp Hennig</a>",
          "description": "Curvature in form of the Hessian or its generalized Gauss-Newton (GGN)\napproximation is valuable for algorithms that rely on a local model for the\nloss to train, compress, or explain deep networks. Existing methods based on\nimplicit multiplication via automatic differentiation or Kronecker-factored\nblock diagonal approximations do not consider noise in the mini-batch. We\npresent ViViT, a curvature model that leverages the GGN's low-rank structure\nwithout further approximations. It allows for efficient computation of\neigenvalues, eigenvectors, as well as per-sample first- and second-order\ndirectional derivatives. The representation is computed in parallel with\ngradients in one backward pass and offers a fine-grained cost-accuracy\ntrade-off, which allows it to scale. As examples for ViViT's usefulness, we\ninvestigate the directional gradients and curvatures during training, and how\nnoise information can be used to improve the stability of second-order methods.",
          "link": "http://arxiv.org/abs/2106.02624",
          "publishedOn": "2021-06-07T03:06:15.929Z",
          "wordCount": 578,
          "title": "ViViT: Curvature access through the generalized Gauss-Newton's low-rank structure. (arXiv:2106.02624v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02615",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vadori_N/0/1/0/all/0/1\">Nelson Vadori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Savani_R/0/1/0/all/0/1\">Rahul Savani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spooner_T/0/1/0/all/0/1\">Thomas Spooner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganesh_S/0/1/0/all/0/1\">Sumitra Ganesh</a>",
          "description": "Recently, Optimistic Multiplicative Weights Update (OMWU) was proven to be\nthe first constant step-size algorithm in the online no-regret framework to\nenjoy last-iterate convergence to Nash Equilibria in the constrained zero-sum\nbimatrix case, where weights represent the probabilities of playing pure\nstrategies. We introduce the second such algorithm, \\textit{Consensus MWU}, for\nwhich we prove local convergence and show empirically that it enjoys faster and\nmore robust convergence than OMWU. Our algorithm shows the importance of a new\nobject, the \\textit{simplex Hessian}, as well as of the interaction of the game\nwith the (eigen)space of vectors summing to zero, which we believe future\nresearch can build on. As for OMWU, CMWU has convergence guarantees in the\nzero-sum case only, but Cheung and Piliouras (2020) recently showed that OMWU\nand MWU display opposite convergence properties depending on whether the game\nis zero-sum or cooperative. Inspired by this work and the recent literature on\nlearning to optimize for single functions, we extend CMWU to non zero-sum games\nby introducing a new framework for online learning in games, where the update\nrule's gradient and Hessian coefficients along a trajectory are learnt by a\nreinforcement learning policy that is conditioned on the nature of the game:\n\\textit{the game signature}. We construct the latter using a new canonical\ndecomposition of two-player games into eight components corresponding to\ncommutative projection operators, generalizing and unifying recent game\nconcepts studied in the literature. We show empirically that our new learning\npolicy is able to exploit the game signature across a wide range of game types.",
          "link": "http://arxiv.org/abs/2106.02615",
          "publishedOn": "2021-06-07T03:06:15.922Z",
          "wordCount": 696,
          "title": "Consensus Multiplicative Weights Update: Learning to Learn using Projector-based Game Signatures. (arXiv:2106.02615v1 [cs.GT])"
        },
        {
          "id": "http://arxiv.org/abs/2004.03238",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shinoda_K/0/1/0/all/0/1\">Kazutoshi Shinoda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugawara_S/0/1/0/all/0/1\">Saku Sugawara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aizawa_A/0/1/0/all/0/1\">Akiko Aizawa</a>",
          "description": "Question answering (QA) models for reading comprehension have achieved\nhuman-level accuracy on in-distribution test sets. However, they have been\ndemonstrated to lack robustness to challenge sets, whose distribution is\ndifferent from that of training sets. Existing data augmentation methods\nmitigate this problem by simply augmenting training sets with synthetic\nexamples sampled from the same distribution as the challenge sets. However,\nthese methods assume that the distribution of a challenge set is known a\npriori, making them less applicable to unseen challenge sets. In this study, we\nfocus on question-answer pair generation (QAG) to mitigate this problem. While\nmost existing QAG methods aim to improve the quality of synthetic examples, we\nconjecture that diversity-promoting QAG can mitigate the sparsity of training\nsets and lead to better robustness. We present a variational QAG model that\ngenerates multiple diverse QA pairs from a paragraph. Our experiments show that\nour method can improve the accuracy of 12 challenge sets, as well as the\nin-distribution accuracy. Our code and data are available at\nhttps://github.com/KazutoshiShinoda/VQAG.",
          "link": "http://arxiv.org/abs/2004.03238",
          "publishedOn": "2021-06-07T03:06:15.914Z",
          "wordCount": 646,
          "title": "Improving the Robustness of QA Models to Challenge Sets with Variational Question-Answer Pair Generation. (arXiv:2004.03238v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02104",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cannella_C/0/1/0/all/0/1\">Chris Cannella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tarokh_V/0/1/0/all/0/1\">Vahid Tarokh</a>",
          "description": "We introduce and demonstrate a semi-empirical procedure for determining\napproximate objective functions suitable for optimizing arbitrarily\nparameterized proposal distributions in MCMC methods. Our proposed Ab Initio\nobjective functions consist of the weighted combination of functions following\nconstraints on their global optima and of coordinate invariance that we argue\nshould be upheld by general measures of MCMC efficiency for use in proposal\noptimization. The coefficients of Ab Initio objective functions are determined\nso as to recover the optimal MCMC behavior prescribed by established\ntheoretical analysis for chosen reference problems. Our experimental results\ndemonstrate that Ab Initio objective functions maintain favorable performance\nand preferable optimization behavior compared to existing objective functions\nfor MCMC optimization when optimizing highly expressive proposal distributions.\nWe argue that Ab Initio objective functions are sufficiently robust to enable\nthe confident optimization of MCMC proposal distributions parameterized by deep\ngenerative networks that extend beyond the traditional limitations of\nindividual MCMC schemes.",
          "link": "http://arxiv.org/abs/2106.02104",
          "publishedOn": "2021-06-07T03:06:15.898Z",
          "wordCount": 577,
          "title": "Semi-Empirical Objective Functions for MCMC Proposal Optimization. (arXiv:2106.02104v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02257",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1\">Jiayi Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xilian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>",
          "description": "When a human asks questions online, or when a conversational virtual agent\nasks human questions, questions triggering emotions or with details might more\nlikely to get responses or answers. we explore how to automatically rewrite\nnatural language questions to improve the response rate from people. In\nparticular, a new task of Visual Question Rewriting(VQR) task is introduced to\nexplore how visual information can be used to improve the new questions. A data\nset containing around 4K bland questions, attractive questions and images\ntriples is collected. We developed some baseline sequence to sequence models\nand more advanced transformer based models, which take a bland question and a\nrelated image as input and output a rewritten question that is expected to be\nmore attractive. Offline experiments and mechanical Turk based evaluations show\nthat it is possible to rewrite bland questions in a more detailed and\nattractive way to increase the response rate, and images can be helpful.",
          "link": "http://arxiv.org/abs/2106.02257",
          "publishedOn": "2021-06-07T03:06:15.889Z",
          "wordCount": 596,
          "title": "Visual Question Rewriting for Increasing Response Rate. (arXiv:2106.02257v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02602",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Romanenkova_E/0/1/0/all/0/1\">Evgenia Romanenkova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaytsev_A/0/1/0/all/0/1\">Alexey Zaytsev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zainulin_R/0/1/0/all/0/1\">Ramil Zainulin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morozov_M/0/1/0/all/0/1\">Matvey Morozov</a>",
          "description": "Change points are abrupt alterations in the distribution of sequential data.\nA change-point detection (CPD) model aims at quick detection of such changes.\nClassic approaches perform poorly for semi-structured sequential data because\nof the absence of adequate data representation learning. To deal with it, we\nintroduce a principled differentiable loss function that considers the\nspecificity of the CPD task. The theoretical results suggest that this function\napproximates well classic rigorous solutions. For such loss function, we\npropose an end-to-end method for the training of deep representation learning\nCPD models. Our experiments provide evidence that the proposed approach\nimproves baseline results of change point detection for various data types,\nincluding real-world videos and image sequences, and improve representations\nfor them.",
          "link": "http://arxiv.org/abs/2106.02602",
          "publishedOn": "2021-06-07T03:06:15.872Z",
          "wordCount": 541,
          "title": "Principled change point detection via representation learning. (arXiv:2106.02602v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2011.01023",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wijeratne_P/0/1/0/all/0/1\">Peter A. Wijeratne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alexander_D/0/1/0/all/0/1\">Daniel C. Alexander</a>",
          "description": "Progressive diseases worsen over time and are characterised by monotonic\nchange in features that track disease progression. Here we connect ideas from\ntwo formerly separate methodologies -- event-based and hidden Markov modelling\n-- to derive a new generative model of disease progression. Our model can\nuniquely infer the most likely group-level sequence and timing of events\n(natural history) from limited datasets. Moreover, it can infer and predict\nindividual-level trajectories (prognosis) even when data are missing, giving it\nhigh clinical utility. Here we derive the model and provide an inference scheme\nbased on the expectation maximisation algorithm. We use clinical, imaging and\nbiofluid data from the Alzheimer's Disease Neuroimaging Initiative to\ndemonstrate the validity and utility of our model. First, we train our model to\nuncover a new group-level sequence of feature changes in Alzheimer's disease\nover a period of ${\\sim}17.3$ years. Next, we demonstrate that our model\nprovides improved utility over a continuous time hidden Markov model by area\nunder the receiver operator characteristic curve ${\\sim}0.23$. Finally, we\ndemonstrate that our model maintains predictive accuracy with up to $50\\%$\nmissing data. These results support the clinical validity of our model and its\nbroader utility in resource-limited medical applications.",
          "link": "http://arxiv.org/abs/2011.01023",
          "publishedOn": "2021-06-07T03:06:15.865Z",
          "wordCount": 671,
          "title": "Learning transition times in event sequences: the Event-Based Hidden Markov Model of disease progression. (arXiv:2011.01023v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07835",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Horn_M/0/1/0/all/0/1\">Max Horn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brouwer_E/0/1/0/all/0/1\">Edward De Brouwer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moor_M/0/1/0/all/0/1\">Michael Moor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moreau_Y/0/1/0/all/0/1\">Yves Moreau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rieck_B/0/1/0/all/0/1\">Bastian Rieck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borgwardt_K/0/1/0/all/0/1\">Karsten Borgwardt</a>",
          "description": "Graph neural networks (GNNs) are a powerful architecture for tackling graph\nlearning tasks, yet have been shown to be oblivious to eminent substructures,\nsuch as cycles. We present TOGL, a novel layer that incorporates global\ntopological information of a graph using persistent homology. TOGL can be\neasily integrated into any type of GNN and is strictly more expressive in terms\nof the Weisfeiler--Lehman test of isomorphism. Augmenting GNNs with our layer\nleads to beneficial predictive performance for graph and node classification\ntasks, both on synthetic data sets, which can be classified by humans using\ntheir topology but not by ordinary GNNs, and on real-world data.",
          "link": "http://arxiv.org/abs/2102.07835",
          "publishedOn": "2021-06-07T03:06:15.851Z",
          "wordCount": null,
          "title": "Topological Graph Neural Networks. (arXiv:2102.07835v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02493",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Melodia_L/0/1/0/all/0/1\">Luciano Melodia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lenz_R/0/1/0/all/0/1\">Richard Lenz</a>",
          "description": "In this paper, we use topological data analysis techniques to construct a\nsuitable neural network classifier for the task of learning sensor signals of\nentire power plants according to their reference designation system. We use\nrepresentations of persistence diagrams to derive necessary preprocessing steps\nand visualize the large amounts of data. We derive architectures with deep\none-dimensional convolutional layers combined with stacked long short-term\nmemories as residual networks suitable for processing the persistence features.\nWe combine three separate sub-networks, obtaining as input the time series\nitself and a representation of the persistent homology for the zeroth and first\ndimension. We give a mathematical derivation for most of the used\nhyper-parameters. For validation, numerical experiments were performed with\nsensor data from four power plants of the same construction type.",
          "link": "http://arxiv.org/abs/2106.02493",
          "publishedOn": "2021-06-07T03:06:15.840Z",
          "wordCount": 557,
          "title": "Homological Time Series Analysis of Sensor Signals from Power Plants. (arXiv:2106.02493v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02542",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alaya_M/0/1/0/all/0/1\">Mokhtar Z. Alaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gasso_G/0/1/0/all/0/1\">Gilles Gasso</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berar_M/0/1/0/all/0/1\">Maxime Berar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rakotomamonjy_A/0/1/0/all/0/1\">Alain Rakotomamonjy</a>",
          "description": "Gromov-Wasserstein (GW) distance is a key tool for manifold learning and\ncross-domain learning, allowing the comparison of distributions that do not\nlive in the same metric space. Because of its high computational complexity,\nseveral approximate GW distances have been proposed based on entropy\nregularization or on slicing, and one-dimensional GW computation. In this\npaper, we propose a novel approach for comparing two incomparable\ndistributions, that hinges on the idea of distributional slicing, embeddings,\nand on computing the closed-form Wasserstein distance between the sliced\ndistributions. We provide a theoretical analysis of this new divergence, called\ndistributional sliced embedding (DSE) discrepancy, and we show that it\npreserves several interesting properties of GW distance including\nrotation-invariance. We show that the embeddings involved in DSE can be\nefficiently learned. Finally, we provide a large set of experiments\nillustrating the behavior of DSE as a divergence in the context of generative\nmodeling and in query framework.",
          "link": "http://arxiv.org/abs/2106.02542",
          "publishedOn": "2021-06-07T03:06:15.828Z",
          "wordCount": 580,
          "title": "Distributional Sliced Embedding Discrepancy for Incomparable Distributions. (arXiv:2106.02542v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.11327",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Muthirayan_D/0/1/0/all/0/1\">Deepan Muthirayan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Khargonekar_P/0/1/0/all/0/1\">Pramod P. Khargonekar</a>",
          "description": "In this paper we provide provable regret guarantees for an online\nmeta-learning receding horizon control algorithm in an iterative control\nsetting. We consider the setting where, in each iteration the system to be\ncontrolled is a linear deterministic system that is different and unknown, the\ncost for the controller in an iteration is a general additive cost function and\nthere are affine control input constraints. By analysing conditions under which\nsub-linear regret is achievable, we prove that the online receding horizon\ncontroller achieves a regret for the controller cost and constraint violation\nthat are $\\tilde{O}(T^{3/4})$ with respect to the best policy that satisfies\nthe control input control constraints, when the preview of the cost functions\nis limited to an interval and the interval size is doubled from one to the\nnext. We then show that the average of the regret for the controller cost and\nconstraint violation with respect to the same policy vary as\n$\\tilde{O}((1+1/\\sqrt{N})T^{3/4})$ with the number of iterations $N$, under the\nsame setting.",
          "link": "http://arxiv.org/abs/2010.11327",
          "publishedOn": "2021-06-07T03:06:15.820Z",
          "wordCount": 715,
          "title": "Meta-Learning Guarantees for Online Receding Horizon Learning Control. (arXiv:2010.11327v12 [eess.SY] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.08360",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_E/0/1/0/all/0/1\">Ella Y. Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Som_A/0/1/0/all/0/1\">Anirudh Som</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shukla_A/0/1/0/all/0/1\">Ankita Shukla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_H/0/1/0/all/0/1\">Hongjun Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turaga_P/0/1/0/all/0/1\">Pavan Turaga</a>",
          "description": "Deep neural networks have increasingly been used as an auxiliary tool in\nhealthcare applications, due to their ability to improve performance of several\ndiagnosis tasks. However, these methods are not widely adopted in clinical\nsettings due to the practical limitations in the reliability, generalizability,\nand interpretability of deep learning based systems. As a result, methods have\nbeen developed that impose additional constraints during network training to\ngain more control as well as improve interpretabilty, facilitating their\nacceptance in healthcare community. In this work, we investigate the benefit of\nusing Orthogonal Spheres (OS) constraint for classification of COVID-19 cases\nfrom chest X-ray images. The OS constraint can be written as a simple\northonormality term which is used in conjunction with the standard\ncross-entropy loss during classification network training. Previous studies\nhave demonstrated significant benefits in applying such constraints to deep\nlearning models. Our findings corroborate these observations, indicating that\nthe orthonormality loss function effectively produces improved semantic\nlocalization via GradCAM visualizations, enhanced classification performance,\nand reduced model calibration error. Our approach achieves an improvement in\naccuracy of 1.6% and 4.8% for two- and three-class classification,\nrespectively; similar results are found for models with data augmentation\napplied. In addition to these findings, our work also presents a new\napplication of the OS regularizer in healthcare, increasing the post-hoc\ninterpretability and performance of deep learning models for COVID-19\nclassification to facilitate adoption of these methods in clinical settings. We\nalso identify the limitations of our strategy that can be explored for further\nresearch in future.",
          "link": "http://arxiv.org/abs/2102.08360",
          "publishedOn": "2021-06-07T03:06:15.801Z",
          "wordCount": null,
          "title": "Interpretable COVID-19 Chest X-Ray Classification via Orthogonality Constraint. (arXiv:2102.08360v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02605",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chaofan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1\">Kangcheng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudin_C/0/1/0/all/0/1\">Cynthia Rudin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaposhnik_Y/0/1/0/all/0/1\">Yaron Shaposhnik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sijia Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tong Wang</a>",
          "description": "Lending decisions are usually made with proprietary models that provide\nminimally acceptable explanations to users. In a future world without such\nsecrecy, what decision support tools would one want to use for justified\nlending decisions? This question is timely, since the economy has dramatically\nshifted due to a pandemic, and a massive number of new loans will be necessary\nin the short term. We propose a framework for such decisions, including a\nglobally interpretable machine learning model, an interactive visualization of\nit, and several types of summaries and explanations for any given decision. The\nmachine learning model is a two-layer additive risk model, which resembles a\ntwo-layer neural network, but is decomposable into subscales. In this model,\neach node in the first (hidden) layer represents a meaningful subscale model,\nand all of the nonlinearities are transparent. Our online visualization tool\nallows exploration of this model, showing precisely how it came to its\nconclusion. We provide three types of explanations that are simpler than, but\nconsistent with, the global model: case-based reasoning explanations that use\nneighboring past cases, a set of features that were the most important for the\nmodel's prediction, and summary-explanations that provide a customized sparse\nexplanation for any particular lending decision made by the model. Our\nframework earned the FICO recognition award for the Explainable Machine\nLearning Challenge, which was the first public challenge in the domain of\nexplainable machine learning.",
          "link": "http://arxiv.org/abs/2106.02605",
          "publishedOn": "2021-06-07T03:06:15.797Z",
          "wordCount": 669,
          "title": "A Holistic Approach to Interpretability in Financial Lending: Models, Visualizations, and Summary-Explanations. (arXiv:2106.02605v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.12748",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_A/0/1/0/all/0/1\">Agniva Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drineas_P/0/1/0/all/0/1\">Petros Drineas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1\">David P. Woodruff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Samson Zhou</a>",
          "description": "Principal component analysis (PCA) is a widely used dimension reduction\ntechnique in machine learning and multivariate statistics. To improve the\ninterpretability of PCA, various approaches to obtain sparse principal\ndirection loadings have been proposed, which are termed Sparse Principal\nComponent Analysis (SPCA). In this paper, we present thresholding as a provably\naccurate, polynomial time, approximation algorithm for the SPCA problem,\nwithout imposing any restrictive assumptions on the input covariance matrix.\nOur first thresholding algorithm using the Singular Value Decomposition is\nconceptually simple; is faster than current state-of-the-art; and performs well\nin practice. On the negative side, our (novel) theoretical bounds do not\naccurately predict the strong practical performance of this approach. The\nsecond algorithm solves a well-known semidefinite programming relaxation and\nthen uses a novel, two step, deterministic thresholding scheme to compute a\nsparse principal vector. It works very well in practice and, remarkably, this\nsolid practical performance is accurately predicted by our theoretical bounds,\nwhich bridge the theory-practice gap better than current state-of-the-art.",
          "link": "http://arxiv.org/abs/2006.12748",
          "publishedOn": "2021-06-07T03:06:15.789Z",
          "wordCount": 624,
          "title": "Approximation Algorithms for Sparse Principal Component Analysis. (arXiv:2006.12748v2 [cs.DS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.09264",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Geada_R/0/1/0/all/0/1\">Rob Geada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prangle_D/0/1/0/all/0/1\">Dennis Prangle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McGough_A/0/1/0/all/0/1\">Andrew Stephen McGough</a>",
          "description": "One-shot Neural Architecture Search (NAS) aims to minimize the computational\nexpense of discovering state-of-the-art models. However, in the past year\nattention has been drawn to the comparable performance of naive random search\nacross the same search spaces used by leading NAS algorithms. To address this,\nwe explore the effects of drastically relaxing the NAS search space, and we\npresent Bonsai-Net, an efficient one-shot NAS method to explore our relaxed\nsearch space. Bonsai-Net is built around a modified differential pruner and can\nconsistently discover state-of-the-art architectures that are significantly\nbetter than random search with fewer parameters than other state-of-the-art\nmethods. Additionally, Bonsai-Net performs simultaneous model search and\ntraining, dramatically reducing the total time it takes to generate\nfully-trained models from scratch.",
          "link": "http://arxiv.org/abs/2006.09264",
          "publishedOn": "2021-06-07T03:06:15.769Z",
          "wordCount": 593,
          "title": "Bonsai-Net: One-Shot Neural Architecture Search via Differentiable Pruners. (arXiv:2006.09264v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02331",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Tanaka_K/0/1/0/all/0/1\">Keitaro Tanaka</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sawata_R/0/1/0/all/0/1\">Ryosuke Sawata</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Takahashi_S/0/1/0/all/0/1\">Shusuke Takahashi</a>",
          "description": "This paper presents a new deep clustering (DC) method called manifold-aware\nDC (M-DC) that can enhance hyperspace utilization more effectively than the\noriginal DC. The original DC has a limitation in that a pair of two speakers\nhas to be embedded having an orthogonal relationship due to its use of the\none-hot vector-based loss function, while our method derives a unique loss\nfunction aimed at maximizing the target angle in the hyperspace based on the\nnature of a regular simplex. Our proposed loss imposes a higher penalty than\nthe original DC when the speaker is assigned incorrectly. The change from DC to\nM-DC can be easily achieved by rewriting just one term in the loss function of\nDC, without any other modifications to the network architecture or model\nparameters. As such, our method has high practicability because it does not\naffect the original inference part. The experimental results show that the\nproposed method improves the performances of the original DC and its expansion\nmethod.",
          "link": "http://arxiv.org/abs/2106.02331",
          "publishedOn": "2021-06-07T03:06:15.758Z",
          "wordCount": 611,
          "title": "Manifold-Aware Deep Clustering: Maximizing Angles between Embedding Vectors Based on Regular Simplex. (arXiv:2106.02331v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02393",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cesa_Bianchi_N/0/1/0/all/0/1\">Nicol&#xf2; Cesa-Bianchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laforgue_P/0/1/0/all/0/1\">Pierre Laforgue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paudice_A/0/1/0/all/0/1\">Andrea Paudice</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pontil_M/0/1/0/all/0/1\">Massimiliano Pontil</a>",
          "description": "We introduce and analyze MT-OMD, a multitask generalization of Online Mirror\nDescent (OMD) which operates by sharing updates between tasks. We prove that\nthe regret of MT-OMD is of order $\\sqrt{1 + \\sigma^2(N-1)}\\sqrt{T}$, where\n$\\sigma^2$ is the task variance according to the geometry induced by the\nregularizer, $N$ is the number of tasks, and $T$ is the time horizon. Whenever\ntasks are similar, that is, $\\sigma^2 \\le 1$, this improves upon the\n$\\sqrt{NT}$ bound obtained by running independent OMDs on each task. Our\nmultitask extensions of Online Gradient Descent and Exponentiated Gradient, two\nimportant instances of OMD, are shown to enjoy closed-form updates, making them\neasy to use in practice. Finally, we provide numerical experiments on four\nreal-world datasets which support our theoretical findings.",
          "link": "http://arxiv.org/abs/2106.02393",
          "publishedOn": "2021-06-07T03:06:15.741Z",
          "wordCount": 540,
          "title": "Multitask Online Mirror Descent. (arXiv:2106.02393v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02234",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maeda_T/0/1/0/all/0/1\">Takashi Nicholas Maeda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shimizu_S/0/1/0/all/0/1\">Shohei Shimizu</a>",
          "description": "Causal discovery from data affected by unobserved variables is an important\nbut difficult problem to solve. The effects that unobserved variables have on\nthe relationships between observed variables are more complex in nonlinear\ncases than in linear cases. In this study, we focus on causal additive models\nin the presence of unobserved variables. Causal additive models exhibit\nstructural equations that are additive in the variables and error terms. We\ntake into account the presence of not only unobserved common causes but also\nunobserved intermediate variables. Our theoretical results show that, when the\ncausal relationships are nonlinear and there are unobserved variables, it is\nnot possible to identify all the causal relationships between observed\nvariables through regression and independence tests. However, our theoretical\nresults also show that it is possible to avoid incorrect inferences. We propose\na method to identify all the causal relationships that are theoretically\npossible to identify without being biased by unobserved variables. The\nempirical results using artificial data and simulated functional magnetic\nresonance imaging (fMRI) data show that our method effectively infers causal\nstructures in the presence of unobserved variables.",
          "link": "http://arxiv.org/abs/2106.02234",
          "publishedOn": "2021-06-07T03:06:15.702Z",
          "wordCount": 628,
          "title": "Discovery of Causal Additive Models in the Presence of Unobserved Variables. (arXiv:2106.02234v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02197",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xinxing Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Q/0/1/0/all/0/1\">Qiang Cheng</a>",
          "description": "Feature selection identifies subsets of informative features and reduces\ndimensions in the original feature space, helping provide insights into data\ngeneration or a variety of domain problems. Existing methods mainly depend on\nfeature scoring functions or sparse regularizations; nonetheless, they have\nlimited ability to reconcile the representativeness and inter-correlations of\nfeatures. In this paper, we introduce a novel, simple yet effective\nregularization approach, named top-$k$ regularization, to supervised feature\nselection in regression and classification tasks. Structurally, the top-$k$\nregularization induces a sub-architecture on the architecture of a learning\nmodel to boost its ability to select the most informative features and model\ncomplex nonlinear relationships simultaneously. Theoretically, we derive and\nmathematically prove a uniform approximation error bound for using this\napproach to approximate high-dimensional sparse functions. Extensive\nexperiments on a wide variety of benchmarking datasets show that the top-$k$\nregularization is effective and stable for supervised feature selection.",
          "link": "http://arxiv.org/abs/2106.02197",
          "publishedOn": "2021-06-07T03:06:15.657Z",
          "wordCount": 571,
          "title": "Top-$k$ Regularization for Supervised Feature Selection. (arXiv:2106.02197v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02346",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Elesedy_B/0/1/0/all/0/1\">Bryn Elesedy</a>",
          "description": "It is a commonly held belief that enforcing invariance improves\ngeneralisation. Although this approach enjoys widespread popularity, it is only\nvery recently that a rigorous theoretical demonstration of this benefit has\nbeen established. In this work we build on the function space perspective of\nElesedy and Zaidi arXiv:2102.10333 to derive a strictly non-zero generalisation\nbenefit of incorporating invariance in kernel ridge regression when the target\nis invariant to the action of a compact group. We study invariance enforced by\nfeature averaging and find that generalisation is governed by a notion of\neffective dimension that arises from the interplay between the kernel and the\ngroup. In building towards this result, we find that the action of the group\ninduces an orthogonal decomposition of both the reproducing kernel Hilbert\nspace and its kernel, which may be of interest in its own right.",
          "link": "http://arxiv.org/abs/2106.02346",
          "publishedOn": "2021-06-07T03:06:15.572Z",
          "wordCount": 564,
          "title": "Provably Strict Generalisation Benefit for Invariance in Kernel Methods. (arXiv:2106.02346v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02575",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tao_Y/0/1/0/all/0/1\">Youming Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yulian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1\">Peng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Di Wang</a>",
          "description": "In this paper we study the problem of stochastic multi-armed bandits (MAB) in\nthe (local) differential privacy (DP/LDP) model. Unlike the previous results\nwhich need to assume bounded reward distributions, here we mainly focus on the\ncase the reward distribution of each arm only has $(1+v)$-th moment with some\n$v\\in (0, 1]$. In the first part, we study the problem in the central\n$\\epsilon$-DP model. We first provide a near-optimal result by developing a\nprivate and robust Upper Confidence Bound (UCB) algorithm. Then, we improve the\nresult via a private and robust version of the Successive Elimination (SE)\nalgorithm. Finally, we show that the instance-dependent regret bound of our\nimproved algorithm is optimal by showing its lower bound. In the second part of\nthe paper, we study the problem in the $\\epsilon$-LDP model. We propose an\nalgorithm which could be seen as locally private and robust version of the SE\nalgorithm, and show it could achieve (near) optimal rates for both\ninstance-dependent and instance-independent regrets. All of the above results\ncan also reveal the differences between the problem of private MAB with bounded\nrewards and heavy-tailed rewards. To achieve these (near) optimal rates, we\ndevelop several new hard instances and private robust estimators as byproducts,\nwhich might could be used to other related problems. Finally, experimental\nresults also support our theoretical analysis and show the effectiveness of our\nalgorithms.",
          "link": "http://arxiv.org/abs/2106.02575",
          "publishedOn": "2021-06-07T03:06:15.207Z",
          "wordCount": 655,
          "title": "Optimal Rates of (Locally) Differentially Private Heavy-tailed Multi-Armed Bandits. (arXiv:2106.02575v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.06175",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Junguang Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1\">Yifei Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Ximei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yufeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianmin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_M/0/1/0/all/0/1\">Mingsheng Long</a>",
          "description": "Domain adaptation (DA) aims at transferring knowledge from a labeled source\ndomain to an unlabeled target domain. Though many DA theories and algorithms\nhave been proposed, most of them are tailored into classification settings and\nmay fail in regression tasks, especially in the practical keypoint detection\ntask. To tackle this difficult but significant task, we present a method of\nregressive domain adaptation (RegDA) for unsupervised keypoint detection.\nInspired by the latest theoretical work, we first utilize an adversarial\nregressor to maximize the disparity on the target domain and train a feature\ngenerator to minimize this disparity. However, due to the high dimension of the\noutput space, this regressor fails to detect samples that deviate from the\nsupport of the source. To overcome this problem, we propose two important\nideas. First, based on our observation that the probability density of the\noutput space is sparse, we introduce a spatial probability distribution to\ndescribe this sparsity and then use it to guide the learning of the adversarial\nregressor. Second, to alleviate the optimization difficulty in the\nhigh-dimensional space, we innovatively convert the minimax game in the\nadversarial training to the minimization of two opposite goals. Extensive\nexperiments show that our method brings large improvement by 8% to 11% in terms\nof PCK on different datasets.",
          "link": "http://arxiv.org/abs/2103.06175",
          "publishedOn": "2021-06-07T03:06:15.201Z",
          "wordCount": 680,
          "title": "Regressive Domain Adaptation for Unsupervised Keypoint Detection. (arXiv:2103.06175v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.01294",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Huanyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mironov_I/0/1/0/all/0/1\">Ilya Mironov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hejazinia_M/0/1/0/all/0/1\">Meisam Hejazinia</a>",
          "description": "Despite intense interest and considerable effort, the current generation of\nneural networks suffers a significant loss of accuracy under most practically\nrelevant privacy training regimes. One particularly challenging class of neural\nnetworks are the wide ones, such as those deployed for NLP typeahead prediction\nor recommender systems. Observing that these models share something in\ncommon--an embedding layer that reduces the dimensionality of the input--we\nfocus on developing a general approach towards training these models that takes\nadvantage of the sparsity of the gradients. More abstractly, we address the\nproblem of differentially private empirical risk minimization (ERM) for models\nthat admit sparse gradients. We demonstrate that for non-convex ERM problems,\nthe loss is logarithmically dependent on the number of parameters, in contrast\nwith polynomial dependence for the general case. Following the same intuition,\nwe propose a novel algorithm for privately training neural networks. Finally,\nwe provide an empirical study of a DP wide neural network on a real-world\ndataset, which has been rarely explored in the previous work.",
          "link": "http://arxiv.org/abs/2103.01294",
          "publishedOn": "2021-06-07T03:06:15.194Z",
          "wordCount": 628,
          "title": "Wide Network Learning with Differential Privacy. (arXiv:2103.01294v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.13256",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mallah_R/0/1/0/all/0/1\">Ranwa Al Mallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Badu_Marfo_G/0/1/0/all/0/1\">Godwin Badu-Marfo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farooq_B/0/1/0/all/0/1\">Bilal Farooq</a>",
          "description": "Federated learning (FL) is a machine learning technique that aims at training\nan algorithm across decentralized entities holding their local data private.\nWireless mobile networks allow users to communicate with other fixed or mobile\nusers. The road traffic network represents an infrastructure-based\nconfiguration of a wireless mobile network where the Connected and Automated\nVehicles (CAV) represent the communicating entities. Applying FL in a wireless\nmobile network setting gives rise to a new threat in the mobile environment\nthat is very different from the traditional fixed networks. The threat is due\nto the intrinsic characteristics of the wireless medium and is caused by the\ncharacteristics of the vehicular networks such as high node-mobility and\nrapidly changing topology. Most cyber defense techniques depend on highly\nreliable and connected networks. This paper explores falsified information\nattacks, which target the FL process that is ongoing at the RSU. We identified\na number of attack strategies conducted by the malicious CAVs to disrupt the\ntraining of the global model in vehicular networks. We show that the attacks\nwere able to increase the convergence time and decrease the accuracy the model.\nWe demonstrate that our attacks bypass FL defense strategies in their primary\nform and highlight the need for novel poisoning resilience defense mechanisms\nin the wireless mobile setting of the future road networks.",
          "link": "http://arxiv.org/abs/2102.13256",
          "publishedOn": "2021-06-07T03:06:15.186Z",
          "wordCount": 692,
          "title": "Cybersecurity Threats in Connected and Automated Vehicles based Federated Learning Systems. (arXiv:2102.13256v3 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02310",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shyn_S/0/1/0/all/0/1\">Sung Kuk Shyn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Donghee Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1\">Kwangsu Kim</a>",
          "description": "Client contribution evaluation, also known as data valuation, is a crucial\napproach in federated learning(FL) for client selection and incentive\nallocation. However, due to restrictions of accessibility of raw data, only\nlimited information such as local weights and local data size of each client is\nopen for quantifying the client contribution. Using data size from available\ninformation, we introduce an empirical evaluation method called Federated\nClient Contribution Evaluation through Accuracy Approximation(FedCCEA). This\nmethod builds the Accuracy Approximation Model(AAM), which estimates a\nsimulated test accuracy using inputs of sampled data size and extracts the\nclients' data quality and data size to measure client contribution. FedCCEA\nstrengthens some advantages: (1) enablement of data size selection to the\nclients, (2) feasible evaluation time regardless of the number of clients, and\n(3) precise estimation in non-IID settings. We demonstrate the superiority of\nFedCCEA compared to previous methods through several experiments: client\ncontribution distribution, client removal, and robustness test to partial\nparticipation.",
          "link": "http://arxiv.org/abs/2106.02310",
          "publishedOn": "2021-06-07T03:06:15.169Z",
          "wordCount": 607,
          "title": "FedCCEA : A Practical Approach of Client Contribution Evaluation for Federated Learning. (arXiv:2106.02310v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02528",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Wal_M/0/1/0/all/0/1\">Michael D. Vander Wal</a> (1), <a href=\"http://arxiv.org/find/physics/1/au:+McClarren_R/0/1/0/all/0/1\">Ryan G. McClarren</a> (1), <a href=\"http://arxiv.org/find/physics/1/au:+Humbird_K/0/1/0/all/0/1\">Kelli D. Humbird</a> (2) ((1) University of Notre Dame, (2) Lawrence Livermore National Laboratory)",
          "description": "Simulations of high energy density physics are expensive in terms of\ncomputational resources. In particular, the computation of opacities of\nplasmas, which are needed to accurately compute radiation transport in the\nnon-local thermal equilibrium (NLTE) regime, are expensive to the point of\neasily requiring multiple times the sum-total compute time of all other\ncomponents of the simulation. As such, there is great interest in finding ways\nto accelerate NLTE computations. Previous work has demonstrated that a\ncombination of fully-connected autoencoders and a deep jointly-informed neural\nnetwork (DJINN) can successfully replace the standard NLTE calculations for the\nopacity of krypton. This work expands this idea to multiple elements in\ndemonstrating that individual surrogate models can be also be generated for\nother elements with the focus being on creating autoencoders that can\naccurately encode and decode the absorptivity and emissivity spectra.\nFurthermore, this work shows that multiple elements across a large range of\natomic numbers can be combined into a single autoencoder when using a\nconvolutional autoencoder while maintaining accuracy that is comparable to\nindividual fully-connected autoencoders. Lastly, it is demonstrated that DJINN\ncan effectively learn the latent space of a convolutional autoencoder that can\nencode multiple elements allowing the combination to effectively function as a\nsurrogate model.",
          "link": "http://arxiv.org/abs/2106.02528",
          "publishedOn": "2021-06-07T03:06:15.163Z",
          "wordCount": 703,
          "title": "Neural Network Surrogate Models for Absorptivity and Emissivity Spectra of Multiple Elements. (arXiv:2106.02528v1 [physics.plasm-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02213",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Diaz_A/0/1/0/all/0/1\">Alex D&#xed;az</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steele_D/0/1/0/all/0/1\">Damian Steele</a>",
          "description": "We examine three non-negative matrix factorization techniques; L2-norm,\nL1-norm, and L2,1-norm. Our aim is to establish the performance of these\ndifferent approaches, and their robustness in real-world applications such as\nfeature selection while managing computational complexity, sensitivity to noise\nand more. We thoroughly examine each approach from a theoretical perspective,\nand examine the performance of each using a series of experiments drawing on\nboth the ORL and YaleB datasets. We examine the Relative Reconstruction Errors\n(RRE), Average Accuracy and Normalized Mutual Information (NMI) as criteria\nunder a range of simulated noise scenarios.",
          "link": "http://arxiv.org/abs/2106.02213",
          "publishedOn": "2021-06-07T03:06:15.157Z",
          "wordCount": 524,
          "title": "Analysis of the robustness of NMF algorithms. (arXiv:2106.02213v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02488",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rahnama_A/0/1/0/all/0/1\">Amir Hossein Akhavan Rahnama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Butepage_J/0/1/0/all/0/1\">Judith Butepage</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geurts_P/0/1/0/all/0/1\">Pierre Geurts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bostrom_H/0/1/0/all/0/1\">Henrik Bostrom</a>",
          "description": "Explanation techniques are commonly evaluated using human-grounded methods,\nlimiting the possibilities for large-scale evaluations and rapid progress in\nthe development of new techniques. We propose a functionally-grounded\nevaluation procedure for local model-agnostic explanation techniques. In our\napproach, we generate ground truth for explanations when the black-box model is\nLogistic Regression and Gaussian Naive Bayes and compare how similar each\nexplanation is to the extracted ground truth. In our empirical study,\nexplanations of Local Interpretable Model-agnostic Explanations (LIME), SHapley\nAdditive exPlanations (SHAP), and Local Permutation Importance (LPI) are\ncompared in terms of how similar they are to the extracted ground truth. In the\ncase of Logistic Regression, we find that the performance of the explanation\ntechniques is highly dependent on the normalization of the data. In contrast,\nLocal Permutation Importance outperforms the other techniques on Naive Bayes,\nirrespective of normalization. We hope that this work lays the foundation for\nfurther research into functionally-grounded evaluation methods for explanation\ntechniques.",
          "link": "http://arxiv.org/abs/2106.02488",
          "publishedOn": "2021-06-07T03:06:15.152Z",
          "wordCount": 599,
          "title": "Evaluation of Local Model-Agnostic Explanations Using Ground Truth. (arXiv:2106.02488v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02400",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1\">Manh-Duy Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_B/0/1/0/all/0/1\">Binh T. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurrin_C/0/1/0/all/0/1\">Cathal Gurrin</a>",
          "description": "Conventional approaches to image-text retrieval mainly focus on indexing\nvisual objects appearing in pictures but ignore the interactions between these\nobjects. Such objects occurrences and interactions are equivalently useful and\nimportant in this field as they are usually mentioned in the text. Scene graph\npresentation is a suitable method for the image-text matching challenge and\nobtained good results due to its ability to capture the inter-relationship\ninformation. Both images and text are represented in scene graph levels and\nformulate the retrieval challenge as a scene graph matching challenge. In this\npaper, we introduce the Local and Global Scene Graph Matching (LGSGM) model\nthat enhances the state-of-the-art method by integrating an extra graph\nconvolution network to capture the general information of a graph.\nSpecifically, for a pair of scene graphs of an image and its caption, two\nseparate models are used to learn the features of each graph's nodes and edges.\nThen a Siamese-structure graph convolution model is employed to embed graphs\ninto vector forms. We finally combine the graph-level and the vector-level to\ncalculate the similarity of this image-text pair. The empirical experiments\nshow that our enhancement with the combination of levels can improve the\nperformance of the baseline method by increasing the recall by more than 10% on\nthe Flickr30k dataset.",
          "link": "http://arxiv.org/abs/2106.02400",
          "publishedOn": "2021-06-07T03:06:15.145Z",
          "wordCount": 652,
          "title": "A Deep Local and Global Scene-Graph Matching for Image-Text Retrieval. (arXiv:2106.02400v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02301",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Saito_M/0/1/0/all/0/1\">Masahiko Saito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kishimoto_T/0/1/0/all/0/1\">Tomoe Kishimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaneta_Y/0/1/0/all/0/1\">Yuya Kaneta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Itoh_T/0/1/0/all/0/1\">Taichi Itoh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Umeda_Y/0/1/0/all/0/1\">Yoshiaki Umeda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanaka_J/0/1/0/all/0/1\">Junichi Tanaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iiyama_Y/0/1/0/all/0/1\">Yutaro Iiyama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sawada_R/0/1/0/all/0/1\">Ryu Sawada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Terashi_K/0/1/0/all/0/1\">Koji Terashi</a>",
          "description": "The usefulness and value of Multi-step Machine Learning (ML), where a task is\norganized into connected sub-tasks with known intermediate inference goals, as\nopposed to a single large model learned end-to-end without intermediate\nsub-tasks, is presented. Pre-optimized ML models are connected and better\nperformance is obtained by re-optimizing the connected one. The selection of an\nML model from several small ML model candidates for each sub-task has been\nperformed by using the idea based on Neural Architecture Search (NAS). In this\npaper, Differentiable Architecture Search (DARTS) and Single Path One-Shot NAS\n(SPOS-NAS) are tested, where the construction of loss functions is improved to\nkeep all ML models smoothly learning. Using DARTS and SPOS-NAS as an\noptimization and selection as well as the connections for multi-step machine\nlearning systems, we find that (1) such a system can quickly and successfully\nselect highly performant model combinations, and (2) the selected models are\nconsistent with baseline algorithms, such as grid search, and their outputs are\nwell controlled.",
          "link": "http://arxiv.org/abs/2106.02301",
          "publishedOn": "2021-06-07T03:06:15.138Z",
          "wordCount": 594,
          "title": "Event Classification with Multi-step Machine Learning. (arXiv:2106.02301v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02183",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Excell_E/0/1/0/all/0/1\">Elizabeth Excell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moubayed_N/0/1/0/all/0/1\">Noura Al Moubayed</a>",
          "description": "Classifiers tend to propagate biases present in the data on which they are\ntrained. Hence, it is important to understand how the demographic identities of\nthe annotators of comments affect the fairness of the resulting model. In this\npaper, we focus on the differences in the ways men and women annotate comments\nfor toxicity, investigating how these differences result in models that amplify\nthe opinions of male annotators. We find that the BERT model as-sociates toxic\ncomments containing offensive words with male annotators, causing the model to\npredict 67.7% of toxic comments as having been annotated by men. We show that\nthis disparity between gender predictions can be mitigated by removing\noffensive words and highly toxic comments from the training data. We then apply\nthe learned associations between gender and language to toxic language\nclassifiers, finding that models trained exclusively on female-annotated data\nperform 1.8% better than those trained solely on male-annotated data and that\ntraining models on data after removing all offensive words reduces bias in the\nmodel by 55.5% while increasing the sensitivity by 0.4%.",
          "link": "http://arxiv.org/abs/2106.02183",
          "publishedOn": "2021-06-07T03:06:15.120Z",
          "wordCount": 624,
          "title": "Towards Equal Gender Representation in the Annotations of Toxic Language Detection. (arXiv:2106.02183v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02073",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">X.Y. Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papyan_V/0/1/0/all/0/1\">Vardan Papyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Donoho_D/0/1/0/all/0/1\">David L. Donoho</a>",
          "description": "Recent work [Papyan, Han, and Donoho, 2020] discovered a phenomenon called\nNeural Collapse (NC) that occurs pervasively in today's deep net training\nparadigm of driving cross-entropy loss towards zero. In this phenomenon, the\nlast-layer features collapse to their class-means, both the classifiers and\nclass-means collapse to the same Simplex Equiangular Tight Frame (ETF), and the\nbehavior of the last-layer classifier converges to that of the\nnearest-class-mean decision rule. Since then, follow-ups-such as Mixon et al.\n[2020] and Poggio and Liao [2020a,b]-formally analyzed this inductive bias by\nreplacing the hard-to-study cross-entropy by the more tractable mean squared\nerror (MSE) loss. But, these works stopped short of demonstrating the empirical\nreality of MSE-NC on benchmark datasets and canonical networks-as had been done\nin Papyan, Han, and Donoho [2020] for the cross-entropy loss. In this work, we\nestablish the empirical reality of MSE-NC by reporting experimental\nobservations for three prototypical networks and five canonical datasets with\ncode for reproducing NC. Following this, we develop three main contributions\ninspired by MSE-NC. Firstly, we show a new theoretical decomposition of the MSE\nloss into (A) a term assuming the last-layer classifier is exactly the\nleast-squares or Webb and Lowe [1990] classifier and (B) a term capturing the\ndeviation from this least-squares classifier. Secondly, we exhibit experiments\non canonical datasets and networks demonstrating that, during training,\nterm-(B) is negligible. This motivates a new theoretical construct: the central\npath, where the linear classifier stays MSE-optimal-for the given feature\nactivations-throughout the dynamics. Finally, through our study of continually\nrenormalized gradient flow along the central path, we produce closed-form\ndynamics that predict full Neural Collapse in an unconstrained features model.",
          "link": "http://arxiv.org/abs/2106.02073",
          "publishedOn": "2021-06-07T03:06:15.112Z",
          "wordCount": 747,
          "title": "Neural Collapse Under MSE Loss: Proximity to and Dynamics on the Central Path. (arXiv:2106.02073v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Smith_L/0/1/0/all/0/1\">Lewis Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amersfoort_J/0/1/0/all/0/1\">Joost van Amersfoort</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Haiwen Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_S/0/1/0/all/0/1\">Stephen Roberts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1\">Yarin Gal</a>",
          "description": "ResNets constrained to be bi-Lipschitz, that is, approximately distance\npreserving, have been a crucial component of recently proposed techniques for\ndeterministic uncertainty quantification in neural models. We show that\ntheoretical justifications for recent regularisation schemes trying to enforce\nsuch a constraint suffer from a crucial flaw -- the theoretical link between\nthe regularisation scheme used and bi-Lipschitzness is only valid under\nconditions which do not hold in practice, rendering existing theory of limited\nuse, despite the strong empirical performance of these models. We provide a\ntheoretical explanation for the effectiveness of these regularisation schemes\nusing a frequency analysis perspective, showing that under mild conditions\nthese schemes will enforce a lower Lipschitz bound on the low-frequency\nprojection of images. We then provide empirical evidence supporting our\ntheoretical claims, and perform further experiments which demonstrate that our\nbroader conclusions appear to hold when some of the mathematical assumptions of\nour proof are relaxed, corresponding to the setup used in prior work. In\naddition, we present a simple constructive algorithm to search for counter\nexamples to the distance preservation condition, and discuss possible\nimplications of our theory for future model design.",
          "link": "http://arxiv.org/abs/2106.02469",
          "publishedOn": "2021-06-07T03:06:15.106Z",
          "wordCount": 642,
          "title": "Can convolutional ResNets approximately preserve input distances? A frequency analysis perspective. (arXiv:2106.02469v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02315",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hamadeh_N/0/1/0/all/0/1\">Nizar Hamadeh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Karouni_A/0/1/0/all/0/1\">Ali Karouni</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Farhat_Z/0/1/0/all/0/1\">Zeinab Farhat</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ghor_H/0/1/0/all/0/1\">Hussein El Ghor</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ghor_M/0/1/0/all/0/1\">Mohamad El Ghor</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Katea_I/0/1/0/all/0/1\">Israa Katea</a>",
          "description": "Intelligent transport systems have efficiently and effectively proved\nthemselves in settling up the problem of traffic congestion around the world.\nThe multi-agent based transportation system is one of the most important\nintelligent transport systems, which represents an interaction among the\nneighbouring vehicles, drivers, roads, infrastructure and vehicles. In this\npaper, two traffic management models have been created to mitigate congestion\nand to ensure that emergency vehicles arrive as quickly as possible. A\ntool-chain SUMO-JADE is employed to create a microscopic simulation symbolizing\nthe interactions of traffic. The simulation model has showed a significant\nreduction of at least 50% in the average time delay and thus a real improvement\nin the entire journey time.",
          "link": "http://arxiv.org/abs/2106.02315",
          "publishedOn": "2021-06-07T03:06:15.100Z",
          "wordCount": 554,
          "title": "Intelligent Transportation Systems to Mitigate Road Traffic Congestion. (arXiv:2106.02315v1 [eess.SY])"
        },
        {
          "id": "http://arxiv.org/abs/1905.02515",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Puolamaki_K/0/1/0/all/0/1\">Kai Puolam&#xe4;ki</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Oikarinen_E/0/1/0/all/0/1\">Emilia Oikarinen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Henelius_A/0/1/0/all/0/1\">Andreas Henelius</a>",
          "description": "Efficient explorative data analysis systems must take into account both what\na user knows and wants to know. This paper proposes a principled framework for\ninteractive visual exploration of relations in data, through views most\ninformative given the user's current knowledge and objectives. The user can\ninput pre-existing knowledge of relations in the data and also formulate\nspecific exploration interests, which are then taken into account in the\nexploration. The idea is to steer the exploration process towards the interests\nof the user, instead of showing uninteresting or already known relations. The\nuser's knowledge is modelled by a distribution over data sets parametrised by\nsubsets of rows and columns of data, called tile constraints. We provide a\ncomputationally efficient implementation of this concept based on constrained\nrandomisation. Furthermore, we describe a novel dimensionality reduction method\nfor finding the views most informative to the user, which at the limit of no\nbackground knowledge and with generic objectives reduces to PCA. We show that\nthe method is suitable for interactive use and is robust to noise, outperforms\nstandard projection pursuit visualisation methods, and gives understandable and\nuseful results in analysis of real-world data. We provide an open-source\nimplementation of the framework.",
          "link": "http://arxiv.org/abs/1905.02515",
          "publishedOn": "2021-06-07T03:06:15.084Z",
          "wordCount": 663,
          "title": "Guided Visual Exploration of Relations in Data Sets. (arXiv:1905.02515v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02264",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Anji Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Broeck_G/0/1/0/all/0/1\">Guy Van den Broeck</a>",
          "description": "Probabilistic Circuits (PCs) are a promising avenue for probabilistic\nmodeling. They combine advantages of probabilistic graphical models (PGMs) with\nthose of neural networks (NNs). Crucially, however, they are tractable\nprobabilistic models, supporting efficient and exact computation of many\nprobabilistic inference queries, such as marginals and MAP. Further, since PCs\nare structured computation graphs, they can take advantage of\ndeep-learning-style parameter updates, which greatly improves their\nscalability. However, this innovation also makes PCs prone to overfitting,\nwhich has been observed in many standard benchmarks. Despite the existence of\nabundant regularization techniques for both PGMs and NNs, they are not\neffective enough when applied to PCs. Instead, we re-think regularization for\nPCs and propose two intuitive techniques, data softening and entropy\nregularization, that both take advantage of PCs' tractability and still have an\nefficient implementation as a computation graph. Specifically, data softening\nprovides a principled way to add uncertainty in datasets in closed form, which\nimplicitly regularizes PC parameters. To learn parameters from a softened\ndataset, PCs only need linear time by virtue of their tractability. In entropy\nregularization, the exact entropy of the distribution encoded by a PC can be\nregularized directly, which is again infeasible for most other density\nestimation models. We show that both methods consistently improve the\ngeneralization performance of a wide variety of PCs. Moreover, when paired with\na simple PC structure, we achieved state-of-the-art results on 10 out of 20\nstandard discrete density estimation benchmarks.",
          "link": "http://arxiv.org/abs/2106.02264",
          "publishedOn": "2021-06-07T03:06:15.078Z",
          "wordCount": 654,
          "title": "Tractable Regularization of Probabilistic Circuits. (arXiv:2106.02264v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02377",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Triess_L/0/1/0/all/0/1\">Larissa T. Triess</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dreissig_M/0/1/0/all/0/1\">Mariella Dreissig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rist_C/0/1/0/all/0/1\">Christoph B. Rist</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zollner_J/0/1/0/all/0/1\">J. Marius Z&#xf6;llner</a>",
          "description": "Scalable systems for automated driving have to reliably cope with an\nopen-world setting. This means, the perception systems are exposed to drastic\ndomain shifts, like changes in weather conditions, time-dependent aspects, or\ngeographic regions. Covering all domains with annotated data is impossible\nbecause of the endless variations of domains and the time-consuming and\nexpensive annotation process. Furthermore, fast development cycles of the\nsystem additionally introduce hardware changes, such as sensor types and\nvehicle setups, and the required knowledge transfer from simulation. To enable\nscalable automated driving, it is therefore crucial to address these domain\nshifts in a robust and efficient manner. Over the last years, a vast amount of\ndifferent domain adaptation techniques evolved. There already exists a number\nof survey papers for domain adaptation on camera images, however, a survey for\nLiDAR perception is absent. Nevertheless, LiDAR is a vital sensor for automated\ndriving that provides detailed 3D scans of the vehicle's surroundings. To\nstimulate future research, this paper presents a comprehensive review of recent\nprogress in domain adaptation methods and formulates interesting research\nquestions specifically targeted towards LiDAR perception.",
          "link": "http://arxiv.org/abs/2106.02377",
          "publishedOn": "2021-06-07T03:06:15.072Z",
          "wordCount": 642,
          "title": "A Survey on Deep Domain Adaptation for LiDAR Perception. (arXiv:2106.02377v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2007.10538",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yulin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1\">Gao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1\">Shiji Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xuran Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yitong Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Cheng Wu</a>",
          "description": "Data augmentation is widely known as a simple yet surprisingly effective\ntechnique for regularizing deep networks. Conventional data augmentation\nschemes, e.g., flipping, translation or rotation, are low-level,\ndata-independent and class-agnostic operations, leading to limited diversity\nfor augmented samples. To this end, we propose a novel semantic data\naugmentation algorithm to complement traditional approaches. The proposed\nmethod is inspired by the intriguing property that deep networks are effective\nin learning linearized features, i.e., certain directions in the deep feature\nspace correspond to meaningful semantic transformations, e.g., changing the\nbackground or view angle of an object. Based on this observation, translating\ntraining samples along many such directions in the feature space can\neffectively augment the dataset for more diversity. To implement this idea, we\nfirst introduce a sampling based method to obtain semantically meaningful\ndirections efficiently. Then, an upper bound of the expected cross-entropy (CE)\nloss on the augmented training set is derived by assuming the number of\naugmented samples goes to infinity, yielding a highly efficient algorithm. In\nfact, we show that the proposed implicit semantic data augmentation (ISDA)\nalgorithm amounts to minimizing a novel robust CE loss, which adds minimal\nextra computational cost to a normal training procedure. In addition to\nsupervised learning, ISDA can be applied to semi-supervised learning tasks\nunder the consistency regularization framework, where ISDA amounts to\nminimizing the upper bound of the expected KL-divergence between the augmented\nfeatures and the original features. Although being simple, ISDA consistently\nimproves the generalization performance of popular deep models (e.g., ResNets\nand DenseNets) on a variety of datasets, i.e., CIFAR-10, CIFAR-100, SVHN,\nImageNet, and Cityscapes.",
          "link": "http://arxiv.org/abs/2007.10538",
          "publishedOn": "2021-06-07T03:06:15.065Z",
          "wordCount": 781,
          "title": "Regularizing Deep Networks with Semantic Data Augmentation. (arXiv:2007.10538v5 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02162",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aden_Ali_I/0/1/0/all/0/1\">Ishaq Aden-Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ashtiani_H/0/1/0/all/0/1\">Hassan Ashtiani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liaw_C/0/1/0/all/0/1\">Christopher Liaw</a>",
          "description": "We consider the problem of learning mixtures of Gaussians under the\nconstraint of approximate differential privacy. We prove that\n$\\widetilde{O}(k^2 d \\log^{3/2}(1/\\delta) / \\alpha^2 \\varepsilon)$ samples are\nsufficient to learn a mixture of $k$ axis-aligned Gaussians in $\\mathbb{R}^d$\nto within total variation distance $\\alpha$ while satisfying $(\\varepsilon,\n\\delta)$-differential privacy. This is the first result for privately learning\nmixtures of unbounded axis-aligned (or even unbounded univariate) Gaussians. If\nthe covariance matrices of each of the Gaussians is the identity matrix, we\nshow that $\\widetilde{O}(kd/\\alpha^2 + kd \\log(1/\\delta) / \\alpha \\varepsilon)$\nsamples are sufficient.\n\nRecently, the \"local covering\" technique of Bun, Kamath, Steinke, and Wu has\nbeen successfully used for privately learning high-dimensional Gaussians with a\nknown covariance matrix and extended to privately learning general\nhigh-dimensional Gaussians by Aden-Ali, Ashtiani, and Kamath. Given these\npositive results, this approach has been proposed as a promising direction for\nprivately learning mixtures of Gaussians. Unfortunately, we show that this is\nnot possible.\n\nWe design a new technique for privately learning mixture distributions. A\nclass of distributions $\\mathcal{F}$ is said to be list-decodable if there is\nan algorithm that, given \"heavily corrupted\" samples from $f\\in \\mathcal{F}$,\noutputs a list of distributions, $\\widehat{\\mathcal{F}}$, such that one of the\ndistributions in $\\widehat{\\mathcal{F}}$ approximates $f$. We show that if\n$\\mathcal{F}$ is privately list-decodable, then we can privately learn mixtures\nof distributions in $\\mathcal{F}$. Finally, we show axis-aligned Gaussian\ndistributions are privately list-decodable, thereby proving mixtures of such\ndistributions are privately learnable.",
          "link": "http://arxiv.org/abs/2106.02162",
          "publishedOn": "2021-06-07T03:06:15.059Z",
          "wordCount": 663,
          "title": "Privately Learning Mixtures of Axis-Aligned Gaussians. (arXiv:2106.02162v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02225",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kong_S/0/1/0/all/0/1\">Shufeng Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guevarra_D/0/1/0/all/0/1\">Dan Guevarra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomes_C/0/1/0/all/0/1\">Carla P. Gomes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gregoire_J/0/1/0/all/0/1\">John M. Gregoire</a>",
          "description": "The adoption of machine learning in materials science has rapidly transformed\nmaterials property prediction. Hurdles limiting full capitalization of recent\nadvancements in machine learning include the limited development of methods to\nlearn the underlying interactions of multiple elements, as well as the\nrelationships among multiple properties, to facilitate property prediction in\nnew composition spaces. To address these issues, we introduce the Hierarchical\nCorrelation Learning for Multi-property Prediction (H-CLMP) framework that\nseamlessly integrates (i) prediction using only a material's composition, (ii)\nlearning and exploitation of correlations among target properties in\nmulti-target regression, and (iii) leveraging training data from tangential\ndomains via generative transfer learning. The model is demonstrated for\nprediction of spectral optical absorption of complex metal oxides spanning 69\n3-cation metal oxide composition spaces. H-CLMP accurately predicts non-linear\ncomposition-property relationships in composition spaces for which no training\ndata is available, which broadens the purview of machine learning to the\ndiscovery of materials with exceptional properties. This achievement results\nfrom the principled integration of latent embedding learning, property\ncorrelation learning, generative transfer learning, and attention models. The\nbest performance is obtained using H-CLMP with Transfer learning (H-CLMP(T))\nwherein a generative adversarial network is trained on computational density of\nstates data and deployed in the target domain to augment prediction of optical\nabsorption from composition. H-CLMP(T) aggregates multiple knowledge sources\nwith a framework that is well-suited for multi-target regression across the\nphysical sciences.",
          "link": "http://arxiv.org/abs/2106.02225",
          "publishedOn": "2021-06-07T03:06:15.053Z",
          "wordCount": 674,
          "title": "Materials Representation and Transfer Learning for Multi-Property Prediction. (arXiv:2106.02225v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02328",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balaji_T/0/1/0/all/0/1\">Thangapavithraa Balaji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blies_P/0/1/0/all/0/1\">Patrick Blies</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gori_G/0/1/0/all/0/1\">Georg G&#xf6;ri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitsch_R/0/1/0/all/0/1\">Raphael Mitsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wasserer_M/0/1/0/all/0/1\">Marcel Wasserer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schon_T/0/1/0/all/0/1\">Torsten Sch&#xf6;n</a>",
          "description": "This work tackles the problem of temporally coherent face anonymization in\nnatural video streams.We propose JaGAN, a two-stage system starting with\ndetecting and masking out faces with black image patches in all individual\nframes of the video. The second stage leverages a privacy-preserving Video\nGenerative Adversarial Network designed to inpaint the missing image patches\nwith artificially generated faces. Our initial experiments reveal that image\nbased generative models are not capable of inpainting patches showing temporal\ncoherent appearance across neighboring video frames. To address this issue we\nintroduce a newly curated video collection, which is made publicly available\nfor the research community along with this paper. We also introduce the\nIdentity Invariance Score IdI as a means to quantify temporal coherency between\nneighboring frames.",
          "link": "http://arxiv.org/abs/2106.02328",
          "publishedOn": "2021-06-07T03:06:15.045Z",
          "wordCount": 574,
          "title": "Temporally coherent video anonymization through GAN inpainting. (arXiv:2106.02328v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02401",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Guanglin Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1\">Qinghua Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pu_S/0/1/0/all/0/1\">Shiliang Pu</a>",
          "description": "Few-shot relation extraction (FSRE) is of great importance in long-tail\ndistribution problem, especially in special domain with low-resource data. Most\nexisting FSRE algorithms fail to accurately classify the relations merely based\non the information of the sentences together with the recognized entity pairs,\ndue to limited samples and lack of knowledge. To address this problem, in this\npaper, we proposed a novel entity CONCEPT-enhanced FEw-shot Relation Extraction\nscheme (ConceptFERE), which introduces the inherent concepts of entities to\nprovide clues for relation prediction and boost the relations classification\nperformance. Firstly, a concept-sentence attention module is developed to\nselect the most appropriate concept from multiple concepts of each entity by\ncalculating the semantic similarity between sentences and concepts. Secondly, a\nself-attention based fusion module is presented to bridge the gap of concept\nembedding and sentence embedding from different semantic spaces. Extensive\nexperiments on the FSRE benchmark dataset FewRel have demonstrated the\neffectiveness and the superiority of the proposed ConceptFERE scheme as\ncompared to the state-of-the-art baselines. Code is available at\nhttps://github.com/LittleGuoKe/ConceptFERE.",
          "link": "http://arxiv.org/abs/2106.02401",
          "publishedOn": "2021-06-07T03:06:15.039Z",
          "wordCount": 605,
          "title": "Entity Concept-enhanced Few-shot Relation Extraction. (arXiv:2106.02401v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02172",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Gang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Daheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Wenhao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1\">Meng Jiang</a>",
          "description": "Learning to predict missing links is important for many graph-based\napplications. Existing methods were designed to learn the observed association\nbetween two sets of variables: (1) the observed graph structure and (2) the\nexistence of link between a pair of nodes. However, the causal relationship\nbetween these variables was ignored and we visit the possibility of learning it\nby simply asking a counterfactual question: \"would the link exist or not if the\nobserved graph structure became different?\" To answer this question by causal\ninference, we consider the information of the node pair as context, global\ngraph structural properties as treatment, and link existence as outcome. In\nthis work, we propose a novel link prediction method that enhances graph\nlearning by the counterfactual inference. It creates counterfactual links from\nthe observed ones, and our method learns representations from both of them.\nExperiments on a number of benchmark datasets show that our proposed method\nachieves the state-of-the-art performance on link prediction.",
          "link": "http://arxiv.org/abs/2106.02172",
          "publishedOn": "2021-06-07T03:06:15.009Z",
          "wordCount": 580,
          "title": "Counterfactual Graph Learning for Link Prediction. (arXiv:2106.02172v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02452",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kommrusch_S/0/1/0/all/0/1\">Steve Kommrusch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barollet_T/0/1/0/all/0/1\">Th&#xe9;o Barollet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pouchet_L/0/1/0/all/0/1\">Louis-No&#xeb;l Pouchet</a>",
          "description": "We target the problem of provably computing the equivalence between two\ncomplex expression trees. To this end, we formalize the problem of equivalence\nbetween two such programs as finding a set of semantics-preserving rewrite\nrules from one into the other, such that after the rewrite the two programs are\nstructurally identical, and therefore trivially equivalent.We then develop a\ngraph-to-sequence neural network system for program equivalence, trained to\nproduce such rewrite sequences from a carefully crafted automatic example\ngeneration algorithm. We extensively evaluate our system on a rich multi-type\nlinear algebra expression language, using arbitrary combinations of 100+\ngraph-rewriting axioms of equivalence. Our machine learning system guarantees\ncorrectness for all true negatives, and ensures 0 false positive by design. It\noutputs via inference a valid proof of equivalence for 93% of the 10,000\nequivalent expression pairs isolated for testing, using up to 50-term\nexpressions. In all cases, the validity of the sequence produced and therefore\nthe provable assertion of program equivalence is always computable, in\nnegligible time.",
          "link": "http://arxiv.org/abs/2106.02452",
          "publishedOn": "2021-06-07T03:06:14.983Z",
          "wordCount": 614,
          "title": "Proving Equivalence Between Complex Expressions Using Graph-to-Sequence Neural Models. (arXiv:2106.02452v1 [cs.PL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02588",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wojtowytsch_S/0/1/0/all/0/1\">Stephan Wojtowytsch</a>",
          "description": "The representation of functions by artificial neural networks depends on a\nlarge number of parameters in a non-linear fashion. Suitable parameters of\nthese are found by minimizing a 'loss functional', typically by stochastic\ngradient descent (SGD) or an advanced SGD-based algorithm.\n\nIn a continuous time model for SGD with noise that follows the 'machine\nlearning scaling', we show that in a certain noise regime, the optimization\nalgorithm prefers 'flat' minima of the objective function in a sense which is\ndifferent from the flat minimum selection of continuous time SGD with\nhomogeneous noise.",
          "link": "http://arxiv.org/abs/2106.02588",
          "publishedOn": "2021-06-07T03:06:14.972Z",
          "wordCount": 541,
          "title": "Stochastic gradient descent with noise of machine learning type. Part II: Continuous time analysis. (arXiv:2106.02588v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02146",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aldroubi_A/0/1/0/all/0/1\">Akram Aldroubi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_R/0/1/0/all/0/1\">Rocio Diaz Martin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Medri_I/0/1/0/all/0/1\">Ivan Medri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rohde_G/0/1/0/all/0/1\">Gustavo K. Rohde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thareja_S/0/1/0/all/0/1\">Sumati Thareja</a>",
          "description": "This paper presents a new mathematical signal transform that is especially\nsuitable for decoding information related to non-rigid signal displacements. We\nprovide a measure theoretic framework to extend the existing Cumulative\nDistribution Transform [ACHA 45 (2018), no. 3, 616-641] to arbitrary (signed)\nsignals on $\\overline{\\mathbb{R}}$. We present both forward (analysis) and\ninverse (synthesis) formulas for the transform, and describe several of its\nproperties including translation, scaling, convexity, linear separability and\nothers. Finally, we describe a metric in transform space, and demonstrate the\napplication of the transform in classifying (detecting) signals under random\ndisplacements.",
          "link": "http://arxiv.org/abs/2106.02146",
          "publishedOn": "2021-06-07T03:06:14.964Z",
          "wordCount": 543,
          "title": "The Signed Cumulative Distribution Transform for 1-D Signal Analysis and Classification. (arXiv:2106.02146v1 [cs.IT])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02212",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huleihel_W/0/1/0/all/0/1\">Wasim Huleihel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazumdar_A/0/1/0/all/0/1\">Arya Mazumdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pal_S/0/1/0/all/0/1\">Soumyabrata Pal</a>",
          "description": "The fuzzy or soft $k$-means objective is a popular generalization of the\nwell-known $k$-means problem, extending the clustering capability of the\n$k$-means to datasets that are uncertain, vague, and otherwise hard to cluster.\nIn this paper, we propose a semi-supervised active clustering framework, where\nthe learner is allowed to interact with an oracle (domain expert), asking for\nthe similarity between a certain set of chosen items. We study the query and\ncomputational complexities of clustering in this framework. We prove that\nhaving a few of such similarity queries enables one to get a polynomial-time\napproximation algorithm to an otherwise conjecturally NP-hard problem. In\nparticular, we provide probabilistic algorithms for fuzzy clustering in this\nsetting that asks $O(\\mathsf{poly}(k)\\log n)$ similarity queries and run with\npolynomial-time-complexity, where $n$ is the number of items. The fuzzy\n$k$-means objective is nonconvex, with $k$-means as a special case, and is\nequivalent to some other generic nonconvex problem such as non-negative matrix\nfactorization. The ubiquitous Lloyd-type algorithms (or,\nexpectation-maximization algorithm) can get stuck at a local minima. Our\nresults show that by making few similarity queries, the problem becomes easier\nto solve. Finally, we test our algorithms over real-world datasets, showing\ntheir effectiveness in real-world applications.",
          "link": "http://arxiv.org/abs/2106.02212",
          "publishedOn": "2021-06-07T03:06:14.945Z",
          "wordCount": 632,
          "title": "Fuzzy Clustering with Similarity Queries. (arXiv:2106.02212v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baccour_E/0/1/0/all/0/1\">Emna Baccour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haouari_F/0/1/0/all/0/1\">Fatima Haouari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erbad_A/0/1/0/all/0/1\">Aiman Erbad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohamed_A/0/1/0/all/0/1\">Amr Mohamed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilal_K/0/1/0/all/0/1\">Kashif Bilal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guizani_M/0/1/0/all/0/1\">Mohsen Guizani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamdi_M/0/1/0/all/0/1\">Mounir Hamdi</a>",
          "description": "Crowdsourced live video streaming (livecast) services such as Facebook Live,\nYouNow, Douyu and Twitch are gaining more momentum recently. Allocating the\nlimited resources in a cost-effective manner while maximizing the Quality of\nService (QoS) through real-time delivery and the provision of the appropriate\nrepresentations for all viewers is a challenging problem. In our paper, we\nintroduce a machine-learning based predictive resource allocation framework for\ngeo-distributed cloud sites, considering the delay and quality constraints to\nguarantee the maximum QoS for viewers and the minimum cost for content\nproviders. First, we present an offline optimization that decides the required\ntranscoding resources in distributed regions near the viewers with a trade-off\nbetween the QoS and the overall cost. Second, we use machine learning to build\nforecasting models that proactively predict the approximate transcoding\nresources to be reserved at each cloud site ahead of time. Finally, we develop\na Greedy Nearest and Cheapest algorithm (GNCA) to perform the resource\nallocation of real-time broadcasted videos on the rented resources. Extensive\nsimulations have shown that GNCA outperforms the state-of-the art resource\nallocation approaches for crowdsourced live streaming by achieving more than\n20% gain in terms of system cost while serving the viewers with relatively\nlower latency.",
          "link": "http://arxiv.org/abs/2106.02420",
          "publishedOn": "2021-06-07T03:06:14.933Z",
          "wordCount": 667,
          "title": "An Intelligent Resource Reservation for Crowdsourced Live Video Streaming Applications in Geo-Distributed Cloud Environment. (arXiv:2106.02420v1 [cs.NI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02613",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Piche_A/0/1/0/all/0/1\">Alexandre Pich&#xe9;</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Marino_J/0/1/0/all/0/1\">Joseph Marino</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Marconi_G/0/1/0/all/0/1\">Gian Maria Marconi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pal_C/0/1/0/all/0/1\">Christopher Pal</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Khan_M/0/1/0/all/0/1\">Mohammad Emtiyaz Khan</a>",
          "description": "Target networks are at the core of recent success in Reinforcement Learning.\nThey stabilize the training by using old parameters to estimate the $Q$-values,\nbut this also limits the propagation of newly-encountered rewards which could\nultimately slow down the training. In this work, we propose an alternative\ntraining method based on functional regularization which does not have this\ndeficiency. Unlike target networks, our method uses up-to-date parameters to\nestimate the target $Q$-values, thereby speeding up training while maintaining\nstability. Surprisingly, in some cases, we can show that target networks are a\nspecial, restricted type of functional regularizers. Using this approach, we\nshow empirical improvements in sample efficiency and performance across a range\nof Atari and simulated robotics environments.",
          "link": "http://arxiv.org/abs/2106.02613",
          "publishedOn": "2021-06-07T03:06:14.915Z",
          "wordCount": 551,
          "title": "Beyond Target Networks: Improving Deep $Q$-learning with Functional Regularization. (arXiv:2106.02613v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02190",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yulun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choma_N/0/1/0/all/0/1\">Nicholas Choma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Andrew Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cashman_M/0/1/0/all/0/1\">Mikaela Cashman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prates_E/0/1/0/all/0/1\">&#xc9;rica T. Prates</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1\">Manesh Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vergara_V/0/1/0/all/0/1\">Ver&#xf3;nica G. Melesse Vergara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clyde_A/0/1/0/all/0/1\">Austin Clyde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brettin_T/0/1/0/all/0/1\">Thomas S. Brettin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jong_W/0/1/0/all/0/1\">Wibe A. de Jong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_N/0/1/0/all/0/1\">Neeraj Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Head_M/0/1/0/all/0/1\">Martha S. Head</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stevens_R/0/1/0/all/0/1\">Rick L. Stevens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nugent_P/0/1/0/all/0/1\">Peter Nugent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobson_D/0/1/0/all/0/1\">Daniel A. Jacobson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_J/0/1/0/all/0/1\">James B. Brown</a>",
          "description": "We developed Distilled Graph Attention Policy Networks (DGAPNs), a\ncuriosity-driven reinforcement learning model to generate novel\ngraph-structured chemical representations that optimize user-defined objectives\nby efficiently navigating a physically constrained domain. The framework is\nexamined on the task of generating molecules that are designed to bind,\nnoncovalently, to functional sites of SARS-CoV-2 proteins. We present a spatial\nGraph Attention Network (sGAT) that leverages self-attention over both node and\nedge attributes as well as encoding spatial structure -- this capability is of\nconsiderable interest in areas such as molecular and synthetic biology and drug\ndiscovery. An attentional policy network is then introduced to learn decision\nrules for a dynamic, fragment-based chemical environment, and state-of-the-art\npolicy gradient techniques are employed to train the network with enhanced\nstability. Exploration is efficiently encouraged by incorporating innovation\nreward bonuses learned and proposed by random network distillation. In\nexperiments, our framework achieved outstanding results compared to\nstate-of-the-art algorithms, while increasing the diversity of proposed\nmolecules and reducing the complexity of paths to chemical synthesis.",
          "link": "http://arxiv.org/abs/2106.02190",
          "publishedOn": "2021-06-07T03:06:14.892Z",
          "wordCount": 682,
          "title": "Spatial Graph Attention and Curiosity-driven Policy for Antiviral Drug Discovery. (arXiv:2106.02190v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02087",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pravilov_M/0/1/0/all/0/1\">Mikhail Pravilov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bogomolov_E/0/1/0/all/0/1\">Egor Bogomolov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golubev_Y/0/1/0/all/0/1\">Yaroslav Golubev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bryksin_T/0/1/0/all/0/1\">Timofey Bryksin</a>",
          "description": "A lot of problems in the field of software engineering - bug fixing, commit\nmessage generation, etc. - require analyzing not only the code itself but\nspecifically code changes. Applying machine learning models to these tasks\nrequires us to create numerical representations of the changes, i.e.\nembeddings. Recent studies demonstrate that the best way to obtain these\nembeddings is to pre-train a deep neural network in an unsupervised manner on a\nlarge volume of unlabeled data and then further fine-tune it for a specific\ntask.\n\nIn this work, we propose an approach for obtaining such embeddings of code\nchanges during pre-training and evaluate them on two different downstream tasks\n- applying changes to code and commit message generation. The pre-training\nconsists of the model learning to apply the given change (an edit sequence) to\nthe code in a correct way, and therefore requires only the code change itself.\nTo increase the quality of the obtained embeddings, we only consider the\nchanged tokens in the edit sequence. In the task of applying code changes, our\nmodel outperforms the model that uses full edit sequences by 5.9 percentage\npoints in accuracy. As for the commit message generation, our model\ndemonstrated the same results as supervised models trained for this specific\ntask, which indicates that it can encode code changes well and can be improved\nin the future by pre-training on a larger dataset of easily gathered code\nchanges.",
          "link": "http://arxiv.org/abs/2106.02087",
          "publishedOn": "2021-06-07T03:06:14.886Z",
          "wordCount": 669,
          "title": "Unsupervised Learning of General-Purpose Embeddings for Code Changes. (arXiv:2106.02087v1 [cs.SE])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02523",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kayhan_O/0/1/0/all/0/1\">Osman Semih Kayhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vredebregt_B/0/1/0/all/0/1\">Bart Vredebregt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gemert_J/0/1/0/all/0/1\">Jan C. van Gemert</a>",
          "description": "We show that object detectors can hallucinate and detect missing objects;\npotentially even accurately localized at their expected, but non-existing,\nposition. This is particularly problematic for applications that rely on visual\npart verification: detecting if an object part is present or absent. We show\nhow popular object detectors hallucinate objects in a visual part verification\ntask and introduce the first visual part verification dataset: DelftBikes,\nwhich has 10,000 bike photographs, with 22 densely annotated parts per image,\nwhere some parts may be missing. We explicitly annotated an extra object state\nlabel for each part to reflect if a part is missing or intact. We propose to\nevaluate visual part verification by relying on recall and compare popular\nobject detectors on DelftBikes.",
          "link": "http://arxiv.org/abs/2106.02523",
          "publishedOn": "2021-06-07T03:06:14.880Z",
          "wordCount": 570,
          "title": "Hallucination In Object Detection -- A Study In Visual Part Verification. (arXiv:2106.02523v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02249",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yikun Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1\">Pan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gandhi_M/0/1/0/all/0/1\">Manan Gandhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theodorou_E/0/1/0/all/0/1\">Evangelos Theodorou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hovakimyan_N/0/1/0/all/0/1\">Naira Hovakimyan</a>",
          "description": "A reinforcement learning (RL) policy trained in a nominal environment could\nfail in a new/perturbed environment due to the existence of dynamic variations.\nExisting robust methods try to obtain a fixed policy for all envisioned dynamic\nvariation scenarios through robust or adversarial training. These methods could\nlead to conservative performance due to emphasis on the worst case, and often\ninvolve tedious modifications to the training environment. We propose an\napproach to robustifying a pre-trained non-robust RL policy with\n$\\mathcal{L}_1$ adaptive control. Leveraging the capability of an\n$\\mathcal{L}_1$ control law in the fast estimation of and active compensation\nfor dynamic variations, our approach can significantly improve the robustness\nof an RL policy trained in a standard (i.e., non-robust) way, either in a\nsimulator or in the real world. Numerical experiments are provided to validate\nthe efficacy of the proposed approach.",
          "link": "http://arxiv.org/abs/2106.02249",
          "publishedOn": "2021-06-07T03:06:14.874Z",
          "wordCount": 574,
          "title": "Robustifying Reinforcement Learning Policies with $\\mathcal{L}_1$ Adaptive Control. (arXiv:2106.02249v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02359",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhijing Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chauhan_G/0/1/0/all/0/1\">Geeticka Chauhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tse_B/0/1/0/all/0/1\">Brian Tse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1\">Mrinmaya Sachan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mihalcea_R/0/1/0/all/0/1\">Rada Mihalcea</a>",
          "description": "Recent years have seen many breakthroughs in natural language processing\n(NLP), transitioning it from a mostly theoretical field to one with many\nreal-world applications. Noting the rising number of applications of other\nmachine learning and AI techniques with pervasive societal impact, we\nanticipate the rising importance of developing NLP technologies for social\ngood. Inspired by theories in moral philosophy and global priorities research,\nwe aim to promote a guideline for social good in the context of NLP. We lay the\nfoundations via moral philosophy's definition of social good, propose a\nframework to evaluate NLP tasks' direct and indirect real-world impact, and\nadopt the methodology of global priorities research to identify priority causes\nfor NLP research. Finally, we use our theoretical framework to provide some\npractical guidelines for future NLP research for social good. Our data and\ncodes are available at this http URL",
          "link": "http://arxiv.org/abs/2106.02359",
          "publishedOn": "2021-06-07T03:06:14.867Z",
          "wordCount": 603,
          "title": "How Good Is NLP? A Sober Look at NLP Tasks through the Lens of Social Impact. (arXiv:2106.02359v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02100",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dubost_F/0/1/0/all/0/1\">Florian Dubost</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saab_K/0/1/0/all/0/1\">Khaled Kamal Saab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_E/0/1/0/all/0/1\">Erin Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_D/0/1/0/all/0/1\">Daniel Yang Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pike_M/0/1/0/all/0/1\">Max Pike</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1\">Siddharth Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1\">Siyi Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhaskhar_N/0/1/0/all/0/1\">Nandita Bhaskhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Messer_C/0/1/0/all/0/1\">Christopher Lee-Messer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_D/0/1/0/all/0/1\">Daniel Rubin</a>",
          "description": "Optimization plays a key role in the training of deep neural networks.\nDeciding when to stop training can have a substantial impact on the performance\nof the network during inference. Under certain conditions, the generalization\nerror can display a double descent pattern during training: the learning curve\nis non-monotonic and seemingly diverges before converging again after\nadditional epochs. This optimization pattern can lead to early stopping\nprocedures to stop training before the second convergence and consequently\nselect a suboptimal set of parameters for the network, with worse performance\nduring inference. In this work, in addition to confirming that double descent\noccurs with small datasets and noisy labels as evidenced by others, we show\nthat noisy labels must be present both in the training and generalization sets\nto observe a double descent pattern. We also show that the learning rate has an\ninfluence on double descent, and study how different optimizers and optimizer\nparameters influence the apparition of double descent. Finally, we show that\nincreasing the learning rate can create an aliasing effect that masks the\ndouble descent pattern without suppressing it. We study this phenomenon through\nextensive experiments on variants of CIFAR-10 and show that they translate to a\nreal world application: the forecast of seizure events in epileptic patients\nfrom continuous electroencephalographic recordings.",
          "link": "http://arxiv.org/abs/2106.02100",
          "publishedOn": "2021-06-07T03:06:14.849Z",
          "wordCount": 656,
          "title": "Double Descent Optimization Pattern and Aliasing: Caveats of Noisy Labels. (arXiv:2106.02100v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02126",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kalvit_A/0/1/0/all/0/1\">Anand Kalvit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeevi_A/0/1/0/all/0/1\">Assaf Zeevi</a>",
          "description": "One of the key drivers of complexity in the classical (stochastic)\nmulti-armed bandit (MAB) problem is the difference between mean rewards in the\ntop two arms, also known as the instance gap. The celebrated Upper Confidence\nBound (UCB) policy is among the simplest optimism-based MAB algorithms that\nnaturally adapts to this gap: for a horizon of play n, it achieves optimal\nO(log n) regret in instances with \"large\" gaps, and a near-optimal O(\\sqrt{n\nlog n}) minimax regret when the gap can be arbitrarily \"small.\" This paper\nprovides new results on the arm-sampling behavior of UCB, leading to several\nimportant insights. Among these, it is shown that arm-sampling rates under UCB\nare asymptotically deterministic, regardless of the problem complexity. This\ndiscovery facilitates new sharp asymptotics and a novel alternative proof for\nthe O(\\sqrt{n log n}) minimax regret of UCB. Furthermore, the paper also\nprovides the first complete process-level characterization of the MAB problem\nunder UCB in the conventional diffusion scaling. Among other things, the\n\"small\" gap worst-case lens adopted in this paper also reveals profound\ndistinctions between the behavior of UCB and Thompson Sampling, such as an\n\"incomplete learning\" phenomenon characteristic of the latter.",
          "link": "http://arxiv.org/abs/2106.02126",
          "publishedOn": "2021-06-07T03:06:14.842Z",
          "wordCount": 625,
          "title": "A Closer Look at the Worst-case Behavior of Multi-armed Bandit Algorithms. (arXiv:2106.02126v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02266",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shahtalebi_S/0/1/0/all/0/1\">Soroosh Shahtalebi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gagnon_Audet_J/0/1/0/all/0/1\">Jean-Christophe Gagnon-Audet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laleh_T/0/1/0/all/0/1\">Touraj Laleh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faramarzi_M/0/1/0/all/0/1\">Mojtaba Faramarzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahuja_K/0/1/0/all/0/1\">Kartik Ahuja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rish_I/0/1/0/all/0/1\">Irina Rish</a>",
          "description": "A major bottleneck in the real-world applications of machine learning models\nis their failure in generalizing to unseen domains whose data distribution is\nnot i.i.d to the training domains. This failure often stems from learning\nnon-generalizable features in the training domains that are spuriously\ncorrelated with the label of data. To address this shortcoming, there has been\na growing surge of interest in learning good explanations that are hard to\nvary, which is studied under the notion of Out-of-Distribution (OOD)\nGeneralization. The search for good explanations that are \\textit{invariant}\nacross different domains can be seen as finding local (global) minimas in the\nloss landscape that hold true across all of the training domains. In this\npaper, we propose a masking strategy, which determines a continuous weight\nbased on the agreement of gradients that flow in each edge of network, in order\nto control the amount of update received by the edge in each step of\noptimization. Particularly, our proposed technique referred to as \"Smoothed-AND\n(SAND)-masking\", not only validates the agreement in the direction of gradients\nbut also promotes the agreement among their magnitudes to further ensure the\ndiscovery of invariances across training domains. SAND-mask is validated over\nthe Domainbed benchmark for domain generalization and significantly improves\nthe state-of-the-art accuracy on the Colored MNIST dataset while providing\ncompetitive results on other domain generalization datasets.",
          "link": "http://arxiv.org/abs/2106.02266",
          "publishedOn": "2021-06-07T03:06:14.835Z",
          "wordCount": 666,
          "title": "SAND-mask: An Enhanced Gradient Masking Strategy for the Discovery of Invariances in Domain Generalization. (arXiv:2106.02266v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02112",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Plumb_G/0/1/0/all/0/1\">Gregory Plumb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_M/0/1/0/all/0/1\">Marco Tulio Ribeiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talwalkar_A/0/1/0/all/0/1\">Ameet Talwalkar</a>",
          "description": "Machine learning models often use spurious patterns such as \"relying on the\npresence of a person to detect a tennis racket,\" which do not generalize. In\nthis work, we present an end-to-end pipeline for identifying and mitigating\nspurious patterns for image classifiers. We start by finding patterns such as\n\"the model's prediction for tennis racket changes 63% of the time if we hide\nthe people.\" Then, if a pattern is spurious, we mitigate it via a novel form of\ndata augmentation. We demonstrate that this approach identifies a diverse set\nof spurious patterns and that it mitigates them by producing a model that is\nboth more accurate on a distribution where the spurious pattern is not helpful\nand more robust to distribution shift.",
          "link": "http://arxiv.org/abs/2106.02112",
          "publishedOn": "2021-06-07T03:06:14.827Z",
          "wordCount": 543,
          "title": "Finding and Fixing Spurious Patterns with Explanations. (arXiv:2106.02112v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2002.02518",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Parker_Holder_J/0/1/0/all/0/1\">Jack Parker-Holder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_V/0/1/0/all/0/1\">Vu Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_S/0/1/0/all/0/1\">Stephen Roberts</a>",
          "description": "Many of the recent triumphs in machine learning are dependent on well-tuned\nhyperparameters. This is particularly prominent in reinforcement learning (RL)\nwhere a small change in the configuration can lead to failure. Despite the\nimportance of tuning hyperparameters, it remains expensive and is often done in\na naive and laborious way. A recent solution to this problem is Population\nBased Training (PBT) which updates both weights and hyperparameters in a single\ntraining run of a population of agents. PBT has been shown to be particularly\neffective in RL, leading to widespread use in the field. However, PBT lacks\ntheoretical guarantees since it relies on random heuristics to explore the\nhyperparameter space. This inefficiency means it typically requires vast\ncomputational resources, which is prohibitive for many small and medium sized\nlabs. In this work, we introduce the first provably efficient PBT-style\nalgorithm, Population-Based Bandits (PB2). PB2 uses a probabilistic model to\nguide the search in an efficient way, making it possible to discover high\nperforming hyperparameter configurations with far fewer agents than typically\nrequired by PBT. We show in a series of RL experiments that PB2 is able to\nachieve high performance with a modest computational budget.",
          "link": "http://arxiv.org/abs/2002.02518",
          "publishedOn": "2021-06-07T03:06:14.822Z",
          "wordCount": 674,
          "title": "Provably Efficient Online Hyperparameter Optimization with Population-Based Bandits. (arXiv:2002.02518v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02154",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ghojogh_B/0/1/0/all/0/1\">Benyamin Ghojogh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ghodsi_A/0/1/0/all/0/1\">Ali Ghodsi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Karray_F/0/1/0/all/0/1\">Fakhri Karray</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Crowley_M/0/1/0/all/0/1\">Mark Crowley</a>",
          "description": "This is a tutorial and survey paper for nonlinear dimensionality and feature\nextraction methods which are based on the Laplacian of graph of data. We first\nintroduce adjacency matrix, definition of Laplacian matrix, and the\ninterpretation of Laplacian. Then, we cover the cuts of graph and spectral\nclustering which applies clustering in a subspace of data. Different\noptimization variants of Laplacian eigenmap and its out-of-sample extension are\nexplained. Thereafter, we introduce the locality preserving projection and its\nkernel variant as linear special cases of Laplacian eigenmap. Versions of graph\nembedding are then explained which are generalized versions of Laplacian\neigenmap and locality preserving projection. Finally, diffusion map is\nintroduced which is a method based on Laplacian of data and random walks on the\ndata graph.",
          "link": "http://arxiv.org/abs/2106.02154",
          "publishedOn": "2021-06-07T03:06:14.802Z",
          "wordCount": 598,
          "title": "Laplacian-Based Dimensionality Reduction Including Spectral Clustering, Laplacian Eigenmap, Locality Preserving Projection, Graph Embedding, and Diffusion Map: Tutorial and Survey. (arXiv:2106.02154v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02412",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shabka_Z/0/1/0/all/0/1\">Zacharaya Shabka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zervas_G/0/1/0/all/0/1\">Georgios Zervas</a>",
          "description": "Data centres (DCs) underline many prominent future technological trends such\nas distributed training of large scale machine learning models and\ninternet-of-things based platforms. DCs will soon account for over 3\\% of\nglobal energy demand, so efficient use of DC resources is essential. Robust DC\nnetworks (DCNs) are essential to form the large scale systems needed to handle\nthis demand, but can bottleneck how efficiently DC-server resources can be used\nwhen servers with insufficient connectivity between them cannot be jointly\nallocated to a job. However, allocating servers' resources whilst accounting\nfor their inter-connectivity maps to an NP-hard combinatorial optimisation\nproblem, and so is often ignored in DC resource management schemes. We present\nNara, a framework based on reinforcement learning (RL) and graph neural\nnetworks (GNN) to learn network-aware allocation policies that increase the\nnumber of requests allocated over time compared to previous methods. Unique to\nour solution is the use of a GNN to generate representations of server-nodes in\nthe DCN, which are then interpreted as actions by a RL policy-network which\nchooses from which servers resources will be allocated to incoming requests.\nNara is agnostic to the topology size and shape and is trained end-to-end. The\nmethod can accept up to 33\\% more requests than the best baseline when deployed\non DCNs with up to the order of $10\\times$ more compute nodes than the DCN seen\nduring training and is able to maintain its policy's performance on DCNs with\nthe order of $100\\times$ more servers than seen during training. It also\ngeneralises to unseen DCN topologies with varied network structure and unseen\nrequest distributions without re-training.",
          "link": "http://arxiv.org/abs/2106.02412",
          "publishedOn": "2021-06-07T03:06:14.795Z",
          "wordCount": 701,
          "title": "Nara: Learning Network-Aware Resource Allocation Algorithms for Cloud Data Centres. (arXiv:2106.02412v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02081",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Vargas_F/0/1/0/all/0/1\">Francisco Vargas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Thodoroff_P/0/1/0/all/0/1\">Pierre Thodoroff</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lawrence_N/0/1/0/all/0/1\">Neil D. Lawrence</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lamacraft_A/0/1/0/all/0/1\">Austen Lamacraft</a>",
          "description": "The Schr\\\"odinger bridge problem (SBP) finds the most likely stochastic\nevolution between two probability distributions given a prior stochastic\nevolution. As well as applications in the natural sciences, problems of this\nkind have important applications in machine learning such as dataset alignment\nand hypothesis testing. Whilst the theory behind this problem is relatively\nmature, scalable numerical recipes to estimate the Schr\\\"odinger bridge remain\nan active area of research. We prove an equivalence between the SBP and maximum\nlikelihood estimation enabling direct application of successful machine\nlearning techniques. We propose a numerical procedure to estimate SBPs using\nGaussian process and demonstrate the practical usage of our approach in\nnumerical simulations and experiments.",
          "link": "http://arxiv.org/abs/2106.02081",
          "publishedOn": "2021-06-07T03:06:14.788Z",
          "wordCount": 544,
          "title": "Solving Schr\\\"odinger Bridges via Maximum Likelihood. (arXiv:2106.02081v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02392",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Miladinovic_A/0/1/0/all/0/1\">Aleksandar Miladinovi&#x107;</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ajcevic_M/0/1/0/all/0/1\">Milo&#x161; Aj&#x10d;evi&#x107;</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Siveri_G/0/1/0/all/0/1\">Giulia Siveri</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liguori_L/0/1/0/all/0/1\">Laura Liguori</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pascazio_L/0/1/0/all/0/1\">Lorenzo Pascazio</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Accardo_A/0/1/0/all/0/1\">Agostino Accardo</a>",
          "description": "The accurate measurement of blood pressure (BP) is an important prerequisite\nfor the reliable diagnosis and efficient management of hypertension and other\nmedical conditions. Office Blood Pressure Measurement (OBP) is a technique\nperformed in-office with the sphygmomanometer, while Ambulatory Blood Pressure\nMonitoring (ABPM) is a technique that measures blood pressure during 24h. The\nBP fluctuations also depend on other factors such as physical activity,\ntemperature, mood, age, sex, any pathologies, a hormonal activity that may\nintrinsically influence the differences between OBP and ABPM. The aim of this\nstudy is to examine the possible influence of sex on the discrepancies between\nOBP and ABPM in 872 subjects with known or suspected hypertension. A\nsignificant correlation was observed between OBP and ABPM mean values\ncalculated during the day, night and 24h (ABPMday, ABPMnight, ABPM24h) in both\ngroups (p<0.0001). The main finding of this study is that no difference between\nsexes was observed in the relation between OBP and mean ABMP values except\nbetween systolic OBP and systolic ABPM during the night. In addition, this\nstudy showed a moderate correlation between BPs obtained with the two\napproaches with a great dispersion around the regression line which suggests\nthat the two approaches cannot be used interchangeably.",
          "link": "http://arxiv.org/abs/2106.02392",
          "publishedOn": "2021-06-07T03:06:14.782Z",
          "wordCount": 647,
          "title": "Ambulatory blood pressure monitoring versus office blood pressure measurement: Are there sex differences?. (arXiv:2106.02392v1 [eess.SP])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02443",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Awasthi_A/0/1/0/all/0/1\">Abhijeet Awasthi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kilgour_K/0/1/0/all/0/1\">Kevin Kilgour</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rom_H/0/1/0/all/0/1\">Hassan Rom</a>",
          "description": "Learning to recognize new keywords with just a few examples is essential for\npersonalizing keyword spotting (KWS) models to a user's choice of keywords.\nHowever, modern KWS models are typically trained on large datasets and\nrestricted to a small vocabulary of keywords, limiting their transferability to\na broad range of unseen keywords. Towards easily customizable KWS models, we\npresent KeySEM (Keyword Speech EMbedding), a speech embedding model pre-trained\non the task of recognizing a large number of keywords. Speech representations\noffered by KeySEM are highly effective for learning new keywords from a limited\nnumber of examples. Comparisons with a diverse range of related work across\nseveral datasets show that our method achieves consistently superior\nperformance with fewer training examples. Although KeySEM was pre-trained only\non English utterances, the performance gains also extend to datasets from four\nother languages indicating that KeySEM learns useful representations well\naligned with the task of keyword spotting. Finally, we demonstrate KeySEM's\nability to learn new keywords sequentially without requiring to re-train on\npreviously learned keywords. Our experimental observations suggest that KeySEM\nis well suited to on-device environments where post-deployment learning and\nease of customization are often desirable.",
          "link": "http://arxiv.org/abs/2106.02443",
          "publishedOn": "2021-06-07T03:06:14.775Z",
          "wordCount": 642,
          "title": "Teaching keyword spotters to spot new keywords with limited examples. (arXiv:2106.02443v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02261",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Canatar_A/0/1/0/all/0/1\">Abdulkadir Canatar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bordelon_B/0/1/0/all/0/1\">Blake Bordelon</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pehlevan_C/0/1/0/all/0/1\">Cengiz Pehlevan</a>",
          "description": "In real word applications, data generating process for training a machine\nlearning model often differs from what the model encounters in the test stage.\nUnderstanding how and whether machine learning models generalize under such\ndistributional shifts have been a theoretical challenge. Here, we study\ngeneralization in kernel regression when the training and test distributions\nare different using methods from statistical physics. Using the replica method,\nwe derive an analytical formula for the out-of-distribution generalization\nerror applicable to any kernel and real datasets. We identify an overlap matrix\nthat quantifies the mismatch between distributions for a given kernel as a key\ndeterminant of generalization performance under distribution shift. Using our\nanalytical expressions we elucidate various generalization phenomena including\npossible improvement in generalization when there is a mismatch. We develop\nprocedures for optimizing training and test distributions for a given data\nbudget to find best and worst case generalizations under the shift. We present\napplications of our theory to real and synthetic datasets and for many kernels.\nWe compare results of our theory applied to Neural Tangent Kernel with\nsimulations of wide networks and show agreement. We analyze linear regression\nin further depth.",
          "link": "http://arxiv.org/abs/2106.02261",
          "publishedOn": "2021-06-07T03:06:14.755Z",
          "wordCount": 618,
          "title": "Out-of-Distribution Generalization in Kernel Regression. (arXiv:2106.02261v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02118",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sun_J/0/1/0/all/0/1\">Ju Sun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Peng_L/0/1/0/all/0/1\">Le Peng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_T/0/1/0/all/0/1\">Taihui Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Adila_D/0/1/0/all/0/1\">Dyah Adila</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zaiman_Z/0/1/0/all/0/1\">Zach Zaiman</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Melton_G/0/1/0/all/0/1\">Genevieve B. Melton</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ingraham_N/0/1/0/all/0/1\">Nicholas Ingraham</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Murray_E/0/1/0/all/0/1\">Eric Murray</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Boley_D/0/1/0/all/0/1\">Daniel Boley</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Switzer_S/0/1/0/all/0/1\">Sean Switzer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Burns_J/0/1/0/all/0/1\">John L. Burns</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_K/0/1/0/all/0/1\">Kun Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Allen_T/0/1/0/all/0/1\">Tadashi Allen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Steenburg_S/0/1/0/all/0/1\">Scott D. Steenburg</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gichoya_J/0/1/0/all/0/1\">Judy Wawira Gichoya</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kummerfeld_E/0/1/0/all/0/1\">Erich Kummerfeld</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tignanelli_C/0/1/0/all/0/1\">Christopher Tignanelli</a>",
          "description": "Importance: An artificial intelligence (AI)-based model to predict COVID-19\nlikelihood from chest x-ray (CXR) findings can serve as an important adjunct to\naccelerate immediate clinical decision making and improve clinical decision\nmaking. Despite significant efforts, many limitations and biases exist in\npreviously developed AI diagnostic models for COVID-19. Utilizing a large set\nof local and international CXR images, we developed an AI model with high\nperformance on temporal and external validation.\n\nConclusions and Relevance: AI-based diagnostic tools may serve as an adjunct,\nbut not replacement, for clinical decision support of COVID-19 diagnosis, which\nlargely hinges on exposure history, signs, and symptoms. While AI-based tools\nhave not yet reached full diagnostic potential in COVID-19, they may still\noffer valuable information to clinicians taken into consideration along with\nclinical signs and symptoms.",
          "link": "http://arxiv.org/abs/2106.02118",
          "publishedOn": "2021-06-07T03:06:14.749Z",
          "wordCount": 670,
          "title": "A Prospective Observational Study to Investigate Performance of a Chest X-ray Artificial Intelligence Diagnostic Support Tool Across 12 U.S. Hospitals. (arXiv:2106.02118v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02267",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yingtao Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clanuwat_T/0/1/0/all/0/1\">Tarin Clanuwat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suzuki_C/0/1/0/all/0/1\">Chikahiko Suzuki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kitamoto_A/0/1/0/all/0/1\">Asanobu Kitamoto</a>",
          "description": "The study of Ukiyo-e, an important genre of pre-modern Japanese art, focuses\non the object and style like other artwork researches. Such study has benefited\nfrom the renewed interest by the machine learning community in culturally\nimportant topics, leading to interdisciplinary works including collections of\nimages, quantitative approaches, and machine learning-based creativities. They,\nhowever, have several drawbacks, and it remains challenging to integrate these\nworks into a comprehensive view. To bridge this gap, we propose a holistic\napproach We first present a large-scale Ukiyo-e dataset with coherent semantic\nlabels and geometric annotations, then show its value in a quantitative study\nof Ukiyo-e paintings' object using these labels and annotations. We further\ndemonstrate the machine learning methods could help style study through soft\ncolor decomposition of Ukiyo-e, and finally provides joint insights into object\nand style by composing sketches and colors using colorization. Dataset\navailable at https://github.com/rois-codh/arc-ukiyoe-faces",
          "link": "http://arxiv.org/abs/2106.02267",
          "publishedOn": "2021-06-07T03:06:14.742Z",
          "wordCount": 584,
          "title": "Ukiyo-e Analysis and Creativity with Attribute and Geometry Annotation. (arXiv:2106.02267v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02252",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Viswanath_V/0/1/0/all/0/1\">Vainavi Viswanath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grannen_J/0/1/0/all/0/1\">Jennifer Grannen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sundaresan_P/0/1/0/all/0/1\">Priya Sundaresan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thananjeyan_B/0/1/0/all/0/1\">Brijen Thananjeyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balakrishna_A/0/1/0/all/0/1\">Ashwin Balakrishna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Novoseller_E/0/1/0/all/0/1\">Ellen Novoseller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ichnowski_J/0/1/0/all/0/1\">Jeffrey Ichnowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laskey_M/0/1/0/all/0/1\">Michael Laskey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1\">Joseph E. Gonzalez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_K/0/1/0/all/0/1\">Ken Goldberg</a>",
          "description": "Disentangling two or more cables requires many steps to remove crossings\nbetween and within cables. We formalize the problem of disentangling multiple\ncables and present an algorithm, Iterative Reduction Of Non-planar Multiple\ncAble kNots (IRON-MAN), that outputs robot actions to remove crossings from\nmulti-cable knotted structures. We instantiate this algorithm with a learned\nperception system, inspired by prior work in single-cable untying that given an\nimage input, can disentangle two-cable twists, three-cable braids, and knots of\ntwo or three cables, such as overhand, square, carrick bend, sheet bend, crown,\nand fisherman's knots. IRON-MAN keeps track of task-relevant keypoints\ncorresponding to target cable endpoints and crossings and iteratively\ndisentangles the cables by identifying and undoing crossings that are critical\nto knot structure. Using a da Vinci surgical robot, we experimentally evaluate\nthe effectiveness of IRON-MAN on untangling multi-cable knots of types that\nappear in the training data, as well as generalizing to novel classes of\nmulti-cable knots. Results suggest that IRON-MAN is effective in disentangling\nknots involving up to three cables with 80.5% success and generalizing to knot\ntypes that are not present during training, with cables of both distinct or\nidentical colors.",
          "link": "http://arxiv.org/abs/2106.02252",
          "publishedOn": "2021-06-07T03:06:14.737Z",
          "wordCount": 633,
          "title": "Disentangling Dense Multi-Cable Knots. (arXiv:2106.02252v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02329",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiuqin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Ying Chen</a>",
          "description": "We propose a deep switching state space model (DS$^3$M) for efficient\ninference and forecasting of nonlinear time series with irregularly switching\namong various regimes. The switching among regimes is captured by both discrete\nand continuous latent variables with recurrent neural networks. The model is\nestimated with variational inference using a reparameterization trick. We test\nthe approach on a variety of simulated and real datasets. In all cases, DS$^3$M\nachieves competitive performance compared to several state-of-the-art methods\n(e.g. GRU, SRNN, DSARF, SNLDS), with superior forecasting accuracy, convincing\ninterpretability of the discrete latent variables, and powerful representation\nof the continuous latent variables for different kinds of time series.\nSpecifically, the MAPE values increase by 0.09\\% to 15.71\\% against the\nsecond-best performing alternative models.",
          "link": "http://arxiv.org/abs/2106.02329",
          "publishedOn": "2021-06-07T03:06:14.730Z",
          "wordCount": 557,
          "title": "Deep Switching State Space Model (DS$^3$M) for Nonlinear Time Series Forecasting with Regime Switching. (arXiv:2106.02329v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02436",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lancewicki_T/0/1/0/all/0/1\">Tal Lancewicki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Segal_S/0/1/0/all/0/1\">Shahar Segal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koren_T/0/1/0/all/0/1\">Tomer Koren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansour_Y/0/1/0/all/0/1\">Yishay Mansour</a>",
          "description": "We study the stochastic Multi-Armed Bandit (MAB) problem with random delays\nin the feedback received by the algorithm. We consider two settings: the\nreward-dependent delay setting, where realized delays may depend on the\nstochastic rewards, and the reward-independent delay setting. Our main\ncontribution is algorithms that achieve near-optimal regret in each of the\nsettings, with an additional additive dependence on the quantiles of the delay\ndistribution. Our results do not make any assumptions on the delay\ndistributions: in particular, we do not assume they come from any parametric\nfamily of distributions and allow for unbounded support and expectation; we\nfurther allow for infinite delays where the algorithm might occasionally not\nobserve any feedback.",
          "link": "http://arxiv.org/abs/2106.02436",
          "publishedOn": "2021-06-07T03:06:14.724Z",
          "wordCount": 542,
          "title": "Stochastic Multi-Armed Bandits with Unrestricted Delay Distributions. (arXiv:2106.02436v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02285",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Shi-Min Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zheng-Ning Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1\">Meng-Hao Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1\">Jun-Xiong Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jiahui Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mu_T/0/1/0/all/0/1\">Tai-Jiang Mu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_R/0/1/0/all/0/1\">Ralph R. Martin</a>",
          "description": "Convolutional neural networks (CNNs) have made great breakthroughs in 2D\ncomputer vision. However, the irregular structure of meshes makes it hard to\nexploit the power of CNNs directly. A subdivision surface provides a\nhierarchical multi-resolution structure, and each face in a closed 2-manifold\ntriangle mesh is exactly adjacent to three faces. Motivated by these two\nproperties, this paper introduces a novel and flexible CNN framework, named\nSubdivNet, for 3D triangle meshes with Loop subdivision sequence connectivity.\nMaking an analogy between mesh faces and pixels in a 2D image allows us to\npresent a mesh convolution operator to aggregate local features from adjacent\nfaces. By exploiting face neighborhoods, this convolution can support standard\n2D convolutional network concepts, e.g. variable kernel size, stride, and\ndilation. Based on the multi-resolution hierarchy, we propose a spatial uniform\npooling layer which merges four faces into one and an upsampling method which\nsplits one face into four. As a result, many popular 2D CNN architectures can\nbe readily adapted to processing 3D meshes. Meshes with arbitrary connectivity\ncan be remeshed to hold Loop subdivision sequence connectivity via\nself-parameterization, making SubdivNet a general approach. Experiments on mesh\nclassification, segmentation, correspondence, and retrieval from the real-world\ndemonstrate the effectiveness and efficiency of SubdivNet.",
          "link": "http://arxiv.org/abs/2106.02285",
          "publishedOn": "2021-06-07T03:06:14.684Z",
          "wordCount": 651,
          "title": "Subdivision-Based Mesh Convolution Networks. (arXiv:2106.02285v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02229",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Miao_Y/0/1/0/all/0/1\">Yingjie Miao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xingyou Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_D/0/1/0/all/0/1\">Daiyi Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_S/0/1/0/all/0/1\">Summer Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brevdo_E/0/1/0/all/0/1\">Eugene Brevdo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faust_A/0/1/0/all/0/1\">Aleksandra Faust</a>",
          "description": "We introduce RL-DARTS, one of the first applications of Differentiable\nArchitecture Search (DARTS) in reinforcement learning (RL) to search for\nconvolutional cells, applied to the Procgen benchmark. We outline the initial\ndifficulties of applying neural architecture search techniques in RL, and\ndemonstrate that by simply replacing the image encoder with a DARTS supernet,\nour search method is sample-efficient, requires minimal extra compute\nresources, and is also compatible with off-policy and on-policy RL algorithms,\nneeding only minor changes in preexisting code. Surprisingly, we find that the\nsupernet can be used as an actor for inference to generate replay data in\nstandard RL training loops, and thus train end-to-end. Throughout this training\nprocess, we show that the supernet gradually learns better cells, leading to\nalternative architectures which can be highly competitive against manually\ndesigned policies, but also verify previous design choices for RL policies.",
          "link": "http://arxiv.org/abs/2106.02229",
          "publishedOn": "2021-06-07T03:06:14.659Z",
          "wordCount": 585,
          "title": "RL-DARTS: Differentiable Architecture Search for Reinforcement Learning. (arXiv:2106.02229v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02396",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Badoual_M/0/1/0/all/0/1\">Mathilde D. Badoual</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moura_S/0/1/0/all/0/1\">Scott J. Moura</a>",
          "description": "Load serving entities with storage units reach sizes and performances that\ncan significantly impact clearing prices in electricity markets. Nevertheless,\nprice endogeneity is rarely considered in storage bidding strategies and\nmodeling the electricity market is a challenging task. Meanwhile, model-free\nreinforcement learning such as the Actor-Critic are becoming increasingly\npopular for designing energy system controllers. Yet implementation frequently\nrequires lengthy, data-intense, and unsafe trial-and-error training. To fill\nthese gaps, we implement an online Supervised Actor-Critic (SAC) algorithm,\nsupervised with a model-based controller -- Model Predictive Control (MPC). The\nenergy storage agent is trained with this algorithm to optimally bid while\nlearning and adjusting to its impact on the market clearing prices. We compare\nthe supervised Actor-Critic algorithm with the MPC algorithm as a supervisor,\nfinding that the former reaps higher profits via learning. Our contribution,\nthus, is an online and safe SAC algorithm that outperforms the current\nmodel-based state-of-the-art.",
          "link": "http://arxiv.org/abs/2106.02396",
          "publishedOn": "2021-06-07T03:06:14.610Z",
          "wordCount": 600,
          "title": "A Learning-based Optimal Market Bidding Strategy for Price-Maker Energy Storage. (arXiv:2106.02396v1 [eess.SY])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02466",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bielak_P/0/1/0/all/0/1\">Piotr Bielak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kajdanowicz_T/0/1/0/all/0/1\">Tomasz Kajdanowicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chawla_N/0/1/0/all/0/1\">Nitesh V. Chawla</a>",
          "description": "The self-supervised learning (SSL) paradigm is an essential exploration area,\nwhich tries to eliminate the need for expensive data labeling. Despite the\ngreat success of SSL methods in computer vision and natural language\nprocessing, most of them employ contrastive learning objectives that require\nnegative samples, which are hard to define. This becomes even more challenging\nin the case of graphs and is a bottleneck for achieving robust representations.\nTo overcome such limitations, we propose a framework for self-supervised graph\nrepresentation learning -- Graph Barlow Twins, which utilizes a\ncross-correlation-based loss function instead of negative samples. Moreover, it\ndoes not rely on non-symmetric neural network architectures -- in contrast to\nstate-of-the-art self-supervised graph representation learning method BGRL. We\nshow that our method achieves as competitive results as BGRL, best\nself-supervised methods, and fully supervised ones while requiring\nsubstantially fewer hyperparameters and converging in an order of magnitude\ntraining steps earlier.",
          "link": "http://arxiv.org/abs/2106.02466",
          "publishedOn": "2021-06-07T03:06:14.601Z",
          "wordCount": 576,
          "title": "Graph Barlow Twins: A self-supervised representation learning framework for graphs. (arXiv:2106.02466v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02584",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kossen_J/0/1/0/all/0/1\">Jannik Kossen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Band_N/0/1/0/all/0/1\">Neil Band</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyle_C/0/1/0/all/0/1\">Clare Lyle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_A/0/1/0/all/0/1\">Aidan N. Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rainforth_T/0/1/0/all/0/1\">Tom Rainforth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1\">Yarin Gal</a>",
          "description": "We challenge a common assumption underlying most supervised deep learning:\nthat a model makes a prediction depending only on its parameters and the\nfeatures of a single input. To this end, we introduce a general-purpose deep\nlearning architecture that takes as input the entire dataset instead of\nprocessing one datapoint at a time. Our approach uses self-attention to reason\nabout relationships between datapoints explicitly, which can be seen as\nrealizing non-parametric models using parametric attention mechanisms. However,\nunlike conventional non-parametric models, we let the model learn end-to-end\nfrom the data how to make use of other datapoints for prediction. Empirically,\nour models solve cross-datapoint lookup and complex reasoning tasks unsolvable\nby traditional deep learning models. We show highly competitive results on\ntabular data, early results on CIFAR-10, and give insight into how the model\nmakes use of the interactions between points.",
          "link": "http://arxiv.org/abs/2106.02584",
          "publishedOn": "2021-06-07T03:06:14.434Z",
          "wordCount": 587,
          "title": "Self-Attention Between Datapoints: Going Beyond Individual Input-Output Pairs in Deep Learning. (arXiv:2106.02584v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.13268",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1\">Jiameng Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenchao Li</a>",
          "description": "Deep reinforcement learning (DRL) agents are often sensitive to visual\nchanges that were unseen in their training environments. To address this\nproblem, we leverage the sequential nature of RL to learn robust\nrepresentations that encode only task-relevant information from observations\nbased on the unsupervised multi-view setting. Specifically, we introduce an\nauxiliary objective based on the multi-view in-formation bottleneck (MIB)\nprinciple which quantifies the amount of task-irrelevant information and\nencourages learning representations that are both predictive of the future and\nless sensitive to task-irrelevant distractions. This enables us to train\nhigh-performance policies that are robust to visual distractions and can\ngeneralize to unseen environments. We demonstrate that our approach can achieve\nSOTA performance on diverse visual control tasks on the DeepMind Control Suite,\neven when the background is replaced with natural videos. In addition, we show\nthat our approach outperforms well-established baselines for generalization to\nunseen environments on the Procgen benchmark. Our code is open-sourced and\navailable at https://github.com/JmfanBU/DRIBO.",
          "link": "http://arxiv.org/abs/2102.13268",
          "publishedOn": "2021-06-07T03:06:14.355Z",
          "wordCount": 615,
          "title": "DRIBO: Robust Deep Reinforcement Learning via Multi-View Information Bottleneck. (arXiv:2102.13268v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02619",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Allen_Zhu_Z/0/1/0/all/0/1\">Zeyuan Allen-Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanzhi Li</a>",
          "description": "Generative adversarial networks (GANs) are among the most successful models\nfor learning high-complexity, real-world distributions. However, in theory, due\nto the highly non-convex, non-concave landscape of the minmax training\nobjective, GAN remains one of the least understood deep learning models. In\nthis work, we formally study how GANs can efficiently learn certain\nhierarchically generated distributions that are close to the distribution of\nimages in practice. We prove that when a distribution has a structure that we\nrefer to as Forward Super-Resolution, then simply training generative\nadversarial networks using gradient descent ascent (GDA) can indeed learn this\ndistribution efficiently, both in terms of sample and time complexities. We\nalso provide concrete empirical evidence that not only our assumption \"forward\nsuper-resolution\" is very natural in practice, but also the underlying learning\nmechanisms that we study in this paper (to allow us efficiently train GAN via\nGDA in theory) simulates the actual learning process of GANs in practice on\nreal-world problems.",
          "link": "http://arxiv.org/abs/2106.02619",
          "publishedOn": "2021-06-07T03:06:14.330Z",
          "wordCount": 609,
          "title": "Forward Super-Resolution: How Can GANs Learn Hierarchical Generative Models for Real-World Distributions. (arXiv:2106.02619v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02246",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Michelle M. Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zitnik_M/0/1/0/all/0/1\">Marinka Zitnik</a>",
          "description": "Spatial context is central to understanding health and disease. Yet reference\nprotein interaction networks lack such contextualization, thereby limiting the\nstudy of where protein interactions likely occur in the human body.\nContextualized protein interactions could better characterize genes with\ndisease-specific interactions and elucidate diseases' manifestation in specific\ncell types. Here, we introduce AWARE, a graph neural message passing approach\nto inject cellular and tissue context into protein embeddings. AWARE optimizes\nfor a multi-scale embedding space, whose structure reflects the topology of\ncell type specific networks. We construct a multi-scale network of the Human\nCell Atlas and apply AWARE to learn protein, cell type, and tissue embeddings\nthat uphold cell type and tissue hierarchies. We demonstrate AWARE on the novel\ntask of predicting whether a gene is associated with a disease and where it\nmost likely manifests in the human body. AWARE embeddings outperform global\nembeddings by at least 12.5%, highlighting the importance of contextual\nlearners for protein networks.",
          "link": "http://arxiv.org/abs/2106.02246",
          "publishedOn": "2021-06-07T03:06:14.321Z",
          "wordCount": 588,
          "title": "Deep Contextual Learners for Protein Networks. (arXiv:2106.02246v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02531",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Batzolis_G/0/1/0/all/0/1\">Georgios Batzolis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carioni_M/0/1/0/all/0/1\">Marcello Carioni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Etmann_C/0/1/0/all/0/1\">Christian Etmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Afyouni_S/0/1/0/all/0/1\">Soroosh Afyouni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kourtzi_Z/0/1/0/all/0/1\">Zoe Kourtzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schonlieb_C/0/1/0/all/0/1\">Carola Bibiane Sch&#xf6;nlieb</a>",
          "description": "We introduce CAFLOW, a new diverse image-to-image translation model that\nsimultaneously leverages the power of auto-regressive modeling and the modeling\nefficiency of conditional normalizing flows. We transform the conditioning\nimage into a sequence of latent encodings using a multi-scale normalizing flow\nand repeat the process for the conditioned image. We model the conditional\ndistribution of the latent encodings by modeling the auto-regressive\ndistributions with an efficient multi-scale normalizing flow, where each\nconditioning factor affects image synthesis at its respective resolution scale.\nOur proposed framework performs well on a range of image-to-image translation\ntasks. It outperforms former designs of conditional flows because of its\nexpressive auto-regressive structure.",
          "link": "http://arxiv.org/abs/2106.02531",
          "publishedOn": "2021-06-07T03:06:14.264Z",
          "wordCount": 546,
          "title": "CAFLOW: Conditional Autoregressive Flows. (arXiv:2106.02531v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02513",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pang_B/0/1/0/all/0/1\">Bo Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nijkamp_E/0/1/0/all/0/1\">Erik Nijkamp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1\">Tian Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Ying Nian Wu</a>",
          "description": "Latent variable models for text, when trained successfully, accurately model\nthe data distribution and capture global semantic and syntactic features of\nsentences. The prominent approach to train such models is variational\nautoencoders (VAE). It is nevertheless challenging to train and often results\nin a trivial local optimum where the latent variable is ignored and its\nposterior collapses into the prior, an issue known as posterior collapse.\nVarious techniques have been proposed to mitigate this issue. Most of them\nfocus on improving the inference model to yield latent codes of higher quality.\nThe present work proposes a short run dynamics for inference. It is initialized\nfrom the prior distribution of the latent variable and then runs a small number\n(e.g., 20) of Langevin dynamics steps guided by its posterior distribution. The\nmajor advantage of our method is that it does not require a separate inference\nmodel or assume simple geometry of the posterior distribution, thus rendering\nan automatic, natural and flexible inference engine. We show that the models\ntrained with short run dynamics more accurately model the data, compared to\nstrong language model and VAE baselines, and exhibit no sign of posterior\ncollapse. Analyses of the latent space show that interpolation in the latent\nspace is able to generate coherent sentences with smooth transition and\ndemonstrate improved classification over strong baselines with latent features\nfrom unsupervised pretraining. These results together expose a well-structured\nlatent space of our generative model.",
          "link": "http://arxiv.org/abs/2106.02513",
          "publishedOn": "2021-06-07T03:06:14.221Z",
          "wordCount": 664,
          "title": "Generative Text Modeling through Short Run Inference. (arXiv:2106.02513v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02110",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Neira_E/0/1/0/all/0/1\">Elva Luz Crespo Neira</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ebadi_A/0/1/0/all/0/1\">Ashkan Ebadi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Beaudry_C/0/1/0/all/0/1\">Catherine Beaudry</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Schiffauerova_A/0/1/0/all/0/1\">Andrea Schiffauerova</a>",
          "description": "Incorporating existing knowledge is vital for innovating, discovering, and\ngenerating new ideas. Knowledge production through research and invention is\nthe key to scientific and technological development. As an emerging technology,\nnanotechnology has already proved its great potential for the global economy,\nattracting considerable federal investments. Canada is reported as one of the\nmajor players in producing nanotechnology research. In this paper, we focused\non the main drivers of knowledge production and diffusion by analyzing Canadian\nnanotechnology researchers. We hypothesized that knowledge production in\nCanadian nanotechnology is influenced by three key proximity factors, namely\ncognitive, geographical, and collaborative. Using statistical analysis, social\nnetwork analysis, and machine learning techniques we comprehensively assessed\nthe influence of the proximity factors on academic knowledge production. Our\nresults not only prove a significant impact of the three key proximity factors\nbut also their predictive potential.",
          "link": "http://arxiv.org/abs/2106.02110",
          "publishedOn": "2021-06-07T03:06:14.212Z",
          "wordCount": 588,
          "title": "Influence of cognitive, geographical, and collaborative proximity on knowledge production of Canadian nanotechnology. (arXiv:2106.02110v1 [physics.soc-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2001.11628",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Okumura_R/0/1/0/all/0/1\">Ryo Okumura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Okada_M/0/1/0/all/0/1\">Masashi Okada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taniguchi_T/0/1/0/all/0/1\">Tadahiro Taniguchi</a>",
          "description": "State representation learning (SRL) in partially observable Markov decision\nprocesses has been studied to learn abstract features of data useful for robot\ncontrol tasks. For SRL, acquiring domain-agnostic states is essential for\nachieving efficient imitation learning. Without these states, imitation\nlearning is hampered by domain-dependent information useless for control.\nHowever, existing methods fail to remove such disturbances from the states when\nthe data from experts and agents show large domain shifts. To overcome this\nissue, we propose a domain-adversarial and conditional state space model\n(DAC-SSM) that enables control systems to obtain domain-agnostic and task- and\ndynamics-aware states. DAC-SSM jointly optimizes the state inference,\nobservation reconstruction, forward dynamics, and reward models. To remove\ndomain-dependent information from the states, the model is trained with domain\ndiscriminators in an adversarial manner, and the reconstruction is conditioned\non domain labels. We experimentally evaluated the model predictive control\nperformance via imitation learning for continuous control of sparse reward\ntasks in simulators and compared it with the performance of the existing SRL\nmethod. The agents from DAC-SSM achieved performance comparable to experts and\nmore than twice the baselines. We conclude domain-agnostic states are essential\nfor imitation learning that has large domain shifts and can be obtained using\nDAC-SSM.",
          "link": "http://arxiv.org/abs/2001.11628",
          "publishedOn": "2021-06-07T03:06:14.203Z",
          "wordCount": 670,
          "title": "Domain-Adversarial and Conditional State Space Model for Imitation Learning. (arXiv:2001.11628v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02260",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ven_L/0/1/0/all/0/1\">Leni Ven</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lederer_J/0/1/0/all/0/1\">Johannes Lederer</a>",
          "description": "Deep learning requires several design choices, such as the nodes' activation\nfunctions and the widths, types, and arrangements of the layers. One\nconsideration when making these choices is the vanishing-gradient problem,\nwhich is the phenomenon of algorithms getting stuck at suboptimal points due to\nsmall gradients. In this paper, we revisit the vanishing-gradient problem in\nthe context of sigmoid-type activation. We use mathematical arguments to\nhighlight two different sources of the phenomenon, namely large individual\nparameters and effects across layers, and to illustrate two simple remedies,\nnamely regularization and rescaling. We then demonstrate the effectiveness of\nthe two remedies in practice. In view of the vanishing-gradient problem being a\nmain reason why tanh and other sigmoid-type activation has become much less\npopular than relu-type activation, our results bring sigmoid-type activation\nback to the table.",
          "link": "http://arxiv.org/abs/2106.02260",
          "publishedOn": "2021-06-07T03:06:14.197Z",
          "wordCount": 565,
          "title": "Regularization and Reparameterization Avoid Vanishing Gradients in Sigmoid-Type Networks. (arXiv:2106.02260v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02522",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Wu_J/0/1/0/all/0/1\">Junran Wu</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Xu_K/0/1/0/all/0/1\">Ke Xu</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Chen_X/0/1/0/all/0/1\">Xueyuan Chen</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Li_S/0/1/0/all/0/1\">Shangzhe Li</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Zhao_J/0/1/0/all/0/1\">Jichang Zhao</a>",
          "description": "Stock prediction, with the purpose of forecasting the future price trends of\nstocks, is crucial for maximizing profits from stock investments. While great\nresearch efforts have been devoted to exploiting deep neural networks for\nimproved stock prediction, the existing studies still suffer from two major\nissues. First, the long-range dependencies in time series are not sufficiently\ncaptured. Second, the chaotic property of financial time series fundamentally\nlowers prediction performance. In this study, we propose a novel framework to\naddress both issues regarding stock prediction. Specifically, in terms of\ntransforming time series into complex networks, we convert market price series\ninto graphs. Then, structural information, referring to associations among\ntemporal points and the node weights, is extracted from the mapped graphs to\nresolve the problems regarding long-range dependencies and the chaotic\nproperty. We take graph embeddings to represent the associations among temporal\npoints as the prediction model inputs. Node weights are used as a priori\nknowledge to enhance the learning of temporal attention. The effectiveness of\nour proposed framework is validated using real-world stock data, and our\napproach obtains the best performance among several state-of-the-art\nbenchmarks. Moreover, in the conducted trading simulations, our framework\nfurther obtains the highest cumulative profits. Our results supplement the\nexisting applications of complex network methods in the financial realm and\nprovide insightful implications for investment applications regarding decision\nsupport in financial markets.",
          "link": "http://arxiv.org/abs/2106.02522",
          "publishedOn": "2021-06-07T03:06:14.186Z",
          "wordCount": 672,
          "title": "Price graphs: Utilizing the structural information of financial time series for stock prediction. (arXiv:2106.02522v1 [q-fin.ST])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02203",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Attrapadung_N/0/1/0/all/0/1\">Nuttapong Attrapadung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamada_K/0/1/0/all/0/1\">Koki Hamada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ikarashi_D/0/1/0/all/0/1\">Dai Ikarashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kikuchi_R/0/1/0/all/0/1\">Ryo Kikuchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matsuda_T/0/1/0/all/0/1\">Takahiro Matsuda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishina_I/0/1/0/all/0/1\">Ibuki Mishina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morita_H/0/1/0/all/0/1\">Hiraku Morita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuldt_J/0/1/0/all/0/1\">Jacob C. N. Schuldt</a>",
          "description": "Privacy-preserving machine learning (PPML) aims at enabling machine learning\n(ML) algorithms to be used on sensitive data. We contribute to this line of\nresearch by proposing a framework that allows efficient and secure evaluation\nof full-fledged state-of-the-art ML algorithms via secure multi-party\ncomputation (MPC). This is in contrast to most prior works, which substitute ML\nalgorithms with approximated \"MPC-friendly\" variants. A drawback of the latter\napproach is that fine-tuning of the combined ML and MPC algorithms is required,\nwhich might lead to less efficient algorithms or inferior quality ML. This is\nan issue for secure deep neural networks (DNN) training in particular, as this\ninvolves arithmetic algorithms thought to be \"MPC-unfriendly\", namely, integer\ndivision, exponentiation, inversion, and square root. In this work, we propose\nsecure and efficient protocols for the above seemingly MPC-unfriendly\ncomputations. Our protocols are three-party protocols in the honest-majority\nsetting, and we propose both passively secure and actively secure with abort\nvariants. A notable feature of our protocols is that they simultaneously\nprovide high accuracy and efficiency. This framework enables us to efficiently\nand securely compute modern ML algorithms such as Adam and the softmax function\n\"as is\", without resorting to approximations. As a result, we obtain secure DNN\ntraining that outperforms state-of-the-art three-party systems; our full\ntraining is up to 6.7 times faster than just the online phase of the recently\nproposed FALCON@PETS'21 on a standard benchmark network. We further perform\nmeasurements on real-world DNNs, AlexNet and VGG16. The performance of our\nframework is up to a factor of about 12-14 faster for AlexNet and 46-48 faster\nfor VGG16 to achieve an accuracy of 70% and 75%, respectively, when compared to\nFALCON.",
          "link": "http://arxiv.org/abs/2106.02203",
          "publishedOn": "2021-06-07T03:06:14.163Z",
          "wordCount": 734,
          "title": "Adam in Private: Secure and Fast Training of Deep Neural Networks with Adaptive Moment Estimation. (arXiv:2106.02203v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02302",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Meng_Z/0/1/0/all/0/1\">Zhong Meng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_Y/0/1/0/all/0/1\">Yu Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kanda_N/0/1/0/all/0/1\">Naoyuki Kanda</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lu_L/0/1/0/all/0/1\">Liang Lu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1\">Xie Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ye_G/0/1/0/all/0/1\">Guoli Ye</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sun_E/0/1/0/all/0/1\">Eric Sun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1\">Jinyu Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gong_Y/0/1/0/all/0/1\">Yifan Gong</a>",
          "description": "Integrating external language models (LMs) into end-to-end (E2E) models\nremains a challenging task for domain-adaptive speech recognition. Recently,\ninternal language model estimation (ILME)-based LM fusion has shown significant\nword error rate (WER) reduction from Shallow Fusion by subtracting a weighted\ninternal LM score from an interpolation of E2E model and external LM scores\nduring beam search. However, on different test sets, the optimal LM\ninterpolation weights vary over a wide range and have to be tuned extensively\non well-matched validation sets. In this work, we perform LM fusion in the\nminimum WER (MWER) training of an E2E model to obviate the need for LM weights\ntuning during inference. Besides MWER training with Shallow Fusion (MWER-SF),\nwe propose a novel MWER training with ILME (MWER-ILME) where the ILME-based\nfusion is conducted to generate N-best hypotheses and their posteriors.\nAdditional gradient is induced when internal LM is engaged in MWER-ILME loss\ncomputation. During inference, LM weights pre-determined in MWER training\nenable robust LM integrations on test sets from different domains. Experimented\nwith 30K-hour trained transformer transducers, MWER-ILME achieves on average\n8.8% and 5.8% relative WER reductions from MWER and MWER-SF training,\nrespectively, on 6 different test sets",
          "link": "http://arxiv.org/abs/2106.02302",
          "publishedOn": "2021-06-07T03:06:14.152Z",
          "wordCount": 675,
          "title": "Minimum Word Error Rate Training with Language Model Fusion for End-to-End Speech Recognition. (arXiv:2106.02302v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2012.05420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+E_W/0/1/0/all/0/1\">Weinan E</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wojtowytsch_S/0/1/0/all/0/1\">Stephan Wojtowytsch</a>",
          "description": "A recent numerical study observed that neural network classifiers enjoy a\nlarge degree of symmetry in the penultimate layer. Namely, if $h(x) = Af(x) +b$\nwhere $A$ is a linear map and $f$ is the output of the penultimate layer of the\nnetwork (after activation), then all data points $x_{i, 1}, \\dots, x_{i, N_i}$\nin a class $C_i$ are mapped to a single point $y_i$ by $f$ and the points $y_i$\nare located at the vertices of a regular $k-1$-dimensional standard simplex in\na high-dimensional Euclidean space.\n\nWe explain this observation analytically in toy models for highly expressive\ndeep neural networks. In complementary examples, we demonstrate rigorously that\neven the final output of the classifier $h$ is not uniform over data samples\nfrom a class $C_i$ if $h$ is a shallow network (or if the deeper layers do not\nbring the data samples into a convenient geometric configuration).",
          "link": "http://arxiv.org/abs/2012.05420",
          "publishedOn": "2021-06-07T03:06:14.139Z",
          "wordCount": 629,
          "title": "On the emergence of simplex symmetry in the final and penultimate layers of neural network classifiers. (arXiv:2012.05420v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02395",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Granese_F/0/1/0/all/0/1\">Federica Granese</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romanelli_M/0/1/0/all/0/1\">Marco Romanelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gorla_D/0/1/0/all/0/1\">Daniele Gorla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palamidessi_C/0/1/0/all/0/1\">Catuscia Palamidessi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piantanida_P/0/1/0/all/0/1\">Pablo Piantanida</a>",
          "description": "Deep neural networks (DNNs) have shown to perform very well on large scale\nobject recognition problems and lead to widespread use for real-world\napplications, including situations where DNN are implemented as \"black boxes\".\nA promising approach to secure their use is to accept decisions that are likely\nto be correct while discarding the others. In this work, we propose DOCTOR, a\nsimple method that aims to identify whether the prediction of a DNN classifier\nshould (or should not) be trusted so that, consequently, it would be possible\nto accept it or to reject it. Two scenarios are investigated: Totally Black Box\n(TBB) where only the soft-predictions are available and Partially Black Box\n(PBB) where gradient-propagation to perform input pre-processing is allowed.\nEmpirically, we show that DOCTOR outperforms all state-of-the-art methods on\nvarious well-known images and sentiment analysis datasets. In particular, we\nobserve a reduction of up to $4\\%$ of the false rejection rate (FRR) in the PBB\nscenario. DOCTOR can be applied to any pre-trained model, it does not require\nprior information about the underlying dataset and is as simple as the simplest\navailable methods in the literature.",
          "link": "http://arxiv.org/abs/2106.02395",
          "publishedOn": "2021-06-07T03:06:14.132Z",
          "wordCount": 624,
          "title": "DOCTOR: A Simple Method for Detecting Misclassification Errors. (arXiv:2106.02395v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02094",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gopalakrishnan_V/0/1/0/all/0/1\">Vishrawas Gopalakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Navalekar_S/0/1/0/all/0/1\">Sayali Navalekar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_P/0/1/0/all/0/1\">Pan Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hooley_R/0/1/0/all/0/1\">Ryan Hooley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miller_J/0/1/0/all/0/1\">Jacob Miller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_R/0/1/0/all/0/1\">Raman Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deshpande_A/0/1/0/all/0/1\">Ajay Deshpande</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bianco_S/0/1/0/all/0/1\">Simone Bianco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaufman_J/0/1/0/all/0/1\">James H. Kaufman</a>",
          "description": "Pandemic control measures like lock-down, restrictions on restaurants and\ngatherings, social-distancing have shown to be effective in curtailing the\nspread of COVID-19. However, their sustained enforcement has negative economic\neffects. To craft strategies and policies that reduce the hardship on the\npeople and the economy while being effective against the pandemic, authorities\nneed to understand the disease dynamics at the right geo-spatial granularity.\nConsidering factors like the hospitals' ability to handle the fluctuating\ndemands, evaluating various reopening scenarios, and accurate forecasting of\ncases are vital to decision making. Towards this end, we present a flexible\nend-to-end solution that seamlessly integrates public health data with tertiary\nclient data to accurately estimate the risk of reopening a community. At its\ncore lies a state-of-the-art prediction model that auto-captures changing\ntrends in transmission and mobility. Benchmarking against various published\nbaselines confirm the superiority of our forecasting algorithm. Combined with\nthe ability to extend to multiple client-specific requirements and perform\ndeductive reasoning through counter-factual analysis, this solution provides\nactionable insights to multiple client domains ranging from government to\neducational institutions, hospitals, and commercial establishments.",
          "link": "http://arxiv.org/abs/2106.02094",
          "publishedOn": "2021-06-07T03:06:14.126Z",
          "wordCount": 682,
          "title": "Adaptive Epidemic Forecasting and Community Risk Evaluation of COVID-19. (arXiv:2106.02094v1 [cs.CY])"
        },
        {
          "id": "http://arxiv.org/abs/2103.10426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chai_L/0/1/0/all/0/1\">Lucy Chai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wulff_J/0/1/0/all/0/1\">Jonas Wulff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isola_P/0/1/0/all/0/1\">Phillip Isola</a>",
          "description": "In recent years, Generative Adversarial Networks have become ubiquitous in\nboth research and public perception, but how GANs convert an unstructured\nlatent code to a high quality output is still an open question. In this work,\nwe investigate regression into the latent space as a probe to understand the\ncompositional properties of GANs. We find that combining the regressor and a\npretrained generator provides a strong image prior, allowing us to create\ncomposite images from a collage of random image parts at inference time while\nmaintaining global consistency. To compare compositional properties across\ndifferent generators, we measure the trade-offs between reconstruction of the\nunrealistic input and image quality of the regenerated samples. We find that\nthe regression approach enables more localized editing of individual image\nparts compared to direct editing in the latent space, and we conduct\nexperiments to quantify this independence effect. Our method is agnostic to the\nsemantics of edits, and does not require labels or predefined concepts during\ntraining. Beyond image composition, our method extends to a number of related\napplications, such as image inpainting or example-based image editing, which we\ndemonstrate on several GANs and datasets, and because it uses only a single\nforward pass, it can operate in real-time. Code is available on our project\npage: https://chail.github.io/latent-composition/.",
          "link": "http://arxiv.org/abs/2103.10426",
          "publishedOn": "2021-06-07T03:06:14.106Z",
          "wordCount": 687,
          "title": "Using latent space regression to analyze and leverage compositionality in GANs. (arXiv:2103.10426v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02357",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Desu_S/0/1/0/all/0/1\">Surya Sai Teja Desu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srijith_P/0/1/0/all/0/1\">P.K. Srijith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_M/0/1/0/all/0/1\">M.V. Panduranga Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sivadasan_N/0/1/0/all/0/1\">Naveen Sivadasan</a>",
          "description": "Linear regression is a popular machine learning approach to learn and predict\nreal valued outputs or dependent variables from independent variables or\nfeatures. In many real world problems, its beneficial to perform sparse linear\nregression to identify important features helpful in predicting the dependent\nvariable. It not only helps in getting interpretable results but also avoids\noverfitting when the number of features is large, and the amount of data is\nsmall. The most natural way to achieve this is by using `best subset selection'\nwhich penalizes non-zero model parameters by adding $\\ell_0$ norm over\nparameters to the least squares loss. However, this makes the objective\nfunction non-convex and intractable even for a small number of features. This\npaper aims to address the intractability of sparse linear regression with\n$\\ell_0$ norm using adiabatic quantum computing, a quantum computing paradigm\nthat is particularly useful for solving optimization problems faster. We\nformulate the $\\ell_0$ optimization problem as a Quadratic Unconstrained Binary\nOptimization (QUBO) problem and solve it using the D-Wave adiabatic quantum\ncomputer. We study and compare the quality of QUBO solution on synthetic and\nreal world datasets. The results demonstrate the effectiveness of the proposed\nadiabatic quantum computing approach in finding the optimal solution. The QUBO\nsolution matches the optimal solution for a wide range of sparsity penalty\nvalues across the datasets.",
          "link": "http://arxiv.org/abs/2106.02357",
          "publishedOn": "2021-06-07T03:06:14.099Z",
          "wordCount": 666,
          "title": "Adiabatic Quantum Feature Selection for Sparse Linear Regression. (arXiv:2106.02357v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02524",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mullenbach_J/0/1/0/all/0/1\">James Mullenbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pruksachatkun_Y/0/1/0/all/0/1\">Yada Pruksachatkun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adler_S/0/1/0/all/0/1\">Sean Adler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seale_J/0/1/0/all/0/1\">Jennifer Seale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swartz_J/0/1/0/all/0/1\">Jordan Swartz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McKelvey_T/0/1/0/all/0/1\">T. Greg McKelvey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1\">Hui Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sontag_D/0/1/0/all/0/1\">David Sontag</a>",
          "description": "Continuity of care is crucial to ensuring positive health outcomes for\npatients discharged from an inpatient hospital setting, and improved\ninformation sharing can help. To share information, caregivers write discharge\nnotes containing action items to share with patients and their future\ncaregivers, but these action items are easily lost due to the lengthiness of\nthe documents. In this work, we describe our creation of a dataset of clinical\naction items annotated over MIMIC-III, the largest publicly available dataset\nof real clinical notes. This dataset, which we call CLIP, is annotated by\nphysicians and covers 718 documents representing 100K sentences. We describe\nthe task of extracting the action items from these documents as multi-aspect\nextractive summarization, with each aspect representing a type of action to be\ntaken. We evaluate several machine learning models on this task, and show that\nthe best models exploit in-domain language model pre-training on 59K\nunannotated documents, and incorporate context from neighboring sentences. We\nalso propose an approach to pre-training data selection that allows us to\nexplore the trade-off between size and domain-specificity of pre-training\ndatasets for this task.",
          "link": "http://arxiv.org/abs/2106.02524",
          "publishedOn": "2021-06-07T03:06:14.093Z",
          "wordCount": 641,
          "title": "CLIP: A Dataset for Extracting Action Items for Physicians from Hospital Discharge Notes. (arXiv:2106.02524v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02390",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Noel_A/0/1/0/all/0/1\">Alejandro Daniel Noel</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Hoof_C/0/1/0/all/0/1\">Charel van Hoof</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Millidge_B/0/1/0/all/0/1\">Beren Millidge</a> (2) ((1) Delft University of Technology, (2) University of Oxford)",
          "description": "Intelligent agents must pursue their goals in complex environments with\npartial information and often limited computational capacity. Reinforcement\nlearning methods have achieved great success by creating agents that optimize\nengineered reward functions, but which often struggle to learn in sparse-reward\nenvironments, generally require many environmental interactions to perform\nwell, and are typically computationally very expensive. Active inference is a\nmodel-based approach that directs agents to explore uncertain states while\nadhering to a prior model of their goal behaviour. This paper introduces an\nactive inference agent which minimizes the novel free energy of the expected\nfuture. Our model is capable of solving sparse-reward problems with a very high\nsample efficiency due to its objective function, which encourages directed\nexploration of uncertain states. Moreover, our model is computationally very\nlight and can operate in a fully online manner while achieving comparable\nperformance to offline RL methods. We showcase the capabilities of our model by\nsolving the mountain car problem, where we demonstrate its superior exploration\nproperties and its robustness to observation noise, which in fact improves\nperformance. We also introduce a novel method for approximating the prior model\nfrom the reward function, which simplifies the expression of complex objectives\nand improves performance over previous active inference approaches.",
          "link": "http://arxiv.org/abs/2106.02390",
          "publishedOn": "2021-06-07T03:06:14.085Z",
          "wordCount": 659,
          "title": "Online reinforcement learning with sparse rewards through an active inference capsule. (arXiv:2106.02390v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02051",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+List_F/0/1/0/all/0/1\">Florian List</a>",
          "description": "Although ubiquitous in the sciences, histogram data have not received much\nattention by the Deep Learning community. Whilst regression and classification\ntasks for scalar and vector data are routinely solved by neural networks, a\nprincipled approach for estimating histogram labels as a function of an input\nvector or image is lacking in the literature. We present a dedicated method for\nDeep Learning-based histogram regression, which incorporates cross-bin\ninformation and yields distributions over possible histograms, expressed by\n$\\tau$-quantiles of the cumulative histogram in each bin. The crux of our\napproach is a new loss function obtained by applying the pinball loss to the\ncumulative histogram, which for 1D histograms reduces to the Earth Mover's\ndistance (EMD) in the special case of the median ($\\tau = 0.5$), and\ngeneralizes it to arbitrary quantiles. We validate our method with an\nillustrative toy example, a football-related task, and an astrophysical\ncomputer vision problem. We show that with our loss function, the accuracy of\nthe predicted median histograms is very similar to the standard EMD case (and\nhigher than for per-bin loss functions such as cross-entropy), while the\npredictions become much more informative at almost no additional computational\ncost.",
          "link": "http://arxiv.org/abs/2106.02051",
          "publishedOn": "2021-06-07T03:06:14.079Z",
          "wordCount": 638,
          "title": "The Earth Mover's Pinball Loss: Quantiles for Histogram-Valued Regression. (arXiv:2106.02051v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02445",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Saito_N/0/1/0/all/0/1\">Namiko Saito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ogata_T/0/1/0/all/0/1\">Tetsuya Ogata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Funabashi_S/0/1/0/all/0/1\">Satoshi Funabashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mori_H/0/1/0/all/0/1\">Hiroki Mori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugano_S/0/1/0/all/0/1\">Shigeki Sugano</a>",
          "description": "Selection of appropriate tools and use of them when performing daily tasks is\na critical function for introducing robots for domestic applications. In\nprevious studies, however, adaptability to target objects was limited, making\nit difficult to accordingly change tools and adjust actions. To manipulate\nvarious objects with tools, robots must both understand tool functions and\nrecognize object characteristics to discern a tool-object-action relation. We\nfocus on active perception using multimodal sensorimotor data while a robot\ninteracts with objects, and allow the robot to recognize their extrinsic and\nintrinsic characteristics. We construct a deep neural networks (DNN) model that\nlearns to recognize object characteristics, acquires tool-object-action\nrelations, and generates motions for tool selection and handling. As an example\ntool-use situation, the robot performs an ingredients transfer task, using a\nturner or ladle to transfer an ingredient from a pot to a bowl. The results\nconfirm that the robot recognizes object characteristics and servings even when\nthe target ingredients are unknown. We also examine the contributions of\nimages, force, and tactile data and show that learning a variety of multimodal\ninformation results in rich perception for tool use.",
          "link": "http://arxiv.org/abs/2106.02445",
          "publishedOn": "2021-06-07T03:06:14.061Z",
          "wordCount": 669,
          "title": "How to select and use tools? : Active Perception of Target Objects Using Multimodal Deep Learning. (arXiv:2106.02445v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02496",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Roget_M/0/1/0/all/0/1\">Mathieu Roget</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Molfetta_G/0/1/0/all/0/1\">Giuseppe Di Molfetta</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Kadri_H/0/1/0/all/0/1\">Hachem Kadri</a>",
          "description": "Quantum machine learning algorithms could provide significant speed-ups over\ntheir classical counterparts; however, whether they could also achieve good\ngeneralization remains unclear. Recently, two quantum perceptron models which\ngive a quadratic improvement over the classical perceptron algorithm using\nGrover's search have been proposed by Wiebe et al. arXiv:1602.04799 . While the\nfirst model reduces the complexity with respect to the size of the training\nset, the second one improves the bound on the number of mistakes made by the\nperceptron. In this paper, we introduce a hybrid quantum-classical perceptron\nalgorithm with lower complexity and better generalization ability than the\nclassical perceptron. We show a quadratic improvement over the classical\nperceptron in both the number of samples and the margin of the data. We derive\na bound on the expected error of the hypothesis returned by our algorithm,\nwhich compares favorably to the one obtained with the classical online\nperceptron. We use numerical experiments to illustrate the trade-off between\ncomputational complexity and statistical accuracy in quantum perceptron\nlearning and discuss some of the key practical issues surrounding the\nimplementation of quantum perceptron models into near-term quantum devices,\nwhose practical implementation represents a serious challenge due to inherent\nnoise. However, the potential benefits make correcting this worthwhile.",
          "link": "http://arxiv.org/abs/2106.02496",
          "publishedOn": "2021-06-07T03:06:14.055Z",
          "wordCount": 630,
          "title": "Quantum Perceptron Revisited: Computational-Statistical Tradeoffs. (arXiv:2106.02496v1 [quant-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02343",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yamaguchi_S/0/1/0/all/0/1\">Shin&#x27;ya Yamaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanai_S/0/1/0/all/0/1\">Sekitoshi Kanai</a>",
          "description": "Generative adversarial networks built from deep convolutional neural networks\n(GANs) lack the ability to exactly replicate the high-frequency components of\nnatural images. To alleviate this issue, we introduce two novel training\ntechniques called frequency dropping (F-Drop) and frequency matching (F-Match).\nThe key idea of F-Drop is to filter out unnecessary high-frequency components\nfrom the input images of the discriminators. This simple modification prevents\nthe discriminators from being confused by perturbations of the high-frequency\ncomponents. In addition, F-Drop makes the GANs focus on fitting in the\nlow-frequency domain, in which there are the dominant components of natural\nimages. F-Match minimizes the difference between real and fake images in the\nfrequency domain for generating more realistic images. F-Match is implemented\nas a regularization term in the objective functions of the generators; it\npenalizes the batch mean error in the frequency domain. F-Match helps the\ngenerators to fit in the high-frequency domain filtered out by F-Drop to the\nreal image. We experimentally demonstrate that the combination of F-Drop and\nF-Match improves the generative performance of GANs in both the frequency and\nspatial domain on multiple image benchmarks (CIFAR, TinyImageNet, STL-10,\nCelebA, and ImageNet).",
          "link": "http://arxiv.org/abs/2106.02343",
          "publishedOn": "2021-06-07T03:06:14.049Z",
          "wordCount": 634,
          "title": "F-Drop&Match: GANs with a Dead Zone in the High-Frequency Domain. (arXiv:2106.02343v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02487",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Likhosherstov_V/0/1/0/all/0/1\">Valerii Likhosherstov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xingyou Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choromanski_K/0/1/0/all/0/1\">Krzysztof Choromanski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1\">Jared Davis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1\">Adrian Weller</a>",
          "description": "Approximate bi-level optimization (ABLO) consists of (outer-level)\noptimization problems, involving numerical (inner-level) optimization loops.\nWhile ABLO has many applications across deep learning, it suffers from time and\nmemory complexity proportional to the length $r$ of its inner optimization\nloop. To address this complexity, an earlier first-order method (FOM) was\nproposed as a heuristic that omits second derivative terms, yielding\nsignificant speed gains and requiring only constant memory. Despite FOM's\npopularity, there is a lack of theoretical understanding of its convergence\nproperties. We contribute by theoretically characterizing FOM's gradient bias\nunder mild assumptions. We further demonstrate a rich family of examples where\nFOM-based SGD does not converge to a stationary point of the ABLO objective. We\naddress this concern by proposing an unbiased FOM (UFOM) enjoying constant\nmemory complexity as a function of $r$. We characterize the introduced\ntime-variance tradeoff, demonstrate convergence bounds, and find an optimal\nUFOM for a given ABLO problem. Finally, we propose an efficient adaptive UFOM\nscheme.",
          "link": "http://arxiv.org/abs/2106.02487",
          "publishedOn": "2021-06-07T03:06:14.041Z",
          "wordCount": 606,
          "title": "Debiasing a First-order Heuristic for Approximate Bi-level Optimization. (arXiv:2106.02487v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02182",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1\">Chenyu You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1\">Yuexian Zou</a>",
          "description": "In spoken conversational question answering (SCQA), the answer to the\ncorresponding question is generated by retrieving and then analyzing a fixed\nspoken document, including multi-part conversations. Most SCQA systems have\nconsidered only retrieving information from ordered utterances. However, the\nsequential order of dialogue is important to build a robust spoken\nconversational question answering system, and the changes of utterances order\nmay severely result in low-quality and incoherent corpora. To this end, we\nintroduce a self-supervised learning approach, including incoherence\ndiscrimination, insertion detection, and question prediction, to explicitly\ncapture the coreference resolution and dialogue coherence among spoken\ndocuments. Specifically, we design a joint learning framework where the\nauxiliary self-supervised tasks can enable the pre-trained SCQA systems towards\nmore coherent and meaningful spoken dialogue learning. We also utilize the\nproposed self-supervised learning tasks to capture intra-sentence coherence.\nExperimental results demonstrate that our proposed method provides more\ncoherent, meaningful, and appropriate responses, yielding superior performance\ngains compared to the original pre-trained language models. Our method achieves\nstate-of-the-art results on the Spoken-CoQA dataset.",
          "link": "http://arxiv.org/abs/2106.02182",
          "publishedOn": "2021-06-07T03:06:14.035Z",
          "wordCount": 613,
          "title": "Self-supervised Dialogue Learning for Spoken Conversational Question Answering. (arXiv:2106.02182v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02297",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kim_J/0/1/0/all/0/1\">Ji-Hoon Kim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_S/0/1/0/all/0/1\">Sang-Hoon Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_J/0/1/0/all/0/1\">Ji-Hyun Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_S/0/1/0/all/0/1\">Seong-Whan Lee</a>",
          "description": "Although recent works on neural vocoder have improved the quality of\nsynthesized audio, there still exists a gap between generated and ground-truth\naudio in frequency space. This difference leads to spectral artifacts such as\nhissing noise or robotic sound, and thus degrades the sample quality. In this\npaper, we propose Fre-GAN which achieves frequency-consistent audio synthesis\nwith highly improved generation quality. Specifically, we first present\nresolution-connected generator and resolution-wise discriminators, which help\nlearn various scales of spectral distributions over multiple frequency bands.\nAdditionally, to reproduce high-frequency components accurately, we leverage\ndiscrete wavelet transform in the discriminators. From our experiments, Fre-GAN\nachieves high-fidelity waveform generation with a gap of only 0.03 MOS compared\nto ground-truth audio while outperforming standard models in quality.",
          "link": "http://arxiv.org/abs/2106.02297",
          "publishedOn": "2021-06-07T03:06:14.028Z",
          "wordCount": 557,
          "title": "Fre-GAN: Adversarial Frequency-consistent Audio Synthesis. (arXiv:2106.02297v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02044",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_P/0/1/0/all/0/1\">Piyush K. Sharma</a>",
          "description": "Data transmission between two or more digital devices in industry and\ngovernment demands secure and agile technology. Digital information\ndistribution often requires deployment of Internet of Things (IoT) devices and\nData Fusion techniques which have also gained popularity in both, civilian and\nmilitary environments, such as, emergence of Smart Cities and Internet of\nBattlefield Things (IoBT). This usually requires capturing and consolidating\ndata from multiple sources. Because datasets do not necessarily originate from\nidentical sensors, fused data typically results in a complex Big Data problem.\nDue to potentially sensitive nature of IoT datasets, Blockchain technology is\nused to facilitate secure sharing of IoT datasets, which allows digital\ninformation to be distributed, but not copied. However, blockchain has several\nlimitations related to complexity, scalability, and excessive energy\nconsumption. We propose an approach to hide information (sensor signal) by\ntransforming it to an image or an audio signal. In one of the latest attempts\nto the military modernization, we investigate sensor fusion approach by\ninvestigating the challenges of enabling an intelligent identification and\ndetection operation and demonstrates the feasibility of the proposed Deep\nLearning and Anomaly Detection models that can support future application for\nspecific hand gesture alert system from wearable devices.",
          "link": "http://arxiv.org/abs/2106.02044",
          "publishedOn": "2021-06-07T03:06:14.010Z",
          "wordCount": 670,
          "title": "Heterogeneous Noisy Short Signal Camouflage in Multi-Domain Environment Decision-Making. (arXiv:2106.02044v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2104.00734",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pinto_J/0/1/0/all/0/1\">Juliano Pinto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hess_G/0/1/0/all/0/1\">Georg Hess</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ljungbergh_W/0/1/0/all/0/1\">William Ljungbergh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yuxuan Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Svensson_L/0/1/0/all/0/1\">Lennart Svensson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wymeersch_H/0/1/0/all/0/1\">Henk Wymeersch</a>",
          "description": "Multitarget Tracking (MTT) is the problem of tracking the states of an\nunknown number of objects using noisy measurements, with important applications\nto autonomous driving, surveillance, robotics, and others. In the model-based\nBayesian setting, there are conjugate priors that enable us to express the\nmulti-object posterior in closed form, which could theoretically provide\nBayes-optimal estimates. However, the posterior involves a super-exponential\ngrowth of the number of hypotheses over time, forcing state-of-the-art methods\nto resort to approximations for remaining tractable, which can impact their\nperformance in complex scenarios. Model-free methods based on deep-learning\nprovide an attractive alternative, as they can, in principle, learn the optimal\nfilter from data, but to the best of our knowledge were never compared to\ncurrent state-of-the-art Bayesian filters, specially not in contexts where\naccurate models are available. In this paper, we propose a high-performing\ndeep-learning method for MTT based on the Transformer architecture and compare\nit to two state-of-the-art Bayesian filters, in a setting where we assume the\ncorrect model is provided. Although this gives an edge to the model-based\nfilters, it also allows us to generate unlimited training data. We show that\nthe proposed model outperforms state-of-the-art Bayesian filters in complex\nscenarios, while matching their performance in simpler cases, which validates\nthe applicability of deep-learning also in the model-based regime. The code for\nall our implementations is made available at\nhttps://github.com/JulianoLagana/MT3 .",
          "link": "http://arxiv.org/abs/2104.00734",
          "publishedOn": "2021-06-07T03:06:14.004Z",
          "wordCount": 713,
          "title": "Next Generation Multitarget Trackers: Random Finite Set Methods vs Transformer-based Deep Learning. (arXiv:2104.00734v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.05022",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Kuchibhotla_A/0/1/0/all/0/1\">Arun Kumar Kuchibhotla</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zheng_Q/0/1/0/all/0/1\">Qinqing Zheng</a>",
          "description": "Many inference problems, such as sequential decision problems like A/B\ntesting, adaptive sampling schemes like bandit selection, are often online in\nnature. The fundamental problem for online inference is to provide a sequence\nof confidence intervals that are valid uniformly over the growing-into-infinity\nsample sizes. To address this question, we provide a near-optimal confidence\nsequence for bounded random variables by utilizing Bentkus' concentration\nresults. We show that it improves on the existing approaches that use the\nCram{\\'e}r-Chernoff technique such as the Hoeffding, Bernstein, and Bennett\ninequalities. The resulting confidence sequence is confirmed to be favorable in\nboth synthetic coverage problems and an application to adaptive stopping\nalgorithms.",
          "link": "http://arxiv.org/abs/2006.05022",
          "publishedOn": "2021-06-07T03:06:13.996Z",
          "wordCount": 574,
          "title": "Near-Optimal Confidence Sequences for Bounded Random Variables. (arXiv:2006.05022v3 [math.ST] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02078",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sridhar_K/0/1/0/all/0/1\">Kaustubh Sridhar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sokolsky_O/0/1/0/all/0/1\">Oleg Sokolsky</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lee_I/0/1/0/all/0/1\">Insup Lee</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Weimer_J/0/1/0/all/0/1\">James Weimer</a>",
          "description": "Improving adversarial robustness of neural networks remains a major\nchallenge. Fundamentally, training a network is a parameter estimation problem.\nIn adaptive control theory, maintaining persistency of excitation (PoE) is\nintegral to ensuring convergence of parameter estimates in dynamical systems to\ntheir robust optima. In this work, we show that network training using gradient\ndescent is equivalent to a dynamical system parameter estimation problem.\nLeveraging this relationship, we prove a sufficient condition for PoE of\ngradient descent is achieved when the learning rate is less than the inverse of\nthe Lipschitz constant of the gradient of loss function. We provide an\nefficient technique for estimating the corresponding Lipschitz constant using\nextreme value theory and demonstrate that by only scaling the learning rate\nschedule we can increase adversarial accuracy by up to 15% on benchmark\ndatasets. Our approach also universally increases the adversarial accuracy by\n0.1% to 0.3% in various state-of-the-art adversarially trained models on the\nAutoAttack benchmark, where every small margin of improvement is significant.",
          "link": "http://arxiv.org/abs/2106.02078",
          "publishedOn": "2021-06-07T03:06:13.988Z",
          "wordCount": 601,
          "title": "Robust Learning via Persistency of Excitation. (arXiv:2106.02078v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02556",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nicholas_F/0/1/0/all/0/1\">Farris Nicholas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brian_M/0/1/0/all/0/1\">Model Brian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richard_S/0/1/0/all/0/1\">Savery Richard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gil_W/0/1/0/all/0/1\">Weinberg Gil</a>",
          "description": "The task of classifying emotions within a musical track has received\nwidespread attention within the Music Information Retrieval (MIR) community.\nMusic emotion recognition has traditionally relied on the use of acoustic\nfeatures, verbal features, and metadata-based filtering. The role of musical\nprosody remains under-explored despite several studies demonstrating a strong\nconnection between prosody and emotion. In this study, we restrict the input of\ntraditional machine learning algorithms to the features of musical prosody.\nFurthermore, our proposed approach builds upon the prior by classifying\nemotions under an expanded emotional taxonomy, using the Geneva Wheel of\nEmotion. We utilize a methodology for individual data collection from\nvocalists, and personal ground truth labeling by the artist themselves. We\nfound that traditional machine learning algorithms when limited to the features\nof musical prosody (1) achieve high accuracies for a single singer, (2)\nmaintain high accuracy when the dataset is expanded to multiple singers, and\n(3) achieve high accuracies when trained on a reduced subset of the total\nfeatures.",
          "link": "http://arxiv.org/abs/2106.02556",
          "publishedOn": "2021-06-07T03:06:13.980Z",
          "wordCount": 605,
          "title": "Musical Prosody-Driven Emotion Classification: Interpreting Vocalists Portrayal of Emotions Through Machine Learning. (arXiv:2106.02556v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02398",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Farhadkhani_S/0/1/0/all/0/1\">Sadegh Farhadkhani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guerraoui_R/0/1/0/all/0/1\">Rachid Guerraoui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoang_L/0/1/0/all/0/1\">L&#xea;-Nguy&#xea;n Hoang</a>",
          "description": "Today's large-scale machine learning algorithms harness massive amounts of\nuser-generated data to train large models. However, especially in the context\nof content recommendation with enormous social, economical and political\nincentives to promote specific views, products or ideologies, strategic users\nmight be tempted to fabricate or mislabel data in order to bias algorithms in\ntheir favor. Unfortunately, today's learning schemes strongly incentivize such\nstrategic data misreporting. This is a major concern, as it endangers the\ntrustworthiness of the entire training datasets, and questions the safety of\nany algorithm trained on such datasets. In this paper, we show that, perhaps\nsurprisingly, incentivizing data misreporting is not a fatality. We propose the\nfirst personalized collaborative learning framework, Licchavi, with provable\nstrategyproofness guarantees through a careful design of the underlying loss\nfunction. Interestingly, we also prove that Licchavi is Byzantine resilient: it\ntolerates a minority of users that provide arbitrary data.",
          "link": "http://arxiv.org/abs/2106.02398",
          "publishedOn": "2021-06-07T03:06:13.964Z",
          "wordCount": 581,
          "title": "Strategyproof Learning: Building Trustworthy User-Generated Datasets. (arXiv:2106.02398v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02305",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zheng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garrett_Z/0/1/0/all/0/1\">Zachary Garrett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Charles_Z/0/1/0/all/0/1\">Zachary Charles</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Luyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_G/0/1/0/all/0/1\">Gauri Joshi</a>",
          "description": "The federated learning (FL) framework trains a machine learning model using\ndecentralized data stored at edge client devices by periodically aggregating\nlocally trained models. Popular optimization algorithms of FL use vanilla\n(stochastic) gradient descent for both local updates at clients and global\nupdates at the aggregating server. Recently, adaptive optimization methods such\nas AdaGrad have been studied for server updates. However, the effect of using\nadaptive optimization methods for local updates at clients is not yet\nunderstood. We show in both theory and practice that while local adaptive\nmethods can accelerate convergence, they can cause a non-vanishing solution\nbias, where the final converged solution may be different from the stationary\npoint of the global objective function. We propose correction techniques to\novercome this inconsistency and complement the local adaptive methods for FL.\nExtensive experiments on realistic federated training tasks show that the\nproposed algorithms can achieve faster convergence and higher test accuracy\nthan the baselines without local adaptivity.",
          "link": "http://arxiv.org/abs/2106.02305",
          "publishedOn": "2021-06-07T03:06:13.958Z",
          "wordCount": 597,
          "title": "Local Adaptivity in Federated Learning: Convergence and Consistency. (arXiv:2106.02305v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02352",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kamyshev_I/0/1/0/all/0/1\">Ilia Kamyshev</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kriukov_D/0/1/0/all/0/1\">Dmitrii Kriukov</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gryazina_E/0/1/0/all/0/1\">Elena Gryazina</a>",
          "description": "The modern artificial intelligence techniques show the outstanding\nperformances in the field of Non-Intrusive Load Monitoring (NILM). However, the\nproblem related to the identification of a large number of appliances working\nsimultaneously is underestimated. One of the reasons is the absence of a\nspecific data. In this research we propose the Synthesizer of Normalized\nSignatures (SNS) algorithm to simulate the aggregated consumption with up to 10\nconcurrent loads. The results show that the synthetic data provides the models\nwith at least as a powerful identification accuracy as the real-world\nmeasurements. We have developed the neural architecture named Concurrent Loads\nDisaggregator (COLD) which is relatively simple and easy to understand in\ncomparison to the previous approaches. Our model allows identifying from 1 to\n10 appliances working simultaneously with mean F1-score 78.95%. The source code\nof the experiments performed is available at\nhttps://github.com/arx7ti/cold-nilm.",
          "link": "http://arxiv.org/abs/2106.02352",
          "publishedOn": "2021-06-07T03:06:13.951Z",
          "wordCount": 573,
          "title": "COLD: Concurrent Loads Disaggregator for Non-Intrusive Load Monitoring. (arXiv:2106.02352v1 [eess.SP])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02295",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhaoyang_Z/0/1/0/all/0/1\">Zhang Zhaoyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wenqi_S/0/1/0/all/0/1\">Shao Wenqi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jinwei_G/0/1/0/all/0/1\">Gu Jinwei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiaogang_W/0/1/0/all/0/1\">Wang Xiaogang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ping_L/0/1/0/all/0/1\">Luo Ping</a>",
          "description": "Model quantization is challenging due to many tedious hyper-parameters such\nas precision (bitwidth), dynamic range (minimum and maximum discrete values)\nand stepsize (interval between discrete values). Unlike prior arts that\ncarefully tune these values, we present a fully differentiable approach to\nlearn all of them, named Differentiable Dynamic Quantization (DDQ), which has\nseveral benefits. (1) DDQ is able to quantize challenging lightweight\narchitectures like MobileNets, where different layers prefer different\nquantization parameters. (2) DDQ is hardware-friendly and can be easily\nimplemented using low-precision matrix-vector multiplication, making it capable\nin many hardware such as ARM. (3) Extensive experiments show that DDQ\noutperforms prior arts on many networks and benchmarks, especially when models\nare already efficient and compact. e.g., DDQ is the first approach that\nachieves lossless 4-bit quantization for MobileNetV2 on ImageNet.",
          "link": "http://arxiv.org/abs/2106.02295",
          "publishedOn": "2021-06-07T03:06:13.945Z",
          "wordCount": 563,
          "title": "Differentiable Dynamic Quantization with Mixed Precision and Adaptive Resolution. (arXiv:2106.02295v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.01678",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Yamashita_R/0/1/0/all/0/1\">Rikiya Yamashita</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Long_J/0/1/0/all/0/1\">Jin Long</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Banda_S/0/1/0/all/0/1\">Snikitha Banda</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shen_J/0/1/0/all/0/1\">Jeanne Shen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rubin_D/0/1/0/all/0/1\">Daniel L. Rubin</a>",
          "description": "Suboptimal generalization of machine learning models on unseen data is a key\nchallenge which hampers the clinical applicability of such models to medical\nimaging. Although various methods such as domain adaptation and domain\ngeneralization have evolved to combat this challenge, learning robust and\ngeneralizable representations is core to medical image understanding, and\ncontinues to be a problem. Here, we propose STRAP (Style TRansfer Augmentation\nfor histoPathology), a form of data augmentation based on random style transfer\nfrom non-medical style source such as artistic paintings, for learning\ndomain-agnostic visual representations in computational pathology. Style\ntransfer replaces the low-level texture content of an image with the\nuninformative style of randomly selected style source image, while preserving\nthe original high-level semantic content. This improves robustness to domain\nshift and can be used as a simple yet powerful tool for learning\ndomain-agnostic representations. We demonstrate that STRAP leads to\nstate-of-the-art performance, particularly in the presence of domain shifts, on\ntwo particular classification tasks in computational pathology.",
          "link": "http://arxiv.org/abs/2102.01678",
          "publishedOn": "2021-06-07T03:06:13.938Z",
          "wordCount": 633,
          "title": "Learning domain-agnostic visual representation for computational pathology using medically-irrelevant style transfer augmentation. (arXiv:2102.01678v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02540",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sana_M/0/1/0/all/0/1\">Mohamed Sana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pietro_N/0/1/0/all/0/1\">Nicola di Pietro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strinati_E/0/1/0/all/0/1\">Emilio Calvanese Strinati</a>",
          "description": "We study the problem of user association, namely finding the optimal\nassignment of user equipment to base stations to achieve a targeted network\nperformance. In this paper, we focus on the knowledge transferability of\nassociation policies. Indeed, traditional non-trivial user association schemes\nare often scenario-specific or deployment-specific and require a policy\nre-design or re-learning when the number or the position of the users change.\nIn contrast, transferability allows to apply a single user association policy,\ndevised for a specific scenario, to other distinct user deployments, without\nneeding a substantial re-learning or re-design phase and considerably reducing\nits computational and management complexity. To achieve transferability, we\nfirst cast user association as a multi-agent reinforcement learning problem.\nThen, based on a neural attention mechanism that we specifically conceived for\nthis context, we propose a novel distributed policy network architecture, which\nis transferable among users with zero-shot generalization capability i.e.,\nwithout requiring additional training.Numerical results show the effectiveness\nof our solution in terms of overall network communication rate, outperforming\ncentralized benchmarks even when the number of users doubles with respect to\nthe initial training point.",
          "link": "http://arxiv.org/abs/2106.02540",
          "publishedOn": "2021-06-07T03:06:13.932Z",
          "wordCount": 621,
          "title": "Transferable and Distributed User Association Policies for 5G and Beyond Networks. (arXiv:2106.02540v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02096",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Yu_B/0/1/0/all/0/1\">Byeongsu Yu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+You_K/0/1/0/all/0/1\">Kisung You</a>",
          "description": "We introduce a linear dimensionality reduction technique preserving\ntopological features via persistent homology. The method is designed to find\nlinear projection $L$ which preserves the persistent diagram of a point cloud\n$\\mathbb{X}$ via simulated annealing. The projection $L$ induces a set of\ncanonical simplicial maps from the Rips (or \\v{C}ech) filtration of\n$\\mathbb{X}$ to that of $L\\mathbb{X}$. In addition to the distance between\npersistent diagrams, the projection induces a map between filtrations, called\nfiltration homomorphism. Using the filtration homomorphism, one can measure the\ndifference between shapes of two filtrations directly comparing simplicial\ncomplexes with respect to quasi-isomorphism $\\mu_{\\operatorname{quasi-iso}}$ or\nstrong homotopy equivalence $\\mu_{\\operatorname{equiv}}$. These\n$\\mu_{\\operatorname{quasi-iso}}$ and $\\mu_{\\operatorname{equiv}}$ measures how\nmuch portion of corresponding simplicial complexes is quasi-isomorphic or\nhomotopy equivalence respectively. We validate the effectiveness of our\nframework with simple examples.",
          "link": "http://arxiv.org/abs/2106.02096",
          "publishedOn": "2021-06-07T03:06:13.913Z",
          "wordCount": 566,
          "title": "Shape-Preserving Dimensionality Reduction : An Algorithm and Measures of Topological Equivalence. (arXiv:2106.02096v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02601",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Kotary_J/0/1/0/all/0/1\">James Kotary</a>, <a href=\"http://arxiv.org/find/math/1/au:+Fioretto_F/0/1/0/all/0/1\">Ferdinando Fioretto</a>, <a href=\"http://arxiv.org/find/math/1/au:+Hentenryck_P/0/1/0/all/0/1\">Pascal Van Hentenryck</a>",
          "description": "Optimization problems are ubiquitous in our societies and are present in\nalmost every segment of the economy. Most of these optimization problems are\nNP-hard and computationally demanding, often requiring approximate solutions\nfor large-scale instances. Machine learning frameworks that learn to\napproximate solutions to such hard optimization problems are a potentially\npromising avenue to address these difficulties, particularly when many closely\nrelated problem instances must be solved repeatedly. Supervised learning\nframeworks can train a model using the outputs of pre-solved instances.\nHowever, when the outputs are themselves approximations, when the optimization\nproblem has symmetric solutions, and/or when the solver uses randomization,\nsolutions to closely related instances may exhibit large differences and the\nlearning task can become inherently more difficult. This paper demonstrates\nthis critical challenge, connects the volatility of the training data to the\nability of a model to approximate it, and proposes a method for producing\n(exact or approximate) solutions to optimization problems that are more\namenable to supervised learning tasks. The effectiveness of the method is\ntested on hard non-linear nonconvex and discrete combinatorial problems.",
          "link": "http://arxiv.org/abs/2106.02601",
          "publishedOn": "2021-06-07T03:06:13.902Z",
          "wordCount": 605,
          "title": "Learning Hard Optimization Problems: A Data Generation Perspective. (arXiv:2106.02601v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02363",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Cheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sungjin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Sunghyun Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Han Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Young-Bum Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarikaya_R/0/1/0/all/0/1\">Ruhi Sarikaya</a>",
          "description": "Real-world machine learning systems are achieving remarkable performance in\nterms of coarse-grained metrics like overall accuracy and F-1 score. However,\nmodel improvement and development often require fine-grained modeling on\nindividual data subsets or slices, for instance, the data slices where the\nmodels have unsatisfactory results. In practice, it gives tangible values for\ndeveloping such models that can pay extra attention to critical or interested\nslices while retaining the original overall performance. This work extends the\nrecent slice-based learning (SBL)~\\cite{chen2019slice} with a mixture of\nattentions (MoA) to learn slice-aware dual attentive representations. We\nempirically show that the MoA approach outperforms the baseline method as well\nas the original SBL approach on monitored slices with two natural language\nunderstanding (NLU) tasks.",
          "link": "http://arxiv.org/abs/2106.02363",
          "publishedOn": "2021-06-07T03:06:13.894Z",
          "wordCount": 556,
          "title": "Learning Slice-Aware Representations with Mixture of Attentions. (arXiv:2106.02363v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02220",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Han_M/0/1/0/all/0/1\">Manhyung Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jeonghyeok Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_T/0/1/0/all/0/1\">Taewoong Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jung Hoon Han</a>",
          "description": "The fluctuation-dissipation theorem (FDT) is a simple yet powerful\nconsequence of the first-order differential equation governing the dynamics of\nsystems subject simultaneously to dissipative and stochastic forces. The linear\nlearning dynamics, in which the input vector maps to the output vector by a\nlinear matrix whose elements are the subject of learning, has a stochastic\nversion closely mimicking the Langevin dynamics when a full-batch gradient\ndescent scheme is replaced by that of stochastic gradient descent. We derive a\ngeneralized FDT for the stochastic linear learning dynamics and verify its\nvalidity among the well-known machine learning data sets such as MNIST,\nCIFAR-10 and EMNIST.",
          "link": "http://arxiv.org/abs/2106.02220",
          "publishedOn": "2021-06-07T03:06:13.888Z",
          "wordCount": 531,
          "title": "Fluctuation-dissipation Type Theorem in Stochastic Linear Learning. (arXiv:2106.02220v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02097",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1\">Mingde Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luan_S/0/1/0/all/0/1\">Sitao Luan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shuyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1\">Doina Precup</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>",
          "description": "We present an end-to-end, model-based deep reinforcement learning agent which\ndynamically attends to relevant parts of its state, in order to plan and to\ngeneralize better out-of-distribution. The agent's architecture uses a set\nrepresentation and a bottleneck mechanism, forcing the number of entities to\nwhich the agent attends at each planning step to be small. In experiments with\ncustomized MiniGrid environments with different dynamics, we observe that the\ndesign allows agents to learn to plan effectively, by attending to the relevant\nobjects, leading to better out-of-distribution generalization.",
          "link": "http://arxiv.org/abs/2106.02097",
          "publishedOn": "2021-06-07T03:06:13.871Z",
          "wordCount": 518,
          "title": "A Consciousness-Inspired Planning Agent for Model-Based Reinforcement Learning. (arXiv:2106.02097v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02479",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bungert_L/0/1/0/all/0/1\">Leon Bungert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roith_T/0/1/0/all/0/1\">Tim Roith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenbrinck_D/0/1/0/all/0/1\">Daniel Tenbrinck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burger_M/0/1/0/all/0/1\">Martin Burger</a>",
          "description": "We propose a novel strategy for Neural Architecture Search (NAS) based on\nBregman iterations. Starting from a sparse neural network our gradient-based\none-shot algorithm gradually adds relevant parameters in an inverse scale space\nmanner. This allows the network to choose the best architecture in the search\nspace which makes it well-designed for a given task, e.g., by adding neurons or\nskip connections. We demonstrate that using our approach one can unveil, for\ninstance, residual autoencoders for denoising, deblurring, and classification\ntasks. Code is available at https://github.com/TimRoith/BregmanLearning.",
          "link": "http://arxiv.org/abs/2106.02479",
          "publishedOn": "2021-06-07T03:06:13.865Z",
          "wordCount": 530,
          "title": "Neural Architecture Search via Bregman Iterations. (arXiv:2106.02479v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02105",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Springer_J/0/1/0/all/0/1\">Jacob M. Springer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitchell_M/0/1/0/all/0/1\">Melanie Mitchell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kenyon_G/0/1/0/all/0/1\">Garrett T. Kenyon</a>",
          "description": "Adversarial examples for neural network image classifiers are known to be\ntransferable: examples optimized to be misclassified by a source classifier are\noften misclassified as well by classifiers with different architectures.\nHowever, targeted adversarial examples -- optimized to be classified as a\nchosen target class -- tend to be less transferable between architectures.\nWhile prior research on constructing transferable targeted attacks has focused\non improving the optimization procedure, in this work we examine the role of\nthe source classifier. Here, we show that training the source classifier to be\n\"slightly robust\" -- that is, robust to small-magnitude adversarial examples --\nsubstantially improves the transferability of targeted attacks, even between\narchitectures as different as convolutional neural networks and transformers.\nWe argue that this result supports a non-intuitive hypothesis: on the spectrum\nfrom non-robust (standard) to highly robust classifiers, those that are only\nslightly robust exhibit the most universal features -- ones that tend to\noverlap with the features learned by other classifiers trained on the same\ndataset. The results we present provide insight into the nature of adversarial\nexamples as well as the mechanisms underlying so-called \"robust\" classifiers.",
          "link": "http://arxiv.org/abs/2106.02105",
          "publishedOn": "2021-06-07T03:06:13.858Z",
          "wordCount": 634,
          "title": "A Little Robustness Goes a Long Way: Leveraging Universal Features for Targeted Transfer Attacks. (arXiv:2106.02105v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02195",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chenghao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+WU_C/0/1/0/all/0/1\">Chengjie WU</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tonghan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1\">Qianchuan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chongjie Zhang</a>",
          "description": "Recently, deep multi-agent reinforcement learning (MARL) has shown the\npromise to solve complex cooperative tasks. Its success is partly because of\nparameter sharing among agents. However, such sharing may lead agents to behave\nsimilarly and limit their coordination capacity. In this paper, we aim to\nintroduce diversity in both optimization and representation of shared\nmulti-agent reinforcement learning. Specifically, we propose an\ninformation-theoretical regularization to maximize the mutual information\nbetween agents' identities and their trajectories, encouraging extensive\nexploration and diverse individualized behaviors. In representation, we\nincorporate agent-specific modules in the shared neural network architecture,\nwhich are regularized by L1-norm to promote learning sharing among agents while\nkeeping necessary diversity. Empirical results show that our method achieves\nstate-of-the-art performance on Google Research Football and super hard\nStarCraft II micromanagement tasks.",
          "link": "http://arxiv.org/abs/2106.02195",
          "publishedOn": "2021-06-07T03:06:13.852Z",
          "wordCount": 554,
          "title": "Celebrating Diversity in Shared Multi-Agent Reinforcement Learning. (arXiv:2106.02195v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.01179",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abboud_R/0/1/0/all/0/1\">Ralph Abboud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ceylan_I/0/1/0/all/0/1\">&#x130;smail &#x130;lkan Ceylan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grohe_M/0/1/0/all/0/1\">Martin Grohe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lukasiewicz_T/0/1/0/all/0/1\">Thomas Lukasiewicz</a>",
          "description": "Graph neural networks (GNNs) are effective models for representation learning\non relational data. However, standard GNNs are limited in their expressive\npower, as they cannot distinguish graphs beyond the capability of the\nWeisfeiler-Leman graph isomorphism heuristic. In order to break this\nexpressiveness barrier, GNNs have been enhanced with random node initialization\n(RNI), where the idea is to train and run the models with randomized initial\nnode features. In this work, we analyze the expressive power of GNNs with RNI,\nand prove that these models are universal, a first such result for GNNs not\nrelying on computationally demanding higher-order properties. This universality\nresult holds even with partially randomized initial node features, and\npreserves the invariance properties of GNNs in expectation. We then empirically\nanalyze the effect of RNI on GNNs, based on carefully constructed datasets. Our\nempirical findings support the superior performance of GNNs with RNI over\nstandard GNNs.",
          "link": "http://arxiv.org/abs/2010.01179",
          "publishedOn": "2021-06-07T03:06:13.844Z",
          "wordCount": 638,
          "title": "The Surprising Power of Graph Neural Networks with Random Node Initialization. (arXiv:2010.01179v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.10201",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1\">Jingxiu Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shepperd_M/0/1/0/all/0/1\">Martin Shepperd</a>",
          "description": "Context: Software engineering researchers have undertaken many experiments\ninvestigating the potential of software defect prediction algorithms.\nUnfortunately, some widely used performance metrics are known to be\nproblematic, most notably F1, but nevertheless F1 is widely used.\n\nObjective: To investigate the potential impact of using F1 on the validity of\nthis large body of research.\n\nMethod: We undertook a systematic review to locate relevant experiments and\nthen extract all pairwise comparisons of defect prediction performance using F1\nand the un-biased Matthews correlation coefficient (MCC).\n\nResults: We found a total of 38 primary studies. These contain 12,471 pairs\nof results. Of these, 21.95% changed direction when the MCC metric is used\ninstead of the biased F1 metric. Unfortunately, we also found evidence\nsuggesting that F1 remains widely used in software defect prediction research.\n\nConclusions: We reiterate the concerns of statisticians that the F1 is a\nproblematic metric outside of an information retrieval context, since we are\nconcerned about both classes (defect-prone and not defect-prone units). This\ninappropriate usage has led to a substantial number (more than one fifth) of\nerroneous (in terms of direction) results. Therefore we urge researchers to (i)\nuse an unbiased metric and (ii) publish detailed results including confusion\nmatrices such that alternative analyses become possible.",
          "link": "http://arxiv.org/abs/2103.10201",
          "publishedOn": "2021-06-07T03:06:13.837Z",
          "wordCount": 706,
          "title": "The impact of using biased performance metrics on software defect prediction research. (arXiv:2103.10201v3 [cs.SE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02433",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ozan_S/0/1/0/all/0/1\">&#x15e;&#xfc;kr&#xfc; Ozan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iheme_L/0/1/0/all/0/1\">Leonardo Obinna Iheme</a>",
          "description": "This work presents a practical solution to the problem of call center agent\nmalpractice. A semi-supervised framework comprising of non-linear power\ntransformation, neural feature learning and k-means clustering is outlined. We\nput these building blocks together and tune the parameters so that the best\nperformance was obtained. The data used in the experiments is obtained from our\nin-house call center. It is made up of recorded agent-customer conversations\nwhich have been annotated using a convolutional neural network based segmenter.\nThe methods provided a means of tuning the parameters of the neural network to\nachieve a desirable result. We show that, using our proposed framework, it is\npossible to significantly reduce the malpractice classification error of a\nk-means-only clustering model which would serve the same purpose. Additionally,\nby presenting the amount of silence per call as a key performance indicator, we\nshow that the proposed system has enhanced agents performance at our call\ncenter since deployment.",
          "link": "http://arxiv.org/abs/2106.02433",
          "publishedOn": "2021-06-07T03:06:13.820Z",
          "wordCount": 598,
          "title": "A Novel Semi-supervised Framework for Call Center Agent Malpractice Detection via Neural Feature Learning. (arXiv:2106.02433v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.07849",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdali_S/0/1/0/all/0/1\">Sara Abdali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurav_R/0/1/0/all/0/1\">Rutuja Gurav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menon_S/0/1/0/all/0/1\">Siddharth Menon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fonseca_D/0/1/0/all/0/1\">Daniel Fonseca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Entezari_N/0/1/0/all/0/1\">Negin Entezari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1\">Neil Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papalexakis_E/0/1/0/all/0/1\">Evangelos E. Papalexakis</a>",
          "description": "Can the look and the feel of a website give information about the\ntrustworthiness of an article? In this paper, we propose to use a promising,\nyet neglected aspect in detecting the misinformativeness: the overall look of\nthe domain webpage. To capture this overall look, we take screenshots of news\narticles served by either misinformative or trustworthy web domains and\nleverage a tensor decomposition based semi-supervised classification technique.\nThe proposed approach i.e., VizFake is insensitive to a number of image\ntransformations such as converting the image to grayscale, vectorizing the\nimage and losing some parts of the screenshots. VizFake leverages a very small\namount of known labels, mirroring realistic and practical scenarios, where\nlabels (especially for known misinformative articles), are scarce and quickly\nbecome dated. The F1 score of VizFake on a dataset of 50k screenshots of news\narticles spanning more than 500 domains is roughly 85% using only 5% of ground\ntruth labels. Furthermore, tensor representations of VizFake, obtained in an\nunsupervised manner, allow for exploratory analysis of the data that provides\nvaluable insights into the problem. Finally, we compare VizFake with deep\ntransfer learning, since it is a very popular black-box approach for image\nclassification and also well-known text text-based methods. VizFake achieves\ncompetitive accuracy with deep transfer learning models while being two orders\nof magnitude faster and not requiring laborious hyper-parameter tuning.",
          "link": "http://arxiv.org/abs/2102.07849",
          "publishedOn": "2021-06-07T03:06:13.813Z",
          "wordCount": 706,
          "title": "Identifying Misinformation from Website Screenshots. (arXiv:2102.07849v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02170",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bhati_S/0/1/0/all/0/1\">Saurabhchand Bhati</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Villalba_J/0/1/0/all/0/1\">Jes&#xfa;s Villalba</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zelasko_P/0/1/0/all/0/1\">Piotr &#x17b;elasko</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moro_Velazquez_L/0/1/0/all/0/1\">Laureano Moro-Velazquez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dehak_N/0/1/0/all/0/1\">Najim Dehak</a>",
          "description": "Automatic detection of phoneme or word-like units is one of the core\nobjectives in zero-resource speech processing. Recent attempts employ\nself-supervised training methods, such as contrastive predictive coding (CPC),\nwhere the next frame is predicted given past context. However, CPC only looks\nat the audio signal's frame-level structure. We overcome this limitation with a\nsegmental contrastive predictive coding (SCPC) framework that can model the\nsignal structure at a higher level e.g. at the phoneme level. In this\nframework, a convolutional neural network learns frame-level representation\nfrom the raw waveform via noise-contrastive estimation (NCE). A differentiable\nboundary detector finds variable-length segments, which are then used to\noptimize a segment encoder via NCE to learn segment representations. The\ndifferentiable boundary detector allows us to train frame-level and\nsegment-level encoders jointly. Typically, phoneme and word segmentation are\ntreated as separate tasks. We unify them and experimentally show that our\nsingle model outperforms existing phoneme and word segmentation methods on\nTIMIT and Buckeye datasets. We analyze the impact of boundary threshold and\nwhen is the right time to include the segmental loss in the learning process.",
          "link": "http://arxiv.org/abs/2106.02170",
          "publishedOn": "2021-06-07T03:06:13.788Z",
          "wordCount": 628,
          "title": "Segmental Contrastive Predictive Coding for Unsupervised Word Segmentation. (arXiv:2106.02170v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2105.14629",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Li Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_R/0/1/0/all/0/1\">Richard Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Di Wang</a>",
          "description": "Diffusion is a fundamental graph procedure and has been a basic building\nblock in a wide range of theoretical and empirical applications such as graph\npartitioning and semi-supervised learning on graphs. In this paper, we study\ncomputationally efficient diffusion primitives beyond random walk.\n\nWe design an $\\widetilde{O}(m)$-time randomized algorithm for the\n$\\ell_2$-norm flow diffusion problem, a recently proposed diffusion model based\non network flow with demonstrated graph clustering related applications both in\ntheory and in practice. Examples include finding locally-biased low conductance\ncuts. Using a known connection between the optimal dual solution of the flow\ndiffusion problem and the local cut structure, our algorithm gives an\nalternative approach for finding such cuts in nearly linear time.\n\nFrom a technical point of view, our algorithm contributes a novel way of\ndealing with inequality constraints in graph optimization problems. It adapts\nthe high-level algorithmic framework of nearly linear time Laplacian system\nsolvers, but requires several new tools: vertex elimination under constraints,\na new family of graph ultra-sparsifiers, and accelerated proximal gradient\nmethods with inexact proximal mapping computation.",
          "link": "http://arxiv.org/abs/2105.14629",
          "publishedOn": "2021-06-07T03:06:13.772Z",
          "wordCount": 619,
          "title": "$\\ell_2$-norm Flow Diffusion in Near-Linear Time. (arXiv:2105.14629v2 [cs.DS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02626",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Bena_G/0/1/0/all/0/1\">Gabriel B&#xe9;na</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Goodman_D/0/1/0/all/0/1\">Dan F. M. Goodman</a>",
          "description": "Modularity of neural networks -- both biological and artificial -- can be\nthought of either structurally or functionally, and the relationship between\nthese is an open question. We show that enforcing structural modularity via\nsparse connectivity between two dense sub-networks which need to communicate to\nsolve the task leads to functional specialization of the sub-networks, but only\nat extreme levels of sparsity. With even a moderate number of interconnections,\nthe sub-networks become functionally entangled. Defining functional\nspecialization is in itself a challenging problem without a universally agreed\nsolution. To address this, we designed three different measures of\nspecialization (based on weight masks, retraining and correlation) and found\nthem to qualitatively agree. Our results have implications in both neuroscience\nand machine learning. For neuroscience, it shows that we cannot conclude that\nthere is functional modularity simply by observing moderate levels of\nstructural modularity: knowing the brain's connectome is not sufficient for\nunderstanding how it breaks down into functional modules. For machine learning,\nusing structure to promote functional modularity -- which may be important for\nrobustness and generalization -- may require extremely narrow bottlenecks\nbetween modules.",
          "link": "http://arxiv.org/abs/2106.02626",
          "publishedOn": "2021-06-07T03:06:13.761Z",
          "wordCount": 630,
          "title": "Extreme sparsity gives rise to functional specialization. (arXiv:2106.02626v1 [q-bio.NC])"
        },
        {
          "id": "http://arxiv.org/abs/2003.10130",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1\">Bo Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziyan Zhang</a>",
          "description": "Graph Neural Networks (GNNs) are gaining increasing attention on graph data\nlearning tasks in recent years. However, in many applications, graph may be\ncoming in an incomplete form where attributes of graph nodes are partially\nunknown/missing. Existing GNNs are generally designed on complete graphs which\ncan not deal with attribute-incomplete graph data directly. To address this\nproblem, we develop a novel partial aggregation based GNNs, named Partial Graph\nNeural Networks (PaGNNs), for attribute-incomplete graph representation and\nlearning. Our work is motivated by the observation that the neighborhood\naggregation function in standard GNNs can be equivalently viewed as the\nneighborhood reconstruction formulation. Based on it, we define two novel\npartial aggregation (reconstruction) functions on incomplete graph and derive\nPaGNNs for incomplete graph data learning. Extensive experiments on several\ndatasets demonstrate the effectiveness and efficiency of the proposed PaGNNs.",
          "link": "http://arxiv.org/abs/2003.10130",
          "publishedOn": "2021-06-07T03:06:13.648Z",
          "wordCount": 600,
          "title": "Incomplete Graph Representation and Learning via Partial Graph Neural Networks. (arXiv:2003.10130v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02193",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mazoure_B/0/1/0/all/0/1\">Bogdan Mazoure</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_A/0/1/0/all/0/1\">Ahmed M. Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+MacAlpine_P/0/1/0/all/0/1\">Patrick MacAlpine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hjelm_R/0/1/0/all/0/1\">R Devon Hjelm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolobov_A/0/1/0/all/0/1\">Andrey Kolobov</a>",
          "description": "A highly desirable property of a reinforcement learning (RL) agent -- and a\nmajor difficulty for deep RL approaches -- is the ability to generalize\npolicies learned on a few tasks over a high-dimensional observation space to\nsimilar tasks not seen during training. Many promising approaches to this\nchallenge consider RL as a process of training two functions simultaneously: a\ncomplex nonlinear encoder that maps high-dimensional observations to a latent\nrepresentation space, and a simple linear policy over this space. We posit that\na superior encoder for zero-shot generalization in RL can be trained by using\nsolely an auxiliary SSL objective if the training process encourages the\nencoder to map behaviorally similar observations to similar representations, as\nreward-based signal can cause overfitting in the encoder (Raileanu et al.,\n2021). We propose Cross-Trajectory Representation Learning (CTRL), a method\nthat runs within an RL agent and conditions its encoder to recognize behavioral\nsimilarity in observations by applying a novel SSL objective to pairs of\ntrajectories from the agent's policies. CTRL can be viewed as having the same\neffect as inducing a pseudo-bisimulation metric but, crucially, avoids the use\nof rewards and associated overfitting risks. Our experiments ablate various\ncomponents of CTRL and demonstrate that in combination with PPO it achieves\nbetter generalization performance on the challenging Procgen benchmark suite\n(Cobbe et al., 2020).",
          "link": "http://arxiv.org/abs/2106.02193",
          "publishedOn": "2021-06-07T03:06:13.624Z",
          "wordCount": 653,
          "title": "Cross-Trajectory Representation Learning for Zero-Shot Generalization in RL. (arXiv:2106.02193v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01908",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yuming Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Ziyi Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Menghan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1\">Jie Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1\">Philip H.S. Torr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1\">Ling Shao</a>",
          "description": "Recent advances in self-supervised learning with instance-level contrastive\nobjectives facilitate unsupervised clustering. However, a standalone datum is\nnot perceiving the context of the holistic cluster, and may undergo sub-optimal\nassignment. In this paper, we extend the mainstream contrastive learning\nparadigm to a cluster-level scheme, where all the data subjected to the same\ncluster contribute to a unified representation that encodes the context of each\ndata group. Contrastive learning with this representation then rewards the\nassignment of each datum. To implement this vision, we propose twin-contrast\nclustering (TCC). We define a set of categorical variables as clustering\nassignment confidence, which links the instance-level learning track with the\ncluster-level one. On one hand, with the corresponding assignment variables\nbeing the weight, a weighted aggregation along the data points implements the\nset representation of a cluster. We further propose heuristic cluster\naugmentation equivalents to enable cluster-level contrastive learning. On the\nother hand, we derive the evidence lower-bound of the instance-level\ncontrastive objective with the assignments. By reparametrizing the assignment\nvariables, TCC is trained end-to-end, requiring no alternating steps. Extensive\nexperiments show that TCC outperforms the state-of-the-art on challenging\nbenchmarks.",
          "link": "http://arxiv.org/abs/2106.01908",
          "publishedOn": "2021-06-04T01:12:31.953Z",
          "wordCount": 619,
          "title": "You Never Cluster Alone. (arXiv:2106.01908v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01950",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wennberg_U/0/1/0/all/0/1\">Ulme Wennberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henter_G/0/1/0/all/0/1\">Gustav Eje Henter</a>",
          "description": "Mechanisms for encoding positional information are central for\ntransformer-based language models. In this paper, we analyze the position\nembeddings of existing language models, finding strong evidence of translation\ninvariance, both for the embeddings themselves and for their effect on\nself-attention. The degree of translation invariance increases during training\nand correlates positively with model performance. Our findings lead us to\npropose translation-invariant self-attention (TISA), which accounts for the\nrelative position between tokens in an interpretable fashion without needing\nconventional position embeddings. Our proposal has several theoretical\nadvantages over existing position-representation approaches. Experiments show\nthat it improves on regular ALBERT on GLUE tasks, while only adding orders of\nmagnitude less positional parameters.",
          "link": "http://arxiv.org/abs/2106.01950",
          "publishedOn": "2021-06-04T01:12:31.948Z",
          "wordCount": 552,
          "title": "The Case for Translation-Invariant Self-Attention in Transformer-Based Language Models. (arXiv:2106.01950v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02019",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lingjie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Habermann_M/0/1/0/all/0/1\">Marc Habermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudnev_V/0/1/0/all/0/1\">Viktor Rudnev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_K/0/1/0/all/0/1\">Kripasindhu Sarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jiatao Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theobalt_C/0/1/0/all/0/1\">Christian Theobalt</a>",
          "description": "We propose Neural Actor (NA), a new method for high-quality synthesis of\nhumans from arbitrary viewpoints and under arbitrary controllable poses. Our\nmethod is built upon recent neural scene representation and rendering works\nwhich learn representations of geometry and appearance from only 2D images.\nWhile existing works demonstrated compelling rendering of static scenes and\nplayback of dynamic scenes, photo-realistic reconstruction and rendering of\nhumans with neural implicit methods, in particular under user-controlled novel\nposes, is still difficult. To address this problem, we utilize a coarse body\nmodel as the proxy to unwarp the surrounding 3D space into a canonical pose. A\nneural radiance field learns pose-dependent geometric deformations and pose-\nand view-dependent appearance effects in the canonical space from multi-view\nvideo input. To synthesize novel views of high fidelity dynamic geometry and\nappearance, we leverage 2D texture maps defined on the body model as latent\nvariables for predicting residual deformations and the dynamic appearance.\nExperiments demonstrate that our method achieves better quality than the\nstate-of-the-arts on playback as well as novel pose synthesis, and can even\ngeneralize well to new poses that starkly differ from the training poses.\nFurthermore, our method also supports body shape control of the synthesized\nresults.",
          "link": "http://arxiv.org/abs/2106.02019",
          "publishedOn": "2021-06-04T01:12:31.919Z",
          "wordCount": 647,
          "title": "Neural Actor: Neural Free-view Synthesis of Human Actors with Pose Control. (arXiv:2106.02019v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/1905.12629",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Paolizzo_F/0/1/0/all/0/1\">Fabio Paolizzo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pichierri_N/0/1/0/all/0/1\">Natalia Pichierri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casali_D/0/1/0/all/0/1\">Daniele Casali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giardino_D/0/1/0/all/0/1\">Daniele Giardino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matta_M/0/1/0/all/0/1\">Marco Matta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Costantini_G/0/1/0/all/0/1\">Giovanni Costantini</a>",
          "description": "Achieving advancements in automatic recognition of emotions that music can\ninduce require considering multiplicity and simultaneity of emotions.\nComparison of different machine learning algorithms performing multilabel and\nmulticlass classification is the core of our work. The study analyzes the\nimplementation of the Geneva Emotional Music Scale 9 in the Emotify music\ndataset and investigates its adoption from a machine-learning perspective. We\napproach the scenario of emotions expression/induction through music as a\nmultilabel and multiclass problem, where multiple emotion labels can be adopted\nfor the same music track by each annotator (multilabel), and each emotion can\nbe identified or not in the music (multiclass). The aim is the automatic\nrecognition of induced emotions through music.",
          "link": "http://arxiv.org/abs/1905.12629",
          "publishedOn": "2021-06-04T01:12:31.913Z",
          "wordCount": 621,
          "title": "A New Multilabel System for Automatic Music Emotion Recognition. (arXiv:1905.12629v2 [cs.SD] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02036",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Girdhar_R/0/1/0/all/0/1\">Rohit Girdhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grauman_K/0/1/0/all/0/1\">Kristen Grauman</a>",
          "description": "We propose Anticipative Video Transformer (AVT), an end-to-end\nattention-based video modeling architecture that attends to the previously\nobserved video in order to anticipate future actions. We train the model\njointly to predict the next action in a video sequence, while also learning\nframe feature encoders that are predictive of successive future frames'\nfeatures. Compared to existing temporal aggregation strategies, AVT has the\nadvantage of both maintaining the sequential progression of observed actions\nwhile still capturing long-range dependencies--both critical for the\nanticipation task. Through extensive experiments, we show that AVT obtains the\nbest reported performance on four popular action anticipation benchmarks:\nEpicKitchens-55, EpicKitchens-100, EGTEA Gaze+, and 50-Salads, including\noutperforming all submissions to the EpicKitchens-100 CVPR'21 challenge.",
          "link": "http://arxiv.org/abs/2106.02036",
          "publishedOn": "2021-06-04T01:12:31.904Z",
          "wordCount": 557,
          "title": "Anticipative Video Transformer. (arXiv:2106.02036v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Junyoung Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choo_J/0/1/0/all/0/1\">Jinhyun Choo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jinkyoo Park</a>",
          "description": "We propose the convergent graph solver (CGS), a deep learning method that\nlearns iterative mappings to predict the properties of a graph system at its\nstationary state (fixed point) with guaranteed convergence. CGS systematically\ncomputes the fixed points of a target graph system and decodes them to estimate\nthe stationary properties of the system without the prior knowledge of existing\nsolvers or intermediate solutions. The forward propagation of CGS proceeds in\nthree steps: (1) constructing the input dependent linear contracting iterative\nmaps, (2) computing the fixed-points of the linear maps, and (3) decoding the\nfixed-points to estimate the properties. The contractivity of the constructed\nlinear maps guarantees the existence and uniqueness of the fixed points\nfollowing the Banach fixed point theorem. To train CGS efficiently, we also\nderive a tractable analytical expression for its gradient by leveraging the\nimplicit function theorem. We evaluate the performance of CGS by applying it to\nvarious network-analytic and graph benchmark problems. The results indicate\nthat CGS has competitive capabilities for predicting the stationary properties\nof graph systems, irrespective of whether the target systems are linear or\nnon-linear. CGS also shows high performance for graph classification problems\nwhere the existence or the meaning of a fixed point is hard to be clearly\ndefined, which highlights the potential of CGS as a general graph neural\nnetwork architecture.",
          "link": "http://arxiv.org/abs/2106.01680",
          "publishedOn": "2021-06-04T01:12:31.710Z",
          "wordCount": 642,
          "title": "Convergent Graph Solvers. (arXiv:2106.01680v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01863",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yuming Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_K/0/1/0/all/0/1\">Kelvin C.K. Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xintao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loy_C/0/1/0/all/0/1\">Chen Change Loy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Ziwei Liu</a>",
          "description": "Reference-based Super-Resolution (Ref-SR) has recently emerged as a promising\nparadigm to enhance a low-resolution (LR) input image by introducing an\nadditional high-resolution (HR) reference image. Existing Ref-SR methods mostly\nrely on implicit correspondence matching to borrow HR textures from reference\nimages to compensate for the information loss in input images. However,\nperforming local transfer is difficult because of two gaps between input and\nreference images: the transformation gap (e.g. scale and rotation) and the\nresolution gap (e.g. HR and LR). To tackle these challenges, we propose\nC2-Matching in this work, which produces explicit robust matching crossing\ntransformation and resolution. 1) For the transformation gap, we propose a\ncontrastive correspondence network, which learns transformation-robust\ncorrespondences using augmented views of the input image. 2) For the resolution\ngap, we adopt a teacher-student correlation distillation, which distills\nknowledge from the easier HR-HR matching to guide the more ambiguous LR-HR\nmatching. 3) Finally, we design a dynamic aggregation module to address the\npotential misalignment issue. In addition, to faithfully evaluate the\nperformance of Ref-SR under a realistic setting, we contribute the\nWebly-Referenced SR (WR-SR) dataset, mimicking the practical usage scenario.\nExtensive experiments demonstrate that our proposed C2-Matching significantly\noutperforms state of the arts by over 1dB on the standard CUFED5 benchmark.\nNotably, it also shows great generalizability on WR-SR dataset as well as\nrobustness across large scale and rotation transformations.",
          "link": "http://arxiv.org/abs/2106.01863",
          "publishedOn": "2021-06-04T01:12:31.654Z",
          "wordCount": 679,
          "title": "Robust Reference-based Super-Resolution via C2-Matching. (arXiv:2106.01863v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01607",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jong_M/0/1/0/all/0/1\">Michiel de Jong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishna_S/0/1/0/all/0/1\">Satyapriya Krishna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1\">Anuva Agarwal</a>",
          "description": "Training a reinforcement learning agent to carry out natural language\ninstructions is limited by the available supervision, i.e. knowing when the\ninstruction has been carried out. We adapt the CLEVR visual question answering\ndataset to generate complex natural language navigation instructions and\naccompanying scene graphs, yielding an environment-agnostic supervised dataset.\nTo demonstrate the use of this data set, we map the scenes to the VizDoom\nenvironment and use the architecture in \\citet{gatedattention} to train an\nagent to carry out these more complex language instructions.",
          "link": "http://arxiv.org/abs/2106.01607",
          "publishedOn": "2021-06-04T01:12:31.615Z",
          "wordCount": 527,
          "title": "Grounding Complex Navigational Instructions Using Scene Graphs. (arXiv:2106.01607v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01703",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Diwan_N/0/1/0/all/0/1\">Nirav Diwan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakravorty_T/0/1/0/all/0/1\">Tanmoy Chakravorty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafiq_Z/0/1/0/all/0/1\">Zubair Shafiq</a>",
          "description": "There are concerns that the ability of language models (LMs) to generate high\nquality synthetic text can be misused to launch spam, disinformation, or\npropaganda. Therefore, the research community is actively working on developing\napproaches to detect whether a given text is organic or synthetic. While this\nis a useful first step, it is important to be able to further fingerprint the\nauthor LM to attribute its origin. Prior work on fingerprinting LMs is limited\nto attributing synthetic text generated by a handful (usually < 10) of\npre-trained LMs. However, LMs such as GPT2 are commonly fine-tuned in a myriad\nof ways (e.g., on a domain-specific text corpus) before being used to generate\nsynthetic text. It is challenging to fingerprinting fine-tuned LMs because the\nuniverse of fine-tuned LMs is much larger in realistic scenarios. To address\nthis challenge, we study the problem of large-scale fingerprinting of\nfine-tuned LMs in the wild. Using a real-world dataset of synthetic text\ngenerated by 108 different fine-tuned LMs, we conduct comprehensive experiments\nto demonstrate the limitations of existing fingerprinting approaches. Our\nresults show that fine-tuning itself is the most effective in attributing the\nsynthetic text generated by fine-tuned LMs.",
          "link": "http://arxiv.org/abs/2106.01703",
          "publishedOn": "2021-06-04T01:12:31.186Z",
          "wordCount": 625,
          "title": "Fingerprinting Fine-tuned Language Models in the Wild. (arXiv:2106.01703v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01836",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Guo_Y/0/1/0/all/0/1\">Yuhang Guo</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Luo_X/0/1/0/all/0/1\">Xiao Luo</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chen_L/0/1/0/all/0/1\">Liang Chen</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Deng_M/0/1/0/all/0/1\">Minghua Deng</a>",
          "description": "Predicting DNA-protein binding is an important and classic problem in\nbioinformatics. Convolutional neural networks have outperformed conventional\nmethods in modeling the sequence specificity of DNA-protein binding. However,\nnone of the studies has utilized graph convolutional networks for motif\ninference. In this work, we propose to use graph convolutional networks for\nmotif inference. We build a sequence k-mer graph for the whole dataset based on\nk-mer co-occurrence and k-mer sequence relationship and then learn DNA Graph\nConvolutional Network (DNA-GCN) for the whole dataset. Our DNA-GCN is\ninitialized with a one-hot representation for all nodes, and it then jointly\nlearns the embeddings for both k-mers and sequences, as supervised by the known\nlabels of sequences. We evaluate our model on 50 datasets from ENCODE. DNA-GCN\nshows its competitive performance compared with the baseline model. Besides, we\nanalyze our model and design several different architectures to help fit\ndifferent datasets.",
          "link": "http://arxiv.org/abs/2106.01836",
          "publishedOn": "2021-06-04T01:12:30.471Z",
          "wordCount": 583,
          "title": "DNA-GCN: Graph convolutional networks for predicting DNA-protein binding. (arXiv:2106.01836v1 [q-bio.GN])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01708",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1\">Buliao Huang</a>",
          "description": "Incomplete instances with various missing attributes in many real-world\nscenes have brought challenges to the classification task. There are some\nmissing values imputation methods to fill the missing values with substitute\nvalues before classification. However, the separation between imputation and\nclassification may lead to inferior performance since label information are\nignored during imputation. Moreover, these imputation methods tend to\ninitialize these missing values with strong prior assumptions, while the\nunreliability of such initialization is rarely considered. To tackle these\nproblems, a novel semi-supervised conditional normalizing flow (SSCFlow) is\nproposed in this paper. SSCFlow explicitly utilizes the observed labels to\nfacilitate the imputation and classification simultaneously by employing a\nsemi-supervised algorithm to estimate the conditional probability density of\nmissing values. Moreover, SSCFlow takes the initialized missing values as\ncorrupted initial imputation and iteratively reconstructs their latent\nrepresentations with an overcomplete denoising autoencoder to approximate the\ntrue conditional probability density of missing values. Experiments have been\nconducted with real-world datasets to demonstrate the robustness and efficiency\nof the proposed algorithm.",
          "link": "http://arxiv.org/abs/2106.01708",
          "publishedOn": "2021-06-04T01:12:30.420Z",
          "wordCount": 595,
          "title": "Semi-supervised Conditional Density Estimation for Imputation and Classification of Incomplete Instances. (arXiv:2106.01708v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01739",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Paul_A/0/1/0/all/0/1\">Aditya Jyoti Paul</a>",
          "description": "Diabetic Retinopathy (DR) is a severe complication that may lead to retinal\nvascular damage and is one of the leading causes of vision impairment and\nblindness. DR broadly is classified into two stages - non-proliferative (NPDR),\nwhere there are almost no symptoms, except a few microaneurysms, and\nproliferative (PDR) involving a huge number of microaneurysms and hemorrhages,\nsoft and hard exudates, neo-vascularization, macular ischemia or a combination\nof these, making it easier to detect. More specifically, DR is usually\nclassified into five levels, labeled 0-4, from 0 indicating no DR to 4 which is\nmost severe. This paper firstly presents a discussion on the risk factors of\nthe disease, then surveys the recent literature on the topic followed by\nexamining certain techniques which were found to be highly effective in\nimproving the prognosis accuracy. Finally, a convolutional neural network model\nis proposed to detect all the stages of DR on a low-memory edge\nmicrocontroller. The model has a size of just 5.9 MB, accuracy and F1 score\nboth of 94% and an inference speed of about 20 frames per second.",
          "link": "http://arxiv.org/abs/2106.01739",
          "publishedOn": "2021-06-04T01:12:30.387Z",
          "wordCount": 664,
          "title": "Advances in Classifying the Stages of Diabetic Retinopathy Using Convolutional Neural Networks in Low Memory Edge Devices. (arXiv:2106.01739v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.15034",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Tang_F/0/1/0/all/0/1\">Fei Tang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Kopp_M/0/1/0/all/0/1\">Michael Kopp</a>",
          "description": "In their recent paper titled \"Large Associative Memory Problem in\nNeurobiology and Machine Learning\" [arXiv:2008.06996] the authors gave a\nbiologically plausible microscopic theory from which one can recover many dense\nassociative memory models discussed in the literature. We show that the layers\nof the recent \"MLP-mixer\" [arXiv:2105.01601] as well as the essentially\nequivalent model in [arXiv:2105.02723] are amongst them.",
          "link": "http://arxiv.org/abs/2105.15034",
          "publishedOn": "2021-06-04T01:12:30.066Z",
          "wordCount": 522,
          "title": "A remark on a paper of Krotov and Hopfield [arXiv:2008.06996]. (arXiv:2105.15034v2 [q-bio.NC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.02866",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Gupta_U/0/1/0/all/0/1\">Umang Gupta</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Stripelis_D/0/1/0/all/0/1\">Dimitris Stripelis</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lam_P/0/1/0/all/0/1\">Pradeep K. Lam</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Thompson_P/0/1/0/all/0/1\">Paul M. Thompson</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ambite_J/0/1/0/all/0/1\">Jos&#xe9; Luis Ambite</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Steeg_G/0/1/0/all/0/1\">Greg Ver Steeg</a>",
          "description": "Ensuring the privacy of research participants is vital, even more so in\nhealthcare environments. Deep learning approaches to neuroimaging require large\ndatasets, and this often necessitates sharing data between multiple sites,\nwhich is antithetical to the privacy objectives. Federated learning is a\ncommonly proposed solution to this problem. It circumvents the need for data\nsharing by sharing parameters during the training process. However, we\ndemonstrate that allowing access to parameters may leak private information\neven if data is never directly shared. In particular, we show that it is\npossible to infer if a sample was used to train the model given only access to\nthe model prediction (black-box) or access to the model itself (white-box) and\nsome leaked samples from the training data distribution. Such attacks are\ncommonly referred to as Membership Inference attacks. We show realistic\nMembership Inference attacks on deep learning models trained for 3D\nneuroimaging tasks in a centralized as well as decentralized setup. We\ndemonstrate feasible attacks on brain age prediction models (deep learning\nmodels that predict a person's age from their brain MRI scan). We correctly\nidentified whether an MRI scan was used in model training with a 60% to over\n80% success rate depending on model complexity and security assumptions.",
          "link": "http://arxiv.org/abs/2105.02866",
          "publishedOn": "2021-06-04T01:12:29.754Z",
          "wordCount": 686,
          "title": "Membership Inference Attacks on Deep Regression Models for Neuroimaging. (arXiv:2105.02866v2 [q-bio.QM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.03183",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Varre_A/0/1/0/all/0/1\">Aditya Varre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pillaud_Vivien_L/0/1/0/all/0/1\">Loucas Pillaud-Vivien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flammarion_N/0/1/0/all/0/1\">Nicolas Flammarion</a>",
          "description": "Motivated by the recent successes of neural networks that have the ability to\nfit the data perfectly and generalize well, we study the noiseless model in the\nfundamental least-squares setup. We assume that an optimum predictor fits\nperfectly inputs and outputs $\\langle \\theta_* , \\phi(X) \\rangle = Y$, where\n$\\phi(X)$ stands for a possibly infinite dimensional non-linear feature map. To\nsolve this problem, we consider the estimator given by the last iterate of\nstochastic gradient descent (SGD) with constant step-size. In this context, our\ncontribution is two fold: (i) from a (stochastic) optimization perspective, we\nexhibit an archetypal problem where we can show explicitly the convergence of\nSGD final iterate for a non-strongly convex problem with constant step-size\nwhereas usual results use some form of average and (ii) from a statistical\nperspective, we give explicit non-asymptotic convergence rates in the\nover-parameterized setting and leverage a fine-grained parameterization of the\nproblem to exhibit polynomial rates that can be faster than $O(1/T)$. The link\nwith reproducing kernel Hilbert spaces is established.",
          "link": "http://arxiv.org/abs/2102.03183",
          "publishedOn": "2021-06-04T01:12:29.705Z",
          "wordCount": 643,
          "title": "Last iterate convergence of SGD for Least-Squares in the Interpolation regime. (arXiv:2102.03183v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.08014",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Li_X/0/1/0/all/0/1\">Xiang Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_S/0/1/0/all/0/1\">Shusen Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chen_K/0/1/0/all/0/1\">Kun Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhihua Zhang</a>",
          "description": "We study distributed computing of the truncated singular value decomposition\nproblem. We develop an algorithm that we call \\texttt{LocalPower} for improving\ncommunication efficiency. Specifically, we uniformly partition the dataset\namong $m$ nodes and alternate between multiple (precisely $p$) local power\niterations and one global aggregation. In the aggregation, we propose to weight\neach local eigenvector matrix with orthogonal Procrustes transformation (OPT).\nAs a practical surrogate of OPT, sign-fixing, which uses a diagonal matrix with\n$\\pm 1$ entries as weights, has better computation complexity and stability in\nexperiments. We theoretically show that under certain assumptions\n\\texttt{LocalPower} lowers the required number of communications by a factor of\n$p$ to reach a constant accuracy. We also show that the strategy of\nperiodically decaying $p$ helps obtain high-precision solutions. We conduct\nexperiments to demonstrate the effectiveness of \\texttt{LocalPower}.",
          "link": "http://arxiv.org/abs/2002.08014",
          "publishedOn": "2021-06-04T01:12:29.690Z",
          "wordCount": 601,
          "title": "Communication-Efficient Distributed SVD via Local Power Iterations. (arXiv:2002.08014v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.14840",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Guo_Z/0/1/0/all/0/1\">Zhishuai Guo</a>, <a href=\"http://arxiv.org/find/math/1/au:+Xu_Y/0/1/0/all/0/1\">Yi Xu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yin_W/0/1/0/all/0/1\">Wotao Yin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Jin_R/0/1/0/all/0/1\">Rong Jin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yang_T/0/1/0/all/0/1\">Tianbao Yang</a>",
          "description": "In this paper, we demonstrate the power of a widely used stochastic estimator\nbased on moving average (SEMA) on a range of stochastic non-convex optimization\nproblems, which only requires {\\bf a general unbiased stochastic oracle}. We\nanalyze various stochastic methods (existing or newly proposed) based on the\n{\\bf variance recursion property} of SEMA for three families of non-convex\noptimization, namely standard stochastic non-convex minimization, stochastic\nnon-convex strongly-concave min-max optimization, and stochastic bilevel\noptimization. Our contributions include: (i) for standard stochastic non-convex\nminimization, we present a simple and intuitive proof of convergence for a\nfamily Adam-style methods (including Adam) with an increasing or large\n\"momentum\" parameter for the first-order moment, which gives an alternative yet\nmore natural way to guarantee Adam converge; (ii) for stochastic non-convex\nstrongly-concave min-max optimization, we present a single-loop stochastic\ngradient descent ascent method based on the moving average estimators and\nestablish its oracle complexity of $O(1/\\epsilon^4)$ without using a large\nmini-batch size, addressing a gap in the literature; (iii) for stochastic\nbilevel optimization, we present a single-loop stochastic method based on the\nmoving average estimators and establish its oracle complexity of $\\widetilde\nO(1/\\epsilon^4)$ without computing the inverse or SVD of the Hessian matrix,\nimproving state-of-the-art results. For all these problems, we also establish a\nvariance diminishing result for the used stochastic gradient estimators.",
          "link": "http://arxiv.org/abs/2104.14840",
          "publishedOn": "2021-06-04T01:12:29.670Z",
          "wordCount": 665,
          "title": "On Stochastic Moving-Average Estimators for Non-Convex Optimization. (arXiv:2104.14840v2 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.11929",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dosovitskiy_A/0/1/0/all/0/1\">Alexey Dosovitskiy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beyer_L/0/1/0/all/0/1\">Lucas Beyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolesnikov_A/0/1/0/all/0/1\">Alexander Kolesnikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weissenborn_D/0/1/0/all/0/1\">Dirk Weissenborn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1\">Xiaohua Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Unterthiner_T/0/1/0/all/0/1\">Thomas Unterthiner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dehghani_M/0/1/0/all/0/1\">Mostafa Dehghani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Minderer_M/0/1/0/all/0/1\">Matthias Minderer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heigold_G/0/1/0/all/0/1\">Georg Heigold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gelly_S/0/1/0/all/0/1\">Sylvain Gelly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uszkoreit_J/0/1/0/all/0/1\">Jakob Uszkoreit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1\">Neil Houlsby</a>",
          "description": "While the Transformer architecture has become the de-facto standard for\nnatural language processing tasks, its applications to computer vision remain\nlimited. In vision, attention is either applied in conjunction with\nconvolutional networks, or used to replace certain components of convolutional\nnetworks while keeping their overall structure in place. We show that this\nreliance on CNNs is not necessary and a pure transformer applied directly to\nsequences of image patches can perform very well on image classification tasks.\nWhen pre-trained on large amounts of data and transferred to multiple mid-sized\nor small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision\nTransformer (ViT) attains excellent results compared to state-of-the-art\nconvolutional networks while requiring substantially fewer computational\nresources to train.",
          "link": "http://arxiv.org/abs/2010.11929",
          "publishedOn": "2021-06-04T01:12:29.662Z",
          "wordCount": 668,
          "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. (arXiv:2010.11929v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.00382",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Dong-Ki Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Miao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riemer_M/0/1/0/all/0/1\">Matthew Riemer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">Chuangchuang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdulhai_M/0/1/0/all/0/1\">Marwa Abdulhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Habibi_G/0/1/0/all/0/1\">Golnaz Habibi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lopez_Cot_S/0/1/0/all/0/1\">Sebastian Lopez-Cot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tesauro_G/0/1/0/all/0/1\">Gerald Tesauro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+How_J/0/1/0/all/0/1\">Jonathan P. How</a>",
          "description": "A fundamental challenge in multiagent reinforcement learning is to learn\nbeneficial behaviors in a shared environment with other simultaneously learning\nagents. In particular, each agent perceives the environment as effectively\nnon-stationary due to the changing policies of other agents. Moreover, each\nagent is itself constantly learning, leading to natural non-stationarity in the\ndistribution of experiences encountered. In this paper, we propose a novel\nmeta-multiagent policy gradient theorem that directly accounts for the\nnon-stationary policy dynamics inherent to multiagent learning settings. This\nis achieved by modeling our gradient updates to consider both an agent's own\nnon-stationary policy dynamics and the non-stationary policy dynamics of other\nagents in the environment. We show that our theoretically grounded approach\nprovides a general solution to the multiagent learning problem, which\ninherently comprises all key aspects of previous state of the art approaches on\nthis topic. We test our method on a diverse suite of multiagent benchmarks and\ndemonstrate a more efficient ability to adapt to new agents as they learn than\nbaseline methods across the full spectrum of mixed incentive, competitive, and\ncooperative domains.",
          "link": "http://arxiv.org/abs/2011.00382",
          "publishedOn": "2021-06-04T01:12:29.656Z",
          "wordCount": 684,
          "title": "A Policy Gradient Algorithm for Learning to Learn in Multiagent Reinforcement Learning. (arXiv:2011.00382v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.02095",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Beknazaryan_A/0/1/0/all/0/1\">Aleksandr Beknazaryan</a>",
          "description": "We provide an entropy bound for the spaces of neural networks with piecewise\nlinear activation functions, such as the ReLU and the absolute value functions.\nThis bound generalizes the known entropy bound for the space of linear\nfunctions on $\\mathbb{R}^d$ and it depends on the value at the point\n$(1,1,...,1)$ of the networks obtained by taking the absolute values of all\nparameters of original networks. Keeping this value together with the depth,\nwidth and the parameters of the networks to have logarithmic dependence on\n$1/\\varepsilon$, we $\\varepsilon$-approximate functions that are analytic on\ncertain regions of $\\mathbb{C}^d$.",
          "link": "http://arxiv.org/abs/2104.02095",
          "publishedOn": "2021-06-04T01:12:29.648Z",
          "wordCount": 533,
          "title": "Deep neural network approximation of analytic functions. (arXiv:2104.02095v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.09545",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiong_B/0/1/0/all/0/1\">Bo Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yimin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Hanrong Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Staab_S/0/1/0/all/0/1\">Steffen Staab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenguo Li</a>",
          "description": "This paper presents a novel and lightweight hyperparameter optimization (HPO)\nmethod, MOdular FActorial Design (MOFA). MOFA pursues several rounds of HPO,\nwhere each round alternates between exploration of hyperparameter space by\nfactorial design and exploitation of evaluation results by factorial analysis.\nEach round first explores the configuration space by constructing a\nlow-discrepancy set of hyperparameters that cover this space well while\nde-correlating hyperparameters, and then exploits evaluation results through\nfactorial analysis that determines which hyperparameters should be further\nexplored and which should become fixed in the next round. We prove that the\ninference of MOFA achieves higher confidence than other sampling schemes. Each\nindividual round is highly parallelizable and hence offers major improvements\nof efficiency compared to model-based methods. Empirical results show that MOFA\nachieves better effectiveness and efficiency compared with state-of-the-art\nmethods.",
          "link": "http://arxiv.org/abs/2011.09545",
          "publishedOn": "2021-06-04T01:12:29.611Z",
          "wordCount": 590,
          "title": "MOFA: Modular Factorial Design for Hyperparameter Optimization. (arXiv:2011.09545v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.00006",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Jo_Y/0/1/0/all/0/1\">Yong-Yeon Jo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kwon_J/0/1/0/all/0/1\">Joon-Myoung Kwon</a>",
          "description": "The electrocardiogram (ECG) records electrical signals in a non-invasive way\nto observe the condition of the heart, typically looking at the heart from 12\ndifferent directions. Several types of the cardiac disease are diagnosed by\nusing 12-lead ECGs Recently, various wearable devices have enabled immediate\naccess to the ECG without the use of wieldy equipment. However, they only\nprovide ECGs with a couple of leads. This results in an inaccurate diagnosis of\ncardiac disease due to lacking of required leads. We propose a deep generative\nmodel for ECG synthesis from two asynchronous leads to ten leads. It first\nrepresents a heart condition referring to two leads, and then generates ten\nleads based on the represented heart condition. Both the rhythm and amplitude\nof leads generated resemble those of the original ones, while the technique\nremoves noise and the baseline wander appearing in the original leads. As a\ndata augmentation method, our model improves the classification performance of\nmodels compared with models using ECGs with only one or two leads.",
          "link": "http://arxiv.org/abs/2103.00006",
          "publishedOn": "2021-06-04T01:12:29.603Z",
          "wordCount": 605,
          "title": "Electrocardiogram synthesis. (arXiv:2103.00006v2 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.12827",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pintor_M/0/1/0/all/0/1\">Maura Pintor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roli_F/0/1/0/all/0/1\">Fabio Roli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brendel_W/0/1/0/all/0/1\">Wieland Brendel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biggio_B/0/1/0/all/0/1\">Battista Biggio</a>",
          "description": "Evaluating adversarial robustness amounts to finding the minimum perturbation\nneeded to have an input sample misclassified. The inherent complexity of the\nunderlying optimization requires current gradient-based attacks to be carefully\ntuned, initialized, and possibly executed for many computationally-demanding\niterations, even if specialized to a given perturbation model. In this work, we\novercome these limitations by proposing a fast minimum-norm (FMN) attack that\nworks with different $\\ell_p$-norm perturbation models ($p=0, 1, 2, \\infty$),\nis robust to hyperparameter choices, does not require adversarial starting\npoints, and converges within few lightweight steps. It works by iteratively\nfinding the sample misclassified with maximum confidence within an\n$\\ell_p$-norm constraint of size $\\epsilon$, while adapting $\\epsilon$ to\nminimize the distance of the current sample to the decision boundary. Extensive\nexperiments show that FMN significantly outperforms existing attacks in terms\nof convergence speed and computation time, while reporting comparable or even\nsmaller perturbation sizes.",
          "link": "http://arxiv.org/abs/2102.12827",
          "publishedOn": "2021-06-04T01:12:29.562Z",
          "wordCount": 607,
          "title": "Fast Minimum-norm Adversarial Attacks through Adaptive Norm Constraints. (arXiv:2102.12827v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.13068",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chalkis_A/0/1/0/all/0/1\">Apostolos Chalkis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fisikopoulos_V/0/1/0/all/0/1\">Vissarion Fisikopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papachristou_M/0/1/0/all/0/1\">Marios Papachristou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsigaridas_E/0/1/0/all/0/1\">Elias Tsigaridas</a>",
          "description": "We introduce Reflective Hamiltonian Monte Carlo (ReHMC), an HMC-based\nalgorithm, to sample from a log-concave distribution restricted to a convex\nbody. We prove that, starting from a warm start, the walk mixes to a\nlog-concave target distribution $\\pi(x) \\propto e^{-f(x)}$, where $f$ is\n$L$-smooth and $m$-strongly-convex, within accuracy $\\varepsilon$ after\n$\\widetilde O(\\kappa d^2 \\ell^2 \\log (1 / \\varepsilon))$ steps for a\nwell-rounded convex body where $\\kappa = L / m$ is the condition number of the\nnegative log-density, $d$ is the dimension, $\\ell$ is an upper bound on the\nnumber of reflections, and $\\varepsilon$ is the accuracy parameter. We also\ndeveloped an efficient open source implementation of ReHMC and we performed an\nexperimental study on various high-dimensional data-sets. The experiments\nsuggest that ReHMC outperfroms Hit-and-Run and Coordinate-Hit-and-Run regarding\nthe time it needs to produce an independent sample and introduces practical\ntruncated sampling in thousands of dimensions.",
          "link": "http://arxiv.org/abs/2102.13068",
          "publishedOn": "2021-06-04T01:12:29.524Z",
          "wordCount": 606,
          "title": "Truncated Log-concave Sampling with Reflective Hamiltonian Monte Carlo. (arXiv:2102.13068v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.00737",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Che_G/0/1/0/all/0/1\">Gwonsoo Che</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hongseok Yang</a>",
          "description": "We present a meta-algorithm for learning a posterior-inference algorithm for\nrestricted probabilistic programs. Our meta-algorithm takes a training set of\nprobabilistic programs that describe models with observations, and attempts to\nlearn an efficient method for inferring the posterior of a similar program. A\nkey feature of our approach is the use of what we call a white-box inference\nalgorithm that extracts information directly from model descriptions\nthemselves, given as programs. Concretely, our white-box inference algorithm is\nequipped with multiple neural networks, one for each type of atomic command,\nand computes an approximate posterior of a given probabilistic program by\nanalysing individual atomic commands in the program using these networks. The\nparameters of these networks are then learnt from a training set by our\nmeta-algorithm. We empirically demonstrate that the learnt inference algorithm\ngeneralises well to unseen programs in terms of both interpolation and\nextrapolation, and report cases where our approach may be preferable to a\nstate-of-the-art inference algorithm such as HMC. The overall results show the\npromise as well as remaining challenges of our approach.",
          "link": "http://arxiv.org/abs/2103.00737",
          "publishedOn": "2021-06-04T01:12:29.505Z",
          "wordCount": 653,
          "title": "Meta-Learning an Inference Algorithm for Probabilistic Programs. (arXiv:2103.00737v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.15761",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vidgen_B/0/1/0/all/0/1\">Bertie Vidgen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thrush_T/0/1/0/all/0/1\">Tristan Thrush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waseem_Z/0/1/0/all/0/1\">Zeerak Waseem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiela_D/0/1/0/all/0/1\">Douwe Kiela</a>",
          "description": "We present a human-and-model-in-the-loop process for dynamically generating\ndatasets and training better performing and more robust hate detection models.\nWe provide a new dataset of ~40,000 entries, generated and labelled by trained\nannotators over four rounds of dynamic data creation. It includes ~15,000\nchallenging perturbations and each hateful entry has fine-grained labels for\nthe type and target of hate. Hateful entries make up 54% of the dataset, which\nis substantially higher than comparable datasets. We show that model\nperformance is substantially improved using this approach. Models trained on\nlater rounds of data collection perform better on test sets and are harder for\nannotators to trick. They also perform better on HateCheck, a suite of\nfunctional tests for online hate detection. We provide the code, dataset and\nannotation guidelines for other researchers to use. Accepted at ACL 2021.",
          "link": "http://arxiv.org/abs/2012.15761",
          "publishedOn": "2021-06-04T01:12:29.486Z",
          "wordCount": 603,
          "title": "Learning from the Worst: Dynamically Generated Datasets to Improve Online Hate Detection. (arXiv:2012.15761v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.07566",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xue_H/0/1/0/all/0/1\">Hao Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salim_F/0/1/0/all/0/1\">Flora D. Salim</a>",
          "description": "The usage of smartphone-collected respiratory sound, trained with deep\nlearning models, for detecting and classifying COVID-19 becomes popular\nrecently. It removes the need for in-person testing procedures especially for\nrural regions where related medical supplies, experienced workers, and\nequipment are limited. However, existing sound-based diagnostic approaches are\ntrained in a fully supervised manner, which requires large scale well-labelled\ndata. It is critical to discover new methods to leverage unlabelled respiratory\ndata, which can be obtained more easily. In this paper, we propose a novel\nself-supervised learning enabled framework for COVID-19 cough classification. A\ncontrastive pre-training phase is introduced to train a Transformer-based\nfeature encoder with unlabelled data. Specifically, we design a random masking\nmechanism to learn robust representations of respiratory sounds. The\npre-trained feature encoder is then fine-tuned in the downstream phase to\nperform cough classification. In addition, different ensembles with varied\nrandom masking rates are also explored in the downstream phase. Through\nextensive evaluations, we demonstrate that the proposed contrastive\npre-training, the random masking mechanism, and the ensemble architecture\ncontribute to improving cough classification performance.",
          "link": "http://arxiv.org/abs/2105.07566",
          "publishedOn": "2021-06-04T01:12:29.473Z",
          "wordCount": 684,
          "title": "Exploring Self-Supervised Representation Ensembles for COVID-19 Cough Classification. (arXiv:2105.07566v2 [cs.SD] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.00345",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Onoe_Y/0/1/0/all/0/1\">Yasumasa Onoe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boratko_M/0/1/0/all/0/1\">Michael Boratko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCallum_A/0/1/0/all/0/1\">Andrew McCallum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durrett_G/0/1/0/all/0/1\">Greg Durrett</a>",
          "description": "Neural entity typing models typically represent fine-grained entity types as\nvectors in a high-dimensional space, but such spaces are not well-suited to\nmodeling these types' complex interdependencies. We study the ability of box\nembeddings, which embed concepts as d-dimensional hyperrectangles, to capture\nhierarchies of types even when these relationships are not defined explicitly\nin the ontology. Our model represents both types and entity mentions as boxes.\nEach mention and its context are fed into a BERT-based model to embed that\nmention in our box space; essentially, this model leverages typological clues\npresent in the surface text to hypothesize a type representation for the\nmention. Box containment can then be used to derive both the posterior\nprobability of a mention exhibiting a given type and the conditional\nprobability relations between types themselves. We compare our approach with a\nvector-based typing model and observe state-of-the-art performance on several\nentity typing benchmarks. In addition to competitive typing performance, our\nbox-based model shows better performance in prediction consistency (predicting\na supertype and a subtype together) and confidence (i.e., calibration),\ndemonstrating that the box-based model captures the latent type hierarchies\nbetter than the vector-based model does.",
          "link": "http://arxiv.org/abs/2101.00345",
          "publishedOn": "2021-06-04T01:12:29.449Z",
          "wordCount": 654,
          "title": "Modeling Fine-Grained Entity Types with Box Embeddings. (arXiv:2101.00345v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.13962",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leibfried_F/0/1/0/all/0/1\">Felix Leibfried</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dutordoir_V/0/1/0/all/0/1\">Vincent Dutordoir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+John_S/0/1/0/all/0/1\">ST John</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durrande_N/0/1/0/all/0/1\">Nicolas Durrande</a>",
          "description": "Gaussian processes (GPs) provide a framework for Bayesian inference that can\noffer principled uncertainty estimates for a large range of problems. For\nexample, if we consider regression problems with Gaussian likelihoods, a GP\nmodel enjoys a posterior in closed form. However, identifying the posterior GP\nscales cubically with the number of training examples and requires to store all\nexamples in memory. In order to overcome these obstacles, sparse GPs have been\nproposed that approximate the true posterior GP with pseudo-training examples.\nImportantly, the number of pseudo-training examples is user-defined and enables\ncontrol over computational and memory complexity. In the general case, sparse\nGPs do not enjoy closed-form solutions and one has to resort to approximate\ninference. In this context, a convenient choice for approximate inference is\nvariational inference (VI), where the problem of Bayesian inference is cast as\nan optimization problem -- namely, to maximize a lower bound of the log\nmarginal likelihood. This paves the way for a powerful and versatile framework,\nwhere pseudo-training examples are treated as optimization arguments of the\napproximate posterior that are jointly identified together with hyperparameters\nof the generative model (i.e. prior and likelihood). The framework can\nnaturally handle a wide scope of supervised learning problems, ranging from\nregression with heteroscedastic and non-Gaussian likelihoods to classification\nproblems with discrete labels, but also multilabel problems. The purpose of\nthis tutorial is to provide access to the basic matter for readers without\nprior knowledge in both GPs and VI. A proper exposition to the subject enables\nalso access to more recent advances (like importance-weighted VI as well as\ninterdomain, multioutput and deep GPs) that can serve as an inspiration for new\nresearch ideas.",
          "link": "http://arxiv.org/abs/2012.13962",
          "publishedOn": "2021-06-04T01:12:29.442Z",
          "wordCount": 801,
          "title": "A Tutorial on Sparse Gaussian Processes and Variational Inference. (arXiv:2012.13962v9 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.00795",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hankook Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1\">Sungsoo Ahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_S/0/1/0/all/0/1\">Seung-Woo Seo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">You Young Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1\">Eunho Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sung-Ju Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1\">Jinwoo Shin</a>",
          "description": "Retrosynthesis, of which the goal is to find a set of reactants for\nsynthesizing a target product, is an emerging research area of deep learning.\nWhile the existing approaches have shown promising results, they currently lack\nthe ability to consider availability (e.g., stability or purchasability) of the\nreactants or generalize to unseen reaction templates (i.e., chemical reaction\nrules). In this paper, we propose a new approach that mitigates the issues by\nreformulating retrosynthesis into a selection problem of reactants from a\ncandidate set of commercially available molecules. To this end, we design an\nefficient reactant selection framework, named RetCL (retrosynthesis via\ncontrastive learning), for enumerating all of the candidate molecules based on\nselection scores computed by graph neural networks. For learning the score\nfunctions, we also propose a novel contrastive training scheme with hard\nnegative mining. Extensive experiments demonstrate the benefits of the proposed\nselection-based approach. For example, when all 671k reactants in the USPTO\n{database} are given as candidates, our RetCL achieves top-1 exact match\naccuracy of $71.3\\%$ for the USPTO-50k benchmark, while a recent\ntransformer-based approach achieves $59.6\\%$. We also demonstrate that RetCL\ngeneralizes well to unseen templates in various settings in contrast to\ntemplate-based approaches.",
          "link": "http://arxiv.org/abs/2105.00795",
          "publishedOn": "2021-06-04T01:12:29.434Z",
          "wordCount": 680,
          "title": "RetCL: A Selection-based Approach for Retrosynthesis via Contrastive Learning. (arXiv:2105.00795v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.12668",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tsukamoto_H/0/1/0/all/0/1\">Hiroyasu Tsukamoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_S/0/1/0/all/0/1\">Soon-Jo Chung</a>",
          "description": "This paper presents Learning-based Autonomous Guidance with RObustness and\nStability guarantees (LAG-ROS), which provides machine learning-based nonlinear\nmotion planners with formal robustness and stability guarantees, by designing a\ndifferential Lyapunov function using contraction theory. LAG-ROS utilizes a\nneural network to model a robust tracking controller independently of a target\ntrajectory, for which we show that the Euclidean distance between the target\nand controlled trajectories is exponentially bounded linearly in the learning\nerror, even under the existence of bounded external disturbances. We also\npresent a convex optimization approach that minimizes the steady-state bound of\nthe tracking error to construct the robust control law for neural network\ntraining. In numerical simulations, it is demonstrated that the proposed method\nindeed possesses superior properties of robustness and nonlinear stability\nresulting from contraction theory, whilst retaining the computational\nefficiency of existing learning-based motion planners.",
          "link": "http://arxiv.org/abs/2102.12668",
          "publishedOn": "2021-06-04T01:12:29.406Z",
          "wordCount": 614,
          "title": "Learning-based Robust Motion Planning with Guaranteed Stability: A Contraction Theory Approach. (arXiv:2102.12668v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01577",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_H/0/1/0/all/0/1\">Honghao Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ying_L/0/1/0/all/0/1\">Lei Ying</a>",
          "description": "This paper presents the first {\\em model-free}, {\\em simulator-free}\nreinforcement learning algorithm for Constrained Markov Decision Processes\n(CMDPs) with sublinear regret and zero constraint violation. The algorithm is\nnamed Triple-Q because it has three key components: a Q-function (also called\naction-value function) for the cumulative reward, a Q-function for the\ncumulative utility for the constraint, and a virtual-Queue that\n(over)-estimates the cumulative constraint violation. Under Triple-Q, at each\nstep, an action is chosen based on the pseudo-Q-value that is a combination of\nthe three Q values. The algorithm updates the reward and utility Q-values with\nlearning rates that depend on the visit counts to the corresponding (state,\naction) pairs and are periodically reset. In the episodic CMDP setting,\nTriple-Q achieves $\\tilde{\\cal O}\\left(\\frac{1 }{\\delta}H^4\nS^{\\frac{1}{2}}A^{\\frac{1}{2}}K^{\\frac{4}{5}} \\right)$ regret, where $K$ is the\ntotal number of episodes, $H$ is the number of steps in each episode, $S$ is\nthe number of states, $A$ is the number of actions, and $\\delta$ is Slater's\nconstant. Furthermore, Triple-Q guarantees zero constraint violation when $K$\nis sufficiently large. Finally, the computational complexity of Triple-Q is\nsimilar to SARSA for unconstrained MDPs and is computationally efficient.",
          "link": "http://arxiv.org/abs/2106.01577",
          "publishedOn": "2021-06-04T01:12:29.399Z",
          "wordCount": 617,
          "title": "A Provably-Efficient Model-Free Algorithm for Constrained Markov Decision Processes. (arXiv:2106.01577v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.14995",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_S/0/1/0/all/0/1\">Shuhao Cao</a>",
          "description": "In this paper, we apply the self-attention from the state-of-the-art\nTransformer in Attention Is All You Need the first time to a data-driven\noperator learning problem related to partial differential equations. We put\ntogether an effort to explain the heuristics of, and improve the efficacy of\nthe self-attention by demonstrating that the softmax normalization in the\nscaled dot-product attention is sufficient but not necessary, and have proved\nthe approximation capacity of a linear variant as a Petrov-Galerkin projection.\nA new layer normalization scheme is proposed to allow a scaling to propagate\nthrough attention layers, which helps the model achieve remarkable accuracy in\noperator learning tasks with unnormalized data. Finally, we present three\noperator learning experiments, including the viscid Burgers' equation, an\ninterface Darcy flow, and an inverse interface coefficient identification\nproblem. All experiments validate the improvements of the newly proposed simple\nattention-based operator learner over their softmax-normalized counterparts.",
          "link": "http://arxiv.org/abs/2105.14995",
          "publishedOn": "2021-06-04T01:12:29.386Z",
          "wordCount": 591,
          "title": "Choose a Transformer: Fourier or Galerkin. (arXiv:2105.14995v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.09703",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiong_Z/0/1/0/all/0/1\">Zhihan Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_R/0/1/0/all/0/1\">Ruoqi Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1\">Simon S. Du</a>",
          "description": "We study exploration using randomized value functions in Thompson Sampling\n(TS)-like algorithms in reinforcement learning. This type of algorithms enjoys\nappealing empirical performance. We show that when we use 1) a single random\nseed in each episode, and 2) a Bernstein-type magnitude of noise, we obtain a\nworst-case $\\widetilde{O}\\left(H\\sqrt{SAT}\\right)$ regret bound for episodic\ntime-inhomogeneous Markov Decision Process where $S$ is the size of state\nspace, $A$ is the size of action space, $H$ is the planning horizon and $T$ is\nthe number of interactions. This bound polynomially improves all existing\nbounds for TS-like algorithms based on randomized value functions, and for the\nfirst time, matches the $\\Omega\\left(H\\sqrt{SAT}\\right)$ lower bound up to\nlogarithmic factors. Our result highlights that randomized exploration can be\nnear-optimal, which was previously only achieved by optimistic algorithms.",
          "link": "http://arxiv.org/abs/2102.09703",
          "publishedOn": "2021-06-04T01:12:29.351Z",
          "wordCount": 630,
          "title": "Randomized Exploration is Near-Optimal for Tabular MDP. (arXiv:2102.09703v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.04108",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_U/0/1/0/all/0/1\">Umang Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferber_A/0/1/0/all/0/1\">Aaron M Ferber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dilkina_B/0/1/0/all/0/1\">Bistra Dilkina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steeg_G/0/1/0/all/0/1\">Greg Ver Steeg</a>",
          "description": "Controlling bias in training datasets is vital for ensuring equal treatment,\nor parity, between different groups in downstream applications. A naive\nsolution is to transform the data so that it is statistically independent of\ngroup membership, but this may throw away too much information when a\nreasonable compromise between fairness and accuracy is desired. Another common\napproach is to limit the ability of a particular adversary who seeks to\nmaximize parity. Unfortunately, representations produced by adversarial\napproaches may still retain biases as their efficacy is tied to the complexity\nof the adversary used during training. To this end, we theoretically establish\nthat by limiting the mutual information between representations and protected\nattributes, we can assuredly control the parity of any downstream classifier.\nWe demonstrate an effective method for controlling parity through mutual\ninformation based on contrastive information estimators and show that they\noutperform approaches that rely on variational bounds based on complex\ngenerative models. We test our approach on UCI Adult and Heritage Health\ndatasets and demonstrate that our approach provides more informative\nrepresentations across a range of desired parity thresholds while providing\nstrong theoretical guarantees on the parity of any downstream algorithm.",
          "link": "http://arxiv.org/abs/2101.04108",
          "publishedOn": "2021-06-04T01:12:29.345Z",
          "wordCount": 699,
          "title": "Controllable Guarantees for Fair Outcomes via Contrastive Information Estimation. (arXiv:2101.04108v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.10395",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wald_Y/0/1/0/all/0/1\">Yoav Wald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feder_A/0/1/0/all/0/1\">Amir Feder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greenfeld_D/0/1/0/all/0/1\">Daniel Greenfeld</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shalit_U/0/1/0/all/0/1\">Uri Shalit</a>",
          "description": "Out-of-domain (OOD) generalization is a significant challenge for machine\nlearning models. Many techniques have been proposed to overcome this challenge,\noften focused on learning models with certain invariance properties. In this\nwork, we draw a link between OOD performance and model calibration, arguing\nthat calibration across multiple domains can be viewed as a special case of an\ninvariant representation leading to better OOD generalization. Specifically, we\nshow that under certain conditions, models which achieve \\emph{multi-domain\ncalibration} are provably free of spurious correlations. This leads us to\npropose multi-domain calibration as a measurable and trainable surrogate for\nthe OOD performance of a classifier. We therefore introduce methods that are\neasy to apply and allow practitioners to improve multi-domain calibration by\ntraining or modifying an existing model, leading to better performance on\nunseen domains. Using five datasets from the recently proposed WILDS OOD\nbenchmark, as well as the Colored MNIST dataset, we demonstrate that training\nor tuning models so they are calibrated across multiple domains leads to\nsignificantly improved performance on unseen test domains. We believe this\nintriguing connection between calibration and OOD generalization is promising\nfrom both a practical and theoretical point of view.",
          "link": "http://arxiv.org/abs/2102.10395",
          "publishedOn": "2021-06-04T01:12:29.333Z",
          "wordCount": 644,
          "title": "On Calibration and Out-of-domain Generalization. (arXiv:2102.10395v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01538",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Matyasko_A/0/1/0/all/0/1\">Alexander Matyasko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chau_L/0/1/0/all/0/1\">Lap-Pui Chau</a>",
          "description": "State-of-the-art deep neural networks are sensitive to small input\nperturbations. Since the discovery of this intriguing vulnerability, many\ndefence methods have been proposed that attempt to improve robustness to\nadversarial noise. Fast and accurate attacks are required to compare various\ndefence methods. However, evaluating adversarial robustness has proven to be\nextremely challenging. Existing norm minimisation adversarial attacks require\nthousands of iterations (e.g. Carlini & Wagner attack), are limited to the\nspecific norms (e.g. Fast Adaptive Boundary), or produce sub-optimal results\n(e.g. Brendel & Bethge attack). On the other hand, PGD attack, which is fast,\ngeneral and accurate, ignores the norm minimisation penalty and solves a\nsimpler perturbation-constrained problem. In this work, we introduce a fast,\ngeneral and accurate adversarial attack that optimises the original non-convex\nconstrained minimisation problem. We interpret optimising the Lagrangian of the\nadversarial attack optimisation problem as a two-player game: the first player\nminimises the Lagrangian wrt the adversarial noise; the second player maximises\nthe Lagrangian wrt the regularisation penalty. Our attack algorithm\nsimultaneously optimises primal and dual variables to find the minimal\nadversarial perturbation. In addition, for non-smooth $l_p$-norm minimisation,\nsuch as $l_{\\infty}$-, $l_1$-, and $l_0$-norms, we introduce primal-dual\nproximal gradient descent attack. We show in the experiments that our attack\noutperforms current state-of-the-art $l_{\\infty}$-, $l_2$-, $l_1$-, and\n$l_0$-attacks on MNIST, CIFAR-10 and Restricted ImageNet datasets against\nunregularised and adversarially trained models.",
          "link": "http://arxiv.org/abs/2106.01538",
          "publishedOn": "2021-06-04T01:12:29.327Z",
          "wordCount": 656,
          "title": "PDPGD: Primal-Dual Proximal Gradient Descent Adversarial Attack. (arXiv:2106.01538v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.05431",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Eisenhofer_T/0/1/0/all/0/1\">Thorsten Eisenhofer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schonherr_L/0/1/0/all/0/1\">Lea Sch&#xf6;nherr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_J/0/1/0/all/0/1\">Joel Frank</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Speckemeier_L/0/1/0/all/0/1\">Lars Speckemeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolossa_D/0/1/0/all/0/1\">Dorothea Kolossa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holz_T/0/1/0/all/0/1\">Thorsten Holz</a>",
          "description": "Adversarial examples seem to be inevitable. These specifically crafted inputs\nallow attackers to arbitrarily manipulate machine learning systems. Even worse,\nthey often seem harmless to human observers. In our digital society, this poses\na significant threat. For example, Automatic Speech Recognition (ASR) systems,\nwhich serve as hands-free interfaces to many kinds of systems, can be attacked\nwith inputs incomprehensible for human listeners. The research community has\nunsuccessfully tried several approaches to tackle this problem. In this paper\nwe propose a different perspective: We accept the presence of adversarial\nexamples against ASR systems, but we require them to be perceivable by human\nlisteners. By applying the principles of psychoacoustics, we can remove\nsemantically irrelevant information from the ASR input and train a model that\nresembles human perception more closely. We implement our idea in a tool named\nDOMPTEUR and demonstrate that our augmented system, in contrast to an\nunmodified baseline, successfully focuses on perceptible ranges of the input\nsignal. This change forces adversarial examples into the audible range, while\nusing minimal computational overhead and preserving benign performance. To\nevaluate our approach, we construct an adaptive attacker that actively tries to\navoid our augmentations and demonstrate that adversarial examples from this\nattacker remain clearly perceivable. Finally, we substantiate our claims by\nperforming a hearing test with crowd-sourced human listeners.",
          "link": "http://arxiv.org/abs/2102.05431",
          "publishedOn": "2021-06-04T01:12:29.309Z",
          "wordCount": 683,
          "title": "Dompteur: Taming Audio Adversarial Examples. (arXiv:2102.05431v2 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05221",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Herrmann_M/0/1/0/all/0/1\">Matthieu Herrmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Webb_G/0/1/0/all/0/1\">Geoffrey I. Webb</a>",
          "description": "Nearest neighbor search under elastic distances is a key tool for time series\nanalysis, supporting many applications. However, straightforward\nimplementations of distances require $O(n^2)$ space and time complexities,\npreventing these applications from scaling to long series. Much work has been\ndevoted to speeding up the NN search process, mostly with the development of\nlower bounds, allowing to avoid costly distance computations when a given\nthreshold is exceeded. This threshold, provided by the similarity search\nprocess, also allows to early abandon the computation of a distance itself.\nAnother approach, is to prune parts of the computation. All these techniques\nare othogonal to each other. In this work, we develop a new generic strategy,\n\"EAPruned\", that tightly integrates pruning with early abandoning. We apply it\nto six elastic distance measures: DTW, CDTW, WDTW, ERP, MSM and TWE, showing\nsubstantial speedup in NN search applications. Pruning alone also shows\nsubstantial speedup for some distances, benefiting applications beyond the\nscope of NN search (e.g. requiring all pairwise distances), and hence where\nearly abandoning is not applicable. We~release our implementation as part of a\nnew C++ library for time series classification, along with easy to use\nPython/Numpy bindings.",
          "link": "http://arxiv.org/abs/2102.05221",
          "publishedOn": "2021-06-04T01:12:29.297Z",
          "wordCount": 654,
          "title": "Early Abandoning and Pruning for Elastic Distances including Dynamic Time Warping. (arXiv:2102.05221v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.14858",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mohan_P/0/1/0/all/0/1\">Puranjay Mohan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paul_A/0/1/0/all/0/1\">Aditya Jyoti Paul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chirania_A/0/1/0/all/0/1\">Abhay Chirania</a>",
          "description": "The world is going through one of the most dangerous pandemics of all time\nwith the rapid spread of the novel coronavirus (COVID-19). According to the\nWorld Health Organisation, the most effective way to thwart the transmission of\ncoronavirus is to wear medical face masks. Monitoring the use of face masks in\npublic places has been a challenge because manual monitoring could be unsafe.\nThis paper proposes an architecture for detecting medical face masks for\ndeployment on resource-constrained endpoints having extremely low memory\nfootprints. A small development board with an ARM Cortex-M7 microcontroller\nclocked at 480 Mhz and having just 496 KB of framebuffer RAM, has been used for\nthe deployment of the model. Using the TensorFlow Lite framework, the model is\nquantized to further reduce its size. The proposed model is 138 KB post\nquantization and runs at the inference speed of 30 FPS.",
          "link": "http://arxiv.org/abs/2011.14858",
          "publishedOn": "2021-06-04T01:12:29.202Z",
          "wordCount": 728,
          "title": "A Tiny CNN Architecture for Medical Face Mask Detection for Resource-Constrained Endpoints. (arXiv:2011.14858v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.10861",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shunqi Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurkoski_B/0/1/0/all/0/1\">Brian M. Kurkoski</a>",
          "description": "Approximate message passing (AMP) is a low-cost iterative\nparameter-estimation technique for certain high-dimensional linear systems with\nnon-Gaussian distributions. However, AMP only applies to independent\nidentically distributed (IID) transform matrices, but may become unreliable\n(e.g. perform poorly or even diverge) for other matrix ensembles, especially\nfor ill-conditioned ones. To handle this difficulty, orthogonal/vector AMP\n(OAMP/VAMP) was proposed for general right-unitarily-invariant matrices.\nHowever, the Bayes-optimal OAMP/VAMP requires high-complexity linear minimum\nmean square error (MMSE) estimator. This limits the application of OAMP/VAMP to\nlarge-scale systems.\n\nTo solve the disadvantages of AMP and OAMP/VAMP, this paper proposes a memory\nAMP (MAMP), in which a long-memory matched filter is proposed for interference\nsuppression. The complexity of MAMP is comparable to AMP. The asymptotic\nGaussianity of estimation errors in MAMP is guaranteed by the orthogonality\nprinciple. A state evolution is derived to asymptotically characterize the\nperformance of MAMP. Based on state evolution, the relaxation parameters and\ndamping vector in MAMP are optimized. For all right-unitarily-invariant\nmatrices, the optimized MAMP converges to the high-complexity OAMP/VAMP, and\nthus is Bayes-optimal if it has a unique fixed point. Finally, simulations are\nprovided to verify the validity and accuracy of the theoretical results.",
          "link": "http://arxiv.org/abs/2012.10861",
          "publishedOn": "2021-06-04T01:12:29.185Z",
          "wordCount": 713,
          "title": "Memory AMP. (arXiv:2012.10861v3 [cs.IT] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.15069",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brossard_R/0/1/0/all/0/1\">R&#xe9;my Brossard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frigo_O/0/1/0/all/0/1\">Oriel Frigo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dehaene_D/0/1/0/all/0/1\">David Dehaene</a>",
          "description": "Despite quick progress in the last few years, recent studies have shown that\nmodern graph neural networks can still fail at very simple tasks, like\ndetecting small cycles. This hints at the fact that current networks fail to\ncatch information about the local structure, which is problematic if the\ndownstream task heavily relies on graph substructure analysis, as in the\ncontext of chemistry. We propose a very simple correction to the now standard\nGIN convolution that enables the network to detect small cycles with nearly no\ncost in terms of computation time and number of parameters. Tested on real life\nmolecule property datasets, our model consistently improves performance on\nlarge multi-tasked datasets over all baselines, both globally and on a per-task\nsetting.",
          "link": "http://arxiv.org/abs/2011.15069",
          "publishedOn": "2021-06-04T01:12:29.168Z",
          "wordCount": 568,
          "title": "Graph convolutions that can finally model local structure. (arXiv:2011.15069v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.03129",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khaki_S/0/1/0/all/0/1\">Saeed Khaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1\">Hieu Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lizhi Wang</a>",
          "description": "Large-scale crop yield estimation is, in part, made possible due to the\navailability of remote sensing data allowing for the continuous monitoring of\ncrops throughout their growth cycle. Having this information allows\nstakeholders the ability to make real-time decisions to maximize yield\npotential. Although various models exist that predict yield from remote sensing\ndata, there currently does not exist an approach that can estimate yield for\nmultiple crops simultaneously, and thus leads to more accurate predictions. A\nmodel that predicts the yield of multiple crops and concurrently considers the\ninteraction between multiple crop yields. We propose a new convolutional neural\nnetwork model called YieldNet which utilizes a novel deep learning framework\nthat uses transfer learning between corn and soybean yield predictions by\nsharing the weights of the backbone feature extractor. Additionally, to\nconsider the multi-target response variable, we propose a new loss function. We\nconduct our experiment using data from 1,132 counties for corn and 1,076\ncounties for soybean across the United States. Numerical results demonstrate\nthat our proposed method accurately predicts corn and soybean yield from one to\nfour months before the harvest with a MAE being 8.74% and 8.70% of the average\nyield, respectively, and is competitive to other state-of-the-art approaches.",
          "link": "http://arxiv.org/abs/2012.03129",
          "publishedOn": "2021-06-04T01:12:29.160Z",
          "wordCount": 714,
          "title": "Simultaneous Corn and Soybean Yield Prediction from Remote Sensing Data Using Deep Transfer Learning. (arXiv:2012.03129v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.12461",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bayerlein_H/0/1/0/all/0/1\">Harald Bayerlein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theile_M/0/1/0/all/0/1\">Mirco Theile</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caccamo_M/0/1/0/all/0/1\">Marco Caccamo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gesbert_D/0/1/0/all/0/1\">David Gesbert</a>",
          "description": "Harvesting data from distributed Internet of Things (IoT) devices with\nmultiple autonomous unmanned aerial vehicles (UAVs) is a challenging problem\nrequiring flexible path planning methods. We propose a multi-agent\nreinforcement learning (MARL) approach that, in contrast to previous work, can\nadapt to profound changes in the scenario parameters defining the data\nharvesting mission, such as the number of deployed UAVs, number, position and\ndata amount of IoT devices, or the maximum flying time, without the need to\nperform expensive recomputations or relearn control policies. We formulate the\npath planning problem for a cooperative, non-communicating, and homogeneous\nteam of UAVs tasked with maximizing collected data from distributed IoT sensor\nnodes subject to flying time and collision avoidance constraints. The path\nplanning problem is translated into a decentralized partially observable Markov\ndecision process (Dec-POMDP), which we solve through a deep reinforcement\nlearning (DRL) approach, approximating the optimal UAV control policy without\nprior knowledge of the challenging wireless channel characteristics in dense\nurban environments. By exploiting a combination of centered global and local\nmap representations of the environment that are fed into convolutional layers\nof the agents, we show that our proposed network architecture enables the\nagents to cooperate effectively by carefully dividing the data collection task\namong themselves, adapt to large complex environments and state spaces, and\nmake movement decisions that balance data collection goals, flight-time\nefficiency, and navigation constraints. Finally, learning a control policy that\ngeneralizes over the scenario parameter space enables us to analyze the\ninfluence of individual parameters on collection performance and provide some\nintuition about system-level benefits.",
          "link": "http://arxiv.org/abs/2010.12461",
          "publishedOn": "2021-06-04T01:12:29.153Z",
          "wordCount": 775,
          "title": "Multi-UAV Path Planning for Wireless Data Harvesting with Deep Reinforcement Learning. (arXiv:2010.12461v3 [cs.MA] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.04820",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shuijing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_P/0/1/0/all/0/1\">Peixin Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_W/0/1/0/all/0/1\">Weihang Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_N/0/1/0/all/0/1\">Neeloy Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Driggs_Campbell_K/0/1/0/all/0/1\">Katherine Driggs-Campbell</a>",
          "description": "Safe and efficient navigation through human crowds is an essential capability\nfor mobile robots. Previous work on robot crowd navigation assumes that the\ndynamics of all agents are known and well-defined. In addition, the performance\nof previous methods deteriorates in partially observable environments and\nenvironments with dense crowds. To tackle these problems, we propose\ndecentralized structural-Recurrent Neural Network (DS-RNN), a novel network\nthat reasons about spatial and temporal relationships for robot decision making\nin crowd navigation. We train our network with model-free deep reinforcement\nlearning without any expert supervision. We demonstrate that our model\noutperforms previous methods in challenging crowd navigation scenarios. We\nsuccessfully transfer the policy learned in the simulator to a real-world\nTurtleBot 2i.",
          "link": "http://arxiv.org/abs/2011.04820",
          "publishedOn": "2021-06-04T01:12:29.145Z",
          "wordCount": 603,
          "title": "Decentralized Structural-RNN for Robot Crowd Navigation with Deep Reinforcement Learning. (arXiv:2011.04820v3 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.03248",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bregoli_A/0/1/0/all/0/1\">Alessandro Bregoli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scutari_M/0/1/0/all/0/1\">Marco Scutari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stella_F/0/1/0/all/0/1\">Fabio Stella</a>",
          "description": "Dynamic Bayesian networks have been well explored in the literature as\ndiscrete-time models: however, their continuous-time extensions have seen\ncomparatively little attention. In this paper, we propose the first\nconstraint-based algorithm for learning the structure of continuous-time\nBayesian networks. We discuss the different statistical tests and the\nunderlying hypotheses used by our proposal to establish conditional\nindependence. Furthermore, we analyze and discuss the computational complexity\nof the best and worst cases for the proposed algorithm. Finally, we validate\nits performance using synthetic data, and we discuss its strengths and\nlimitations comparing it with the score-based structure learning algorithm from\nNodelman et al. (2003). We find the latter to be more accurate in learning\nnetworks with binary variables, while our constraint-based approach is more\naccurate with variables assuming more than two values. Numerical experiments\nconfirm that score-based and constraint-based algorithms are comparable in\nterms of computation time.",
          "link": "http://arxiv.org/abs/2007.03248",
          "publishedOn": "2021-06-04T01:12:29.138Z",
          "wordCount": 630,
          "title": "A Constraint-Based Algorithm for the Structural Learning of Continuous-Time Bayesian Networks. (arXiv:2007.03248v3 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.09895",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Padi_S/0/1/0/all/0/1\">Sarala Padi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manocha_D/0/1/0/all/0/1\">Dinesh Manocha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sriram_R/0/1/0/all/0/1\">Ram D.Sriram</a>",
          "description": "We present a Multi-Window Data Augmentation (MWA-SER) approach for speech\nemotion recognition. MWA-SER is a unimodal approach that focuses on two key\nconcepts; designing the speech augmentation method and building the deep\nlearning model to recognize the underlying emotion of an audio signal. Our\nproposed multi-window augmentation approach generates additional data samples\nfrom the speech signal by employing multiple window sizes in the audio feature\nextraction process. We show that our augmentation method, combined with a deep\nlearning model, improves speech emotion recognition performance. We evaluate\nthe performance of our approach on three benchmark datasets: IEMOCAP, SAVEE,\nand RAVDESS. We show that the multi-window model improves the SER performance\nand outperforms a single-window model. The notion of finding the best window\nsize is an essential step in audio feature extraction. We perform extensive\nexperimental evaluations to find the best window choice and explore the\nwindowing effect for SER analysis.",
          "link": "http://arxiv.org/abs/2010.09895",
          "publishedOn": "2021-06-04T01:12:29.132Z",
          "wordCount": 620,
          "title": "Multi-Window Data Augmentation Approach for Speech Emotion Recognition. (arXiv:2010.09895v3 [cs.SD] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01986",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Hang_H/0/1/0/all/0/1\">Hanyuan Hang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huang_T/0/1/0/all/0/1\">Tao Huang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cai_Y/0/1/0/all/0/1\">Yuchao Cai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yang_H/0/1/0/all/0/1\">Hanfang Yang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lin_Z/0/1/0/all/0/1\">Zhouchen Lin</a>",
          "description": "In this paper, we propose a gradient boosting algorithm for large-scale\nregression problems called \\textit{Gradient Boosted Binary Histogram Ensemble}\n(GBBHE) based on binary histogram partition and ensemble learning. From the\ntheoretical perspective, by assuming the H\\\"{o}lder continuity of the target\nfunction, we establish the statistical convergence rate of GBBHE in the space\n$C^{0,\\alpha}$ and $C^{1,0}$, where a lower bound of the convergence rate for\nthe base learner demonstrates the advantage of boosting. Moreover, in the space\n$C^{1,0}$, we prove that the number of iterations to achieve the fast\nconvergence rate can be reduced by using ensemble regressor as the base\nlearner, which improves the computational efficiency. In the experiments,\ncompared with other state-of-the-art algorithms such as gradient boosted\nregression tree (GBRT), Breiman's forest, and kernel-based methods, our GBBHE\nalgorithm shows promising performance with less running time on large-scale\ndatasets.",
          "link": "http://arxiv.org/abs/2106.01986",
          "publishedOn": "2021-06-04T01:12:29.111Z",
          "wordCount": 568,
          "title": "Gradient Boosted Binary Histogram Ensemble for Large-scale Regression. (arXiv:2106.01986v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2010.15120",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bailey_A/0/1/0/all/0/1\">Andrew Bailey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plumbley_M/0/1/0/all/0/1\">Mark D. Plumbley</a>",
          "description": "Depression is a large-scale mental health problem and a challenging area for\nmachine learning researchers in detection of depression. Datasets such as\nDistress Analysis Interview Corpus - Wizard of Oz (DAIC-WOZ) have been created\nto aid research in this area. However, on top of the challenges inherent in\naccurately detecting depression, biases in datasets may result in skewed\nclassification performance. In this paper we examine gender bias in the\nDAIC-WOZ dataset. We show that gender biases in DAIC-WOZ can lead to an\noverreporting of performance. By different concepts from Fair Machine Learning,\nsuch as data re-distribution, and using raw audio features, we can mitigate\nagainst the harmful effects of bias.",
          "link": "http://arxiv.org/abs/2010.15120",
          "publishedOn": "2021-06-04T01:12:29.104Z",
          "wordCount": 582,
          "title": "Gender Bias in Depression Detection Using Audio Features. (arXiv:2010.15120v2 [cs.SD] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02034",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rao_Y/0/1/0/all/0/1\">Yongming Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wenliang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Benlin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jiwen Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1\">Cho-Jui Hsieh</a>",
          "description": "Attention is sparse in vision transformers. We observe the final prediction\nin vision transformers is only based on a subset of most informative tokens,\nwhich is sufficient for accurate image recognition. Based on this observation,\nwe propose a dynamic token sparsification framework to prune redundant tokens\nprogressively and dynamically based on the input. Specifically, we devise a\nlightweight prediction module to estimate the importance score of each token\ngiven the current features. The module is added to different layers to prune\nredundant tokens hierarchically. To optimize the prediction module in an\nend-to-end manner, we propose an attention masking strategy to differentiably\nprune a token by blocking its interactions with other tokens. Benefiting from\nthe nature of self-attention, the unstructured sparse tokens are still hardware\nfriendly, which makes our framework easy to achieve actual speed-up. By\nhierarchically pruning 66% of the input tokens, our method greatly reduces\n31%~37% FLOPs and improves the throughput by over 40% while the drop of\naccuracy is within 0.5% for various vision transformers. Equipped with the\ndynamic token sparsification framework, DynamicViT models can achieve very\ncompetitive complexity/accuracy trade-offs compared to state-of-the-art CNNs\nand vision transformers on ImageNet. Code is available at\nhttps://github.com/raoyongming/DynamicViT",
          "link": "http://arxiv.org/abs/2106.02034",
          "publishedOn": "2021-06-04T01:12:29.096Z",
          "wordCount": 644,
          "title": "DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification. (arXiv:2106.02034v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2010.09322",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Diwan_A/0/1/0/all/0/1\">Anuj Diwan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jyothi_P/0/1/0/all/0/1\">Preethi Jyothi</a>",
          "description": "This work presents a seemingly simple but effective technique to improve\nlow-resource ASR systems for phonetic languages. By identifying sets of\nacoustically similar graphemes in these languages, we first reduce the output\nalphabet of the ASR system using linguistically meaningful reductions and then\nreconstruct the original alphabet using a standalone module. We demonstrate\nthat this lessens the burden and improves the performance of low-resource\nend-to-end ASR systems (because only reduced-alphabet predictions are needed)\nand that it is possible to design a very simple but effective reconstruction\nmodule that recovers sequences in the original alphabet from sequences in the\nreduced alphabet. We present a finite state transducer-based reconstruction\nmodule that operates on the 1-best ASR hypothesis in the reduced alphabet. We\ndemonstrate the efficacy of our proposed technique using ASR systems for two\nIndian languages, Gujarati and Telugu. With access to only 10 hrs of speech\ndata, we obtain relative WER reductions of up to 7% compared to systems that do\nnot use any reduction.",
          "link": "http://arxiv.org/abs/2010.09322",
          "publishedOn": "2021-06-04T01:12:29.090Z",
          "wordCount": 634,
          "title": "Reduce and Reconstruct: ASR for Low-Resource Phonetic Languages. (arXiv:2010.09322v2 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.05120",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zarpellon_G/0/1/0/all/0/1\">Giulia Zarpellon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jo_J/0/1/0/all/0/1\">Jason Jo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lodi_A/0/1/0/all/0/1\">Andrea Lodi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>",
          "description": "Branch and Bound (B&B) is the exact tree search method typically used to\nsolve Mixed-Integer Linear Programming problems (MILPs). Learning branching\npolicies for MILP has become an active research area, with most works proposing\nto imitate the strong branching rule and specialize it to distinct classes of\nproblems. We aim instead at learning a policy that generalizes across\nheterogeneous MILPs: our main hypothesis is that parameterizing the state of\nthe B&B search tree can aid this type of generalization. We propose a novel\nimitation learning framework, and introduce new input features and\narchitectures to represent branching. Experiments on MILP benchmark instances\nclearly show the advantages of incorporating an explicit parameterization of\nthe state of the search tree to modulate the branching decisions, in terms of\nboth higher accuracy and smaller B&B trees. The resulting policies\nsignificantly outperform the current state-of-the-art method for \"learning to\nbranch\" by effectively allowing generalization to generic unseen instances.",
          "link": "http://arxiv.org/abs/2002.05120",
          "publishedOn": "2021-06-04T01:12:29.083Z",
          "wordCount": 671,
          "title": "Parameterizing Branch-and-Bound Search Trees to Learn Branching Policies. (arXiv:2002.05120v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1911.04436",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_C/0/1/0/all/0/1\">Changxiao Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Gen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poor_H/0/1/0/all/0/1\">H. Vincent Poor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuxin Chen</a>",
          "description": "We study a noisy tensor completion problem of broad practical interest,\nnamely, the reconstruction of a low-rank tensor from highly incomplete and\nrandomly corrupted observations of its entries. While a variety of prior work\nhas been dedicated to this problem, prior algorithms either are computationally\ntoo expensive for large-scale applications, or come with sub-optimal\nstatistical guarantees. Focusing on \"incoherent\" and well-conditioned tensors\nof a constant CP rank, we propose a two-stage nonconvex algorithm -- (vanilla)\ngradient descent following a rough initialization -- that achieves the best of\nboth worlds. Specifically, the proposed nonconvex algorithm faithfully\ncompletes the tensor and retrieves all individual tensor factors within nearly\nlinear time, while at the same time enjoying near-optimal statistical\nguarantees (i.e. minimal sample complexity and optimal estimation accuracy).\nThe estimation errors are evenly spread out across all entries, thus achieving\noptimal $\\ell_{\\infty}$ statistical accuracy. We have also discussed how to\nextend our approach to accommodate asymmetric tensors. The insight conveyed\nthrough our analysis of nonconvex optimization might have implications for\nother tensor estimation problems.",
          "link": "http://arxiv.org/abs/1911.04436",
          "publishedOn": "2021-06-04T01:12:29.065Z",
          "wordCount": 649,
          "title": "Nonconvex Low-Rank Tensor Completion from Noisy Data. (arXiv:1911.04436v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.08198",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengchun Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sharma_H/0/1/0/all/0/1\">Hemant Sharma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Park_J/0/1/0/all/0/1\">Jun-Sang Park</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kenesei_P/0/1/0/all/0/1\">Peter Kenesei</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Miceli_A/0/1/0/all/0/1\">Antonino Miceli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Almer_J/0/1/0/all/0/1\">Jonathan Almer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kettimuthu_R/0/1/0/all/0/1\">Rajkumar Kettimuthu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Foster_I/0/1/0/all/0/1\">Ian Foster</a>",
          "description": "X-ray diffraction based microscopy techniques such as High Energy Diffraction\nMicroscopy rely on knowledge of the position of diffraction peaks with high\nprecision. These positions are typically computed by fitting the observed\nintensities in area detector data to a theoretical peak shape such as\npseudo-Voigt. As experiments become more complex and detector technologies\nevolve, the computational cost of such peak detection and shape fitting becomes\nthe biggest hurdle to the rapid analysis required for real-time feedback during\nin-situ experiments. To this end, we propose BraggNN, a deep learning-based\nmethod that can determine peak positions much more rapidly than conventional\npseudo-Voigt peak fitting. When applied to a test dataset, BraggNN gives errors\nof less than 0.29 and 0.57 pixels, relative to the conventional method, for 75%\nand 95% of the peaks, respectively. When applied to a real experimental\ndataset, a 3D reconstruction that used peak positions computed by BraggNN\nyields 15% better results on average as compared to a reconstruction obtained\nusing peak positions determined using conventional 2D pseudo-Voigt fitting.\nRecent advances in deep learning method implementations and special-purpose\nmodel inference accelerators allow BraggNN to deliver enormous performance\nimprovements relative to the conventional method, running, for example, more\nthan 200 times faster than a conventional method on a consumer-class GPU card\nwith out-of-the-box software.",
          "link": "http://arxiv.org/abs/2008.08198",
          "publishedOn": "2021-06-04T01:12:29.055Z",
          "wordCount": 676,
          "title": "BraggNN: Fast X-ray Bragg Peak Analysis Using Deep Learning. (arXiv:2008.08198v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.03375",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+He_J/0/1/0/all/0/1\">Jingyu He</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hahn_P/0/1/0/all/0/1\">P. Richard Hahn</a>",
          "description": "This paper develops a novel stochastic tree ensemble method for nonlinear\nregression, which we refer to as XBART, short for Accelerated Bayesian Additive\nRegression Trees. By combining regularization and stochastic search strategies\nfrom Bayesian modeling with computationally efficient techniques from recursive\npartitioning approaches, the new method attains state-of-the-art performance:\nin many settings it is both faster and more accurate than the widely-used\nXGBoost algorithm. Via careful simulation studies, we demonstrate that our new\napproach provides accurate point-wise estimates of the mean function and does\nso faster than popular alternatives, such as BART, XGBoost and neural networks\n(using Keras). We also prove a number of basic theoretical results about the\nnew algorithm, including consistency of the single tree version of the model\nand stationarity of the Markov chain produced by the ensemble version.\nFurthermore, we demonstrate that initializing standard Bayesian additive\nregression trees Markov chain Monte Carlo (MCMC) at XBART-fitted trees\nconsiderably improves credible interval coverage and reduces total run-time.",
          "link": "http://arxiv.org/abs/2002.03375",
          "publishedOn": "2021-06-04T01:12:29.048Z",
          "wordCount": 619,
          "title": "Stochastic tree ensembles for regularized nonlinear regression. (arXiv:2002.03375v4 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01969",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leonardos_S/0/1/0/all/0/1\">Stefanos Leonardos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Overman_W/0/1/0/all/0/1\">Will Overman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panageas_I/0/1/0/all/0/1\">Ioannis Panageas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piliouras_G/0/1/0/all/0/1\">Georgios Piliouras</a>",
          "description": "Potential games are arguably one of the most important and widely studied\nclasses of normal form games. They define the archetypal setting of multi-agent\ncoordination as all agent utilities are perfectly aligned with each other via a\ncommon potential function. Can this intuitive framework be transplanted in the\nsetting of Markov Games? What are the similarities and differences between\nmulti-agent coordination with and without state dependence? We present a novel\ndefinition of Markov Potential Games (MPG) that generalizes prior attempts at\ncapturing complex stateful multi-agent coordination. Counter-intuitively,\ninsights from normal-form potential games do not carry over as MPGs can consist\nof settings where state-games can be zero-sum games. In the opposite direction,\nMarkov games where every state-game is a potential game are not necessarily\nMPGs. Nevertheless, MPGs showcase standard desirable properties such as the\nexistence of deterministic Nash policies. In our main technical result, we\nprove fast convergence of independent policy gradient to Nash policies by\nadapting recent gradient dominance property arguments developed for single\nagent MDPs to multi-agent learning settings.",
          "link": "http://arxiv.org/abs/2106.01969",
          "publishedOn": "2021-06-04T01:12:29.041Z",
          "wordCount": 605,
          "title": "Global Convergence of Multi-Agent Policy Gradient in Markov Potential Games. (arXiv:2106.01969v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02018",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rebrova_E/0/1/0/all/0/1\">Elizaveta Rebrova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1\">Yu-Hang Tang</a>",
          "description": "We introduce and investigate matrix approximation by decomposition into a sum\nof radial basis function (RBF) components. An RBF component is a generalization\nof the outer product between a pair of vectors, where an RBF function replaces\nthe scalar multiplication between individual vector elements. Even though the\nRBF functions are positive definite, the summation across components is not\nrestricted to convex combinations and allows us to compute the decomposition\nfor any real matrix that is not necessarily symmetric or positive definite. We\nformulate the problem of seeking such a decomposition as an optimization\nproblem with a nonlinear and non-convex loss function. Several modern versions\nof the gradient descent method, including their scalable stochastic\ncounterparts, are used to solve this problem. We provide extensive empirical\nevidence of the effectiveness of the RBF decomposition and that of the\ngradient-based fitting algorithm. While being conceptually motivated by\nsingular value decomposition (SVD), our proposed nonlinear counterpart\noutperforms SVD by drastically reducing the memory required to approximate a\ndata matrix with the same $L_2$-error for a wide range of matrix types. For\nexample, it leads to 2 to 10 times memory save for Gaussian noise, graph\nadjacency matrices, and kernel matrices. Moreover, this proximity-based\ndecomposition can offer additional interpretability in applications that\ninvolve, e.g., capturing the inner low-dimensional structure of the data,\nretaining graph connectivity structure, and preserving the acutance of images.",
          "link": "http://arxiv.org/abs/2106.02018",
          "publishedOn": "2021-06-04T01:12:29.034Z",
          "wordCount": 652,
          "title": "Nonlinear Matrix Approximation with Radial Basis Function Components. (arXiv:2106.02018v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02029",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhan_R/0/1/0/all/0/1\">Ruohan Zhan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hadad_V/0/1/0/all/0/1\">Vitor Hadad</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hirshberg_D/0/1/0/all/0/1\">David A. Hirshberg</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Athey_S/0/1/0/all/0/1\">Susan Athey</a>",
          "description": "It has become increasingly common for data to be collected adaptively, for\nexample using contextual bandits. Historical data of this type can be used to\nevaluate other treatment assignment policies to guide future innovation or\nexperiments. However, policy evaluation is challenging if the target policy\ndiffers from the one used to collect data, and popular estimators, including\ndoubly robust (DR) estimators, can be plagued by bias, excessive variance, or\nboth. In particular, when the pattern of treatment assignment in the collected\ndata looks little like the pattern generated by the policy to be evaluated, the\nimportance weights used in DR estimators explode, leading to excessive\nvariance.\n\nIn this paper, we improve the DR estimator by adaptively weighting\nobservations to control its variance. We show that a t-statistic based on our\nimproved estimator is asymptotically normal under certain conditions, allowing\nus to form confidence intervals and test hypotheses. Using synthetic data and\npublic benchmarks, we provide empirical evidence for our estimator's improved\naccuracy and inferential properties relative to existing alternatives.",
          "link": "http://arxiv.org/abs/2106.02029",
          "publishedOn": "2021-06-04T01:12:29.017Z",
          "wordCount": 605,
          "title": "Off-Policy Evaluation via Adaptive Weighting with Data from Contextual Bandits. (arXiv:2106.02029v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2005.00123",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Raghu_D/0/1/0/all/0/1\">Dinesh Raghu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_N/0/1/0/all/0/1\">Nikhil Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mausam/0/1/0/all/0/1\">Mausam</a>",
          "description": "Task-oriented dialog (TOD) systems often need to formulate knowledge base\n(KB) queries corresponding to the user intent and use the query results to\ngenerate system responses. Existing approaches require dialog datasets to\nexplicitly annotate these KB queries -- these annotations can be time\nconsuming, and expensive. In response, we define the novel problems of\npredicting the KB query and training the dialog agent, without explicit KB\nquery annotation. For query prediction, we propose a reinforcement learning\n(RL) baseline, which rewards the generation of those queries whose KB results\ncover the entities mentioned in subsequent dialog. Further analysis reveals\nthat correlation among query attributes in KB can significantly confuse memory\naugmented policy optimization (MAPO), an existing state of the art RL agent. To\naddress this, we improve the MAPO baseline with simple but important\nmodifications suited to our task. To train the full TOD system for our setting,\nwe propose a pipelined approach: it independently predicts when to make a KB\nquery (query position predictor), then predicts a KB query at the predicted\nposition (query predictor), and uses the results of predicted query in\nsubsequent dialog (next response predictor). Overall, our work proposes first\nsolutions to our novel problem, and our analysis highlights the research\nchallenges in training TOD systems without query annotation.",
          "link": "http://arxiv.org/abs/2005.00123",
          "publishedOn": "2021-06-04T01:12:29.010Z",
          "wordCount": 689,
          "title": "Unsupervised Learning of KB Queries in Task-Oriented Dialogs. (arXiv:2005.00123v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2003.00865",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Soremekun_E/0/1/0/all/0/1\">Ezekiel Soremekun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Udeshi_S/0/1/0/all/0/1\">Sakshi Udeshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chattopadhyay_S/0/1/0/all/0/1\">Sudipta Chattopadhyay</a>",
          "description": "The introduction of robust optimisation has pushed the state-of-the-art in\ndefending against adversarial attacks. However, the behaviour of such\noptimisation has not been studied in the light of a fundamentally different\nclass of attacks called backdoors. In this paper, we demonstrate that\nadversarially robust models are susceptible to backdoor attacks. Subsequently,\nwe observe that backdoors are reflected in the feature representation of such\nmodels. Then, this observation is leveraged to detect backdoor-infected models\nvia a detection technique called AEGIS. Specifically, AEGIS uses feature\nclustering to effectively detect backdoor-infected robust Deep Neural Networks\n(DNNs). In our evaluation of several visible and hidden backdoor triggers on\nmajor classification tasks using CIFAR-10, MNIST and FMNIST datasets, AEGIS\neffectively detects robust DNNs infected with backdoors. AEGIS detects a\nbackdoor-infected model with 91.6% accuracy, without any false positives.\nFurthermore, AEGIS detects the targeted class in the backdoor-infected model\nwith a reasonably low (11.1%) false positive rate. Our investigation reveals\nthat salient features of adversarially robust DNNs break the stealthy nature of\nbackdoor attacks.",
          "link": "http://arxiv.org/abs/2003.00865",
          "publishedOn": "2021-06-04T01:12:29.003Z",
          "wordCount": 641,
          "title": "Exposing Backdoors in Robust Machine Learning Models. (arXiv:2003.00865v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02017",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mozhi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deb_B/0/1/0/all/0/1\">Budhaditya Deb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1\">Guoqing Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shokouhi_M/0/1/0/all/0/1\">Milad Shokouhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1\">Ahmed Hassan Awadallah</a>",
          "description": "Reply suggestion models help users process emails and chats faster. Previous\nwork only studies English reply suggestion. Instead, we present MRS, a\nmultilingual reply suggestion dataset with ten languages. MRS can be used to\ncompare two families of models: 1) retrieval models that select the reply from\na fixed set and 2) generation models that produce the reply from scratch.\nTherefore, MRS complements existing cross-lingual generalization benchmarks\nthat focus on classification and sequence labeling tasks. We build a generation\nmodel and a retrieval model as baselines for MRS. The two models have different\nstrengths in the monolingual setting, and they require different strategies to\ngeneralize across languages. MRS is publicly available at\nhttps://github.com/zhangmozhi/mrs.",
          "link": "http://arxiv.org/abs/2106.02017",
          "publishedOn": "2021-06-04T01:12:28.996Z",
          "wordCount": 553,
          "title": "A Dataset and Baselines for Multilingual Reply Suggestion. (arXiv:2106.02017v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01982",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Pinder_T/0/1/0/all/0/1\">Thomas Pinder</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Turnbull_K/0/1/0/all/0/1\">Kathryn Turnbull</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nemeth_C/0/1/0/all/0/1\">Christopher Nemeth</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Leslie_D/0/1/0/all/0/1\">David Leslie</a>",
          "description": "We derive a Matern Gaussian process (GP) on the vertices of a hypergraph.\nThis enables estimation of regression models of observed or latent values\nassociated with the vertices, in which the correlation and uncertainty\nestimates are informed by the hypergraph structure. We further present a\nframework for embedding the vertices of a hypergraph into a latent space using\nthe hypergraph GP. Finally, we provide a scheme for identifying a small number\nof representative inducing vertices that enables scalable inference through\nsparse GPs. We demonstrate the utility of our framework on three challenging\nreal-world problems that concern multi-class classification for the political\nparty affiliation of legislators on the basis of voting behaviour,\nprobabilistic matrix factorisation of movie reviews, and embedding a hypergraph\nof animals into a low-dimensional latent space.",
          "link": "http://arxiv.org/abs/2106.01982",
          "publishedOn": "2021-06-04T01:12:28.989Z",
          "wordCount": 553,
          "title": "Gaussian Processes on Hypergraphs. (arXiv:2106.01982v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2002.02620",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Courts_J/0/1/0/all/0/1\">Jarrad Courts</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wills_A/0/1/0/all/0/1\">Adrian Wills</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schon_T/0/1/0/all/0/1\">Thomas B. Sch&#xf6;n</a>",
          "description": "In this paper, the problem of state estimation, in the context of both\nfiltering and smoothing, for nonlinear state-space models is considered. Due to\nthe nonlinear nature of the models, the state estimation problem is generally\nintractable as it involves integrals of general nonlinear functions and the\nfiltered and smoothed state distributions lack closed-form solutions. As such,\nit is common to approximate the state estimation problem. In this paper, we\ndevelop an assumed Gaussian solution based on variational inference, which\noffers the key advantage of a flexible, but principled, mechanism for\napproximating the required distributions. Our main contribution lies in a new\nformulation of the state estimation problem as an optimisation problem, which\ncan then be solved using standard optimisation routines that employ exact\nfirst- and second-order derivatives. The resulting state estimation approach\ninvolves a minimal number of assumptions and applies directly to nonlinear\nsystems with both Gaussian and non-Gaussian probabilistic models. The\nperformance of our approach is demonstrated on several examples; a challenging\nscalar system, a model of a simple robotic system, and a target tracking\nproblem using a von Mises-Fisher distribution and outperforms alternative\nassumed Gaussian approaches to state estimation.",
          "link": "http://arxiv.org/abs/2002.02620",
          "publishedOn": "2021-06-04T01:12:28.971Z",
          "wordCount": 646,
          "title": "Gaussian Variational State Estimation for Nonlinear State-Space Models. (arXiv:2002.02620v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2003.04696",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Perez_Garcia_F/0/1/0/all/0/1\">Fernando P&#xe9;rez-Garc&#xed;a</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sparks_R/0/1/0/all/0/1\">Rachel Sparks</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ourselin_S/0/1/0/all/0/1\">S&#xe9;bastien Ourselin</a>",
          "description": "Processing of medical images such as MRI or CT presents unique challenges\ncompared to RGB images typically used in computer vision. These include a lack\nof labels for large datasets, high computational costs, and metadata to\ndescribe the physical properties of voxels. Data augmentation is used to\nartificially increase the size of the training datasets. Training with image\npatches decreases the need for computational power. Spatial metadata needs to\nbe carefully taken into account in order to ensure a correct alignment of\nvolumes.\n\nWe present TorchIO, an open-source Python library to enable efficient\nloading, preprocessing, augmentation and patch-based sampling of medical images\nfor deep learning. TorchIO follows the style of PyTorch and integrates standard\nmedical image processing libraries to efficiently process images during\ntraining of neural networks. TorchIO transforms can be composed, reproduced,\ntraced and extended. We provide multiple generic preprocessing and augmentation\noperations as well as simulation of MRI-specific artifacts.\n\nSource code, comprehensive tutorials and extensive documentation for TorchIO\ncan be found at https://github.com/fepegar/torchio. The package can be\ninstalled from the Python Package Index running 'pip install torchio'. It\nincludes a command-line interface which allows users to apply transforms to\nimage files without using Python. Additionally, we provide a graphical\ninterface within a TorchIO extension in 3D Slicer to visualize the effects of\ntransforms.\n\nTorchIO was developed to help researchers standardize medical image\nprocessing pipelines and allow them to focus on the deep learning experiments.\nIt encourages open science, as it supports reproducibility and is version\ncontrolled so that the software can be cited precisely. Due to its modularity,\nthe library is compatible with other frameworks for deep learning with medical\nimages.",
          "link": "http://arxiv.org/abs/2003.04696",
          "publishedOn": "2021-06-04T01:12:28.964Z",
          "wordCount": 802,
          "title": "TorchIO: a Python library for efficient loading, preprocessing, augmentation and patch-based sampling of medical images in deep learning. (arXiv:2003.04696v4 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02039",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Janner_M/0/1/0/all/0/1\">Michael Janner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qiyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>",
          "description": "Reinforcement learning (RL) is typically concerned with estimating\nsingle-step policies or single-step models, leveraging the Markov property to\nfactorize the problem in time. However, we can also view RL as a sequence\nmodeling problem, with the goal being to predict a sequence of actions that\nleads to a sequence of high rewards. Viewed in this way, it is tempting to\nconsider whether powerful, high-capacity sequence prediction models that work\nwell in other domains, such as natural-language processing, can also provide\nsimple and effective solutions to the RL problem. To this end, we explore how\nRL can be reframed as \"one big sequence modeling\" problem, using\nstate-of-the-art Transformer architectures to model distributions over\nsequences of states, actions, and rewards. Addressing RL as a sequence modeling\nproblem significantly simplifies a range of design decisions: we no longer\nrequire separate behavior policy constraints, as is common in prior work on\noffline model-free RL, and we no longer require ensembles or other epistemic\nuncertainty estimators, as is common in prior work on model-based RL. All of\nthese roles are filled by the same Transformer sequence model. In our\nexperiments, we demonstrate the flexibility of this approach across\nlong-horizon dynamics prediction, imitation learning, goal-conditioned RL, and\noffline RL.",
          "link": "http://arxiv.org/abs/2106.02039",
          "publishedOn": "2021-06-04T01:12:28.957Z",
          "wordCount": 629,
          "title": "Reinforcement Learning as One Big Sequence Modeling Problem. (arXiv:2106.02039v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/1911.03070",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_M/0/1/0/all/0/1\">Michelle Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mozhi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durme_B/0/1/0/all/0/1\">Benjamin Van Durme</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Findlater_L/0/1/0/all/0/1\">Leah Findlater</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boyd_Graber_J/0/1/0/all/0/1\">Jordan Boyd-Graber</a>",
          "description": "Cross-lingual word embeddings transfer knowledge between languages: models\ntrained on high-resource languages can predict in low-resource languages. We\nintroduce CLIME, an interactive system to quickly refine cross-lingual word\nembeddings for a given classification problem. First, CLIME ranks words by\ntheir salience to the downstream task. Then, users mark similarity between\nkeywords and their nearest neighbors in the embedding space. Finally, CLIME\nupdates the embeddings using the annotations. We evaluate CLIME on identifying\nhealth-related text in four low-resource languages: Ilocano, Sinhalese,\nTigrinya, and Uyghur. Embeddings refined by CLIME capture more nuanced word\nsemantics and have higher test accuracy than the original embeddings. CLIME\noften improves accuracy faster than an active learning baseline and can be\neasily combined with active learning to improve results.",
          "link": "http://arxiv.org/abs/1911.03070",
          "publishedOn": "2021-06-04T01:12:28.950Z",
          "wordCount": 608,
          "title": "Interactive Refinement of Cross-Lingual Word Embeddings. (arXiv:1911.03070v4 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.05265",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_F/0/1/0/all/0/1\">Fangke Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Shengtian Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venkat_A/0/1/0/all/0/1\">Anand Venkat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marcus_R/0/1/0/all/0/1\">Ryan Marcus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tatbul_N/0/1/0/all/0/1\">Nesime Tatbul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tithi_J/0/1/0/all/0/1\">Jesmin Jahan Tithi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasabnis_N/0/1/0/all/0/1\">Niranjan Hasabnis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petersen_P/0/1/0/all/0/1\">Paul Petersen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mattson_T/0/1/0/all/0/1\">Timothy Mattson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kraska_T/0/1/0/all/0/1\">Tim Kraska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubey_P/0/1/0/all/0/1\">Pradeep Dubey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_V/0/1/0/all/0/1\">Vivek Sarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gottschlich_J/0/1/0/all/0/1\">Justin Gottschlich</a>",
          "description": "Code semantics similarity can be used for many tasks such as code\nrecommendation, automated software defect correction, and clone detection. Yet,\nthe accuracy of such systems has not yet reached a level of general purpose\nreliability. To help address this, we present Machine Inferred Code Similarity\n(MISIM), a neural code semantics similarity system consisting of two core\ncomponents: (i)MISIM uses a novel context-aware semantics structure, which was\npurpose-built to lift semantics from code syntax; (ii)MISIM uses an extensible\nneural code similarity scoring algorithm, which can be used for various neural\nnetwork architectures with learned parameters. We compare MISIM to four\nstate-of-the-art systems, including two additional hand-customized models, over\n328K programs consisting of over 18 million lines of code. Our experiments show\nthat MISIM has 8.08% better accuracy (using MAP@R) compared to the next best\nperforming system.",
          "link": "http://arxiv.org/abs/2006.05265",
          "publishedOn": "2021-06-04T01:12:28.943Z",
          "wordCount": 672,
          "title": "MISIM: A Neural Code Semantics Similarity System Using the Context-Aware Semantics Structure. (arXiv:2006.05265v6 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.03355",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+He_X/0/1/0/all/0/1\">Xi He</a>",
          "description": "Correlation alignment (CORAL), a representative domain adaptation (DA)\nalgorithm, decorrelates and aligns a labelled source domain dataset to an\nunlabelled target domain dataset to minimize the domain shift such that a\nclassifier can be applied to predict the target domain labels. In this paper,\nwe implement the CORAL on quantum devices by two different methods. One method\nutilizes quantum basic linear algebra subroutines (QBLAS) to implement the\nCORAL with exponential speedup in the number and dimension of the given data\nsamples. The other method is achieved through a variational hybrid\nquantum-classical procedure. In addition, the numerical experiments of the\nCORAL with three different types of data sets, namely the synthetic data, the\nsynthetic-Iris data, the handwritten digit data, are presented to evaluate the\nperformance of our work. The simulation results prove that the variational\nquantum correlation alignment algorithm (VQCORAL) can achieve competitive\nperformance compared with the classical CORAL.",
          "link": "http://arxiv.org/abs/2005.03355",
          "publishedOn": "2021-06-04T01:12:28.925Z",
          "wordCount": 618,
          "title": "Quantum correlation alignment for unsupervised domain adaptation. (arXiv:2005.03355v4 [quant-ph] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01963",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Torres_L/0/1/0/all/0/1\">Luis Caicedo Torres</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pereira_L/0/1/0/all/0/1\">Luiz Manella Pereira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amini_M/0/1/0/all/0/1\">M. Hadi Amini</a>",
          "description": "Optimal Transport (OT) theory has seen an increasing amount of attention from\nthe computer science community due to its potency and relevance in modeling and\nmachine learning. It introduces means that serve as powerful ways to compare\nprobability distributions with each other, as well as producing optimal\nmappings to minimize cost functions. In this survey, we present a brief\nintroduction and history, a survey of previous work and propose directions of\nfuture study. We will begin by looking at the history of optimal transport and\nintroducing the founders of this field. We then give a brief glance into the\nalgorithms related to OT. Then, we will follow up with a mathematical\nformulation and the prerequisites to understand OT. These include Kantorovich\nduality, entropic regularization, KL Divergence, and Wassertein barycenters.\nSince OT is a computationally expensive problem, we then introduce the\nentropy-regularized version of computing optimal mappings, which allowed OT\nproblems to become applicable in a wide range of machine learning problems. In\nfact, the methods generated from OT theory are competitive with the current\nstate-of-the-art methods. We follow this up by breaking down research papers\nthat focus on image processing, graph learning, neural architecture search,\ndocument representation, and domain adaptation. We close the paper with a small\nsection on future research. Of the recommendations presented, three main\nproblems are fundamental to allow OT to become widely applicable but rely\nstrongly on its mathematical formulation and thus are hardest to answer. Since\nOT is a novel method, there is plenty of space for new research, and with more\nand more competitive methods (either on an accuracy level or computational\nspeed level) being created, the future of applied optimal transport is bright\nas it has become pervasive in machine learning.",
          "link": "http://arxiv.org/abs/2106.01963",
          "publishedOn": "2021-06-04T01:12:28.917Z",
          "wordCount": 719,
          "title": "A Survey on Optimal Transport for Machine Learning: Theory and Applications. (arXiv:2106.01963v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2008.11700",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lew_T/0/1/0/all/0/1\">Thomas Lew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Apoorva Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harrison_J/0/1/0/all/0/1\">James Harrison</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bylard_A/0/1/0/all/0/1\">Andrew Bylard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pavone_M/0/1/0/all/0/1\">Marco Pavone</a>",
          "description": "Safe deployment of autonomous robots in diverse scenarios requires agents\nthat are capable of efficiently adapting to new environments while satisfying\nconstraints. In this work, we propose a practical and theoretically-justified\napproach to maintaining safety in the presence of dynamics uncertainty. Our\napproach leverages Bayesian meta-learning with last-layer adaptation: the\nexpressiveness of neural-network features trained offline, paired with\nefficient last-layer online adaptation, enables the derivation of tight\nconfidence sets which contract around the true dynamics as the model adapts\nonline. We exploit these confidence sets to plan trajectories that guarantee\nthe safety of the system. Our approach handles problems with high dynamics\nuncertainty where reaching the goal safely is initially infeasible by first\nexploring to gather data and reduce uncertainty, before autonomously exploiting\nthe acquired information to safely perform the task. Under reasonable\nassumptions, we prove that our framework has high-probability guarantees of\nsatisfying all constraints at all times jointly. This analysis also motivates\ntwo regularizers of last-layer meta-learners that improve online adaptation\ncapabilities as well as performance by reducing the size of the confidence\nsets. We extensively demonstrate our approach in simulation and on hardware.",
          "link": "http://arxiv.org/abs/2008.11700",
          "publishedOn": "2021-06-04T01:12:28.909Z",
          "wordCount": 663,
          "title": "Safe Active Dynamics Learning and Control: A Sequential Exploration-Exploitation Framework. (arXiv:2008.11700v3 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01960",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vechtomova_O/0/1/0/all/0/1\">Olga Vechtomova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahu_G/0/1/0/all/0/1\">Gaurav Sahu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_D/0/1/0/all/0/1\">Dhruv Kumar</a>",
          "description": "We describe a real-time system that receives a live audio stream from a jam\nsession and generates lyric lines that are congruent with the live music being\nplayed. Two novel approaches are proposed to align the learned latent spaces of\naudio and text representations that allow the system to generate novel lyric\nlines matching live instrumental music. One approach is based on adversarial\nalignment of latent representations of audio and lyrics, while the other\napproach learns to transfer the topology from the music latent space to the\nlyric latent space. A user study with music artists using the system showed\nthat the system was useful not only in lyric composition, but also encouraged\nthe artists to improvise and find new musical expressions. Another user study\ndemonstrated that users preferred the lines generated using the proposed\nmethods to the lines generated by a baseline model.",
          "link": "http://arxiv.org/abs/2106.01960",
          "publishedOn": "2021-06-04T01:12:28.902Z",
          "wordCount": 598,
          "title": "LyricJam: A system for generating lyrics for live instrumental music. (arXiv:2106.01960v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01975",
          "author": "<a href=\"http://arxiv.org/find/hep-lat/1/au:+Kanwar_G/0/1/0/all/0/1\">Gurtej Kanwar</a>",
          "description": "In lattice quantum field theory studies, parameters defining the lattice\ntheory must be tuned toward criticality to access continuum physics. Commonly\nused Markov chain Monte Carlo (MCMC) methods suffer from critical slowing down\nin this limit, restricting the precision of continuum extrapolations. Further\ndifficulties arise when measuring correlation functions of operators widely\nseparated in spacetime: for most correlation functions, an exponentially severe\nsignal-to-noise problem is encountered as the operators are taken to be widely\nseparated. This dissertation details two new techniques to address these\nissues. First, we define a novel MCMC algorithm based on generative flow-based\nmodels. Such models utilize machine learning methods to describe efficient\napproximate samplers for distributions of interest. Independently drawn\nflow-based samples are then used as proposals in an asymptotically exact\nMetropolis-Hastings Markov chain. We address incorporating symmetries of\ninterest, including translational and gauge symmetries. We secondly introduce\nan approach to \"deform\" Monte Carlo estimators based on contour deformations\napplied to the domain of the path integral. The deformed estimators associated\nwith an observable give equivalent unbiased measurements of that observable,\nbut generically have different variances. We define families of deformed\nmanifolds for lattice gauge theories and introduce methods to efficiently\noptimize the choice of manifold (the \"observifold\"), minimizing the deformed\nobservable variance. Finally, we demonstrate that flow-based MCMC can mitigate\ncritical slowing down and observifolds can exponentially reduce variance in\nproof-of-principle applications to scalar $\\phi^4$ theory and $\\mathrm{U}(1)$\nand $\\mathrm{SU}(N)$ lattice gauge theories.",
          "link": "http://arxiv.org/abs/2106.01975",
          "publishedOn": "2021-06-04T01:12:28.895Z",
          "wordCount": 687,
          "title": "Machine Learning and Variational Algorithms for Lattice Field Theory. (arXiv:2106.01975v1 [hep-lat])"
        },
        {
          "id": "http://arxiv.org/abs/1905.04629",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yao_Q/0/1/0/all/0/1\">Quanming Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hangsi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_E/0/1/0/all/0/1\">En-Liang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwok_J/0/1/0/all/0/1\">James Kwok</a>",
          "description": "In real-world applications, it is important for machine learning algorithms\nto be robust against data outliers or corruptions. In this paper, we focus on\nimproving the robustness of a large class of learning algorithms that are\nformulated as low-rank semi-definite programming (SDP) problems. Traditional\nformulations use square loss, which is notorious for being sensitive to\noutliers. We propose to replace this with more robust noise models, including\nthe $\\ell_1$-loss and other nonconvex losses. However, the resultant\noptimization problem becomes difficult as the objective is no longer convex or\nsmooth. To alleviate this problem, we design an efficient algorithm based on\nmajorization-minimization. The crux is on constructing a good optimization\nsurrogate, and we show that this surrogate can be efficiently obtained by the\nalternating direction method of multipliers (ADMM). By properly monitoring\nADMM's convergence, the proposed algorithm is empirically efficient and also\ntheoretically guaranteed to converge to a critical point. Extensive experiments\nare performed on four machine learning applications using both synthetic and\nreal-world data sets. Results show that the proposed algorithm is not only fast\nbut also has better performance than the state-of-the-art.",
          "link": "http://arxiv.org/abs/1905.04629",
          "publishedOn": "2021-06-04T01:12:28.875Z",
          "wordCount": 655,
          "title": "Efficient Low-Rank Semidefinite Programming with Robust Loss Functions. (arXiv:1905.04629v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01981",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oreshkin_B/0/1/0/all/0/1\">Boris N. Oreshkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bocquelet_F/0/1/0/all/0/1\">Florent Bocquelet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harvey_F/0/1/0/all/0/1\">F&#xe9;lix H. Harvey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raitt_B/0/1/0/all/0/1\">Bay Raitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laflamme_D/0/1/0/all/0/1\">Dominic Laflamme</a>",
          "description": "Our work focuses on the development of a learnable neural representation of\nhuman pose for advanced AI assisted animation tooling. Specifically, we tackle\nthe problem of constructing a full static human pose based on sparse and\nvariable user inputs (e.g. locations and/or orientations of a subset of body\njoints). To solve this problem, we propose a novel neural architecture that\ncombines residual connections with prototype encoding of a partially specified\npose to create a new complete pose from the learned latent space. We show that\nour architecture outperforms a baseline based on Transformer, both in terms of\naccuracy and computational efficiency. Additionally, we develop a user\ninterface to integrate our neural model in Unity, a real-time 3D development\nplatform. Furthermore, we introduce two new datasets representing the static\nhuman pose modeling problem, based on high-quality human motion capture data,\nwhich will be released publicly along with model code.",
          "link": "http://arxiv.org/abs/2106.01981",
          "publishedOn": "2021-06-04T01:12:28.860Z",
          "wordCount": 592,
          "title": "ProtoRes: Proto-Residual Architecture for Deep Modeling of Human Pose. (arXiv:2106.01981v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01504",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Killea_R/0/1/0/all/0/1\">Ryan Killea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bastani_S/0/1/0/all/0/1\">Saeed Bastani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McLachlan_P/0/1/0/all/0/1\">Paul McLachlan</a>",
          "description": "Point clouds are a basic data type that is increasingly of interest as 3D\ncontent becomes more ubiquitous. Applications using point clouds include\nvirtual, augmented, and mixed reality and autonomous driving. We propose a more\nefficient deep learning-based encoder architecture for point clouds compression\nthat incorporates principles from established 3D object detection and image\ncompression architectures. Through an ablation study, we show that\nincorporating the learned activation function from Computational Efficient\nNeural Image Compression (CENIC) and designing more parameter-efficient\nconvolutional blocks yields dramatic gains in efficiency and performance. Our\nproposed architecture incorporates Generalized Divisive Normalization\nactivations and propose a spatially separable InceptionV4-inspired block. We\nthen evaluate rate-distortion curves on the standard JPEG Pleno 8i Voxelized\nFull Bodies dataset to evaluate our model's performance. Our proposed\nmodifications outperform the baseline approaches by a small margin in terms of\nBjontegard delta rate and PSNR values, yet reduces necessary encoder\nconvolution operations by 8 percent and reduces total encoder parameters by 20\npercent. Our proposed architecture, when considered on its own, has a small\npenalty of 0.02 percent in Chamfer's Distance and 0.32 percent increased bit\nrate in Point to Plane Distance for the same peak signal-to-noise ratio.",
          "link": "http://arxiv.org/abs/2106.01504",
          "publishedOn": "2021-06-04T01:12:28.845Z",
          "wordCount": 639,
          "title": "DeepCompress: Efficient Point Cloud Geometry Compression. (arXiv:2106.01504v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01958",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nair_A/0/1/0/all/0/1\">Abhishek Ramdas Nair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nath_P/0/1/0/all/0/1\">Pallab Kumar Nath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakrabartty_S/0/1/0/all/0/1\">Shantanu Chakrabartty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thakur_C/0/1/0/all/0/1\">Chetan Singh Thakur</a>",
          "description": "We present a novel framework for designing multiplierless kernel machines\nthat can be used on resource-constrained platforms like intelligent edge\ndevices. The framework uses a piecewise linear (PWL) approximation based on a\nmargin propagation (MP) technique and uses only addition/subtraction, shift,\ncomparison, and register underflow/overflow operations. We propose a\nhardware-friendly MP-based inference and online training algorithm that has\nbeen optimized for a Field Programmable Gate Array (FPGA) platform. Our FPGA\nimplementation eliminates the need for DSP units and reduces the number of\nLUTs. By reusing the same hardware for inference and training, we show that the\nplatform can overcome classification errors and local minima artifacts that\nresult from the MP approximation. Using the FPGA platform, we also show that\nthe proposed multiplierless MP-kernel machine demonstrates superior performance\nin terms of power, performance, and area compared to other comparable\nimplementations.",
          "link": "http://arxiv.org/abs/2106.01958",
          "publishedOn": "2021-06-04T01:12:28.743Z",
          "wordCount": 568,
          "title": "Multiplierless MP-Kernel Machine For Energy-efficient Edge Devices. (arXiv:2106.01958v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01954",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Korotin_A/0/1/0/all/0/1\">Alexander Korotin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lingxiao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Genevay_A/0/1/0/all/0/1\">Aude Genevay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Solomon_J/0/1/0/all/0/1\">Justin Solomon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Filippov_A/0/1/0/all/0/1\">Alexander Filippov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burnaev_E/0/1/0/all/0/1\">Evgeny Burnaev</a>",
          "description": "Despite the recent popularity of neural network-based solvers for optimal\ntransport (OT), there is no standard quantitative way to evaluate their\nperformance. In this paper, we address this issue for quadratic-cost transport\n-- specifically, computation of the Wasserstein-2 distance, a commonly-used\nformulation of optimal transport in machine learning. To overcome the challenge\nof computing ground truth transport maps between continuous measures needed to\nassess these solvers, we use input-convex neural networks (ICNN) to construct\npairs of measures whose ground truth OT maps can be obtained analytically. This\nstrategy yields pairs of continuous benchmark measures in high-dimensional\nspaces such as spaces of images. We thoroughly evaluate existing optimal\ntransport solvers using these benchmark measures. Even though these solvers\nperform well in downstream tasks, many do not faithfully recover optimal\ntransport maps. To investigate the cause of this discrepancy, we further test\nthe solvers in a setting of image generation. Our study reveals crucial\nlimitations of existing solvers and shows that increased OT accuracy does not\nnecessarily correlate to better results downstream.",
          "link": "http://arxiv.org/abs/2106.01954",
          "publishedOn": "2021-06-04T01:12:28.689Z",
          "wordCount": 602,
          "title": "Do Neural Optimal Transport Solvers Work? A Continuous Wasserstein-2 Benchmark. (arXiv:2106.01954v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01854",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Taghibakhshi_A/0/1/0/all/0/1\">Ali Taghibakhshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+MacLachlan_S/0/1/0/all/0/1\">Scott MacLachlan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olson_L/0/1/0/all/0/1\">Luke Olson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+West_M/0/1/0/all/0/1\">Matthew West</a>",
          "description": "Large sparse linear systems of equations are ubiquitous in science and\nengineering, such as those arising from discretizations of partial differential\nequations. Algebraic multigrid (AMG) methods are one of the most common methods\nof solving such linear systems, with an extensive body of underlying\nmathematical theory. A system of linear equations defines a graph on the set of\nunknowns and each level of a multigrid solver requires the selection of an\nappropriate coarse graph along with restriction and interpolation operators\nthat map to and from the coarse representation. The efficiency of the multigrid\nsolver depends critically on this selection and many selection methods have\nbeen developed over the years. Recently, it has been demonstrated that it is\npossible to directly learn the AMG interpolation and restriction operators,\ngiven a coarse graph selection. In this paper, we consider the complementary\nproblem of learning to coarsen graphs for a multigrid solver. We propose a\nmethod using a reinforcement learning (RL) agent based on graph neural networks\n(GNNs), which can learn to perform graph coarsening on small training graphs\nand then be applied to unstructured large graphs. We demonstrate that this\nmethod can produce better coarse graphs than existing algorithms, even as the\ngraph size increases and other properties of the graph are varied. We also\npropose an efficient inference procedure for performing graph coarsening that\nresults in linear time complexity in graph size.",
          "link": "http://arxiv.org/abs/2106.01854",
          "publishedOn": "2021-06-04T01:12:28.682Z",
          "wordCount": 652,
          "title": "Optimization-Based Algebraic Multigrid Coarsening Using Reinforcement Learning. (arXiv:2106.01854v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01834",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lesort_T/0/1/0/all/0/1\">Timoth&#xe9;e Lesort</a>, <a href=\"http://arxiv.org/find/cs/1/au:+George_T/0/1/0/all/0/1\">Thomas George</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rish_I/0/1/0/all/0/1\">Irina Rish</a>",
          "description": "We study how different output layer types of a deep neural network learn and\nforget in continual learning settings. We describe the three factors affecting\ncatastrophic forgetting in the output layer: (1) weights modifications, (2)\ninterferences, and (3) projection drift. Our goal is to provide more insights\ninto how different types of output layers can address (1) and (2). We also\npropose potential solutions and evaluate them on several benchmarks. We show\nthat the best-performing output layer type depends on the data distribution\ndrifts or the amount of data available. In particular, in some cases where a\nstandard linear layer would fail, it is sufficient to change the\nparametrization and get significantly better performance while still training\nwith SGD. Our results and analysis shed light on the dynamics of the output\nlayer in continual learning scenarios and help select the best-suited output\nlayer for a given scenario.",
          "link": "http://arxiv.org/abs/2106.01834",
          "publishedOn": "2021-06-04T01:12:28.675Z",
          "wordCount": 578,
          "title": "Continual Learning in Deep Networks: an Analysis of the Last Layer. (arXiv:2106.01834v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01761",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Luo_L/0/1/0/all/0/1\">Luo Luo</a>, <a href=\"http://arxiv.org/find/math/1/au:+Xie_G/0/1/0/all/0/1\">Guangzeng Xie</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_T/0/1/0/all/0/1\">Tong Zhang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhihua Zhang</a>",
          "description": "This paper considers stochastic first-order algorithms for convex-concave\nminimax problems of the form $\\min_{\\bf x}\\max_{\\bf y}f(\\bf x, \\bf y)$, where\n$f$ can be presented by the average of $n$ individual components which are\n$L$-average smooth. For $\\mu_x$-strongly-convex-$\\mu_y$-strongly-concave\nsetting, we propose a new method which could find a $\\varepsilon$-saddle point\nof the problem in $\\tilde{\\mathcal O}\n\\big(\\sqrt{n(\\sqrt{n}+\\kappa_x)(\\sqrt{n}+\\kappa_y)}\\log(1/\\varepsilon)\\big)$\nstochastic first-order complexity, where $\\kappa_x\\triangleq L/\\mu_x$ and\n$\\kappa_y\\triangleq L/\\mu_y$. This upper bound is near optimal with respect to\n$\\varepsilon$, $n$, $\\kappa_x$ and $\\kappa_y$ simultaneously. In addition, the\nalgorithm is easily implemented and works well in practical. Our methods can be\nextended to solve more general unbalanced convex-concave minimax problems and\nthe corresponding upper complexity bounds are also near optimal.",
          "link": "http://arxiv.org/abs/2106.01761",
          "publishedOn": "2021-06-04T01:12:28.668Z",
          "wordCount": 548,
          "title": "Near Optimal Stochastic Algorithms for Finite-Sum Unbalanced Convex-Concave Minimax Optimization. (arXiv:2106.01761v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01858",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tjostheim_D/0/1/0/all/0/1\">Dag Tj&#xf8;stheim</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Jullum_M/0/1/0/all/0/1\">Martin Jullum</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Loland_A/0/1/0/all/0/1\">Anders L&#xf8;land</a>",
          "description": "There has been an intense recent activity in embedding of very high\ndimensional and nonlinear data structures, much of it in the data science and\nmachine learning literature. We survey this activity in four parts. In the\nfirst part we cover nonlinear methods such as principal curves,\nmultidimensional scaling, local linear methods, ISOMAP, graph based methods and\nkernel based methods. The second part is concerned with topological embedding\nmethods, in particular mapping topological properties into persistence\ndiagrams. Another type of data sets with a tremendous growth is very\nhigh-dimensional network data. The task considered in part three is how to\nembed such data in a vector space of moderate dimension to make the data\namenable to traditional techniques such as cluster and classification\ntechniques. The final part of the survey deals with embedding in\n$\\mathbb{R}^2$, which is visualization. Three methods are presented: $t$-SNE,\nUMAP and LargeVis based on methods in parts one, two and three, respectively.\nThe methods are illustrated and compared on two simulated data sets; one\nconsisting of a triple of noisy Ranunculoid curves, and one consisting of\nnetworks of increasing complexity and with two types of nodes.",
          "link": "http://arxiv.org/abs/2106.01858",
          "publishedOn": "2021-06-04T01:12:28.662Z",
          "wordCount": 621,
          "title": "Statistical embedding: Beyond principal components. (arXiv:2106.01858v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01798",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Niepert_M/0/1/0/all/0/1\">Mathias Niepert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Minervini_P/0/1/0/all/0/1\">Pasquale Minervini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Franceschi_L/0/1/0/all/0/1\">Luca Franceschi</a>",
          "description": "Integrating discrete probability distributions and combinatorial optimization\nproblems into neural networks has numerous applications but poses several\nchallenges. We propose Implicit Maximum Likelihood Estimation (I-MLE), a\nframework for end-to-end learning of models combining discrete exponential\nfamily distributions and differentiable neural components. I-MLE is widely\napplicable: it only requires the ability to compute the most probable states;\nand does not rely on smooth relaxations. The framework encompasses several\napproaches, such as perturbation-based implicit differentiation and recent\nmethods to differentiate through black-box combinatorial solvers. We introduce\na novel class of noise distributions for approximating marginals via\nperturb-and-MAP. Moreover, we show that I-MLE simplifies to maximum likelihood\nestimation when used in some recently studied learning settings that involve\ncombinatorial solvers. Experiments on several datasets suggest that I-MLE is\ncompetitive with and often outperforms existing approaches which rely on\nproblem-specific relaxations.",
          "link": "http://arxiv.org/abs/2106.01798",
          "publishedOn": "2021-06-04T01:12:28.655Z",
          "wordCount": 562,
          "title": "Implicit MLE: Backpropagating Through Discrete Exponential Family Distributions. (arXiv:2106.01798v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01917",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bauer_Marquart_F/0/1/0/all/0/1\">Fabian Bauer-Marquart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leue_S/0/1/0/all/0/1\">Stefan Leue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schilling_C/0/1/0/all/0/1\">Christian Schilling</a>",
          "description": "Decisions made by deep neural networks (DNNs) have a tremendous impact on the\ndependability of the systems that they are embedded into, which is of\nparticular concern in the realm of safety-critical systems. In this paper we\nconsider specification-based falsification of DNNs with the aim to support\ndebugging and repair. We propose DeepOpt, a falsification technique based on\nblack-box optimization, which generates counterexamples from a DNN in a\nrefinement loop. DeepOpt can analyze input-output specifications, which makes\nit more general than falsification approaches that only support robustness\nspecifications. The key idea is to algebraically combine the DNN with the input\nand output constraints derived from the specification. We have implemented\nDeepOpt and evaluated it on DNNs of varying sizes and architectures.\nExperimental comparisons demonstrate DeepOpt's precision and scalability; in\nparticular, DeepOpt requires very few queries to the DNN.",
          "link": "http://arxiv.org/abs/2106.01917",
          "publishedOn": "2021-06-04T01:12:28.636Z",
          "wordCount": 569,
          "title": "DeepOpt: Scalable Specification-based Falsification of Neural Networks using Black-Box Optimization. (arXiv:2106.01917v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01939",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kaddour_J/0/1/0/all/0/1\">Jean Kaddour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yuchen Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kusner_M/0/1/0/all/0/1\">Matt J. Kusner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_R/0/1/0/all/0/1\">Ricardo Silva</a>",
          "description": "We address the estimation of conditional average treatment effects (CATEs)\nwhen treatments are graph-structured (e.g., molecular graphs of drugs). Given a\nweak condition on the effect, we propose a plug-in estimator that decomposes\nCATE estimation into separate, simpler optimization problems. Our estimator (a)\nisolates the causal estimands (reducing regularization bias), and (b) allows\none to plug in arbitrary models for learning. In experiments with small-world\nand molecular graphs, we show that our approach outperforms prior approaches\nand is robust to varying selection biases. Our implementation is online.",
          "link": "http://arxiv.org/abs/2106.01939",
          "publishedOn": "2021-06-04T01:12:28.630Z",
          "wordCount": 517,
          "title": "Graph Intervention Networks for Causal Effect Estimation. (arXiv:2106.01939v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01933",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Gaddy_D/0/1/0/all/0/1\">David Gaddy</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Klein_D/0/1/0/all/0/1\">Dan Klein</a>",
          "description": "In this paper, we present an improved model for voicing silent speech, where\naudio is synthesized from facial electromyography (EMG) signals. To give our\nmodel greater flexibility to learn its own input features, we directly use EMG\nsignals as input in the place of hand-designed features used by prior work. Our\nmodel uses convolutional layers to extract features from the signals and\nTransformer layers to propagate information across longer distances. To provide\nbetter signal for learning, we also introduce an auxiliary task of predicting\nphoneme labels in addition to predicting speech audio features. On an open\nvocabulary intelligibility evaluation, our model improves the state of the art\nfor this task by an absolute 25.8%.",
          "link": "http://arxiv.org/abs/2106.01933",
          "publishedOn": "2021-06-04T01:12:28.624Z",
          "wordCount": 555,
          "title": "An Improved Model for Voicing Silent Speech. (arXiv:2106.01933v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01862",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Paredes_Valles_F/0/1/0/all/0/1\">Federico Paredes-Vall&#xe9;s</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hagenaars_J/0/1/0/all/0/1\">Jesse Hagenaars</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Croon_G/0/1/0/all/0/1\">Guido de Croon</a>",
          "description": "Neuromorphic sensing and computing hold a promise for highly energy-efficient\nand high-bandwidth-sensor processing. A major challenge for neuromorphic\ncomputing is that learning algorithms for traditional artificial neural\nnetworks (ANNs) do not transfer directly to spiking neural networks (SNNs) due\nto the discrete spikes and more complex neuronal dynamics. As a consequence,\nSNNs have not yet been successfully applied to complex, large-scale tasks. In\nthis article, we focus on the self-supervised learning problem of optical flow\nestimation from event-based camera inputs, and investigate the changes that are\nnecessary to the state-of-the-art ANN training pipeline in order to\nsuccessfully tackle it with SNNs. More specifically, we first modify the input\nevent representation to encode a much smaller time slice with minimal explicit\ntemporal information. Consequently, we make the network's neuronal dynamics and\nrecurrent connections responsible for integrating information over time.\nMoreover, we reformulate the self-supervised loss function for event-based\noptical flow to improve its convexity. We perform experiments with various\ntypes of recurrent ANNs and SNNs using the proposed pipeline. Concerning SNNs,\nwe investigate the effects of elements such as parameter initialization and\noptimization, surrogate gradient shape, and adaptive neuronal mechanisms. We\nfind that initialization and surrogate gradient width play a crucial part in\nenabling learning with sparse inputs, while the inclusion of adaptivity and\nlearnable neuronal parameters can improve performance. We show that the\nperformance of the proposed ANNs and SNNs are on par with that of the current\nstate-of-the-art ANNs trained in a self-supervised manner.",
          "link": "http://arxiv.org/abs/2106.01862",
          "publishedOn": "2021-06-04T01:12:28.618Z",
          "wordCount": 686,
          "title": "Self-Supervised Learning of Event-Based Optical Flow with Spiking Neural Networks. (arXiv:2106.01862v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01915",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Han_C/0/1/0/all/0/1\">Changhee Han</a>",
          "description": "Convolutional Neural Networks (CNNs) can play a key role in Medical Image\nAnalysis under large-scale annotated datasets. However, preparing such massive\ndataset is demanding. In this context, Generative Adversarial Networks (GANs)\ncan generate realistic but novel samples, and thus effectively cover the real\nimage distribution. In terms of interpolation, the GAN-based medical image\naugmentation is reliable because medical modalities can display the human\nbody's strong anatomical consistency at fixed position while clearly reflecting\ninter-subject variability; thus, we propose to use noise-to-image GANs (e.g.,\nrandom noise samples to diverse pathological images) for (i) medical Data\nAugmentation (DA) and (ii) physician training. Regarding the DA, the\nGAN-generated images can improve Computer-Aided Diagnosis based on supervised\nlearning. For the physician training, the GANs can display novel desired\npathological images and help train medical trainees despite\ninfrastructural/legal constraints. This thesis contains four GAN projects\naiming to present such novel applications' clinical relevance in collaboration\nwith physicians. Whereas the methods are more generally applicable, this thesis\nonly explores a few oncological applications.",
          "link": "http://arxiv.org/abs/2106.01915",
          "publishedOn": "2021-06-04T01:12:28.600Z",
          "wordCount": 631,
          "title": "Pathology-Aware Generative Adversarial Networks for Medical Image Augmentation. (arXiv:2106.01915v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01920",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhardwaj_K/0/1/0/all/0/1\">Kunal Bhardwaj</a>",
          "description": "With technological advancements and the exponential growth of data, we have\nbeen unfolding different capabilities of neural networks in different sectors.\nIn this paper, I have tried to use a specific type of Neural Network known as\nConvolutional Neural Network(CNN/ConvNet) in the stock market. In other words,\nI have tried to construct and train a convolutional neural network on past\nstock prices data and then tried to predict the movement of stock price i.e.\nwhether the stock price would rise or fall, in the coming time.",
          "link": "http://arxiv.org/abs/2106.01920",
          "publishedOn": "2021-06-04T01:12:28.594Z",
          "wordCount": 527,
          "title": "Convolutional Neural Network(CNN/ConvNet) in Stock Price Movement Prediction. (arXiv:2106.01920v1 [cs.NE])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01921",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Long_J/0/1/0/all/0/1\">James P. Long</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ha_M/0/1/0/all/0/1\">Min Jin Ha</a>",
          "description": "Causal models are notoriously difficult to validate because they make\nuntestable assumptions regarding confounding. New scientific experiments offer\nthe possibility of evaluating causal models using prediction performance.\nPrediction performance measures are typically robust to violations in causal\nassumptions. However prediction performance does depend on the selection of\ntraining and test sets. In particular biased training sets can lead to\noptimistic assessments of model performance. In this work, we revisit the\nprediction performance of several recently proposed causal models tested on a\ngenetic perturbation data set of Kemmeren [Kemmeren et al., 2014]. We find that\nsample selection bias is likely a key driver of model performance. We propose\nusing a less-biased evaluation set for assessing prediction performance on\nKemmeren and compare models on this new set. In this setting, the causal model\ntested have similar performance to standard association based estimators such\nas Lasso. Finally we compare the performance of causal estimators in simulation\nstudies which reproduce the Kemmeren structure of genetic knockout experiments\nbut without any sample selection bias. These results provide an improved\nunderstanding of the performance of several causal models and offer guidance on\nhow future studies should use Kemmeren.",
          "link": "http://arxiv.org/abs/2106.01921",
          "publishedOn": "2021-06-04T01:12:28.588Z",
          "wordCount": 635,
          "title": "Sample Selection Bias in Evaluation of Prediction Performance of Causal Models. (arXiv:2106.01921v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01741",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bossens_D/0/1/0/all/0/1\">David M. Bossens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sobey_A/0/1/0/all/0/1\">Adam J. Sobey</a>",
          "description": "A long-standing challenge in artificial intelligence is lifelong learning. In\nlifelong learning, many tasks are presented in sequence and learners must\nefficiently transfer knowledge between tasks while avoiding catastrophic\nforgetting over long lifetimes. On these problems, policy reuse and other\nmulti-policy reinforcement learning techniques can learn many tasks. However,\nthey can generate many temporary or permanent policies, resulting in memory\nissues. Consequently, there is a need for lifetime-scalable methods that\ncontinually refine a policy library of a pre-defined size. This paper presents\na first approach to lifetime-scalable policy reuse. To pre-select the number of\npolicies, a notion of task capacity, the maximal number of tasks that a policy\ncan accurately solve, is proposed. To evaluate lifetime policy reuse using this\nmethod, two state-of-the-art single-actor base-learners are compared: 1) a\nvalue-based reinforcement learner, Deep Q-Network (DQN) or Deep Recurrent\nQ-Network (DRQN); and 2) an actor-critic reinforcement learner, Proximal Policy\nOptimisation (PPO) with or without Long Short-Term Memory layer. By selecting\nthe number of policies based on task capacity, D(R)QN achieves near-optimal\nperformance with 6 policies in a 27-task MDP domain and 9 policies in an\n18-task POMDP domain; with fewer policies, catastrophic forgetting and negative\ntransfer are observed. Due to slow, monotonic improvement, PPO requires fewer\npolicies, 1 policy for the 27-task domain and 4 policies for the 18-task\ndomain, but it learns the tasks with lower accuracy than D(R)QN. These findings\nvalidate lifetime-scalable policy reuse and suggest using D(R)QN for larger and\nPPO for smaller library sizes.",
          "link": "http://arxiv.org/abs/2106.01741",
          "publishedOn": "2021-06-04T01:12:28.581Z",
          "wordCount": 682,
          "title": "Lifetime policy reuse and the importance of task capacity. (arXiv:2106.01741v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01782",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akhmedov_K/0/1/0/all/0/1\">Kodirjon Akhmedov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phan_A/0/1/0/all/0/1\">Anh Huy Phan</a>",
          "description": "Prediction of the real-time multiplayer online battle arena (MOBA) games'\nmatch outcome is one of the most important and exciting tasks in Esports\nanalytical research. This research paper predominantly focuses on building\npredictive machine and deep learning models to identify the outcome of the Dota\n2 MOBA game using the new method of multi-forward steps predictions. Three\nmodels were investigated and compared: Linear Regression (LR), Neural Networks\n(NN), and a type of recurrent neural network Long Short-Term Memory (LSTM). In\norder to achieve the goals, we developed a data collecting python server using\nGame State Integration (GSI) to track the real-time data of the players. Once\nthe exploratory feature analysis and tuning hyper-parameters were done, our\nmodels' experiments took place on different players with dissimilar backgrounds\nof playing experiences. The achieved accuracy scores depend on the\nmulti-forward prediction parameters, which for the worse case in linear\nregression 69\\% but on average 82\\%, while in the deep learning models hit the\nutmost accuracy of prediction on average 88\\% for NN, and 93\\% for LSTM models.",
          "link": "http://arxiv.org/abs/2106.01782",
          "publishedOn": "2021-06-04T01:12:28.575Z",
          "wordCount": 610,
          "title": "Machine learning models for DOTA 2 outcomes prediction. (arXiv:2106.01782v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01779",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Lu_Y/0/1/0/all/0/1\">Ying Lu</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Li_Y/0/1/0/all/0/1\">Yue-Min Li</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Zhou_P/0/1/0/all/0/1\">Peng-Fei Zhou</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Ran_S/0/1/0/all/0/1\">Shi-Ju Ran</a>",
          "description": "State preparation is of fundamental importance in quantum physics, which can\nbe realized by constructing the quantum circuit as a unitary that transforms\nthe initial state to the target, or implementing a quantum control protocol to\nevolve to the target state with a designed Hamiltonian. In this work, we study\nthe latter on quantum many-body systems by the time evolution with fixed\ncouplings and variational magnetic fields. In specific, we consider to prepare\nthe ground states of the Hamiltonians containing certain interactions that are\nmissing in the Hamiltonians for the time evolution. An optimization method is\nproposed to optimize the magnetic fields by \"fine-graining\" the discretization\nof time, in order to gain high precision and stability. The back propagation\ntechnique is utilized to obtain the gradients of the fields against the\nlogarithmic fidelity. Our method is tested on preparing the ground state of\nHeisenberg chain with the time evolution by the XY and Ising interactions, and\nits performance surpasses two baseline methods that use local and global\noptimization strategies, respectively. Our work can be applied and generalized\nto other quantum models such as those defined on higher dimensional lattices.\nIt enlightens to reduce the complexity of the required interactions for\nimplementing quantum control or other tasks in quantum information and\ncomputation by means of optimizing the magnetic fields.",
          "link": "http://arxiv.org/abs/2106.01779",
          "publishedOn": "2021-06-04T01:12:28.568Z",
          "wordCount": 667,
          "title": "Preparation of Many-body Ground States by Time Evolution with Variational Microscopic Magnetic Fields and Incomplete Interactions. (arXiv:2106.01779v1 [quant-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01735",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tasar_D/0/1/0/all/0/1\">D. Emre Ta&#x15f;ar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozan_S/0/1/0/all/0/1\">&#x15e;&#xfc;kr&#xfc; Ozan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozdil_U/0/1/0/all/0/1\">Umut &#xd6;zdil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akca_M/0/1/0/all/0/1\">M. Fatih Akca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olmez_O/0/1/0/all/0/1\">O&#x11f;uzhan &#xd6;lmez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gulum_S/0/1/0/all/0/1\">Semih G&#xfc;l&#xfc;m</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kutal_S/0/1/0/all/0/1\">Se&#xe7;ilay Kutal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belhan_C/0/1/0/all/0/1\">Ceren Belhan</a>",
          "description": "The problem of categorizing short speech sentences according to their\nsemantic features with high accuracy is a subject studied in natural language\nprocessing. In this study, a data set created with samples classified in 46\ndifferent categories was used. Examples consist of sentences taken from chat\nconversations between a company's customer representatives and the company's\nwebsite visitors. The primary purpose is to automatically tag questions and\nrequests from visitors in the most accurate way for 46 predetermined categories\nfor use in a chat application to generate meaningful answers to the questions\nasked by the website visitors. For this, different BERT models and one GPT-2\nmodel, pre-trained in Turkish, were preferred. The classification performances\nof the relevant models were analyzed in detail and reported accordingly.",
          "link": "http://arxiv.org/abs/2106.01735",
          "publishedOn": "2021-06-04T01:12:28.562Z",
          "wordCount": 569,
          "title": "Auto-tagging of Short Conversational Sentences using Transformer Methods. (arXiv:2106.01735v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01805",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiang_T/0/1/0/all/0/1\">Tiange Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chaoyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yang Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Siqi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1\">Hongliang Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_W/0/1/0/all/0/1\">Weidong Cai</a>",
          "description": "Regularizers helped deep neural networks prevent feature co-adaptations.\nDropout,as a commonly used regularization technique, stochastically disables\nneuron ac-tivations during network optimization. However, such complete feature\ndisposal can affect the feature representation and network understanding.\nToward betterdescriptions of latent representations, we present DropGraph that\nlearns regularization function by constructing a stand-alone graph from the\nbackbone features. DropGraph first samples stochastic spatial feature vectors\nand then incorporates graph reasoning methods to generate feature map\ndistortions. This add-on graph regularizes the network during training and can\nbe completely skipped during inference. We provide intuitions on the linkage\nbetween graph reasoning andDropout with further discussions on how partial\ngraph reasoning method reduces feature correlations. To this end, we\nextensively study the modeling of graphvertex dependencies and the utilization\nof the graph for distorting backbone featuremaps. DropGraph was validated on\nfour tasks with a total of 7 different datasets.The experimental results show\nthat our method outperforms other state-of-the-art regularizers while leaving\nthe base model structure unmodified during inference.",
          "link": "http://arxiv.org/abs/2106.01805",
          "publishedOn": "2021-06-04T01:12:28.544Z",
          "wordCount": 599,
          "title": "Partial Graph Reasoning for Neural Network Regularization. (arXiv:2106.01805v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01770",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Trick_S/0/1/0/all/0/1\">Susanne Trick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rothkopf_C/0/1/0/all/0/1\">Constantin A. Rothkopf</a>",
          "description": "Combining the outputs of multiple classifiers or experts into a single\nprobabilistic classification is a fundamental task in machine learning with\nbroad applications from classifier fusion to expert opinion pooling. Here we\npresent a hierarchical Bayesian model of probabilistic classifier fusion based\non a new correlated Dirichlet distribution. This distribution explicitly models\npositive correlations between marginally Dirichlet-distributed random vectors\nthereby allowing normative modeling of correlations between base classifiers or\nexperts. The proposed model naturally accommodates the classic Independent\nOpinion Pool and other independent fusion algorithms as special cases. It is\nevaluated by uncertainty reduction and correctness of fusion on synthetic and\nreal-world data sets. We show that a change in performance of the fused\nclassifier due to uncertainty reduction can be Bayes optimal even for highly\ncorrelated base classifiers.",
          "link": "http://arxiv.org/abs/2106.01770",
          "publishedOn": "2021-06-04T01:12:28.538Z",
          "wordCount": 560,
          "title": "A Normative Model of Classifier Fusion. (arXiv:2106.01770v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01830",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Fukuda_A/0/1/0/all/0/1\">Akihiro Fukuda</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Han_C/0/1/0/all/0/1\">Changhee Han</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hakamada_K/0/1/0/all/0/1\">Kazumi Hakamada</a>",
          "description": "Machine Learning-based fast and quantitative automated screening plays a key\nrole in analyzing human bones on Computed Tomography (CT) scans. However,\ndespite the requirement in drug safety assessment, such research is rare on\nanimal fetus micro-CT scans due to its laborious data collection and\nannotation. Therefore, we propose various bone feature engineering techniques\nto thoroughly automate the skeletal localization/labeling/abnormality detection\nof rat fetuses on whole-body micro-CT scans with minimum effort. Despite\nlimited training data of 49 fetuses, in skeletal labeling and abnormality\ndetection, we achieve accuracy of 0.900 and 0.810, respectively.",
          "link": "http://arxiv.org/abs/2106.01830",
          "publishedOn": "2021-06-04T01:12:28.531Z",
          "wordCount": 550,
          "title": "Effort-free Automated Skeletal Abnormality Detection of Rat Fetuses on Whole-body Micro-CT Scans. (arXiv:2106.01830v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01883",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xue Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaojiang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jirui Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ming_Q/0/1/0/all/0/1\">Qi Ming</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wentao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1\">Qi Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Junchi Yan</a>",
          "description": "Existing rotated object detectors are mostly inherited from the horizontal\ndetection paradigm, as the latter has evolved into a well-developed area.\nHowever, these detectors are difficult to perform prominently in high-precision\ndetection due to the limitation of current regression loss design, especially\nfor objects with large aspect ratios. Taking the perspective that horizontal\ndetection is a special case for rotated object detection, in this paper, we are\nmotivated to change the design of rotation regression loss from induction\nparadigm to deduction methodology, in terms of the relation between rotation\nand horizontal detection. We show that one essential challenge is how to\nmodulate the coupled parameters in the rotation regression loss, as such the\nestimated parameters can influence to each other during the dynamic joint\noptimization, in an adaptive and synergetic way. Specifically, we first convert\nthe rotated bounding box into a 2-D Gaussian distribution, and then calculate\nthe Kullback-Leibler Divergence (KLD) between the Gaussian distributions as the\nregression loss. By analyzing the gradient of each parameter, we show that KLD\n(and its derivatives) can dynamically adjust the parameter gradients according\nto the characteristics of the object. It will adjust the importance (gradient\nweight) of the angle parameter according to the aspect ratio. This mechanism\ncan be vital for high-precision detection as a slight angle error would cause a\nserious accuracy drop for large aspect ratios objects. More importantly, we\nhave proved that KLD is scale invariant. We further show that the KLD loss can\nbe degenerated into the popular $l_{n}$-norm loss for horizontal detection.\nExperimental results on seven datasets using different detectors show its\nconsistent superiority, and codes are available at\nhttps://github.com/yangxue0827/RotationDetection.",
          "link": "http://arxiv.org/abs/2106.01883",
          "publishedOn": "2021-06-04T01:12:28.514Z",
          "wordCount": 731,
          "title": "Learning High-Precision Bounding Box for Rotated Object Detection via Kullback-Leibler Divergence. (arXiv:2106.01883v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01467",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akhmetov_K/0/1/0/all/0/1\">Kamil Akhmetov</a>",
          "description": "Bringing empathy to a computerized system could significantly improve the\nquality of human-computer communications, as soon as machines would be able to\nunderstand customer intentions and better serve their needs. According to\ndifferent studies (Literature Review), visual information is one of the most\nimportant channels of human interaction and contains significant behavioral\nsignals, that may be captured from facial expressions. Therefore, it is\nconsistent and natural that the research in the field of Facial Expression\nRecognition (FER) has acquired increased interest over the past decade due to\nhaving diverse application area including health-care, sociology, psychology,\ndriver-safety, virtual reality, cognitive sciences, security, entertainment,\nmarketing, etc. We propose a new architecture for the task of FER and examine\nthe impact of domain discrimination loss regularization on the learning\nprocess. With regard to observations, including both classical training\nconditions and unsupervised domain adaptation scenarios, important aspects of\nthe considered domain adaptation approach integration are traced. The results\nmay serve as a foundation for further research in the field.",
          "link": "http://arxiv.org/abs/2106.01467",
          "publishedOn": "2021-06-04T01:12:28.507Z",
          "wordCount": 600,
          "title": "Domain Adaptation for Facial Expression Classifier via Domain Discrimination and Gradient Reversal. (arXiv:2106.01467v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01730",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pulgarin_E/0/1/0/all/0/1\">Erwin Jose Lopez Pulgarin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herrmann_G/0/1/0/all/0/1\">Guido Herrmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leonards_U/0/1/0/all/0/1\">Ute Leonards</a>",
          "description": "As autonomous machines such as robots and vehicles start performing tasks\ninvolving human users, ensuring a safe interaction between them becomes an\nimportant issue. Translating methods from human-robot interaction (HRI) studies\nto the interaction between humans and other highly complex machines (e.g.\nsemi-autonomous vehicles) could help advance the use of those machines in\nscenarios requiring human interaction. One method involves understanding human\nintentions and decision-making to estimate the human's present and near-future\nactions whilst interacting with a robot. This idea originates from the\npsychological concept of Theory of Mind, which has been broadly explored for\nrobotics and recently for autonomous and semi-autonomous vehicles. In this\nwork, we explored how to predict human intentions before an action is performed\nby combining data from human-motion, vehicle-state and human inputs (e.g.\nsteering wheel, pedals). A data-driven approach based on Recurrent Neural\nNetwork models was used to classify the current driving manoeuvre and to\npredict the future manoeuvre to be performed. A state-transition model was used\nwith a fixed set of manoeuvres to label data recorded during the trials for\nreal-time applications. Models were trained and tested using drivers of\ndifferent seat preferences, driving expertise and arm-length; precision and\nrecall metrics over 95% for manoeuvre identification and 86% for manoeuvre\nprediction were achieved, with prediction time-windows of up to 1 second for\nboth known and unknown test subjects. Compared to our previous results,\nperformance improved and manoeuvre prediction was possible for unknown test\nsubjects without knowing the current manoeuvre.",
          "link": "http://arxiv.org/abs/2106.01730",
          "publishedOn": "2021-06-04T01:12:28.501Z",
          "wordCount": 687,
          "title": "Drivers' Manoeuvre Modelling and Prediction for Safe HRI. (arXiv:2106.01730v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01808",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Isacchini_G/0/1/0/all/0/1\">Giulio Isacchini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spisak_N/0/1/0/all/0/1\">Natanael Spisak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nourmohammad_A/0/1/0/all/0/1\">Armita Nourmohammad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mora_T/0/1/0/all/0/1\">Thierry Mora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walczak_A/0/1/0/all/0/1\">Aleksandra M. Walczak</a>",
          "description": "Simulation-based inference enables learning the parameters of a model even\nwhen its likelihood cannot be computed in practice. One class of methods uses\ndata simulated with different parameters to infer an amortized estimator for\nthe likelihood-to-evidence ratio, or equivalently the posterior function. We\nshow that this approach can be formulated in terms of mutual information\nmaximization between model parameters and simulated data. We use this\nequivalence to reinterpret existing approaches for amortized inference, and\npropose two new methods that rely on lower bounds of the mutual information. We\napply our framework to the inference of parameters of stochastic processes and\nchaotic dynamical systems from sampled trajectories, using artificial neural\nnetworks for posterior prediction. Our approach provides a unified framework\nthat leverages the power of mutual information estimators for inference.",
          "link": "http://arxiv.org/abs/2106.01808",
          "publishedOn": "2021-06-04T01:12:28.494Z",
          "wordCount": 567,
          "title": "MINIMALIST: Mutual INformatIon Maximization for Amortized Likelihood Inference from Sampled Trajectories. (arXiv:2106.01808v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01777",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Snoswell_A/0/1/0/all/0/1\">Aaron J. Snoswell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Surya P. N. Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_N/0/1/0/all/0/1\">Nan Ye</a>",
          "description": "Multiple-Intent Inverse Reinforcement Learning (MI-IRL) seeks to find a\nreward function ensemble to rationalize demonstrations of different but\nunlabelled intents. Within the popular expectation maximization (EM) framework\nfor learning probabilistic MI-IRL models, we present a warm-start strategy\nbased on up-front clustering of the demonstrations in feature space. Our\ntheoretical analysis shows that this warm-start solution produces a\nnear-optimal reward ensemble, provided the behavior modes satisfy mild\nseparation conditions. We also propose a MI-IRL performance metric that\ngeneralizes the popular Expected Value Difference measure to directly assesses\nlearned rewards against the ground-truth reward ensemble. Our metric elegantly\naddresses the difficulty of pairing up learned and ground truth rewards via a\nmin-cost flow formulation, and is efficiently computable. We also develop a\nMI-IRL benchmark problem that allows for more comprehensive algorithmic\nevaluations. On this problem, we find our MI-IRL warm-start strategy helps\navoid poor quality local minima reward ensembles, resulting in a significant\nimprovement in behavior clustering. Our extensive sensitivity analysis\ndemonstrates that the quality of the learned reward ensembles is improved under\nvarious settings, including cases where our theoretical assumptions do not\nnecessarily hold. Finally, we demonstrate the effectiveness of our methods by\ndiscovering distinct driving styles in a large real-world dataset of driver GPS\ntrajectories.",
          "link": "http://arxiv.org/abs/2106.01777",
          "publishedOn": "2021-06-04T01:12:28.478Z",
          "wordCount": 638,
          "title": "LiMIIRL: Lightweight Multiple-Intent Inverse Reinforcement Learning. (arXiv:2106.01777v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01706",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kamran_S/0/1/0/all/0/1\">Sara Kamran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zall_R/0/1/0/all/0/1\">Raziyeh Zall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kangavari_M/0/1/0/all/0/1\">Mohammad Reza Kangavari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hosseini_S/0/1/0/all/0/1\">Saeid Hosseini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahmani_S/0/1/0/all/0/1\">Sana Rahmani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1\">Wen Hua</a>",
          "description": "The latent knowledge in the emotions and the opinions of the individuals that\nare manifested via social networks are crucial to numerous applications\nincluding social management, dynamical processes, and public security.\nAffective computing, as an interdisciplinary research field, linking artificial\nintelligence to cognitive inference, is capable to exploit emotion-oriented\nknowledge from brief contents. The textual contents convey hidden information\nsuch as personality and cognition about corresponding authors that can\ndetermine both correlations and variations between users. Emotion recognition\nfrom brief contents should embrace the contrast between authors where the\ndifferences in personality and cognition can be traced within emotional\nexpressions. To tackle this challenge, we devise a framework that, on the one\nhand, infers latent individual aspects, from brief contents and, on the other\nhand, presents a novel ensemble classifier equipped with dynamic dropout\nconvnets to extract emotions from textual context. To categorize short text\ncontents, our proposed method conjointly leverages cognitive factors and\nexploits hidden information. We utilize the outcome vectors in a novel\nembedding model to foster emotion-pertinent features that are collectively\nassembled by lexicon inductions. Experimental results show that compared to\nother competitors, our proposed model can achieve a higher performance in\nrecognizing emotion from noisy contents.",
          "link": "http://arxiv.org/abs/2106.01706",
          "publishedOn": "2021-06-04T01:12:28.471Z",
          "wordCount": 651,
          "title": "EmoDNN: Understanding emotions from short texts through a deep neural network ensemble. (arXiv:2106.01706v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01709",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_S/0/1/0/all/0/1\">Shuang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yuting Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1\">Baobao Chang</a>",
          "description": "Document-level relation extraction has attracted much attention in recent\nyears. It is usually formulated as a classification problem that predicts\nrelations for all entity pairs in the document. However, previous works\nindiscriminately represent intra- and inter-sentential relations in the same\nway, confounding the different patterns for predicting them. Besides, they\ncreate a document graph and use paths between entities on the graph as clues\nfor logical reasoning. However, not all entity pairs can be connected with a\npath and have the correct logical reasoning paths in their graph. Thus many\ncases of logical reasoning cannot be covered. This paper proposes an effective\narchitecture, SIRE, to represent intra- and inter-sentential relations in\ndifferent ways. We design a new and straightforward form of logical reasoning\nmodule that can cover more logical reasoning chains. Experiments on the public\ndatasets show SIRE outperforms the previous state-of-the-art methods. Further\nanalysis shows that our predictions are reliable and explainable. Our code is\navailable at https://github.com/DreamInvoker/SIRE.",
          "link": "http://arxiv.org/abs/2106.01709",
          "publishedOn": "2021-06-04T01:12:28.394Z",
          "wordCount": 615,
          "title": "SIRE: Separate Intra- and Inter-sentential Reasoning for Document-level Relation Extraction. (arXiv:2106.01709v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01723",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bibaut_A/0/1/0/all/0/1\">Aur&#xe9;lien Bibaut</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chambaz_A/0/1/0/all/0/1\">Antoine Chambaz</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dimakopoulou_M/0/1/0/all/0/1\">Maria Dimakopoulou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kallus_N/0/1/0/all/0/1\">Nathan Kallus</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Laan_M/0/1/0/all/0/1\">Mark van der Laan</a>",
          "description": "Empirical risk minimization (ERM) is the workhorse of machine learning,\nwhether for classification and regression or for off-policy policy learning,\nbut its model-agnostic guarantees can fail when we use adaptively collected\ndata, such as the result of running a contextual bandit algorithm. We study a\ngeneric importance sampling weighted ERM algorithm for using adaptively\ncollected data to minimize the average of a loss function over a hypothesis\nclass and provide first-of-their-kind generalization guarantees and fast\nconvergence rates. Our results are based on a new maximal inequality that\ncarefully leverages the importance sampling structure to obtain rates with the\nright dependence on the exploration rate in the data. For regression, we\nprovide fast rates that leverage the strong convexity of squared-error loss.\nFor policy learning, we provide rate-optimal regret guarantees that close an\nopen gap in the existing literature whenever exploration decays to zero, as is\nthe case for bandit-collected data. An empirical investigation validates our\ntheory.",
          "link": "http://arxiv.org/abs/2106.01723",
          "publishedOn": "2021-06-04T01:12:28.387Z",
          "wordCount": 602,
          "title": "Risk Minimization from Adaptively Collected Data: Guarantees for Supervised and Policy Learning. (arXiv:2106.01723v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01714",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">Dongrui Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1\">Haoyi Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_B/0/1/0/all/0/1\">Bo Dai</a>",
          "description": "Unlike the conventional wisdom in statistical learning theory, the test error\nof a deep neural network (DNN) often demonstrates double descent: as the model\ncomplexity increases, it first follows a classical U-shaped curve and then\nshows a second descent. Through bias-variance decomposition, recent studies\nrevealed that the bell-shaped variance is the major cause of model-wise double\ndescent (when the DNN is widened gradually). This paper investigates epoch-wise\ndouble descent, i.e., the test error of a DNN also shows double descent as the\nnumber of training epoches increases. By extending the bias-variance analysis\nto epoch-wise double descent of the zero-one loss, we surprisingly find that\nthe variance itself, without the bias, varies consistently with the test error.\nInspired by this result, we propose a novel metric, optimization variance (OV),\nto measure the diversity of model updates caused by the stochastic gradients of\nrandom training batches drawn in the same iteration. OV can be estimated using\nsamples from the training set only but correlates well with the (unknown)\n\\emph{test} error, and hence early stopping may be achieved without using a\nvalidation set.",
          "link": "http://arxiv.org/abs/2106.01714",
          "publishedOn": "2021-06-04T01:12:28.352Z",
          "wordCount": 611,
          "title": "Optimization Variance: Exploring Generalization Properties of DNNs. (arXiv:2106.01714v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01711",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kazmierski_M/0/1/0/all/0/1\">Michal Kazmierski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haibe_Kains_B/0/1/0/all/0/1\">Benjamin Haibe-Kains</a>",
          "description": "Predicting outcomes, such as survival or metastasis for individual cancer\npatients is a crucial component of precision oncology. Machine learning (ML)\noffers a promising way to exploit rich multi-modal data, including clinical\ninformation and imaging to learn predictors of disease trajectory and help\ninform clinical decision making. In this paper, we present a novel graph-based\napproach to incorporate imaging characteristics of existing cancer spread to\nlocal lymph nodes (LNs) as well as their connectivity patterns in a prognostic\nML model. We trained an edge-gated Graph Convolutional Network (Gated-GCN) to\naccurately predict the risk of distant metastasis (DM) by propagating\ninformation across the LN graph with the aid of soft edge attention mechanism.\nIn a cohort of 1570 head and neck cancer patients, the Gated-GCN achieves AUROC\nof 0.757 for 2-year DM classification and $C$-index of 0.725 for lifetime DM\nrisk prediction, outperforming current prognostic factors as well as previous\napproaches based on aggregated LN features. We also explored the importance of\ngraph structure and individual lymph nodes through ablation experiments and\ninterpretability studies, highlighting the importance of considering individual\nLN characteristics as well as the relationships between regions of cancer\nspread.",
          "link": "http://arxiv.org/abs/2106.01711",
          "publishedOn": "2021-06-04T01:12:28.334Z",
          "wordCount": 633,
          "title": "Lymph Node Graph Neural Networks for Cancer Metastasis Prediction. (arXiv:2106.01711v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01678",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Mingyi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhiying Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiaofei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhongjie Wang</a>",
          "description": "Representation learning on graphs that evolve has recently received\nsignificant attention due to its wide application scenarios, such as\nbioinformatics, knowledge graphs, and social networks. The propagation of\ninformation in graphs is important in learning dynamic graph representations,\nand most of the existing methods achieve this by aggregation. However, relying\nonly on aggregation to propagate information in dynamic graphs can result in\ndelays in information propagation and thus affect the performance of the\nmethod. To alleviate this problem, we propose an aggregation-diffusion (AD)\nmechanism that actively propagates information to its neighbor by diffusion\nafter the node updates its embedding through the aggregation mechanism. In\nexperiments on two real-world datasets in the dynamic link prediction task, the\nAD mechanism outperforms the baseline models that only use aggregation to\npropagate information. We further conduct extensive experiments to discuss the\ninfluence of different factors in the AD mechanism.",
          "link": "http://arxiv.org/abs/2106.01678",
          "publishedOn": "2021-06-04T01:12:28.326Z",
          "wordCount": 576,
          "title": "Learning Representation over Dynamic Graph using Aggregation-Diffusion Mechanism. (arXiv:2106.01678v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01700",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bayramoglu_N/0/1/0/all/0/1\">Neslihan Bayramoglu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nieminen_M/0/1/0/all/0/1\">Miika T. Nieminen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Saarakkala_S/0/1/0/all/0/1\">Simo Saarakkala</a>",
          "description": "Objective is to assess the ability of texture features for detecting\nradiographic patellofemoral osteoarthritis (PFOA) from knee lateral view\nradiographs. We used lateral view knee radiographs from MOST public use\ndatasets (n = 5507 knees). Patellar region-of-interest (ROI) was automatically\ndetected using landmark detection tool (BoneFinder). Hand-crafted features,\nbased on LocalBinary Patterns (LBP), were then extracted to describe the\npatellar texture. First, a machine learning model (Gradient Boosting Machine)\nwas trained to detect radiographic PFOA from the LBP features. Furthermore, we\nused end-to-end trained deep convolutional neural networks (CNNs) directly on\nthe texture patches for detecting the PFOA. The proposed classification models\nwere eventually compared with more conventional reference models that use\nclinical assessments and participant characteristics such as age, sex, body\nmass index(BMI), the total WOMAC score, and tibiofemoral Kellgren-Lawrence (KL)\ngrade. Atlas-guided visual assessment of PFOA status by expert readers provided\nin the MOST public use datasets was used as a classification outcome for the\nmodels. Performance of prediction models was assessed using the area under the\nreceiver operating characteristic curve (ROC AUC), the area under the\nprecision-recall (PR) curve-average precision (AP)-, and Brier score in the\nstratified 5-fold cross validation setting.Of the 5507 knees, 953 (17.3%) had\nPFOA. AUC and AP for the strongest reference model including age, sex, BMI,\nWOMAC score, and tibiofemoral KL grade to predict PFOA were 0.817 and 0.487,\nrespectively. Textural ROI classification using CNN significantly improved the\nprediction performance (ROC AUC= 0.889, AP= 0.714). We present the first study\nthat analyses patellar bone texture for diagnosing PFOA. Our results\ndemonstrates the potential of using texture features of patella to predict\nPFOA.",
          "link": "http://arxiv.org/abs/2106.01700",
          "publishedOn": "2021-06-04T01:12:28.305Z",
          "wordCount": 721,
          "title": "Machine Learning Based Texture Analysis of Patella from X-Rays for Detecting Patellofemoral Osteoarthritis. (arXiv:2106.01700v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01682",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sprangers_O/0/1/0/all/0/1\">Olivier Sprangers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schelter_S/0/1/0/all/0/1\">Sebastian Schelter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1\">Maarten de Rijke</a>",
          "description": "Gradient Boosting Machines (GBM) are hugely popular for solving tabular data\nproblems. However, practitioners are not only interested in point predictions,\nbut also in probabilistic predictions in order to quantify the uncertainty of\nthe predictions. Creating such probabilistic predictions is difficult with\nexisting GBM-based solutions: they either require training multiple models or\nthey become too computationally expensive to be useful for large-scale\nsettings. We propose Probabilistic Gradient Boosting Machines (PGBM), a method\nto create probabilistic predictions with a single ensemble of decision trees in\na computationally efficient manner. PGBM approximates the leaf weights in a\ndecision tree as a random variable, and approximates the mean and variance of\neach sample in a dataset via stochastic tree ensemble update equations. These\nlearned moments allow us to subsequently sample from a specified distribution\nafter training. We empirically demonstrate the advantages of PGBM compared to\nexisting state-of-the-art methods: (i) PGBM enables probabilistic estimates\nwithout compromising on point performance in a single model, (ii) PGBM learns\nprobabilistic estimates via a single model only (and without requiring\nmulti-parameter boosting), and thereby offers a speedup of up to several orders\nof magnitude over existing state-of-the-art methods on large datasets, and\n(iii) PGBM achieves accurate probabilistic estimates in tasks with complex\ndifferentiable loss functions, such as hierarchical time series problems, where\nwe observed up to 10\\% improvement in point forecasting performance and up to\n300\\% improvement in probabilistic forecasting performance.",
          "link": "http://arxiv.org/abs/2106.01682",
          "publishedOn": "2021-06-04T01:12:28.288Z",
          "wordCount": 662,
          "title": "Probabilistic Gradient Boosting Machines for Large-Scale Probabilistic Regression. (arXiv:2106.01682v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01635",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kovatchev_V/0/1/0/all/0/1\">Venelin Kovatchev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_P/0/1/0/all/0/1\">Phillip Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1\">Mark Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Devine_R/0/1/0/all/0/1\">Rory Devine</a>",
          "description": "In this paper we implement and compare 7 different data augmentation\nstrategies for the task of automatic scoring of children's ability to\nunderstand others' thoughts, feelings, and desires (or \"mindreading\").\n\nWe recruit in-domain experts to re-annotate augmented samples and determine\nto what extent each strategy preserves the original rating. We also carry out\nmultiple experiments to measure how much each augmentation strategy improves\nthe performance of automatic scoring systems. To determine the capabilities of\nautomatic systems to generalize to unseen data, we create UK-MIND-20 - a new\ncorpus of children's performance on tests of mindreading, consisting of 10,320\nquestion-answer pairs.\n\nWe obtain a new state-of-the-art performance on the MIND-CA corpus, improving\nmacro-F1-score by 6 points. Results indicate that both the number of training\nexamples and the quality of the augmentation strategies affect the performance\nof the systems. The task-specific augmentations generally outperform\ntask-agnostic augmentations. Automatic augmentations based on vectors (GloVe,\nFastText) perform the worst.\n\nWe find that systems trained on MIND-CA generalize well to UK-MIND-20. We\ndemonstrate that data augmentation strategies also improve the performance on\nunseen data.",
          "link": "http://arxiv.org/abs/2106.01635",
          "publishedOn": "2021-06-04T01:12:28.281Z",
          "wordCount": 638,
          "title": "Can vectors read minds better than experts? Comparing data augmentation strategies for the automated scoring of children's mindreading ability. (arXiv:2106.01635v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01606",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yinpeng Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Ke Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_T/0/1/0/all/0/1\">Tianyu Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zhijie Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hang Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun Zhu</a>",
          "description": "It is well known that deep learning models have a propensity for fitting the\nentire training set even with random labels, which requires memorization of\nevery training sample. In this paper, we investigate the memorization effect in\nadversarial training (AT) for promoting a deeper understanding of capacity,\nconvergence, generalization, and especially robust overfitting of adversarially\ntrained classifiers. We first demonstrate that deep networks have sufficient\ncapacity to memorize adversarial examples of training data with completely\nrandom labels, but not all AT algorithms can converge under the extreme\ncircumstance. Our study of AT with random labels motivates further analyses on\nthe convergence and generalization of AT. We find that some AT methods suffer\nfrom a gradient instability issue, and the recently suggested complexity\nmeasures cannot explain robust generalization by considering models trained on\nrandom labels. Furthermore, we identify a significant drawback of memorization\nin AT that it could result in robust overfitting. We then propose a new\nmitigation algorithm motivated by detailed memorization analyses. Extensive\nexperiments on various datasets validate the effectiveness of the proposed\nmethod.",
          "link": "http://arxiv.org/abs/2106.01606",
          "publishedOn": "2021-06-04T01:12:28.273Z",
          "wordCount": 611,
          "title": "Exploring Memorization in Adversarial Training. (arXiv:2106.01606v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01642",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Cheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheung_G/0/1/0/all/0/1\">Gene Cheung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_W/0/1/0/all/0/1\">Wai-tian Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_G/0/1/0/all/0/1\">Guangtao Zhai</a>",
          "description": "In semi-supervised graph-based binary classifier learning, a subset of known\nlabels $\\hat{x}_i$ are used to infer unknown labels, assuming that the label\nsignal $x$ is smooth with respect to a similarity graph specified by a\nLaplacian matrix. When restricting labels $x_i$ to binary values, the problem\nis NP-hard. While a conventional semi-definite programming (SDP) relaxation can\nbe solved in polynomial time using, for example, the alternating direction\nmethod of multipliers (ADMM), the complexity of iteratively projecting a\ncandidate matrix $M$ onto the positive semi-definite (PSD) cone ($M \\succeq 0$)\nremains high. In this paper, leveraging a recent linear algebraic theory called\nGershgorin disc perfect alignment (GDPA), we propose a fast projection-free\nmethod by solving a sequence of linear programs (LP) instead. Specifically, we\nfirst recast the SDP relaxation to its SDP dual, where a feasible solution $H\n\\succeq 0$ can be interpreted as a Laplacian matrix corresponding to a balanced\nsigned graph sans the last node. To achieve graph balance, we split the last\nnode into two that respectively contain the original positive and negative\nedges, resulting in a new Laplacian $\\bar{H}$. We repose the SDP dual for\nsolution $\\bar{H}$, then replace the PSD cone constraint $\\bar{H} \\succeq 0$\nwith linear constraints derived from GDPA -- sufficient conditions to ensure\n$\\bar{H}$ is PSD -- so that the optimization becomes an LP per iteration.\nFinally, we extract predicted labels from our converged LP solution $\\bar{H}$.\nExperiments show that our algorithm enjoyed a $40\\times$ speedup on average\nover the next fastest scheme while retaining comparable label prediction\nperformance.",
          "link": "http://arxiv.org/abs/2106.01642",
          "publishedOn": "2021-06-04T01:12:28.265Z",
          "wordCount": 682,
          "title": "Projection-free Graph-based Classifier Learning using Gershgorin Disc Perfect Alignment. (arXiv:2106.01642v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01613",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1\">Chun-Hao Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caruana_R/0/1/0/all/0/1\">Rich Caruana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldenberg_A/0/1/0/all/0/1\">Anna Goldenberg</a>",
          "description": "Deployment of machine learning models in real high-risk settings (e.g.\nhealthcare) often depends not only on model's accuracy but also on its\nfairness, robustness and interpretability. Generalized Additive Models (GAMs)\nhave a long history of use in these high-risk domains, but lack desirable\nfeatures of deep learning such as differentiability and scalability. In this\nwork, we propose a neural GAM (NODE-GAM) and neural GA$^2$M (NODE-GA$^2$M) that\nscale well to large datasets, while remaining interpretable and accurate. We\nshow that our proposed models have comparable accuracy to other\nnon-interpretable models, and outperform other GAMs on large datasets. We also\nshow that our models are more accurate in self-supervised learning setting when\naccess to labeled data is limited.",
          "link": "http://arxiv.org/abs/2106.01613",
          "publishedOn": "2021-06-04T01:12:28.247Z",
          "wordCount": 539,
          "title": "NODE-GAM: Neural Generalized Additive Model for Interpretable Deep Learning. (arXiv:2106.01613v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01617",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1\">Pengfei Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Linyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_R/0/1/0/all/0/1\">Ruoxi Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_K/0/1/0/all/0/1\">Kai Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuhao Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_G/0/1/0/all/0/1\">Guoen Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_B/0/1/0/all/0/1\">Bin Yan</a>",
          "description": "Deep neural networks(DNNs) is vulnerable to be attacked by adversarial\nexamples. Black-box attack is the most threatening attack. At present,\nblack-box attack methods mainly adopt gradient-based iterative attack methods,\nwhich usually limit the relationship between the iteration step size, the\nnumber of iterations, and the maximum perturbation. In this paper, we propose a\nnew gradient iteration framework, which redefines the relationship between the\nabove three. Under this framework, we easily improve the attack success rate of\nDI-TI-MIM. In addition, we propose a gradient iterative attack method based on\ninput dropout, which can be well combined with our framework. We further\npropose a multi dropout rate version of this method. Experimental results show\nthat our best method can achieve attack success rate of 96.2\\% for defense\nmodel on average, which is higher than the state-of-the-art gradient-based\nattacks.",
          "link": "http://arxiv.org/abs/2106.01617",
          "publishedOn": "2021-06-04T01:12:28.239Z",
          "wordCount": 583,
          "title": "Improving the Transferability of Adversarial Examples with New Iteration Framework and Input Dropout. (arXiv:2106.01617v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01624",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abhishek_K/0/1/0/all/0/1\">Kumar Abhishek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghalme_G/0/1/0/all/0/1\">Ganesh Ghalme</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gujar_S/0/1/0/all/0/1\">Sujit Gujar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narahari_Y/0/1/0/all/0/1\">Yadati Narahari</a>",
          "description": "In this paper, we study an interesting combination of sleeping and\ncombinatorial stochastic bandits. In the mixed model studied here, at each\ndiscrete time instant, an arbitrary \\emph{availability set} is generated from a\nfixed set of \\emph{base} arms. An algorithm can select a subset of arms from\nthe \\emph{availability set} (sleeping bandits) and receive the corresponding\nreward along with semi-bandit feedback (combinatorial bandits).\n\nWe adapt the well-known CUCB algorithm in the sleeping combinatorial bandits\nsetting and refer to it as \\CSUCB. We prove -- under mild smoothness conditions\n-- that the \\CSUCB\\ algorithm achieves an $O(\\log (T))$ instance-dependent\nregret guarantee. We further prove that (i) when the range of the rewards is\nbounded, the regret guarantee of \\CSUCB\\ algorithm is $O(\\sqrt{T \\log (T)})$\nand (ii) the instance-independent regret is $O(\\sqrt[3]{T^2 \\log(T)})$ in a\ngeneral setting. Our results are quite general and hold under general\nenvironments -- such as non-additive reward functions, volatile arm\navailability, a variable number of base-arms to be pulled -- arising in\npractical applications. We validate the proven theoretical guarantees through\nexperiments.",
          "link": "http://arxiv.org/abs/2106.01624",
          "publishedOn": "2021-06-04T01:12:28.231Z",
          "wordCount": 588,
          "title": "Sleeping Combinatorial Bandits. (arXiv:2106.01624v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01674",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1\">Qian Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_X/0/1/0/all/0/1\">Xiaochao Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1\">Hao Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Guangxing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenlin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Guobao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zha_Z/0/1/0/all/0/1\">Zhiwei Zha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_D/0/1/0/all/0/1\">Daxiang Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_D/0/1/0/all/0/1\">Dejing Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1\">Haoyi Xiong</a>",
          "description": "In modern internet industries, deep learning based recommender systems have\nbecame an indispensable building block for a wide spectrum of applications,\nsuch as search engine, news feed, and short video clips. However, it remains\nchallenging to carry the well-trained deep models for online real-time\ninference serving, with respect to the time-varying web-scale traffics from\nbillions of users, in a cost-effective manner. In this work, we present JIZHI -\na Model-as-a-Service system - that per second handles hundreds of millions of\nonline inference requests to huge deep models with more than trillions of\nsparse parameters, for over twenty real-time recommendation services at Baidu,\nInc. In JIZHI, the inference workflow of every recommendation request is\ntransformed to a Staged Event-Driven Pipeline (SEDP), where each node in the\npipeline refers to a staged computation or I/O intensive task processor. With\ntraffics of real-time inference requests arrived, each modularized processor\ncan be run in a fully asynchronized way and managed separately. Besides, JIZHI\nintroduces heterogeneous and hierarchical storage to further accelerate the\nonline inference process by reducing unnecessary computations and potential\ndata access latency induced by ultra-sparse model parameters. Moreover, an\nintelligent resource manager has been deployed to maximize the throughput of\nJIZHI over the shared infrastructure by searching the optimal resource\nallocation plan from historical logs and fine-tuning the load shedding policies\nover intermediate system feedback. Extensive experiments have been done to\ndemonstrate the advantages of JIZHI from the perspectives of end-to-end service\nlatency, system-wide throughput, and resource consumption. JIZHI has helped\nBaidu saved more than ten million US dollars in hardware and utility costs\nwhile handling 200% more traffics without sacrificing inference efficiency.",
          "link": "http://arxiv.org/abs/2106.01674",
          "publishedOn": "2021-06-04T01:12:28.225Z",
          "wordCount": 740,
          "title": "JIZHI: A Fast and Cost-Effective Model-As-A-Service System for Web-Scale Online Inference at Baidu. (arXiv:2106.01674v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01660",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lattimore_T/0/1/0/all/0/1\">Tor Lattimore</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hao_B/0/1/0/all/0/1\">Botao Hao</a>",
          "description": "We study a bandit version of phase retrieval where the learner chooses\nactions $(A_t)_{t=1}^n$ in the $d$-dimensional unit ball and the expected\nreward is $\\langle A_t, \\theta_\\star\\rangle^2$ where $\\theta_\\star \\in \\mathbb\nR^d$ is an unknown parameter vector. We prove that the minimax cumulative\nregret in this problem is $\\smash{\\tilde \\Theta(d \\sqrt{n})}$, which improves\non the best known bounds by a factor of $\\smash{\\sqrt{d}}$. We also show that\nthe minimax simple regret is $\\smash{\\tilde \\Theta(d / \\sqrt{n})}$ and that\nthis is only achievable by an adaptive algorithm. Our analysis shows that an\napparently convincing heuristic for guessing lower bounds can be misleading and\nthat uniform bounds on the information ratio for information-directed sampling\nare not sufficient for optimal regret.",
          "link": "http://arxiv.org/abs/2106.01660",
          "publishedOn": "2021-06-04T01:12:28.218Z",
          "wordCount": 541,
          "title": "Bandit Phase Retrieval. (arXiv:2106.01660v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01604",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_H/0/1/0/all/0/1\">Hyun-Jin Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_P/0/1/0/all/0/1\">Pai Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moreno_I/0/1/0/all/0/1\">Ignacio Lopez Moreno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subrahmanya_N/0/1/0/all/0/1\">Niranjan Subrahmanya</a>",
          "description": "We propose self-training with noisy student-teacher approach for streaming\nkeyword spotting, that can utilize large-scale unlabeled data and aggressive\ndata augmentation. The proposed method applies aggressive data augmentation\n(spectral augmentation) on the input of both student and teacher and utilize\nunlabeled data at scale, which significantly boosts the accuracy of student\nagainst challenging conditions. Such aggressive augmentation usually degrades\nmodel performance when used with supervised training with hard-labeled data.\nExperiments show that aggressive spec augmentation on baseline supervised\ntraining method degrades accuracy, while the proposed self-training with noisy\nstudent-teacher training improves accuracy of some difficult-conditioned test\nsets by as much as 60%.",
          "link": "http://arxiv.org/abs/2106.01604",
          "publishedOn": "2021-06-04T01:12:28.195Z",
          "wordCount": 530,
          "title": "Noisy student-teacher training for robust keyword spotting. (arXiv:2106.01604v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sadique_F/0/1/0/all/0/1\">Farhan Sadique</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Astaburuaga_I/0/1/0/all/0/1\">Ignacio Astaburuaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaul_R/0/1/0/all/0/1\">Raghav Kaul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sengupta_S/0/1/0/all/0/1\">Shamik Sengupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Badsha_S/0/1/0/all/0/1\">Shahriar Badsha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schnebly_J/0/1/0/all/0/1\">James Schnebly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cassell_A/0/1/0/all/0/1\">Adam Cassell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Springer_J/0/1/0/all/0/1\">Jeff Springer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Latourrette_N/0/1/0/all/0/1\">Nancy Latourrette</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dascalu_S/0/1/0/all/0/1\">Sergiu M. Dascalu</a>",
          "description": "Cybersecurity information sharing (CIS) is envisioned to protect\norganizations more effectively from advanced cyber attacks. However, a\ncompletely automated CIS platform is not widely adopted. The major challenges\nare: (1) the absence of a robust cyber threat language (CTL) and (2) the\nconcerns over data privacy. This work introduces Cybersecurity Information\nExchangewith Privacy (CYBEX-P), as a CIS framework, to tackle these challenges.\nCYBEX-P allows organizations to share heterogeneous data with granular,\nattribute based privacy control. It correlates the data to automatically\ngenerate intuitive reports and defensive rules. To achieve such versatility, we\nhave developed TAHOE - a graph based CTL. TAHOE is a structure for\nstoring,sharing and analyzing threat data. It also intrinsically correlates the\ndata. We have further developed a universal Threat Data Query Language (TDQL).\nIn this paper, we propose the system architecture for CYBEX-P. We then discuss\nits scalability and privacy features along with a use case of CYBEX-P providing\nInfrastructure as a Service (IaaS). We further introduce TAHOE& TDQL as better\nalternatives to existing CTLs and formulate ThreatRank - an algorithm to detect\nnew malicious even",
          "link": "http://arxiv.org/abs/2106.01632",
          "publishedOn": "2021-06-04T01:12:28.189Z",
          "wordCount": 630,
          "title": "Cybersecurity Information Exchange with Privacy (CYBEX-P) and TAHOE -- A Cyberthreat Language. (arXiv:2106.01632v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01474",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Shi_C/0/1/0/all/0/1\">Chengchun Shi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhou_Y/0/1/0/all/0/1\">Yunzhe Zhou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_L/0/1/0/all/0/1\">Lexin Li</a>",
          "description": "In this article, we propose a new hypothesis testing method for directed\nacyclic graph (DAG). While there is a rich class of DAG estimation methods,\nthere is a relative paucity of DAG inference solutions. Moreover, the existing\nmethods often impose some specific model structures such as linear models or\nadditive models, and assume independent data observations. Our proposed test\ninstead allows the associations among the random variables to be nonlinear and\nthe data to be time-dependent. We build the test based on some highly flexible\nneural networks learners. We establish the asymptotic guarantees of the test,\nwhile allowing either the number of subjects or the number of time points for\neach subject to diverge to infinity. We demonstrate the efficacy of the test\nthrough simulations and a brain connectivity network analysis.",
          "link": "http://arxiv.org/abs/2106.01474",
          "publishedOn": "2021-06-04T01:12:28.182Z",
          "wordCount": 563,
          "title": "Testing Directed Acyclic Graph via Structural, Supervised and Generative Adversarial Learning. (arXiv:2106.01474v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01516",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kobayashi_T/0/1/0/all/0/1\">Taisuke Kobayashi</a>",
          "description": "This paper proposes a new reinforcement learning with hyperbolic discounting.\nCombining a new temporal difference error with the hyperbolic discounting in\nrecursive manner and reward-punishment framework, a new scheme to learn the\noptimal policy is derived. In simulations, it is found that the proposal\noutperforms the standard reinforcement learning, although the performance\ndepends on the design of reward and punishment. In addition, the averages of\ndiscount factors w.r.t. reward and punishment are different from each other,\nlike a sign effect in animal behaviors.",
          "link": "http://arxiv.org/abs/2106.01516",
          "publishedOn": "2021-06-04T01:12:28.172Z",
          "wordCount": 508,
          "title": "Hyperbolically-Discounted Reinforcement Learning on Reward-Punishment Framework. (arXiv:2106.01516v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01601",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jiao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1\">Nanyun Peng</a>",
          "description": "Human activities can be seen as sequences of events, which are crucial to\nunderstanding societies. Disproportional event distribution for different\ndemographic groups can manifest and amplify social stereotypes, and potentially\njeopardize the ability of members in some groups to pursue certain goals. In\nthis paper, we present the first event-centric study of gender biases in a\nWikipedia corpus. To facilitate the study, we curate a corpus of career and\npersonal life descriptions with demographic information consisting of 7,854\nfragments from 10,412 celebrities. Then we detect events with a\nstate-of-the-art event detection model, calibrate the results using\nstrategically generated templates, and extract events that have asymmetric\nassociations with genders. Our study discovers that the Wikipedia pages tend to\nintermingle personal life events with professional events for females but not\nfor males, which calls for the awareness of the Wikipedia community to\nformalize guidelines and train the editors to mind the implicit biases that\ncontributors carry. Our work also lays the foundation for future works on\nquantifying and discovering event biases at the corpus level.",
          "link": "http://arxiv.org/abs/2106.01601",
          "publishedOn": "2021-06-04T01:12:28.166Z",
          "wordCount": 613,
          "title": "Men Are Elected, Women Are Married: Events Gender Bias on Wikipedia. (arXiv:2106.01601v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01608",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_D/0/1/0/all/0/1\">Dai Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_A/0/1/0/all/0/1\">Andi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Junbin Gao</a>",
          "description": "Dimensionality reduction (DR) and manifold learning (ManL) have been applied\nextensively in many machine learning tasks, including signal processing, speech\nrecognition, and neuroinformatics. However, the understanding of whether DR and\nManL models can generate valid learning results remains unclear. In this work,\nwe investigate the validity of learning results of some widely used DR and ManL\nmethods through the chart mapping function of a manifold. We identify a\nfundamental problem of these methods: the mapping functions induced by these\nmethods violate the basic settings of manifolds, and hence they are not\nlearning manifold in the mathematical sense. To address this problem, we\nprovide a provably correct algorithm called fixed points Laplacian mapping\n(FPLM), that has the geometric guarantee to find a valid manifold\nrepresentation (up to a homeomorphism). Combining one additional\ncondition(orientation preserving), we discuss a sufficient condition for an\nalgorithm to be bijective for any d-simplex decomposition result on a\nd-manifold. However, constructing such a mapping function and its computational\nmethod satisfying these conditions is still an open problem in mathematics.",
          "link": "http://arxiv.org/abs/2106.01608",
          "publishedOn": "2021-06-04T01:12:28.146Z",
          "wordCount": 595,
          "title": "A Discussion On the Validity of Manifold Learning. (arXiv:2106.01608v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01655",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Steccanella_L/0/1/0/all/0/1\">Lorenzo Steccanella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Totaro_S/0/1/0/all/0/1\">Simone Totaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jonsson_A/0/1/0/all/0/1\">Anders Jonsson</a>",
          "description": "In this paper we present a novel method for learning hierarchical\nrepresentations of Markov decision processes. Our method works by partitioning\nthe state space into subsets, and defines subtasks for performing transitions\nbetween the partitions. We formulate the problem of partitioning the state\nspace as an optimization problem that can be solved using gradient descent\ngiven a set of sampled trajectories, making our method suitable for\nhigh-dimensional problems with large state spaces. We empirically validate the\nmethod, by showing that it can successfully learn a useful hierarchical\nrepresentation in a navigation domain. Once learned, the hierarchical\nrepresentation can be used to solve different tasks in the given domain, thus\ngeneralizing knowledge across tasks.",
          "link": "http://arxiv.org/abs/2106.01655",
          "publishedOn": "2021-06-04T01:12:28.140Z",
          "wordCount": 536,
          "title": "Hierarchical Representation Learning for Markov Decision Processes. (arXiv:2106.01655v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01597",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maurya_K/0/1/0/all/0/1\">Kaushal Kumar Maurya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Desarkar_M/0/1/0/all/0/1\">Maunendra Sankar Desarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kano_Y/0/1/0/all/0/1\">Yoshinobu Kano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deepshikha_K/0/1/0/all/0/1\">Kumari Deepshikha</a>",
          "description": "Despite the recent advancement in NLP research, cross-lingual transfer for\nnatural language generation is relatively understudied. In this work, we\ntransfer supervision from high resource language (HRL) to multiple low-resource\nlanguages (LRLs) for natural language generation (NLG). We consider four NLG\ntasks (text summarization, question generation, news headline generation, and\ndistractor generation) and three syntactically diverse languages, i.e.,\nEnglish, Hindi, and Japanese. We propose an unsupervised cross-lingual language\ngeneration framework (called ZmBART) that does not use any parallel or\npseudo-parallel/back-translated data. In this framework, we further pre-train\nmBART sequence-to-sequence denoising auto-encoder model with an auxiliary task\nusing monolingual data of three languages. The objective function of the\nauxiliary task is close to the target tasks which enriches the multi-lingual\nlatent representation of mBART and provides good initialization for target\ntasks. Then, this model is fine-tuned with task-specific supervised English\ndata and directly evaluated with low-resource languages in the Zero-shot\nsetting. To overcome catastrophic forgetting and spurious correlation issues,\nwe applied freezing model component and data argumentation approaches\nrespectively. This simple modeling approach gave us promising results.We\nexperimented with few-shot training (with 1000 supervised data points) which\nboosted the model performance further. We performed several ablations and\ncross-lingual transferability analyses to demonstrate the robustness of ZmBART.",
          "link": "http://arxiv.org/abs/2106.01597",
          "publishedOn": "2021-06-04T01:12:28.134Z",
          "wordCount": 650,
          "title": "ZmBART: An Unsupervised Cross-lingual Transfer Framework for Language Generation. (arXiv:2106.01597v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01596",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Ho Hin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1\">Yucheng Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xin Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_S/0/1/0/all/0/1\">Shunxing Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Landman_B/0/1/0/all/0/1\">Bennett A. Landman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huo_Y/0/1/0/all/0/1\">Yuankai Huo</a>",
          "description": "Contrastive learning has shown superior performance in embedding global and\nspatial invariant features in computer vision (e.g., image classification).\nHowever, its overall success of embedding local and spatial variant features is\nstill limited, especially for semantic segmentation. In a per-pixel prediction\ntask, more than one label can exist in a single image for segmentation (e.g.,\nan image contains both cat, dog, and grass), thereby it is difficult to define\n'positive' or 'negative' pairs in a canonical contrastive learning setting. In\nthis paper, we propose an attention-guided supervised contrastive learning\napproach to highlight a single semantic object every time as the target. With\nour design, the same image can be embedded to different semantic clusters with\nsemantic attention (i.e., coerce semantic masks) as an additional input\nchannel. To achieve such attention, a novel two-stage training strategy is\npresented. We evaluate the proposed method on multi-organ medical image\nsegmentation task, as our major task, with both in-house data and BTCV 2015\ndatasets. Comparing with the supervised and semi-supervised training\nstate-of-the-art in the backbone of ResNet-50, our proposed pipeline yields\nsubstantial improvement of 5.53% and 6.09% in Dice score for both medical image\nsegmentation cohorts respectively. The performance of the proposed method on\nnatural images is assessed via PASCAL VOC 2012 dataset, and achieves 2.75%\nsubstantial improvement.",
          "link": "http://arxiv.org/abs/2106.01596",
          "publishedOn": "2021-06-04T01:12:28.127Z",
          "wordCount": 664,
          "title": "Attention-Guided Supervised Contrastive Learning for Semantic Segmentation. (arXiv:2106.01596v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01487",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kusupati_A/0/1/0/all/0/1\">Aditya Kusupati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallingford_M/0/1/0/all/0/1\">Matthew Wallingford</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramanujan_V/0/1/0/all/0/1\">Vivek Ramanujan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Somani_R/0/1/0/all/0/1\">Raghav Somani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jae Sung Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pillutla_K/0/1/0/all/0/1\">Krishna Pillutla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1\">Prateek Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1\">Sham Kakade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farhadi_A/0/1/0/all/0/1\">Ali Farhadi</a>",
          "description": "Learning binary representations of instances and classes is a classical\nproblem with several high potential applications. In modern settings, the\ncompression of high-dimensional neural representations to low-dimensional\nbinary codes is a challenging task and often require large bit-codes to be\naccurate. In this work, we propose a novel method for Learning Low-dimensional\nbinary Codes (LLC) for instances as well as classes. Our method does not\nrequire any side-information, like annotated attributes or label meta-data, and\nlearns extremely low-dimensional binary codes (~20 bits for ImageNet-1K). The\nlearnt codes are super-efficient while still ensuring nearly optimal\nclassification accuracy for ResNet50 on ImageNet-1K. We demonstrate that the\nlearnt codes capture intrinsically important features in the data, by\ndiscovering an intuitive taxonomy over classes. We further quantitatively\nmeasure the quality of our codes by applying it to the efficient image\nretrieval as well as out-of-distribution (OOD) detection problems. For\nImageNet-100 retrieval problem, our learnt binary codes outperform 16 bit\nHashNet using only 10 bits and also are as accurate as 10 dimensional real\nrepresentations. Finally, our learnt binary codes can perform OOD detection,\nout-of-the-box, as accurately as a baseline that needs ~3000 samples to tune\nits threshold, while we require none. Code and pre-trained models are available\nat https://github.com/RAIVNLab/LLC.",
          "link": "http://arxiv.org/abs/2106.01487",
          "publishedOn": "2021-06-04T01:12:28.120Z",
          "wordCount": 652,
          "title": "LLC: Accurate, Multi-purpose Learnt Low-dimensional Binary Codes. (arXiv:2106.01487v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01491",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Herlihy_C/0/1/0/all/0/1\">Christine Herlihy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudinger_R/0/1/0/all/0/1\">Rachel Rudinger</a>",
          "description": "Crowdworker-constructed natural language inference (NLI) datasets have been\nfound to contain statistical artifacts associated with the annotation process\nthat allow hypothesis-only classifiers to achieve better-than-random\nperformance (Poliak et al., 2018; Gururanganet et al., 2018; Tsuchiya, 2018).\nWe investigate whether MedNLI, a physician-annotated dataset with premises\nextracted from clinical notes, contains such artifacts (Romanov and Shivade,\n2018). We find that entailed hypotheses contain generic versions of specific\nconcepts in the premise, as well as modifiers related to responsiveness,\nduration, and probability. Neutral hypotheses feature conditions and behaviors\nthat co-occur with, or cause, the condition(s) in the premise. Contradiction\nhypotheses feature explicit negation of the premise and implicit negation via\nassertion of good health. Adversarial filtering demonstrates that performance\ndegrades when evaluated on the difficult subset. We provide partition\ninformation and recommendations for alternative dataset construction strategies\nfor knowledge-intensive domains.",
          "link": "http://arxiv.org/abs/2106.01491",
          "publishedOn": "2021-06-04T01:12:28.113Z",
          "wordCount": 574,
          "title": "MedNLI Is Not Immune: Natural Language Inference Artifacts in the Clinical Domain. (arXiv:2106.01491v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01583",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1\">Meng Jiang</a>",
          "description": "Graph neural networks have been widely used for learning representations of\nnodes for many downstream tasks on graph data. Existing models were designed\nfor the nodes on a single graph, which would not be able to utilize information\nacross multiple graphs. The real world does have multiple graphs where the\nnodes are often partially aligned. For examples, knowledge graphs share a\nnumber of named entities though they may have different relation schema;\ncollaboration networks on publications and awarded projects share some\nresearcher nodes who are authors and investigators, respectively; people use\nmultiple web services, shopping, tweeting, rating movies, and some may register\nthe same email account across the platforms. In this paper, I propose partially\naligned graph convolutional networks to learn node representations across the\nmodels. I investigate multiple methods (including model sharing,\nregularization, and alignment reconstruction) as well as theoretical analysis\nto positively transfer knowledge across the (small) set of partially aligned\nnodes. Extensive experiments on real-world knowledge graphs and collaboration\nnetworks show the superior performance of our proposed methods on relation\nclassification and link prediction.",
          "link": "http://arxiv.org/abs/2106.01583",
          "publishedOn": "2021-06-04T01:12:28.094Z",
          "wordCount": 603,
          "title": "Cross-Network Learning with Partially Aligned Graph Convolutional Networks. (arXiv:2106.01583v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01441",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Memeti_S/0/1/0/all/0/1\">Suejb Memeti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pllana_S/0/1/0/all/0/1\">Sabri Pllana</a>",
          "description": "Heterogeneous computing systems provide high performance and energy\nefficiency. However, to optimally utilize such systems, solutions that\ndistribute the work across host CPUs and accelerating devices are needed. In\nthis paper, we present a performance and energy aware approach that combines AI\nplanning heuristics for parameter space exploration with a machine learning\nmodel for performance and energy evaluation to determine a near-optimal system\nconfiguration. For data-parallel applications our approach determines a\nnear-optimal host-device distribution of work, number of processing units\nrequired and the corresponding scheduling strategy. We evaluate our approach\nfor various heterogeneous systems accelerated with GPU or the Intel Xeon Phi.\nThe experimental results demonstrate that our approach finds a near-optimal\nsystem configuration by evaluating only about 7% of reasonable configurations.\nFurthermore, the performance per Joule estimation of system configurations\nusing our machine learning model is more than 1000x faster compared to the\nsystem evaluation by program execution.",
          "link": "http://arxiv.org/abs/2106.01441",
          "publishedOn": "2021-06-04T01:12:28.088Z",
          "wordCount": 596,
          "title": "Optimization of Heterogeneous Systems with AI Planning Heuristics and Machine Learning: A Performance and Energy Aware Approach. (arXiv:2106.01441v1 [cs.SE])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01489",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Ziyun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinshao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Haojin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1\">Di Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Robertson_N/0/1/0/all/0/1\">Neil M. Robertson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clifton_D/0/1/0/all/0/1\">David A. Clifton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meinel_C/0/1/0/all/0/1\">Christoph Meinel</a>",
          "description": "Mutual knowledge distillation (MKD) improves a model by distilling knowledge\nfrom another model. However, not all knowledge is certain and correct,\nespecially under adverse conditions. For example, label noise usually leads to\nless reliable models due to the undesired memorisation [1, 2]. Wrong knowledge\nmisleads the learning rather than helps. This problem can be handled by two\naspects: (i) improving the reliability of a model where the knowledge is from\n(i.e., knowledge source's reliability); (ii) selecting reliable knowledge for\ndistillation. In the literature, making a model more reliable is widely studied\nwhile selective MKD receives little attention. Therefore, we focus on studying\nselective MKD and highlight its importance in this work.\n\nConcretely, a generic MKD framework, Confident knowledge selection followed\nby Mutual Distillation (CMD), is designed. The key component of CMD is a\ngeneric knowledge selection formulation, making the selection threshold either\nstatic (CMD-S) or progressive (CMD-P). Additionally, CMD covers two special\ncases: zero knowledge and all knowledge, leading to a unified MKD framework. We\nempirically find CMD-P performs better than CMD-S. The main reason is that a\nmodel's knowledge upgrades and becomes confident as the training progresses.\n\nExtensive experiments are present to demonstrate the effectiveness of CMD and\nthoroughly justify the design of CMD. For example, CMD-P obtains new\nstate-of-the-art results in robustness against label noise.",
          "link": "http://arxiv.org/abs/2106.01489",
          "publishedOn": "2021-06-04T01:12:28.038Z",
          "wordCount": 660,
          "title": "Not All Knowledge Is Created Equal. (arXiv:2106.01489v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01506",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wright_M/0/1/0/all/0/1\">Matthew A. Wright</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1\">Joseph E. Gonzalez</a>",
          "description": "Despite their ubiquity in core AI fields like natural language processing,\nthe mechanics of deep attention-based neural networks like the Transformer\nmodel are not fully understood. In this article, we present a new perspective\ntowards understanding how Transformers work. In particular, we show that the\n\"dot-product attention\" that is the core of the Transformer's operation can be\ncharacterized as a kernel learning method on a pair of Banach spaces. In\nparticular, the Transformer's kernel is characterized as having an infinite\nfeature dimension. Along the way we consider an extension of the standard\nkernel learning problem to a binary setting, where data come from two input\ndomains and a response is defined for every cross-domain pair. We prove a new\nrepresenter theorem for these binary kernel machines with non-Mercer\n(indefinite, asymmetric) kernels (implying that the functions learned are\nelements of reproducing kernel Banach spaces rather than Hilbert spaces), and\nalso prove a new universal approximation theorem showing that the Transformer\ncalculation can learn any binary non-Mercer reproducing kernel Banach space\npair. We experiment with new kernels in Transformers, and obtain results that\nsuggest the infinite dimensionality of the standard Transformer kernel is\npartially responsible for its performance. This paper's results provide a new\ntheoretical understanding of a very important but poorly understood model in\nmodern machine~learning.",
          "link": "http://arxiv.org/abs/2106.01506",
          "publishedOn": "2021-06-04T01:12:28.029Z",
          "wordCount": 649,
          "title": "Transformers are Deep Infinite-Dimensional Non-Mercer Binary Kernel Machines. (arXiv:2106.01506v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01540",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xuezhe Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_X/0/1/0/all/0/1\">Xiang Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sinong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chunting Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+May_J/0/1/0/all/0/1\">Jonathan May</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1\">Hao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>",
          "description": "The quadratic computational and memory complexities of the Transformer's\nattention mechanism have limited its scalability for modeling long sequences.\nIn this paper, we propose Luna, a linear unified nested attention mechanism\nthat approximates softmax attention with two nested linear attention functions,\nyielding only linear (as opposed to quadratic) time and space complexity.\nSpecifically, with the first attention function, Luna packs the input sequence\ninto a sequence of fixed length. Then, the packed sequence is unpacked using\nthe second attention function. As compared to a more traditional attention\nmechanism, Luna introduces an additional sequence with a fixed length as input\nand an additional corresponding output, which allows Luna to perform attention\noperation linearly, while also storing adequate contextual information. We\nperform extensive evaluations on three benchmarks of sequence modeling tasks:\nlong-context sequence modeling, neural machine translation and masked language\nmodeling for large-scale pretraining. Competitive or even better experimental\nresults demonstrate both the effectiveness and efficiency of Luna compared to a\nvariety",
          "link": "http://arxiv.org/abs/2106.01540",
          "publishedOn": "2021-06-04T01:12:28.018Z",
          "wordCount": 595,
          "title": "Luna: Linear Unified Nested Attention. (arXiv:2106.01540v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01515",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Saxena_A/0/1/0/all/0/1\">Apoorv Saxena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakrabarti_S/0/1/0/all/0/1\">Soumen Chakrabarti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talukdar_P/0/1/0/all/0/1\">Partha Talukdar</a>",
          "description": "Temporal Knowledge Graphs (Temporal KGs) extend regular Knowledge Graphs by\nproviding temporal scopes (start and end times) on each edge in the KG. While\nQuestion Answering over KG (KGQA) has received some attention from the research\ncommunity, QA over Temporal KGs (Temporal KGQA) is a relatively unexplored\narea. Lack of broad coverage datasets has been another factor limiting progress\nin this area. We address this challenge by presenting CRONQUESTIONS, the\nlargest known Temporal KGQA dataset, clearly stratified into buckets of\nstructural complexity. CRONQUESTIONS expands the only known previous dataset by\na factor of 340x. We find that various state-of-the-art KGQA methods fall far\nshort of the desired performance on this new dataset. In response, we also\npropose CRONKGQA, a transformer-based solution that exploits recent advances in\nTemporal KG embeddings, and achieves performance superior to all baselines,\nwith an increase of 120% in accuracy over the next best performing method.\nThrough extensive experiments, we give detailed insights into the workings of\nCRONKGQA, as well as situations where significant further improvements appear\npossible. In addition to the dataset, we have released our code as well.",
          "link": "http://arxiv.org/abs/2106.01515",
          "publishedOn": "2021-06-04T01:12:28.000Z",
          "wordCount": 603,
          "title": "Question Answering Over Temporal Knowledge Graphs. (arXiv:2106.01515v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01590",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vega_R/0/1/0/all/0/1\">Roberto Vega</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flores_L/0/1/0/all/0/1\">Leonardo Flores</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greiner_R/0/1/0/all/0/1\">Russell Greiner</a>",
          "description": "Accurate forecasts of the number of newly infected people during an epidemic\nare critical for making effective timely decisions. This paper addresses this\nchallenge using the SIMLR model, which incorporates machine learning (ML) into\nthe epidemiological SIR model. For each region, SIMLR tracks the changes in the\npolicies implemented at the government level, which it uses to estimate the\ntime-varying parameters of an SIR model for forecasting the number of new\ninfections 1- to 4-weeks in advance.It also forecasts the probability of\nchanges in those government policies at each of these future times, which is\nessential for the longer-range forecasts. We applied SIMLR to data from regions\nin Canada and in the United States,and show that its MAPE (mean average\npercentage error) performance is as good as SOTA forecasting models, with the\nadded advantage of being an interpretable model. We expect that this approach\nwill be useful not only for forecasting COVID-19 infections, but also in\npredicting the evolution of other infectious diseases.",
          "link": "http://arxiv.org/abs/2106.01590",
          "publishedOn": "2021-06-04T01:12:27.972Z",
          "wordCount": 639,
          "title": "SIMLR: Machine Learning inside the SIR model for COVID-19 Forecasting. (arXiv:2106.01590v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01580",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuchen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Risteski_A/0/1/0/all/0/1\">Andrej Risteski</a>",
          "description": "Incorporating syntax into neural approaches in NLP has a multitude of\npractical and scientific benefits. For instance, a language model that is\nsyntax-aware is likely to be able to produce better samples; even a\ndiscriminative model like BERT with a syntax module could be used for core NLP\ntasks like unsupervised syntactic parsing. Rapid progress in recent years was\narguably spurred on by the empirical success of the Parsing-Reading-Predict\narchitecture of (Shen et al., 2018a), later simplified by the Order Neuron LSTM\nof (Shen et al., 2019). Most notably, this is the first time neural approaches\nwere able to successfully perform unsupervised syntactic parsing (evaluated by\nvarious metrics like F-1 score).\n\nHowever, even heuristic (much less fully mathematical) understanding of why\nand when these architectures work is lagging severely behind. In this work, we\nanswer representational questions raised by the architectures in (Shen et al.,\n2018a, 2019), as well as some transition-based syntax-aware language models\n(Dyer et al., 2016): what kind of syntactic structure can current neural\napproaches to syntax represent? Concretely, we ground this question in the\nsandbox of probabilistic context-free-grammars (PCFGs), and identify a key\naspect of the representational power of these approaches: the amount and\ndirectionality of context that the predictor has access to when forced to make\nparsing decision. We show that with limited context (either bounded, or\nunidirectional), there are PCFGs, for which these approaches cannot represent\nthe max-likelihood parse; conversely, if the context is unlimited, they can\nrepresent the max-likelihood parse of any PCFG.",
          "link": "http://arxiv.org/abs/2106.01580",
          "publishedOn": "2021-06-04T01:12:27.951Z",
          "wordCount": 690,
          "title": "The Limitations of Limited Context for Constituency Parsing. (arXiv:2106.01580v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01425",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Diao_E/0/1/0/all/0/1\">Enmao Diao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_J/0/1/0/all/0/1\">Jie Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tarokh_V/0/1/0/all/0/1\">Vahid Tarokh</a>",
          "description": "In distributed settings, collaborations between different entities, such as\nfinancial institutions, medical centers, and retail markets, are crucial to\nproviding improved service and performance. However, the underlying entities\nmay have little interest in sharing their private data, proprietary models, and\nobjective functions. These privacy requirements have created new challenges for\ncollaboration. In this work, we propose Gradient Assisted Learning (GAL), a new\nmethod for various entities to assist each other in supervised learning tasks\nwithout sharing data, models, and objective functions. In this framework, all\nparticipants collaboratively optimize the aggregate of local loss functions,\nand each participant autonomously builds its own model by iteratively fitting\nthe gradients of the objective function. Experimental studies demonstrate that\nGradient Assisted Learning can achieve performance close to centralized\nlearning when all data, models, and objective functions are fully disclosed.",
          "link": "http://arxiv.org/abs/2106.01425",
          "publishedOn": "2021-06-04T01:12:27.944Z",
          "wordCount": 547,
          "title": "Gradient Assisted Learning. (arXiv:2106.01425v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01586",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pahuja_V/0/1/0/all/0/1\">Vardaan Pahuja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yu Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenhu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bahrami_M/0/1/0/all/0/1\">Mehdi Bahrami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei-Peng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yu Su</a>",
          "description": "Knowledge bases (KBs) and text often contain complementary knowledge: KBs\nstore structured knowledge that can support long range reasoning, while text\nstores more comprehensive and timely knowledge in an unstructured way.\nSeparately embedding the individual knowledge sources into vector spaces has\ndemonstrated tremendous successes in encoding the respective knowledge, but how\nto jointly embed and reason with both knowledge sources to fully leverage the\ncomplementary information is still largely an open problem. We conduct a\nlarge-scale, systematic investigation of aligning KB and text embeddings for\njoint reasoning. We set up a novel evaluation framework with two evaluation\ntasks, few-shot link prediction and analogical reasoning, and evaluate an array\nof KB-text embedding alignment methods. We also demonstrate how such alignment\ncan infuse textual information into KB embeddings for more accurate link\nprediction on emerging entities and events, using COVID-19 as a case study.",
          "link": "http://arxiv.org/abs/2106.01586",
          "publishedOn": "2021-06-04T01:12:27.937Z",
          "wordCount": 634,
          "title": "A Systematic Investigation of KB-Text Embedding Alignment at Scale. (arXiv:2106.01586v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01497",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sharma_P/0/1/0/all/0/1\">Piyush K. Sharma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dennison_M/0/1/0/all/0/1\">Mark Dennison</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Raglin_A/0/1/0/all/0/1\">Adrienne Raglin</a>",
          "description": "Deployment of Internet of Things (IoT) devices and Data Fusion techniques\nhave gained popularity in public and government domains. This usually requires\ncapturing and consolidating data from multiple sources. As datasets do not\nnecessarily originate from identical sensors, fused data typically results in a\ncomplex data problem. Because military is investigating how heterogeneous IoT\ndevices can aid processes and tasks, we investigate a multi-sensor approach.\nMoreover, we propose a signal to image encoding approach to transform\ninformation (signal) to integrate (fuse) data from IoT wearable devices to an\nimage which is invertible and easier to visualize supporting decision making.\nFurthermore, we investigate the challenge of enabling an intelligent\nidentification and detection operation and demonstrate the feasibility of the\nproposed Deep Learning and Anomaly Detection models that can support future\napplication that utilizes hand gesture data from wearable devices.",
          "link": "http://arxiv.org/abs/2106.01497",
          "publishedOn": "2021-06-04T01:12:27.919Z",
          "wordCount": 612,
          "title": "IoT Solutions with Multi-Sensor Fusion and Signal-Image Encoding for Secure Data Transfer and Decision Making. (arXiv:2106.01497v1 [eess.SP])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01548",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiangning Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1\">Cho-Jui Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_B/0/1/0/all/0/1\">Boqing Gong</a>",
          "description": "Vision Transformers (ViTs) and MLPs signal further efforts on replacing\nhand-wired features or inductive biases with general-purpose neural\narchitectures. Existing works empower the models by massive data, such as\nlarge-scale pretraining and/or repeated strong data augmentations, and still\nreport optimization-related problems (e.g., sensitivity to initialization and\nlearning rate). Hence, this paper investigates ViTs and MLP-Mixers from the\nlens of loss geometry, intending to improve the models' data efficiency at\ntraining and generalization at inference. Visualization and Hessian reveal\nextremely sharp local minima of converged models. By promoting smoothness with\na recently proposed sharpness-aware optimizer, we substantially improve the\naccuracy and robustness of ViTs and MLP-Mixers on various tasks spanning\nsupervised, adversarial, contrastive, and transfer learning (e.g., +5.3\\% and\n+11.0\\% top-1 accuracy on ImageNet for ViT-B/16 and Mixer-B/16, respectively,\nwith the simple Inception-style preprocessing). We show that the improved\nsmoothness attributes to sparser active neurons in the first few layers. The\nresultant ViTs outperform ResNets of similar size and throughput when trained\nfrom scratch on ImageNet without large-scale pretraining or strong data\naugmentations. They also possess more perceptive attention maps.",
          "link": "http://arxiv.org/abs/2106.01548",
          "publishedOn": "2021-06-04T01:12:27.912Z",
          "wordCount": 617,
          "title": "When Vision Transformers Outperform ResNets without Pretraining or Strong Data Augmentations. (arXiv:2106.01548v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01501",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Suri_S/0/1/0/all/0/1\">Sahaana Suri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ilyas_I/0/1/0/all/0/1\">Ihab F. Ilyas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Re_C/0/1/0/all/0/1\">Christopher R&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rekatsinas_T/0/1/0/all/0/1\">Theodoros Rekatsinas</a>",
          "description": "Structured data, or data that adheres to a pre-defined schema, can suffer\nfrom fragmented context: information describing a single entity can be\nscattered across multiple datasets or tables tailored for specific business\nneeds, with no explicit linking keys (e.g., primary key-foreign key\nrelationships or heuristic functions). Context enrichment, or rebuilding\nfragmented context, using keyless joins is an implicit or explicit step in\nmachine learning (ML) pipelines over structured data sources. This process is\ntedious, domain-specific, and lacks support in now-prevalent no-code ML systems\nthat let users create ML pipelines using just input data and high-level\nconfiguration files. In response, we propose Ember, a system that abstracts and\nautomates keyless joins to generalize context enrichment. Our key insight is\nthat Ember can enable a general keyless join operator by constructing an index\npopulated with task-specific embeddings. Ember learns these embeddings by\nleveraging Transformer-based representation learning techniques. We describe\nour core architectural principles and operators when developing Ember, and\nempirically demonstrate that Ember allows users to develop no-code pipelines\nfor five domains, including search, recommendation and question answering, and\ncan exceed alternatives by up to 39% recall, with as little as a single line\nconfiguration change.",
          "link": "http://arxiv.org/abs/2106.01501",
          "publishedOn": "2021-06-04T01:12:27.903Z",
          "wordCount": 621,
          "title": "Ember: No-Code Context Enrichment via Similarity-Based Keyless Joins. (arXiv:2106.01501v1 [cs.DB])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01485",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tang_C/0/1/0/all/0/1\">Chengliang Tang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yuan_G/0/1/0/all/0/1\">Gan Yuan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zheng_T/0/1/0/all/0/1\">Tian Zheng</a>",
          "description": "The past two decades have witnessed the great success of the algorithmic\nmodeling framework advocated by Breiman et al. (2001). Nevertheless, the\nexcellent prediction performance of these black-box models rely heavily on the\navailability of strong supervision, i.e. a large set of accurate and exact\nground-truth labels. In practice, strong supervision can be unavailable or\nexpensive, which calls for modeling techniques under weak supervision. In this\ncomment, we summarize the key concepts in weakly supervised learning and\ndiscuss some recent developments in the field. Using algorithmic modeling alone\nunder a weak supervision might lead to unstable and misleading results. A\npromising direction would be integrating the data modeling culture into such a\nframework.",
          "link": "http://arxiv.org/abs/2106.01485",
          "publishedOn": "2021-06-04T01:12:27.895Z",
          "wordCount": 544,
          "title": "Weakly Supervised Learning Creates a Fusion of Modeling Cultures. (arXiv:2106.01485v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01528",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Hansen_D/0/1/0/all/0/1\">Derek Hansen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Manzo_B/0/1/0/all/0/1\">Brian Manzo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Regier_J/0/1/0/all/0/1\">Jeffrey Regier</a>",
          "description": "The goal of controlled feature selection is to discover the features a\nresponse depends on while limiting the proportion of false discoveries to a\npredefined level. Recently, multiple methods have been proposed that use deep\nlearning to generate knockoffs for controlled feature selection through the\nModel-X knockoff framework. We demonstrate, however, that these methods often\nfail to control the false discovery rate (FDR). There are two reasons for this\nshortcoming. First, these methods often learn inaccurate models of features.\nSecond, the \"swap\" property, which is required for knockoffs to be valid, is\noften not well enforced. We propose a new procedure called FlowSelect that\nremedies both of these problems. To more accurately model the features,\nFlowSelect uses normalizing flows, the state-of-the-art method for density\nestimation. To circumvent the need to enforce the swap property, FlowSelect\nuses a novel MCMC-based procedure to directly compute p-values for each\nfeature. Asymptotically, FlowSelect controls the FDR exactly. Empirically,\nFlowSelect controls the FDR well on both synthetic and semi-synthetic\nbenchmarks, whereas competing knockoff-based approaches fail to do so.\nFlowSelect also demonstrates greater power on these benchmarks. Additionally,\nusing data from a genome-wide association study of soybeans, FlowSelect\ncorrectly infers the genetic variants associated with specific soybean traits.",
          "link": "http://arxiv.org/abs/2106.01528",
          "publishedOn": "2021-06-04T01:12:27.887Z",
          "wordCount": 636,
          "title": "Normalizing Flows for Knockoff-free Controlled Feature Selection. (arXiv:2106.01528v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01450",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Park_J/0/1/0/all/0/1\">Ji Won Park</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Villar_A/0/1/0/all/0/1\">Ashley Villar</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Li_Y/0/1/0/all/0/1\">Yin Li</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Jiang_Y/0/1/0/all/0/1\">Yan-Fei Jiang</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Ho_S/0/1/0/all/0/1\">Shirley Ho</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Lin_J/0/1/0/all/0/1\">Joshua Yao-Yu Lin</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Marshall_P/0/1/0/all/0/1\">Philip J. Marshall</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Roodman_A/0/1/0/all/0/1\">Aaron Roodman</a>",
          "description": "Among the most extreme objects in the Universe, active galactic nuclei (AGN)\nare luminous centers of galaxies where a black hole feeds on surrounding\nmatter. The variability patterns of the light emitted by an AGN contain\ninformation about the physical properties of the underlying black hole.\nUpcoming telescopes will observe over 100 million AGN in multiple broadband\nwavelengths, yielding a large sample of multivariate time series with long gaps\nand irregular sampling. We present a method that reconstructs the AGN time\nseries and simultaneously infers the posterior probability density distribution\n(PDF) over the physical quantities of the black hole, including its mass and\nluminosity. We apply this method to a simulated dataset of 11,000 AGN and\nreport precision and accuracy of 0.4 dex and 0.3 dex in the inferred black hole\nmass. This work is the first to address probabilistic time series\nreconstruction and parameter inference for AGN in an end-to-end fashion.",
          "link": "http://arxiv.org/abs/2106.01450",
          "publishedOn": "2021-06-04T01:12:27.736Z",
          "wordCount": 644,
          "title": "Inferring Black Hole Properties from Astronomical Multivariate Time Series with Bayesian Attentive Neural Processes. (arXiv:2106.01450v1 [astro-ph.IM])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01488",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fiez_T/0/1/0/all/0/1\">Tanner Fiez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1\">Chi Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Netrapalli_P/0/1/0/all/0/1\">Praneeth Netrapalli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ratliff_L/0/1/0/all/0/1\">Lillian J. Ratliff</a>",
          "description": "This paper considers minimax optimization $\\min_x \\max_y f(x, y)$ in the\nchallenging setting where $f$ can be both nonconvex in $x$ and nonconcave in\n$y$. Though such optimization problems arise in many machine learning paradigms\nincluding training generative adversarial networks (GANs) and adversarially\nrobust models, many fundamental issues remain in theory, such as the absence of\nefficiently computable optimality notions, and cyclic or diverging behavior of\nexisting algorithms. Our framework sprouts from the practical consideration\nthat under a computational budget, the max-player can not fully maximize\n$f(x,\\cdot)$ since nonconcave maximization is NP-hard in general. So, we\npropose a new algorithm for the min-player to play against smooth algorithms\ndeployed by the adversary (i.e., the max-player) instead of against full\nmaximization. Our algorithm is guaranteed to make monotonic progress (thus\nhaving no limit cycles), and to find an appropriate \"stationary point\" in a\npolynomial number of iterations. Our framework covers practical settings where\nthe smooth algorithms deployed by the adversary are multi-step stochastic\ngradient ascent, and its accelerated version. We further provide complementing\nexperiments that confirm our theoretical findings and demonstrate the\neffectiveness of the proposed approach in practice.",
          "link": "http://arxiv.org/abs/2106.01488",
          "publishedOn": "2021-06-04T01:12:27.713Z",
          "wordCount": 616,
          "title": "Minimax Optimization with Smooth Algorithmic Adversaries. (arXiv:2106.01488v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01465",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jieyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khashabi_D/0/1/0/all/0/1\">Daniel Khashabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khot_T/0/1/0/all/0/1\">Tushar Khot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabharwal_A/0/1/0/all/0/1\">Ashish Sabharwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>",
          "description": "Is it possible to use natural language to intervene in a model's behavior and\nalter its prediction in a desired way? We investigate the effectiveness of\nnatural language interventions for reading-comprehension systems, studying this\nin the context of social stereotypes. Specifically, we propose a new language\nunderstanding task, Linguistic Ethical Interventions (LEI), where the goal is\nto amend a question-answering (QA) model's unethical behavior by communicating\ncontext-specific principles of ethics and equity to it. To this end, we build\nupon recent methods for quantifying a system's social stereotypes, augmenting\nthem with different kinds of ethical interventions and the desired model\nbehavior under such interventions. Our zero-shot evaluation finds that even\ntoday's powerful neural language models are extremely poor ethical-advice\ntakers, that is, they respond surprisingly little to ethical interventions even\nthough these interventions are stated as simple sentences. Few-shot learning\nimproves model behavior but remains far from the desired outcome, especially\nwhen evaluated for various types of generalization. Our new task thus poses a\nnovel language understanding challenge for the community.",
          "link": "http://arxiv.org/abs/2106.01465",
          "publishedOn": "2021-06-04T01:12:27.700Z",
          "wordCount": 616,
          "title": "Ethical-Advice Taker: Do Language Models Understand Natural Language Interventions?. (arXiv:2106.01465v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01440",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rosa_B/0/1/0/all/0/1\">Biagio La Rosa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Capobianco_R/0/1/0/all/0/1\">Roberto Capobianco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nardi_D/0/1/0/all/0/1\">Daniele Nardi</a>",
          "description": "Due to their black-box and data-hungry nature, deep learning techniques are\nnot yet widely adopted for real-world applications in critical domains, like\nhealthcare and justice. This paper presents Memory Wrap, a plug-and-play\nextension to any image classification model. Memory Wrap improves both\ndata-efficiency and model interpretability, adopting a content-attention\nmechanism between the input and some memories of past training samples. We show\nthat Memory Wrap outperforms standard classifiers when it learns from a limited\nset of data, and it reaches comparable performance when it learns from the full\ndataset. We discuss how its structure and content-attention mechanisms make\npredictions interpretable, compared to standard classifiers. To this end, we\nboth show a method to build explanations by examples and counterfactuals, based\non the memory content, and how to exploit them to get insights about its\ndecision process. We test our approach on image classification tasks using\nseveral architectures on three different datasets, namely CIFAR10, SVHN, and\nCINIC10.",
          "link": "http://arxiv.org/abs/2106.01440",
          "publishedOn": "2021-06-04T01:12:27.692Z",
          "wordCount": 589,
          "title": "Memory Wrap: a Data-Efficient and Interpretable Extension to Image Classification Models. (arXiv:2106.01440v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01452",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Keller_Y/0/1/0/all/0/1\">Yannik Keller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mackensen_J/0/1/0/all/0/1\">Jan Mackensen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eger_S/0/1/0/all/0/1\">Steffen Eger</a>",
          "description": "Adversarial attacks expose important blind spots of deep learning systems.\nWhile word- and sentence-level attack scenarios mostly deal with finding\nsemantic paraphrases of the input that fool NLP models, character-level attacks\ntypically insert typos into the input stream. It is commonly thought that these\nare easier to defend via spelling correction modules. In this work, we show\nthat both a standard spellchecker and the approach of Pruthi et al. (2019),\nwhich trains to defend against insertions, deletions and swaps, perform poorly\non the character-level benchmark recently proposed in Eger and Benz (2020)\nwhich includes more challenging attacks such as visual and phonetic\nperturbations and missing word segmentations. In contrast, we show that an\nuntrained iterative approach which combines context-independent character-level\ninformation with context-dependent information from BERT's masked language\nmodeling can perform on par with human crowd-workers from Amazon Mechanical\nTurk (AMT) supervised via 3-shot learning.",
          "link": "http://arxiv.org/abs/2106.01452",
          "publishedOn": "2021-06-04T01:12:27.683Z",
          "wordCount": 590,
          "title": "BERT-Defense: A Probabilistic Model Based on BERT to Combat Cognitively Inspired Orthographic Adversarial Attacks. (arXiv:2106.01452v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karbasi_A/0/1/0/all/0/1\">Amin Karbasi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mirrokni_V/0/1/0/all/0/1\">Vahab Mirrokni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shadravan_M/0/1/0/all/0/1\">Mohammad Shadravan</a>",
          "description": "How can we make use of information parallelism in online decision making\nproblems while efficiently balancing the exploration-exploitation trade-off? In\nthis paper, we introduce a batch Thompson Sampling framework for two canonical\nonline decision making problems, namely, stochastic multi-arm bandit and linear\ncontextual bandit with finitely many arms. Over a time horizon $T$, our\n\\textit{batch} Thompson Sampling policy achieves the same (asymptotic) regret\nbound of a fully sequential one while carrying out only $O(\\log T)$ batch\nqueries. To achieve this exponential reduction, i.e., reducing the number of\ninteractions from $T$ to $O(\\log T)$, our batch policy dynamically determines\nthe duration of each batch in order to balance the exploration-exploitation\ntrade-off. We also demonstrate experimentally that dynamic batch allocation\ndramatically outperforms natural baselines such as static batch allocations.",
          "link": "http://arxiv.org/abs/2106.01420",
          "publishedOn": "2021-06-04T01:12:27.674Z",
          "wordCount": 553,
          "title": "Parallelizing Thompson Sampling. (arXiv:2106.01420v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01429",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Poon_C/0/1/0/all/0/1\">Clarice Poon</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Peyre_G/0/1/0/all/0/1\">Gabriel Peyr&#xe9;</a>",
          "description": "Iteratively reweighted least square (IRLS) is a popular approach to solve\nsparsity-enforcing regression problems in machine learning. State of the art\napproaches are more efficient but typically rely on specific coordinate pruning\nschemes. In this work, we show how a surprisingly simple reparametrization of\nIRLS, coupled with a bilevel resolution (instead of an alternating scheme) is\nable to achieve top performances on a wide range of sparsity (such as Lasso,\ngroup Lasso and trace norm regularizations), regularization strength (including\nhard constraints), and design matrices (ranging from correlated designs to\ndifferential operators). Similarly to IRLS, our method only involves linear\nsystems resolutions, but in sharp contrast, corresponds to the minimization of\na smooth function. Despite being non-convex, we show that there is no spurious\nminima and that saddle points are \"ridable\", so that there always exists a\ndescent direction. We thus advocate for the use of a BFGS quasi-Newton solver,\nwhich makes our approach simple, robust and efficient. We perform a numerical\nbenchmark of the convergence speed of our algorithm against state of the art\nsolvers for Lasso, group Lasso, trace norm and linearly constrained problems.\nThese results highlight the versatility of our approach, removing the need to\nuse different solvers depending on the specificity of the ML problem under\nstudy.",
          "link": "http://arxiv.org/abs/2106.01429",
          "publishedOn": "2021-06-04T01:12:27.655Z",
          "wordCount": 635,
          "title": "Smooth Bilevel Programming for Sparse Regularization. (arXiv:2106.01429v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01432",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Diao_E/0/1/0/all/0/1\">Enmao Diao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_J/0/1/0/all/0/1\">Jie Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tarokh_V/0/1/0/all/0/1\">Vahid Tarokh</a>",
          "description": "Federated Learning allows training machine learning models by using the\ncomputation and private data resources of a large number of distributed clients\nsuch as smartphones and IoT devices. Most existing works on Federated Learning\n(FL) assume the clients have ground-truth labels. However, in many practical\nscenarios, clients may be unable to label task-specific data, e.g., due to lack\nof expertise. In this work, we consider a server that hosts a labeled dataset,\nand wishes to leverage clients with unlabeled data for supervised learning. We\npropose a new Federated Learning framework referred to as SemiFL in order to\naddress the problem of Semi-Supervised Federated Learning (SSFL). In SemiFL,\nclients have completely unlabeled data, while the server has a small amount of\nlabeled data. SemiFL is communication efficient since it separates the training\nof server-side supervised data and client-side unsupervised data. We\ndemonstrate various efficient strategies of SemiFL that enhance learning\nperformance. Extensive empirical evaluations demonstrate that our communication\nefficient method can significantly improve the performance of a labeled server\nwith unlabeled clients. Moreover, we demonstrate that SemiFL can outperform\nmany existing FL results trained with fully supervised data, and perform\ncompetitively with the state-of-the-art centralized Semi-Supervised Learning\n(SSL) methods. For instance, in standard communication efficient scenarios, our\nmethod can perform 93% accuracy on the CIFAR10 dataset with only 4000 labeled\nsamples at the server. Such accuracy is only 2% away from the result trained\nfrom 50000 fully labeled data, and it improves about 30% upon existing SSFL\nmethods in the communication efficient setting.",
          "link": "http://arxiv.org/abs/2106.01432",
          "publishedOn": "2021-06-04T01:12:27.646Z",
          "wordCount": 676,
          "title": "SemiFL: Communication Efficient Semi-Supervised Federated Learning with Unlabeled Clients. (arXiv:2106.01432v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01434",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bian_X/0/1/0/all/0/1\">Xihan Bian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mendez_O/0/1/0/all/0/1\">Oscar Mendez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hadfield_S/0/1/0/all/0/1\">Simon Hadfield</a>",
          "description": "Robots need to be able to work in multiple different environments. Even when\nperforming similar tasks, different behaviour should be deployed to best fit\nthe current environment. In this paper, We propose a new approach to\nnavigation, where it is treated as a multi-task learning problem. This enables\nthe robot to learn to behave differently in visual navigation tasks for\ndifferent environments while also learning shared expertise across\nenvironments. We evaluated our approach in both simulated environments as well\nas real-world data. Our method allows our system to converge with a 26%\nreduction in training time, while also increasing accuracy.",
          "link": "http://arxiv.org/abs/2106.01434",
          "publishedOn": "2021-06-04T01:12:27.631Z",
          "wordCount": 537,
          "title": "Robot in a China Shop: Using Reinforcement Learning for Location-Specific Navigation Behaviour. (arXiv:2106.01434v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01423",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kvinge_H/0/1/0/all/0/1\">Henry Kvinge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Howland_S/0/1/0/all/0/1\">Scott Howland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Courts_N/0/1/0/all/0/1\">Nico Courts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phillips_L/0/1/0/all/0/1\">Lauren A. Phillips</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buckheit_J/0/1/0/all/0/1\">John Buckheit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+New_Z/0/1/0/all/0/1\">Zachary New</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Skomski_E/0/1/0/all/0/1\">Elliott Skomski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jung H. Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tiwari_S/0/1/0/all/0/1\">Sandeep Tiwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hibler_J/0/1/0/all/0/1\">Jessica Hibler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Corley_C/0/1/0/all/0/1\">Courtney D. Corley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hodas_N/0/1/0/all/0/1\">Nathan O. Hodas</a>",
          "description": "The field of few-shot learning has made remarkable strides in developing\npowerful models that can operate in the small data regime. Nearly all of these\nmethods assume every unlabeled instance encountered will belong to a handful of\nknown classes for which one has examples. This can be problematic for\nreal-world use cases where one routinely finds 'none-of-the-above' examples. In\nthis paper we describe this challenge of identifying what we term\n'out-of-support' (OOS) examples. We describe how this problem is subtly\ndifferent from out-of-distribution detection and describe a new method of\nidentifying OOS examples within the Prototypical Networks framework using a\nfixed point which we call the generic representation. We show that our method\noutperforms other existing approaches in the literature as well as other\napproaches that we propose in this paper. Finally, we investigate how the use\nof such a generic point affects the geometry of a model's feature space.",
          "link": "http://arxiv.org/abs/2106.01423",
          "publishedOn": "2021-06-04T01:12:27.622Z",
          "wordCount": 627,
          "title": "One Representation to Rule Them All: Identifying Out-of-Support Examples in Few-shot Learning with Generic Representations. (arXiv:2106.01423v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01413",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Caterini_A/0/1/0/all/0/1\">Anthony L. Caterini</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Loaiza_Ganem_G/0/1/0/all/0/1\">Gabriel Loaiza-Ganem</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pleiss_G/0/1/0/all/0/1\">Geoff Pleiss</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cunningham_J/0/1/0/all/0/1\">John P. Cunningham</a>",
          "description": "Normalizing flows are invertible neural networks with tractable\nchange-of-volume terms, which allows optimization of their parameters to be\nefficiently performed via maximum likelihood. However, data of interest is\ntypically assumed to live in some (often unknown) low-dimensional manifold\nembedded in high-dimensional ambient space. The result is a modelling mismatch\nsince -- by construction -- the invertibility requirement implies\nhigh-dimensional support of the learned distribution. Injective flows, mapping\nfrom low- to high-dimensional space, aim to fix this discrepancy by learning\ndistributions on manifolds, but the resulting volume-change term becomes more\nchallenging to evaluate. Current approaches either avoid computing this term\nentirely using various heuristics, or assume the manifold is known beforehand\nand therefore are not widely applicable. Instead, we propose two methods to\ntractably calculate the gradient of this term with respect to the parameters of\nthe model, relying on careful use of automatic differentiation and techniques\nfrom numerical linear algebra. Both approaches perform end-to-end nonlinear\nmanifold learning and density estimation for data projected onto this manifold.\nWe study the trade-offs between our proposed methods, empirically verify that\nwe outperform approaches ignoring the volume-change term by more accurately\nlearning manifolds and the corresponding distributions on them, and show\npromising results on out-of-distribution detection.",
          "link": "http://arxiv.org/abs/2106.01413",
          "publishedOn": "2021-06-04T01:12:27.611Z",
          "wordCount": 626,
          "title": "Rectangular Flows for Manifold Learning. (arXiv:2106.01413v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01404",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jongwook Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Archit Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Honglak Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1\">Shixiang Shane Gu</a>",
          "description": "Learning to reach goal states and learning diverse skills through mutual\ninformation (MI) maximization have been proposed as principled frameworks for\nself-supervised reinforcement learning, allowing agents to acquire broadly\napplicable multitask policies with minimal reward engineering. Starting from a\nsimple observation that the standard goal-conditioned RL (GCRL) is encapsulated\nby the optimization objective of variational empowerment, we discuss how GCRL\nand MI-based RL can be generalized into a single family of methods, which we\nname variational GCRL (VGCRL), interpreting variational MI maximization, or\nvariational empowerment, as representation learning methods that acquire\nfunctionally-aware state representations for goal reaching. This novel\nperspective allows us to: (1) derive simple but unexplored variants of GCRL to\nstudy how adding small representation capacity can already expand its\ncapabilities; (2) investigate how discriminator function capacity and\nsmoothness determine the quality of discovered skills, or latent goals, through\nmodifying latent dimensionality and applying spectral normalization; (3) adapt\ntechniques such as hindsight experience replay (HER) from GCRL to MI-based RL;\nand lastly, (4) propose a novel evaluation metric, named latent goal reaching\n(LGR), for comparing empowerment algorithms with different choices of latent\ndimensionality and discriminator parameterization. Through principled\nmathematical derivations and careful experimental studies, our work lays a\nnovel foundation from which to evaluate, analyze, and develop representation\nlearning techniques in goal-based RL.",
          "link": "http://arxiv.org/abs/2106.01404",
          "publishedOn": "2021-06-04T01:12:27.492Z",
          "wordCount": 658,
          "title": "Variational Empowerment as Representation Learning for Goal-Based Reinforcement Learning. (arXiv:2106.01404v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01370",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hussain_S/0/1/0/all/0/1\">Syed Saiq Hussain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Usman_M/0/1/0/all/0/1\">Muhammad Usman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siddique_T/0/1/0/all/0/1\">Taha Hasan Masood Siddique</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naseem_I/0/1/0/all/0/1\">Imran Naseem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Togneri_R/0/1/0/all/0/1\">Roberto Togneri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bennamoun_M/0/1/0/all/0/1\">Mohammed Bennamoun</a>",
          "description": "In this research a novel stochastic gradient descent based learning approach\nfor the radial basis function neural networks (RBFNN) is proposed. The proposed\nmethod is based on the q-gradient which is also known as Jackson derivative. In\ncontrast to the conventional gradient, which finds the tangent, the q-gradient\nfinds the secant of the function and takes larger steps towards the optimal\nsolution. The proposed $q$-RBFNN is analyzed for its convergence performance in\nthe context of least square algorithm. In particular, a closed form expression\nof the Wiener solution is obtained, and stability bounds of the learning rate\n(step-size) is derived. The analytical results are validated through computer\nsimulation. Additionally, we propose an adaptive technique for the time-varying\n$q$-parameter to improve convergence speed with no trade-offs in the steady\nstate performance.",
          "link": "http://arxiv.org/abs/2106.01370",
          "publishedOn": "2021-06-04T01:12:27.482Z",
          "wordCount": 572,
          "title": "q-RBFNN:A Quantum Calculus-based RBF Neural Network. (arXiv:2106.01370v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01388",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Hubregtsen_T/0/1/0/all/0/1\">Thomas Hubregtsen</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Wilde_F/0/1/0/all/0/1\">Frederik Wilde</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Qasim_S/0/1/0/all/0/1\">Shozab Qasim</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Eisert_J/0/1/0/all/0/1\">Jens Eisert</a>",
          "description": "Many near-term quantum computing algorithms are conceived as variational\nquantum algorithms, in which parameterized quantum circuits are optimized in a\nhybrid quantum-classical setup. Examples are variational quantum eigensolvers,\nquantum approximate optimization algorithms as well as various algorithms in\nthe context of quantum-assisted machine learning. A common bottleneck of any\nsuch algorithm is constituted by the optimization of the variational\nparameters. A popular set of optimization methods work on the estimate of the\ngradient, obtained by means of circuit evaluations. We will refer to the way in\nwhich one can combine these circuit evaluations as gradient rules. This work\nprovides a comprehensive picture of the family of gradient rules that vary\nparameters of quantum gates individually. The most prominent known members of\nthis family are the parameter shift rule and the finite differences method. To\nunite this family, we propose a generalized parameter shift rule that expresses\nall members of the aforementioned family as special cases, and discuss how all\nof these can be seen as providing access to a linear combination of exact\nfirst- and second-order derivatives. We further prove that a parameter shift\nrule with one non-shifted evaluation and only one shifted circuit evaluation\ncan not exist does not exist, and introduce a novel perspective for approaching\nnew gradient rules.",
          "link": "http://arxiv.org/abs/2106.01388",
          "publishedOn": "2021-06-04T01:12:27.473Z",
          "wordCount": 641,
          "title": "Single-component gradient rules for variational quantum algorithms. (arXiv:2106.01388v1 [quant-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01400",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kumar_M/0/1/0/all/0/1\">Mari Ganesh Kumar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kuriakose_J/0/1/0/all/0/1\">Jom Kuriakose</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Thyagachandran_A/0/1/0/all/0/1\">Anand Thyagachandran</a>, <a href=\"http://arxiv.org/find/eess/1/au:+A_A/0/1/0/all/0/1\">Arun Kumar A</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Seth_A/0/1/0/all/0/1\">Ashish Seth</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Prasad_L/0/1/0/all/0/1\">Lodagala Durga Prasad</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jaiswal_S/0/1/0/all/0/1\">Saish Jaiswal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Prakash_A/0/1/0/all/0/1\">Anusha Prakash</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Murthy_H/0/1/0/all/0/1\">Hema Murthy</a>",
          "description": "India is home to multiple languages, and training automatic speech\nrecognition (ASR) systems for languages is challenging. Over time, each\nlanguage has adopted words from other languages, such as English, leading to\ncode-mixing. Most Indian languages also have their own unique scripts, which\nposes a major limitation in training multilingual and code-switching ASR\nsystems.\n\nInspired by results in text-to-speech synthesis, in this work, we use an\nin-house rule-based phoneme-level common label set (CLS) representation to\ntrain multilingual and code-switching ASR for Indian languages. We propose two\nend-to-end (E2E) ASR systems. In the first system, the E2E model is trained on\nthe CLS representation, and we use a novel data-driven back-end to recover the\nnative language script. In the second system, we propose a modification to the\nE2E model, wherein the CLS representation and the native language characters\nare used simultaneously for training. We show our results on the multilingual\nand code-switching tasks of the Indic ASR Challenge 2021. Our best results\nachieve 6% and 5% improvement (approx) in word error rate over the baseline\nsystem for the multilingual and code-switching tasks, respectively, on the\nchallenge development data.",
          "link": "http://arxiv.org/abs/2106.01400",
          "publishedOn": "2021-06-04T01:12:27.461Z",
          "wordCount": 649,
          "title": "Dual Script E2E framework for Multilingual and Code-Switching ASR. (arXiv:2106.01400v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01382",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Caro_M/0/1/0/all/0/1\">Matthias C. Caro</a>",
          "description": "Machine learning researchers and practitioners steadily enlarge the multitude\nof successful learning models. They achieve this through in-depth theoretical\nanalyses and experiential heuristics. However, there is no known\ngeneral-purpose procedure for rigorously evaluating whether newly proposed\nmodels indeed successfully learn from data. We show that such a procedure\ncannot exist. For PAC binary classification, uniform and universal online\nlearning, and exact learning through teacher-learner interactions, learnability\nis in general undecidable, both in the sense of independence of the axioms in a\nformal system and in the sense of uncomputability. Our proofs proceed via\ncomputable constructions of function classes that encode the consistency\nproblem for formal systems and the halting problem for Turing machines into\ncomplexity measures that characterize learnability. Our work shows that\nundecidability appears in the theoretical foundations of machine learning:\nThere is no one-size-fits-all algorithm for deciding whether a machine learning\nmodel can be successful. We cannot in general automatize the process of\nassessing new learning models.",
          "link": "http://arxiv.org/abs/2106.01382",
          "publishedOn": "2021-06-04T01:12:27.447Z",
          "wordCount": 591,
          "title": "Undecidability of Learnability. (arXiv:2106.01382v1 [cs.CC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01367",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Coimbra_D/0/1/0/all/0/1\">David Coimbra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reis_S/0/1/0/all/0/1\">Sofia Reis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abreu_R/0/1/0/all/0/1\">Rui Abreu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pasareanu_C/0/1/0/all/0/1\">Corina P&#x103;s&#x103;reanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erdogmus_H/0/1/0/all/0/1\">Hakan Erdogmus</a>",
          "description": "This paper presents an evaluation of the code representation model Code2vec\nwhen trained on the task of detecting security vulnerabilities in C source\ncode. We leverage the open-source library astminer to extract path-contexts\nfrom the abstract syntax trees of a corpus of labeled C functions. Code2vec is\ntrained on the resulting path-contexts with the task of classifying a function\nas vulnerable or non-vulnerable. Using the CodeXGLUE benchmark, we show that\nthe accuracy of Code2vec for this task is comparable to simple\ntransformer-based methods such as pre-trained RoBERTa, and outperforms more\nnaive NLP-based methods. We achieved an accuracy of 61.43% while maintaining\nlow computational requirements relative to larger models.",
          "link": "http://arxiv.org/abs/2106.01367",
          "publishedOn": "2021-06-04T01:12:27.425Z",
          "wordCount": 568,
          "title": "On using distributed representations of source code for the detection of C security vulnerabilities. (arXiv:2106.01367v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01399",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Orr_J/0/1/0/all/0/1\">J. Walker Orr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Russell_N/0/1/0/all/0/1\">Nathaniel Russell</a>",
          "description": "The assessment of program functionality can generally be accomplished with\nstraight-forward unit tests. However, assessing the design quality of a program\nis a much more difficult and nuanced problem. Design quality is an important\nconsideration since it affects the readability and maintainability of programs.\nAssessing design quality and giving personalized feedback is very time\nconsuming task for instructors and teaching assistants. This limits the scale\nof giving personalized feedback to small class settings. Further, design\nquality is nuanced and is difficult to concisely express as a set of rules. For\nthese reasons, we propose a neural network model to both automatically assess\nthe design of a program and provide personalized feedback to guide students on\nhow to make corrections. The model's effectiveness is evaluated on a corpus of\nstudent programs written in Python. The model has an accuracy rate from 83.67%\nto 94.27%, depending on the dataset, when predicting design scores as compared\nto historical instructor assessment. Finally, we present a study where students\ntried to improve the design of their programs based on the personalized\nfeedback produced by the model. Students who participated in the study improved\ntheir program design scores by 19.58%.",
          "link": "http://arxiv.org/abs/2106.01399",
          "publishedOn": "2021-06-04T01:12:27.402Z",
          "wordCount": 637,
          "title": "Automatic Assessment of the Design Quality of Python Programs with Personalized Feedback. (arXiv:2106.01399v1 [cs.SE])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01001",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vecoven_N/0/1/0/all/0/1\">Nicolas Vecoven</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ernst_D/0/1/0/all/0/1\">Damien Ernst</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drion_G/0/1/0/all/0/1\">Guillaume Drion</a>",
          "description": "Training recurrent neural networks is known to be difficult when time\ndependencies become long. Consequently, training standard gated cells such as\ngated recurrent units and long-short term memory on benchmarks where long-term\nmemory is required remains an arduous task. In this work, we propose a general\nway to initialize any recurrent network connectivity through a process called\n\"warm-up\" to improve its capability to learn arbitrarily long time\ndependencies. This initialization process is designed to maximize network\nreachable multi-stability, i.e. the number of attractors within the network\nthat can be reached through relevant input trajectories. Warming-up is\nperformed before training, using stochastic gradient descent on a specifically\ndesigned loss. We show that warming-up greatly improves recurrent neural\nnetwork performance on long-term memory benchmarks for multiple recurrent cell\ntypes, but can sometimes impede precision. We therefore introduce a parallel\nrecurrent network structure with partial warm-up that is shown to greatly\nimprove learning on long time-series while maintaining high levels of\nprecision. This approach provides a general framework for improving learning\nabilities of any recurrent cell type when long-term memory is required.",
          "link": "http://arxiv.org/abs/2106.01001",
          "publishedOn": "2021-06-03T02:10:37.731Z",
          "wordCount": 606,
          "title": "Warming-up recurrent neural networks to maximize reachable multi-stability greatly improves learning. (arXiv:2106.01001v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01271",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dumas_J/0/1/0/all/0/1\">Jonathan Dumas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cointe_C/0/1/0/all/0/1\">Colin Cointe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fettweis_X/0/1/0/all/0/1\">Xavier Fettweis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cornelusse_B/0/1/0/all/0/1\">Bertrand Corn&#xe9;lusse</a>",
          "description": "This paper develops probabilistic PV forecasters by taking advantage of\nrecent breakthroughs in deep learning. It tailored forecasting tool, named\nencoder-decoder, is implemented to compute intraday multi-output PV quantiles\nforecasts to efficiently capture the time correlation. The models are trained\nusing quantile regression, a non-parametric approach that assumes no prior\nknowledge of the probabilistic forecasting distribution. The case study is\ncomposed of PV production monitored on-site at the University of Li\\`ege\n(ULi\\`ege), Belgium. The weather forecasts from the regional climate model\nprovided by the Laboratory of Climatology are used as inputs of the deep\nlearning models. The forecast quality is quantitatively assessed by the\ncontinuous ranked probability and interval scores. The results indicate this\narchitecture improves the forecast quality and is computationally efficient to\nbe incorporated in an intraday decision-making tool for robust optimization.",
          "link": "http://arxiv.org/abs/2106.01271",
          "publishedOn": "2021-06-03T02:10:37.726Z",
          "wordCount": 562,
          "title": "Deep learning-based multi-output quantile forecasting of PV generation. (arXiv:2106.01271v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.09432",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Lohani_S/0/1/0/all/0/1\">Sanjaya Lohani</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Searles_T/0/1/0/all/0/1\">Thomas A. Searles</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Kirby_B/0/1/0/all/0/1\">Brian T. Kirby</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Glasser_R/0/1/0/all/0/1\">Ryan T. Glasser</a>",
          "description": "We determine the resource scaling of machine learning-based quantum state\nreconstruction methods, in terms of inference and training, for systems of up\nto four qubits when constrained to pure states. Further, we examine system\nperformance in the low-count regime, likely to be encountered in the tomography\nof high-dimensional systems. Finally, we implement our quantum state\nreconstruction method on an IBM Q quantum computer, and compare against both\nunconstrained and constrained MLE state reconstruction.",
          "link": "http://arxiv.org/abs/2012.09432",
          "publishedOn": "2021-06-03T02:10:37.722Z",
          "wordCount": 533,
          "title": "On the experimental feasibility of quantum state reconstruction via machine learning. (arXiv:2012.09432v2 [quant-ph] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.10423",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mai_Z/0/1/0/all/0/1\">Zheda Mai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruiwen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_J/0/1/0/all/0/1\">Jihwan Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quispe_D/0/1/0/all/0/1\">David Quispe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyunwoo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanner_S/0/1/0/all/0/1\">Scott Sanner</a>",
          "description": "Online continual learning for image classification studies the problem of\nlearning to classify images from an online stream of data and tasks, where\ntasks may include new classes (class incremental) or data nonstationarity\n(domain incremental). One of the key challenges of continual learning is to\navoid catastrophic forgetting (CF), i.e., forgetting old tasks in the presence\nof more recent tasks. Over the past few years, many methods and tricks have\nbeen introduced to address this problem, but many have not been fairly and\nsystematically compared under a variety of realistic and practical settings. To\nbetter understand the relative advantages of various approaches and the\nsettings where they work best, this survey aims to (1) compare state-of-the-art\nmethods such as MIR, iCARL, and GDumb and determine which works best at\ndifferent experimental settings; (2) determine if the best class incremental\nmethods are also competitive in domain incremental setting; (3) evaluate the\nperformance of 7 simple but effective trick such as \"review\" trick and nearest\nclass mean (NCM) classifier to assess their relative impact. Regarding (1), we\nobserve iCaRL remains competitive when the memory buffer is small; GDumb\noutperforms many recently proposed methods in medium-size datasets and MIR\nperforms the best in larger-scale datasets. For (2), we note that GDumb\nperforms quite poorly while MIR -- already competitive for (1) -- is also\nstrongly competitive in this very different but important setting. Overall,\nthis allows us to conclude that MIR is overall a strong and versatile method\nacross a wide variety of settings. For (3), we find that all 7 tricks are\nbeneficial, and when augmented with the \"review\" trick and NCM classifier, MIR\nproduces performance levels that bring online continual learning much closer to\nits ultimate goal of matching offline training.",
          "link": "http://arxiv.org/abs/2101.10423",
          "publishedOn": "2021-06-03T02:10:37.707Z",
          "wordCount": 763,
          "title": "Online Continual Learning in Image Classification: An Empirical Survey. (arXiv:2101.10423v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.14963",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wolflein_G/0/1/0/all/0/1\">Georg W&#xf6;lflein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arandjelovic_O/0/1/0/all/0/1\">Ognjen Arandjelovi&#x107;</a>",
          "description": "Identifying the configuration of chess pieces from an image of a chessboard\nis a problem in computer vision that has not yet been solved accurately.\nHowever, it is important for helping amateur chess players improve their games\nby facilitating automatic computer analysis without the overhead of manually\nentering the pieces. Current approaches are limited by the lack of large\ndatasets and are not designed to adapt to unseen chess sets. This paper puts\nforth a new dataset synthesised from a 3D model that is an order of magnitude\nlarger than existing ones. Trained on this dataset, a novel end-to-end chess\nrecognition system is presented that combines traditional computer vision\ntechniques with deep learning. It localises the chessboard using a RANSAC-based\nalgorithm that computes a projective transformation of the board onto a regular\ngrid. Using two convolutional neural networks, it then predicts an occupancy\nmask for the squares in the warped image and finally classifies the pieces. The\ndescribed system achieves an error rate of 0.23% per square on the test set, 28\ntimes better than the current state of the art. Further, a few-shot transfer\nlearning approach is developed that is able to adapt the inference system to a\npreviously unseen chess set using just two photos of the starting position,\nobtaining a per-square accuracy of 99.83% on images of that new chess set. The\ncode, dataset, and trained models are made available online.",
          "link": "http://arxiv.org/abs/2104.14963",
          "publishedOn": "2021-06-03T02:10:37.703Z",
          "wordCount": 700,
          "title": "Determining Chess Game State From an Image. (arXiv:2104.14963v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01309",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Liang_Q/0/1/0/all/0/1\">Qiaohao Liang</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Gongora_A/0/1/0/all/0/1\">Aldair E. Gongora</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Ren_Z/0/1/0/all/0/1\">Zekun Ren</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Tiihonen_A/0/1/0/all/0/1\">Armi Tiihonen</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Liu_Z/0/1/0/all/0/1\">Zhe Liu</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Sun_S/0/1/0/all/0/1\">Shijing Sun</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Deneault_J/0/1/0/all/0/1\">James R. Deneault</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Bash_D/0/1/0/all/0/1\">Daniil Bash</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Mekki_Berrada_F/0/1/0/all/0/1\">Flore Mekki-Berrada</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Khan_S/0/1/0/all/0/1\">Saif A. Khan</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Hippalgaonkar_K/0/1/0/all/0/1\">Kedar Hippalgaonkar</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Maruyama_B/0/1/0/all/0/1\">Benji Maruyama</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Brown_K/0/1/0/all/0/1\">Keith A. Brown</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Fisher_J/0/1/0/all/0/1\">John Fisher III</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Buonassisi_T/0/1/0/all/0/1\">Tonio Buonassisi</a>",
          "description": "In the field of machine learning (ML) for materials optimization, active\nlearning algorithms, such as Bayesian Optimization (BO), have been leveraged\nfor guiding autonomous and high-throughput experimentation systems. However,\nvery few studies have evaluated the efficiency of BO as a general optimization\nalgorithm across a broad range of experimental materials science domains. In\nthis work, we evaluate the performance of BO algorithms with a collection of\nsurrogate model and acquisition function pairs across five diverse experimental\nmaterials systems, namely carbon nanotube polymer blends, silver nanoparticles,\nlead-halide perovskites, as well as additively manufactured polymer structures\nand shapes. By defining acceleration and enhancement metrics for general\nmaterials optimization objectives, we find that for surrogate model selection,\nGaussian Process (GP) with anisotropic kernels (automatic relevance detection,\nARD) and Random Forests (RF) have comparable performance and both outperform\nthe commonly used GP without ARD. We discuss the implicit distributional\nassumptions of RF and GP, and the benefits of using GP with anisotropic kernels\nin detail. We provide practical insights for experimentalists on surrogate\nmodel selection of BO during materials optimization campaigns.",
          "link": "http://arxiv.org/abs/2106.01309",
          "publishedOn": "2021-06-03T02:10:37.698Z",
          "wordCount": 651,
          "title": "Benchmarking the Performance of Bayesian Optimization across Multiple Experimental Materials Science Domains. (arXiv:2106.01309v1 [cond-mat.mtrl-sci])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01277",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gutierrez_P/0/1/0/all/0/1\">Pierre Gutierrez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cordier_A/0/1/0/all/0/1\">Antoine Cordier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caldeira_T/0/1/0/all/0/1\">Tha&#xef;s Caldeira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sautory_T/0/1/0/all/0/1\">Th&#xe9;ophile Sautory</a>",
          "description": "The use of deep features coming from pre-trained neural networks for\nunsupervised anomaly detection purposes has recently gathered momentum in the\ncomputer vision field. In particular, industrial inspection applications can\ntake advantage of such features, as demonstrated by the multiple successes of\nrelated methods on the MVTec Anomaly Detection (MVTec AD) dataset. These\nmethods make use of neural networks pre-trained on auxiliary classification\ntasks such as ImageNet. However, to our knowledge, no comparative study of\nrobustness to the low data regimes between these approaches has been conducted\nyet. For quality inspection applications, the handling of limited sample sizes\nmay be crucial as large quantities of images are not available for small\nseries. In this work, we aim to compare three approaches based on deep\npre-trained features when varying the quantity of available data in MVTec AD:\nKNN, Mahalanobis, and PaDiM. We show that although these methods are mostly\nrobust to small sample sizes, they still can benefit greatly from using data\naugmentation in the original image space, which allows to deal with very small\nproduction runs.",
          "link": "http://arxiv.org/abs/2106.01277",
          "publishedOn": "2021-06-03T02:10:37.692Z",
          "wordCount": 651,
          "title": "Data augmentation and pre-trained networks for extremely low data regimes unsupervised visual inspection. (arXiv:2106.01277v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.02504",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Meunier_D/0/1/0/all/0/1\">Dimitri Meunier</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Alquier_P/0/1/0/all/0/1\">Pierre Alquier</a>",
          "description": "Online gradient methods, like the online gradient algorithm (OGA), often\ndepend on tuning parameters that are difficult to set in practice. We consider\nan online meta-learning scenario, and we propose a meta-strategy to learn these\nparameters from past tasks. Our strategy is based on the minimization of a\nregret bound. It allows to learn the initialization and the step size in OGA\nwith guarantees. We provide a regret analysis of the strategy in the case of\nconvex losses. It suggests that, when there are parameters\n$\\theta_1,\\dots,\\theta_T$ solving well tasks $1,\\dots,T$ respectively and that\nare close enough one to each other, our strategy indeed improves on learning\neach task in isolation.",
          "link": "http://arxiv.org/abs/2102.02504",
          "publishedOn": "2021-06-03T02:10:37.677Z",
          "wordCount": 558,
          "title": "Meta-strategy for Learning Tuning Parameters with Guarantees. (arXiv:2102.02504v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01242",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nagar_A/0/1/0/all/0/1\">Anudit Nagar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_C/0/1/0/all/0/1\">Cuong Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fioretto_F/0/1/0/all/0/1\">Ferdinando Fioretto</a>",
          "description": "Distributed multi-agent learning enables agents to cooperatively train a\nmodel without requiring to share their datasets. While this setting ensures\nsome level of privacy, it has been shown that, even when data is not directly\nshared, the training process is vulnerable to privacy attacks including data\nreconstruction and model inversion attacks. Additionally, malicious agents that\ntrain on inverted labels or random data, may arbitrarily weaken the accuracy of\nthe global model. This paper addresses these challenges and presents\nPrivacy-preserving and trustable Distributed Learning (PT-DL), a fully\ndecentralized framework that relies on Differential Privacy to guarantee strong\nprivacy protections of the agents' data, and Ethereum smart contracts to ensure\ntrustability. The paper shows that PT-DL is resilient up to a 50% collusion\nattack, with high probability, in a malicious trust model and the experimental\nevaluation illustrates the benefits of the proposed model as a\nprivacy-preserving and trustable distributed multi-agent learning system on\nseveral classification tasks.",
          "link": "http://arxiv.org/abs/2106.01242",
          "publishedOn": "2021-06-03T02:10:37.672Z",
          "wordCount": 593,
          "title": "A Privacy-Preserving and Trustable Multi-agent Learning Framework. (arXiv:2106.01242v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2004.09317",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jong_D/0/1/0/all/0/1\">D. B. de Jong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paredes_Valles_F/0/1/0/all/0/1\">F. Paredes-Vall&#xe9;s</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Croon_G/0/1/0/all/0/1\">G. C. H. E. de Croon</a>",
          "description": "End-to-end trained convolutional neural networks have led to a breakthrough\nin optical flow estimation. The most recent advances focus on improving the\noptical flow estimation by improving the architecture and setting a new\nbenchmark on the publicly available MPI-Sintel dataset. Instead, in this\narticle, we investigate how deep neural networks estimate optical flow. A\nbetter understanding of how these networks function is important for (i)\nassessing their generalization capabilities to unseen inputs, and (ii)\nsuggesting changes to improve their performance. For our investigation, we\nfocus on FlowNetS, as it is the prototype of an encoder-decoder neural network\nfor optical flow estimation. Furthermore, we use a filter identification method\nthat has played a major role in uncovering the motion filters present in animal\nbrains in neuropsychological research. The method shows that the filters in the\ndeepest layer of FlowNetS are sensitive to a variety of motion patterns. Not\nonly do we find translation filters, as demonstrated in animal brains, but\nthanks to the easier measurements in artificial neural networks, we even unveil\ndilation, rotation, and occlusion filters. Furthermore, we find similarities in\nthe refinement part of the network and the perceptual filling-in process which\noccurs in the mammal primary visual cortex.",
          "link": "http://arxiv.org/abs/2004.09317",
          "publishedOn": "2021-06-03T02:10:37.667Z",
          "wordCount": 698,
          "title": "How Do Neural Networks Estimate Optical Flow? A Neuropsychology-Inspired Study. (arXiv:2004.09317v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00772",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khodadadian_S/0/1/0/all/0/1\">Sajad Khodadadian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nafea_M/0/1/0/all/0/1\">Mohamed Nafea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghassami_A/0/1/0/all/0/1\">AmirEmad Ghassami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiyavash_N/0/1/0/all/0/1\">Negar Kiyavash</a>",
          "description": "Machine earning algorithms are increasingly used for consequential decision\nmaking regarding individuals based on their relevant features. Features that\nare relevant for accurate decisions may however lead to either explicit or\nimplicit forms of discrimination against unprivileged groups, such as those of\ncertain race or gender. This happens due to existing biases in the training\ndata, which are often replicated or even exacerbated by the learning algorithm.\nIdentifying and measuring these biases at the data level is a challenging\nproblem due to the interdependence among the features, and the decision\noutcome. In this work, we develop a framework for fairness-aware feature\nselection, based on information theoretic measures for the accuracy and\ndiscriminatory impacts of features. Specifically, our goal is to design a\nfairness utility score for each feature which quantifies how this feature\ninfluences accurate as well as nondiscriminatory decisions. We first propose\ninformation theoretic measures for the impact of different subsets of features\non the accuracy and discrimination of the model. Subsequently, we deduce the\nmarginal impact of each feature using Shapley value function. Our framework\ndepends on the joint statistics of the data rather than a particular classifier\ndesign. We examine our proposed framework on real and synthetic data to\nevaluate its performance.",
          "link": "http://arxiv.org/abs/2106.00772",
          "publishedOn": "2021-06-03T02:10:37.661Z",
          "wordCount": 642,
          "title": "Information Theoretic Measures for Fairness-aware Feature Selection. (arXiv:2106.00772v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00927",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Wang_X/0/1/0/all/0/1\">Xufei Wang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Xu_Y/0/1/0/all/0/1\">Yuanda Xu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zheng_H/0/1/0/all/0/1\">Han Zheng</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Yu_K/0/1/0/all/0/1\">Kuang Yu</a>",
          "description": "An accurate force field is the key to the success of all molecular mechanics\nsimulations on organic polymers and biomolecules. Accuracy beyond density\nfunctional theory is often needed to describe the intermolecular interactions,\nwhile most correlated wavefunction (CW) methods are prohibitively expensive for\nlarge molecules. Therefore, it posts a great challenge to develop an extendible\nab initio force field for large flexible organic molecules at CW level of\naccuracy. In this work, we face this challenge by combining the physics-driven\nnonbonding potential with a data-driven subgraph neural network bonding model\n(named sGNN). Tests on polyethylene glycol polymer chains show that our\nstrategy is highly accurate and robust for molecules of different sizes.\nTherefore, we can develop the force field from small molecular fragments (with\nsizes easily accessible to CW methods) and safely transfer it to large\npolymers, thus opening a new path to the next-generation organic force fields.",
          "link": "http://arxiv.org/abs/2106.00927",
          "publishedOn": "2021-06-03T02:10:37.632Z",
          "wordCount": 603,
          "title": "An Extendible, Graph-Neural-Network-Based Approach for Accurate Force Field Development of Large Flexible Organic Molecules. (arXiv:2106.00927v1 [physics.chem-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01078",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yingtao Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qiang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuntian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Wenbo Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun Zhu</a>",
          "description": "Partial differential equations (PDEs) fitting scientific data can represent\nphysical laws with explainable mechanisms for various mathematically-oriented\nsubjects. Most natural dynamics are expressed by PDEs with varying coefficients\n(PDEs-VC), which highlights the importance of PDE discovery. Previous\nalgorithms can discover some simple instances of PDEs-VC but fail in the\ndiscovery of PDEs with coefficients of higher complexity, as a result of\ncoefficient estimation inaccuracy. In this paper, we propose KO-PDE, a kernel\noptimized regression method that incorporates the kernel density estimation of\nadjacent coefficients to reduce the coefficient estimation error. KO-PDE can\ndiscover PDEs-VC on which previous baselines fail and is more robust against\ninevitable noise in data. In experiments, the PDEs-VC of seven challenging\nspatiotemporal scientific datasets in fluid dynamics are all discovered by\nKO-PDE, while the three baselines render false results in most cases. With\nstate-of-the-art performance, KO-PDE sheds light on the automatic description\nof natural phenomenons using discovered PDEs in the real world.",
          "link": "http://arxiv.org/abs/2106.01078",
          "publishedOn": "2021-06-03T02:10:37.444Z",
          "wordCount": 597,
          "title": "KO-PDE: Kernel Optimized Discovery of Partial Differential Equations with Varying Coefficients. (arXiv:2106.01078v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.08050",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hanxiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Z/0/1/0/all/0/1\">Zihang Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+So_D/0/1/0/all/0/1\">David R. So</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1\">Quoc V. Le</a>",
          "description": "Transformers have become one of the most important architectural innovations\nin deep learning and have enabled many breakthroughs over the past few years.\nHere we propose a simple network architecture, gMLP, based on MLPs with gating,\nand show that it can perform as well as Transformers in key language and vision\napplications. Our comparisons show that self-attention is not critical for\nVision Transformers, as gMLP can achieve the same accuracy. For BERT, our model\nachieves parity with Transformers on pretraining perplexity and is better on\nsome downstream NLP tasks. On finetuning tasks where gMLP performs worse,\nmaking the gMLP model substantially larger can close the gap with Transformers.\nIn general, our experiments show that gMLP can scale as well as Transformers\nover increased data and compute.",
          "link": "http://arxiv.org/abs/2105.08050",
          "publishedOn": "2021-06-03T02:10:37.421Z",
          "wordCount": 587,
          "title": "Pay Attention to MLPs. (arXiv:2105.08050v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00884",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Armandpour_M/0/1/0/all/0/1\">Mohammadreza Armandpour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kidd_B/0/1/0/all/0/1\">Brian Kidd</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yu Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jianhua Z. Huang</a>",
          "description": "In this paper, we study the problem of blood glucose forecasting and provide\na deep personalized solution. Predicting blood glucose level in people with\ndiabetes has significant value because health complications of abnormal glucose\nlevel are serious, sometimes even leading to death. Therefore, having a model\nthat can accurately and quickly warn patients of potential problems is\nessential. To develop a better deep model for blood glucose forecasting, we\nanalyze the data and detect important patterns. These observations helped us to\npropose a method that has several key advantages over existing methods: 1- it\nlearns a personalized model for each patient as well as a global model; 2- it\nuses an attention mechanism and extracted time features to better learn\nlong-term dependencies in the data; 3- it introduces a new, robust training\nprocedure for time series data. We empirically show the efficacy of our model\non a real dataset.",
          "link": "http://arxiv.org/abs/2106.00884",
          "publishedOn": "2021-06-03T02:10:37.410Z",
          "wordCount": 590,
          "title": "Deep Personalized Glucose Level Forecasting Using Attention-based Recurrent Neural Networks. (arXiv:2106.00884v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2003.07132",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Yang_Z/0/1/0/all/0/1\">Zebin Yang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_A/0/1/0/all/0/1\">Aijun Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sudjianto_A/0/1/0/all/0/1\">Agus Sudjianto</a>",
          "description": "The lack of interpretability is an inevitable problem when using neural\nnetwork models in real applications. In this paper, an explainable neural\nnetwork based on generalized additive models with structured interactions\n(GAMI-Net) is proposed to pursue a good balance between prediction accuracy and\nmodel interpretability. GAMI-Net is a disentangled feedforward network with\nmultiple additive subnetworks; each subnetwork consists of multiple hidden\nlayers and is designed for capturing one main effect or one pairwise\ninteraction. Three interpretability aspects are further considered, including\na) sparsity, to select the most significant effects for parsimonious\nrepresentations; b) heredity, a pairwise interaction could only be included\nwhen at least one of its parent main effects exists; and c) marginal clarity,\nto make main effects and pairwise interactions mutually distinguishable. An\nadaptive training algorithm is developed, where main effects are first trained\nand then pairwise interactions are fitted to the residuals. Numerical\nexperiments on both synthetic functions and real-world datasets show that the\nproposed model enjoys superior interpretability and it maintains competitive\nprediction accuracy in comparison to the explainable boosting machine and other\nclassic machine learning models.",
          "link": "http://arxiv.org/abs/2003.07132",
          "publishedOn": "2021-06-03T02:10:37.395Z",
          "wordCount": 637,
          "title": "GAMI-Net: An Explainable Neural Network based on Generalized Additive Models with Structured Interactions. (arXiv:2003.07132v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14201",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Q/0/1/0/all/0/1\">Qianren Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1\">Hao Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hongdong Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianxin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zheng Wang</a>",
          "description": "By producing summaries for long-running events, timeline summarization (TLS)\nunderpins many information retrieval tasks. Successful TLS requires identifying\nan appropriate set of key dates (the timeline length) to cover. However, doing\nso is challenging as the right length can change from one topic to another.\nExisting TLS solutions either rely on an event-agnostic fixed length or an\nexpert-supplied setting. Neither of the strategies is desired for real-life TLS\nscenarios. A fixed, event-agnostic setting ignores the diversity of events and\ntheir development and hence can lead to low-quality TLS. Relying on\nexpert-crafted settings is neither scalable nor sustainable for processing many\ndynamically changing events. This paper presents a better TLS approach for\nautomatically and dynamically determining the TLS timeline length. We achieve\nthis by employing the established elbow method from the machine learning\ncommunity to automatically find the minimum number of dates within the time\nseries to generate concise and informative summaries. We applied our approach\nto four TLS datasets of English and Chinese and compared them against three\nprior methods. Experimental results show that our approach delivers comparable\nor even better summaries over state-of-art TLS methods, but it achieves this\nwithout expert involvement.",
          "link": "http://arxiv.org/abs/2105.14201",
          "publishedOn": "2021-06-03T02:10:37.354Z",
          "wordCount": 629,
          "title": "Automated Timeline Length Selection for Flexible Timeline Summarization. (arXiv:2105.14201v1 [cs.AI] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00753",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ramzi_Z/0/1/0/all/0/1\">Zaccharie Ramzi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vignaud_A/0/1/0/all/0/1\">Alexandre Vignaud</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Starck_J/0/1/0/all/0/1\">Jean-Luc Starck</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ciuciu_P/0/1/0/all/0/1\">Philippe Ciuciu</a>",
          "description": "We perform a qualitative analysis of performance of XPDNet, a\nstate-of-the-art deep learning approach for MRI reconstruction, compared to\nGRAPPA, a classical approach. We do this in multiple settings, in particular\ntesting the robustness of the XPDNet to unseen settings, and show that the\nXPDNet can to some degree generalize well.",
          "link": "http://arxiv.org/abs/2106.00753",
          "publishedOn": "2021-06-03T02:10:37.347Z",
          "wordCount": 490,
          "title": "Is good old GRAPPA dead?. (arXiv:2106.00753v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2012.00517",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Korpihalkola_J/0/1/0/all/0/1\">Joni Korpihalkola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sipola_T/0/1/0/all/0/1\">Tuomo Sipola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Puuska_S/0/1/0/all/0/1\">Samir Puuska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kokkonen_T/0/1/0/all/0/1\">Tero Kokkonen</a>",
          "description": "Computer vision and machine learning can be used to automate various tasks in\ncancer diagnostic and detection. If an attacker can manipulate the automated\nprocessing, the results can be devastating and in the worst case lead to wrong\ndiagnosis and treatment. In this research, the goal is to demonstrate the use\nof one-pixel attacks in a real-life scenario with a real pathology dataset,\nTUPAC16, which consists of digitized whole-slide images. We attack against the\nIBM CODAIT's MAX breast cancer detector using adversarial images. These\nadversarial examples are found using differential evolution to perform the\none-pixel modification to the images in the dataset. The results indicate that\na minor one-pixel modification of a whole slide image under analysis can affect\nthe diagnosis by reversing the automatic diagnosis result. The attack poses a\nthreat from the cyber security perspective: the one-pixel method can be used as\nan attack vector by a motivated attacker.",
          "link": "http://arxiv.org/abs/2012.00517",
          "publishedOn": "2021-06-03T02:10:37.340Z",
          "wordCount": 623,
          "title": "One-Pixel Attack Deceives Computer-Assisted Diagnosis of Cancer. (arXiv:2012.00517v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11075",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Eriksson_H/0/1/0/all/0/1\">Hannes Eriksson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basu_D/0/1/0/all/0/1\">Debabrota Basu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alibeigi_M/0/1/0/all/0/1\">Mina Alibeigi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dimitrakakis_C/0/1/0/all/0/1\">Christos Dimitrakakis</a>",
          "description": "In this paper, we consider risk-sensitive sequential decision-making in\nmodel-based Reinforcement Learning (RL). Our contributions are two-fold. First,\nwe introduce a novel and coherent quantification of risk, namely composite\nrisk, which quantifies joint effect of aleatory and epistemic risk during the\nlearning process. Existing works considered either aleatory or epistemic risk\nindividually, or an additive combination of the two. We prove that the additive\nformulation is a particular case of the composite risk when the epistemic risk\nmeasure is replaced with expectation. Thus, the composite risk provides an\nestimate more sensitive to both aleatory and epistemic sources of uncertainties\nthan the individual and additive formulations. Following that, we propose to\nuse a bootstrapping method, SENTINEL-K, for performing distributional RL.\nSENTINEL-K uses an ensemble of $K$ learners to estimate the return\ndistribution. We use the Follow The Regularised Leader (FTRL) to aggregate the\nreturn distributions of $K$ learners and to estimate the composite risk. We\nexperimentally verify that SENTINEL-K estimates the return distribution better,\nand while used with composite risk estimate, demonstrates better risk-sensitive\nperformance than state-of-the-art risk-sensitive and distributional RL\nalgorithms.",
          "link": "http://arxiv.org/abs/2102.11075",
          "publishedOn": "2021-06-03T02:10:37.330Z",
          "wordCount": 640,
          "title": "SENTINEL: Taming Uncertainty with Ensemble-based Distributional Reinforcement Learning. (arXiv:2102.11075v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00734",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Martin_C/0/1/0/all/0/1\">Charles H. Martin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahoney_M/0/1/0/all/0/1\">Michael W. Mahoney</a>",
          "description": "To understand better the causes of good generalization performance in\nstate-of-the-art neural network (NN) models, we analyze of a corpus of models\nthat was made publicly-available for a contest to predict the generalization\naccuracy of NNs. These models include a wide range of qualities and were\ntrained with a range of architectures and regularization hyperparameters. We\nidentify what amounts to a Simpson's paradox: where \"scale\" metrics (from\ntraditional statistical learning theory) perform well overall but perform\npoorly on subpartitions of the data of a given depth, when regularization\nhyperparameters are varied; and where \"shape\" metrics (from Heavy-Tailed Self\nRegularization theory) perform well on subpartitions of the data, when\nhyperparameters are varied for models of a given depth, but perform poorly\noverall when models with varying depths are aggregated. Our results highlight\nthe subtly of comparing models when both architectures and hyperparameters are\nvaried, as well as the complementary role of implicit scale versus implicit\nshape parameters in understanding NN model quality. Our results also suggest\ncaution when one tries to extract causal insight with a single metric applied\nto aggregate data, and they highlight the need to go beyond one-size-fits-all\nmetrics based on upper bounds from generalization theory to describe the\nperformance of state-of-the-art NN models. Based on these findings, we present\ntwo novel shape metrics, one data-independent, and the other data-dependent,\nwhich can predict trends in the test accuracy of a series of NNs, of a fixed\narchitecture/depth, when varying solver hyperparameters.",
          "link": "http://arxiv.org/abs/2106.00734",
          "publishedOn": "2021-06-03T02:10:37.315Z",
          "wordCount": 699,
          "title": "Post-mortem on a deep learning contest: a Simpson's paradox and the complementary roles of scale metrics versus shape metrics. (arXiv:2106.00734v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2104.14937",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1\">Xiaoliang Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1\">Jianzhong Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_C/0/1/0/all/0/1\">Chenglu Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Cheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1\">Rongshan Yu</a>",
          "description": "Fairness has emerged as a critical problem in federated learning (FL). In\nthis work, we identify a cause of unfairness in FL -- \\emph{conflicting}\ngradients with large differences in the magnitudes. To address this issue, we\npropose the federated fair averaging (FedFV) algorithm to mitigate potential\nconflicts among clients before averaging their gradients. We first use the\ncosine similarity to detect gradient conflicts, and then iteratively eliminate\nsuch conflicts by modifying both the direction and the magnitude of the\ngradients. We further show the theoretical foundation of FedFV to mitigate the\nissue conflicting gradients and converge to Pareto stationary solutions.\nExtensive experiments on a suite of federated datasets confirm that FedFV\ncompares favorably against state-of-the-art methods in terms of fairness,\naccuracy and efficiency.",
          "link": "http://arxiv.org/abs/2104.14937",
          "publishedOn": "2021-06-03T02:10:37.293Z",
          "wordCount": 588,
          "title": "Federated Learning with Fair Averaging. (arXiv:2104.14937v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00787",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_P/0/1/0/all/0/1\">Piyush K. Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raglin_A/0/1/0/all/0/1\">Adrienne Raglin</a>",
          "description": "The military is investigating methods to improve communication and agility in\nits multi-domain operations (MDO). Nascent popularity of Internet of Things\n(IoT) has gained traction in public and government domains. Its usage in MDO\nmay revolutionize future battlefields and may enable strategic advantage. While\nthis technology offers leverage to military capabilities, it comes with\nchallenges where one is the uncertainty and associated risk. A key question is\nhow can these uncertainties be addressed. Recently published studies proposed\ninformation camouflage to transform information from one data domain to\nanother. As this is comparatively a new approach, we investigate challenges of\nsuch transformations and how these associated uncertainties can be detected and\naddressed, specifically unknown-unknowns to improve decision-making.",
          "link": "http://arxiv.org/abs/2106.00787",
          "publishedOn": "2021-06-03T02:10:37.288Z",
          "wordCount": 565,
          "title": "Image-Audio Encoding to Improve C2 Decision-Making in Multi-Domain Environment. (arXiv:2106.00787v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.01948",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dadashi_R/0/1/0/all/0/1\">Robert Dadashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rezaeifar_S/0/1/0/all/0/1\">Shideh Rezaeifar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vieillard_N/0/1/0/all/0/1\">Nino Vieillard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hussenot_L/0/1/0/all/0/1\">L&#xe9;onard Hussenot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pietquin_O/0/1/0/all/0/1\">Olivier Pietquin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geist_M/0/1/0/all/0/1\">Matthieu Geist</a>",
          "description": "Offline Reinforcement Learning methods seek to learn a policy from logged\ntransitions of an environment, without any interaction. In the presence of\nfunction approximation, and under the assumption of limited coverage of the\nstate-action space of the environment, it is necessary to enforce the policy to\nvisit state-action pairs close to the support of logged transitions. In this\nwork, we propose an iterative procedure to learn a pseudometric (closely\nrelated to bisimulation metrics) from logged transitions, and use it to define\nthis notion of closeness. We show its convergence and extend it to the function\napproximation setting. We then use this pseudometric to define a new lookup\nbased bonus in an actor-critic algorithm: PLOFF. This bonus encourages the\nactor to stay close, in terms of the defined pseudometric, to the support of\nlogged transitions. Finally, we evaluate the method on hand manipulation and\nlocomotion tasks.",
          "link": "http://arxiv.org/abs/2103.01948",
          "publishedOn": "2021-06-03T02:10:37.227Z",
          "wordCount": 603,
          "title": "Offline Reinforcement Learning with Pseudometric Learning. (arXiv:2103.01948v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.08736",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_Q/0/1/0/all/0/1\">Qi Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Youzhi Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1\">Shuiwang Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1\">Tianbao Yang</a>",
          "description": "Areas under ROC (AUROC) and precision-recall curves (AUPRC) are common\nmetrics for evaluating classification performance for imbalanced problems.\nCompared with AUROC, AUPRC is a more appropriate metric for highly imbalanced\ndatasets. While stochastic optimization of AUROC has been studied extensively,\nprincipled stochastic optimization of AUPRC has been rarely explored. In this\nwork, we propose a principled technical method to optimize AUPRC for deep\nlearning. Our approach is based on maximizing the averaged precision (AP),\nwhich is an unbiased point estimator of AUPRC. We cast the objective into a sum\nof {\\it dependent compositional functions} with inner functions dependent on\nrandom variables of the outer level. We propose efficient adaptive and\nnon-adaptive stochastic algorithms with {\\it provable convergence guarantee\nunder mild conditions} by leveraging recent advances in stochastic\ncompositional optimization. Extensive experimental results on image and graph\ndatasets demonstrate that our proposed method outperforms prior methods on\nimbalanced problems in terms of AUPRC. To the best of our knowledge, our work\nrepresents the first attempt to optimize AUPRC with provable convergence.",
          "link": "http://arxiv.org/abs/2104.08736",
          "publishedOn": "2021-06-03T02:10:37.193Z",
          "wordCount": 651,
          "title": "Stochastic Optimization of Areas Under Precision-Recall Curves with Provable Convergence. (arXiv:2104.08736v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.00113",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mirsky_Y/0/1/0/all/0/1\">Yisroel Mirsky</a>",
          "description": "Applications such as autonomous vehicles and medical screening use deep\nlearning models to localize and identify hundreds of objects in a single frame.\nIn the past, it has been shown how an attacker can fool these models by placing\nan adversarial patch within a scene. However, these patches must be placed in\nthe target location and do not explicitly alter the semantics elsewhere in the\nimage.\n\nIn this paper, we introduce a new type of adversarial patch which alters a\nmodel's perception of an image's semantics. These patches can be placed\nanywhere within an image to change the classification or semantics of locations\nfar from the patch. We call this new class of adversarial examples `remote\nadversarial patches' (RAP).\n\nWe implement our own RAP called IPatch and perform an in-depth analysis on\nimage segmentation RAP attacks using five state-of-the-art architectures with\neight different encoders on the CamVid street view dataset. Moreover, we\ndemonstrate that the attack can be extended to object recognition models with\npreliminary results on the popular YOLOv3 model. We found that the patch can\nchange the classification of a remote target region with a success rate of up\nto 93% on average.",
          "link": "http://arxiv.org/abs/2105.00113",
          "publishedOn": "2021-06-03T02:10:37.165Z",
          "wordCount": 652,
          "title": "IPatch: A Remote Adversarial Patch. (arXiv:2105.00113v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.08609",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jinhai Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hua Yang</a>",
          "description": "Crowd segmentation is a fundamental task serving as the basis of crowded\nscene analysis, and it is highly desirable to obtain refined pixel-level\nsegmentation maps. However, it remains a challenging problem, as existing\napproaches either require dense pixel-level annotations to train deep learning\nmodels or merely produce rough segmentation maps from optical or particle flows\nwith physical models. In this paper, we propose the Motion Prior-Aware Siamese\nNetwork (MPASNET) for unsupervised crowd semantic segmentation. This model not\nonly eliminates the need for annotation but also yields high-quality\nsegmentation maps. Specially, we first analyze the coherent motion patterns\nacross the frames and then apply a circular region merging strategy on the\ncollective particles to generate pseudo-labels. Moreover, we equip MPASNET with\nsiamese branches for augmentation-invariant regularization and siamese feature\naggregation. Experiments over benchmark datasets indicate that our model\noutperforms the state-of-the-arts by more than 12% in terms of mIoU.",
          "link": "http://arxiv.org/abs/2101.08609",
          "publishedOn": "2021-06-03T02:10:37.070Z",
          "wordCount": 619,
          "title": "MPASNET: Motion Prior-Aware Siamese Network for Unsupervised Deep Crowd Segmentation in Video Scenes. (arXiv:2101.08609v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.08658",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mendelevitch_O/0/1/0/all/0/1\">Ofer Mendelevitch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lesh_M/0/1/0/all/0/1\">Michael D. Lesh</a>",
          "description": "The digitization of medical records ushered in a new era of big data to\nclinical science, and with it the possibility that data could be shared, to\nmultiply insights beyond what investigators could abstract from paper records.\nThe need to share individual-level medical data to accelerate innovation in\nprecision medicine continues to grow, and has never been more urgent, as\nscientists grapple with the COVID-19 pandemic. However, enthusiasm for the use\nof big data has been tempered by a fully appropriate concern for patient\nautonomy and privacy. That is, the ability to extract private or confidential\ninformation about an individual, in practice, renders it difficult to share\ndata, since significant infrastructure and data governance must be established\nbefore data can be shared. Although HIPAA provided de-identification as an\napproved mechanism for data sharing, linkage attacks were identified as a major\nvulnerability. A variety of mechanisms have been established to avoid leaking\nprivate information, such as field suppression or abstraction, strictly\nlimiting the amount of information that can be shared, or employing\nmathematical techniques such as differential privacy. Another approach, which\nwe focus on here, is creating synthetic data that mimics the underlying data.\nFor synthetic data to be a useful mechanism in support of medical innovation\nand a proxy for real-world evidence, one must demonstrate two properties of the\nsynthetic dataset: (1) any analysis on the real data must be matched by\nanalysis of the synthetic data (statistical fidelity) and (2) the synthetic\ndata must preserve privacy, with minimal risk of re-identification (privacy\nguarantee). In this paper we propose a framework for quantifying the\nstatistical fidelity and privacy preservation properties of synthetic datasets\nand demonstrate these metrics for synthetic data generated by Syntegra\ntechnology.",
          "link": "http://arxiv.org/abs/2101.08658",
          "publishedOn": "2021-06-03T02:10:37.054Z",
          "wordCount": 779,
          "title": "Fidelity and Privacy of Synthetic Medical Data. (arXiv:2101.08658v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.05571",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1\">Byunggu Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Junwhan Kim</a>",
          "description": "In order to detect unknown intrusions and runtime errors of computer\nprograms, the cyber-security community has developed various detection\ntechniques. Anomaly detection is an approach that is designed to profile the\nnormal runtime behavior of computer programs in order to detect intrusions and\nerrors as anomalous deviations from the observed normal. However, normal but\nunobserved behavior can trigger false positives. This limitation has\nsignificantly decreased the practical viability of anomaly detection\ntechniques. Reported approaches to this limitation span a simple alert\nthreshold definition to distribution models for approximating all normal\nbehavior based on the limited observation. However, each assumption or\napproximation poses the potential for even greater false positive rates. This\npaper presents our study on how to explain the presence of anomalies using a\nneural network, particularly Long Short-Term Memory, independent of actual data\ndistributions. We present and compare three anomaly detection models, and\nreport on our experience running different types of attacks on an Apache\nHypertext Transfer Protocol server. We performed a comparative study, focusing\non each model's ability to detect the onset of each attack while avoiding false\npositives resulting from unknown normal behavior. Our best-performing model\ndetected the true onset of every attack with zero false positives.",
          "link": "http://arxiv.org/abs/2104.05571",
          "publishedOn": "2021-06-03T02:10:37.026Z",
          "wordCount": 677,
          "title": "Using a Neural Network to Detect Anomalies given an N-gram Profile. (arXiv:2104.05571v2 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.13177",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yixin Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1\">Austin S. Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rai_A/0/1/0/all/0/1\">Akshara Rai</a>",
          "description": "Many manipulation tasks can be naturally cast as a sequence of spatial\nrelationships and constraints between objects. We aim to discover and scale\nthese task-specific spatial relationships by representing manipulation tasks as\noperations over graphs. To do this, we pose manipulating a large, variable\nnumber of objects as a probabilistic classification problem over actions,\nobjects and goals, learned using graph neural networks (GNNs). Our formulation\nfirst transforms the environment into a graph representation, then applies a\ntrained GNN policy to predict which object to manipulate towards which goal\nstate. Our GNN policies are trained using very few expert demonstrations on\nsimple tasks, and exhibit generalization over number and configurations of\nobjects in the environment and even to new, more complex tasks, while providing\ninterpretable explanations for their decision-making. We present experiments\nwhich show that a single learned GNN policy can solve a variety of long-horizon\nblockstacking and rearrangement tasks.",
          "link": "http://arxiv.org/abs/2102.13177",
          "publishedOn": "2021-06-03T02:10:36.953Z",
          "wordCount": 603,
          "title": "Efficient and Interpretable Robot Manipulation with Graph Neural Networks. (arXiv:2102.13177v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.06390",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tuna_O/0/1/0/all/0/1\">Omer Faruk Tuna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Catak_F/0/1/0/all/0/1\">Ferhat Ozgur Catak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eskil_M/0/1/0/all/0/1\">M. Taner Eskil</a>",
          "description": "While state-of-the-art Deep Neural Network (DNN) models are considered to be\nrobust to random perturbations, it was shown that these architectures are\nhighly vulnerable to deliberately crafted perturbations, albeit being\nquasi-imperceptible. These vulnerabilities make it challenging to deploy DNN\nmodels in security-critical areas. In recent years, many research studies have\nbeen conducted to develop new attack methods and come up with new defense\ntechniques that enable more robust and reliable models. In this work, we\nexplore and assess the usage of different type of metrics for detecting\nadversarial samples. We first leverage the usage of moment-based predictive\nuncertainty estimates of a DNN classifier obtained using Monte-Carlo Dropout\nSampling. And we also introduce a new method that operates in the subspace of\ndeep features extracted by the model. We verified the effectiveness of our\napproach on a range of standard datasets like MNIST (Digit), MNIST (Fashion)\nand CIFAR-10. Our experiments show that these two different approaches\ncomplement each other, and the combined usage of all the proposed metrics\nyields up to 99 \\% ROC-AUC scores regardless of the attack algorithm.",
          "link": "http://arxiv.org/abs/2012.06390",
          "publishedOn": "2021-06-03T02:10:36.921Z",
          "wordCount": 645,
          "title": "Closeness and Uncertainty Aware Adversarial Examples Detection in Adversarial Machine Learning. (arXiv:2012.06390v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.06504",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_P/0/1/0/all/0/1\">Pingchuan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martinez_B/0/1/0/all/0/1\">Brais Martinez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petridis_S/0/1/0/all/0/1\">Stavros Petridis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pantic_M/0/1/0/all/0/1\">Maja Pantic</a>",
          "description": "Lipreading has witnessed a lot of progress due to the resurgence of neural\nnetworks. Recent works have placed emphasis on aspects such as improving\nperformance by finding the optimal architecture or improving generalization.\nHowever, there is still a significant gap between the current methodologies and\nthe requirements for an effective deployment of lipreading in practical\nscenarios. In this work, we propose a series of innovations that significantly\nbridge that gap: first, we raise the state-of-the-art performance by a wide\nmargin on LRW and LRW-1000 to 88.5% and 46.6%, respectively using\nself-distillation. Secondly, we propose a series of architectural changes,\nincluding a novel Depthwise Separable Temporal Convolutional Network (DS-TCN)\nhead, that slashes the computational cost to a fraction of the (already quite\nefficient) original model. Thirdly, we show that knowledge distillation is a\nvery effective tool for recovering performance of the lightweight models. This\nresults in a range of models with different accuracy-efficiency trade-offs.\nHowever, our most promising lightweight models are on par with the current\nstate-of-the-art while showing a reduction of 8.2x and 3.9x in terms of\ncomputational cost and number of parameters, respectively, which we hope will\nenable the deployment of lipreading models in practical applications.",
          "link": "http://arxiv.org/abs/2007.06504",
          "publishedOn": "2021-06-03T02:10:36.901Z",
          "wordCount": 674,
          "title": "Towards Practical Lipreading with Distilled and Efficient Models. (arXiv:2007.06504v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01072",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thorne_J/0/1/0/all/0/1\">James Thorne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vlachos_A/0/1/0/all/0/1\">Andreas Vlachos</a>",
          "description": "This paper introduces the task of factual error correction: performing edits\nto a claim so that the generated rewrite is better supported by evidence. This\nextends the well-studied task of fact verification by providing a mechanism to\ncorrect written texts that are refuted or only partially supported by evidence.\nWe demonstrate that it is feasible to train factual error correction systems\nfrom existing fact checking datasets which only contain labeled claims\naccompanied by evidence, but not the correction. We achieve this by employing a\ntwo-stage distant supervision approach that incorporates evidence into masked\nclaims when generating corrections. Our approach, based on the T5 transformer\nand using retrieved evidence, achieved better results than existing work which\nused a pointer copy network and gold evidence, producing accurate factual error\ncorrections for 5x more instances in human evaluation and a .125 increase in\nSARI score. The evaluation is conducted on a dataset of 65,000 instances based\non a recent fact verification shared task and we release it to enable further\nwork on the task.",
          "link": "http://arxiv.org/abs/2106.01072",
          "publishedOn": "2021-06-03T02:10:36.896Z",
          "wordCount": 605,
          "title": "Evidence-based Factual Error Correction. (arXiv:2106.01072v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2011.08826",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wickramasinghe_U/0/1/0/all/0/1\">Udaranga Wickramasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knott_G/0/1/0/all/0/1\">Graham Knott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fua_P/0/1/0/all/0/1\">Pascal Fua</a>",
          "description": "Active Surface Models have a long history of being useful to model complex 3D\nsurfaces but only Active Contours have been used in conjunction with deep\nnetworks, and then only to produce the data term as well as meta-parameter maps\ncontrolling them. In this paper, we advocate a much tighter integration. We\nintroduce layers that implement them that can be integrated seamlessly into\nGraph Convolutional Networks to enforce sophisticated smoothness priors at an\nacceptable computational cost. We will show that the resulting Deep Active\nSurface Models outperform equivalent architectures that use traditional\nregularization loss terms to impose smoothness priors for 3D surface\nreconstruction from 2D images and for 3D volume segmentation.",
          "link": "http://arxiv.org/abs/2011.08826",
          "publishedOn": "2021-06-03T02:10:36.892Z",
          "wordCount": 590,
          "title": "Deep Active Surface Models. (arXiv:2011.08826v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01043",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Giriraj_R/0/1/0/all/0/1\">Rohan Giriraj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thomas_S/0/1/0/all/0/1\">Sinnu Susan Thomas</a>",
          "description": "In recent years, causal modelling has been used widely to improve\ngeneralization and to provide interpretability in machine learning models. To\ndetermine cause-effect relationships in the absence of a randomized trial, we\ncan model causal systems with counterfactuals and interventions given enough\ndomain knowledge. However, there are several cases where domain knowledge is\nalmost absent and the only recourse is using a statistical method to estimate\ncausal relationships. While there have been several works done in estimating\ncausal relationships in unstructured data, we are yet to find a well-defined\nframework for estimating causal relationships in Knowledge Graphs (KG). It is\ncommonly used to provide a semantic framework for data with complex\ninter-domain relationships. In this work, we define a hybrid approach that\nallows us to discover cause-effect relationships in KG. The proposed approach\nis based around the finding of the instantaneous causal structure of a\nnon-experimental matrix using a non-Gaussian model, i.e; finding the causal\nordering of the variables in a non-Gaussian setting. The non-experimental\nmatrix is a low-dimensional tensor projection obtained by decomposing the\nadjacency tensor of a KG. We use two different pre-existing algorithms, one for\nthe causal discovery and the other for decomposing the KG and combining them to\nget the causal structure in a KG.",
          "link": "http://arxiv.org/abs/2106.01043",
          "publishedOn": "2021-06-03T02:10:36.878Z",
          "wordCount": 646,
          "title": "Causal Discovery in Knowledge Graphs by Exploiting Asymmetric Properties of Non-Gaussian Distributions. (arXiv:2106.01043v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2009.03979",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wilkinson_L/0/1/0/all/0/1\">Leland Wilkinson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Hengrui Luo</a>",
          "description": "Visualizing very large matrices involves many formidable problems. Various\npopular solutions to these problems involve sampling, clustering, projection,\nor feature selection to reduce the size and complexity of the original task. An\nimportant aspect of these methods is how to preserve relative distances between\npoints in the higher-dimensional space after reducing rows and columns to fit\nin a lower dimensional space. This aspect is important because conclusions\nbased on faulty visual reasoning can be harmful. Judging dissimilar points as\nsimilar or similar points as dissimilar on the basis of a visualization can\nlead to false conclusions. To ameliorate this bias and to make visualizations\nof very large datasets feasible, we introduce two new algorithms that\nrespectively select a subset of rows and columns of a rectangular matrix. This\nselection is designed to preserve relative distances as closely as possible. We\ncompare our matrix sketch to more traditional alternatives on a variety of\nartificial and real datasets.",
          "link": "http://arxiv.org/abs/2009.03979",
          "publishedOn": "2021-06-03T02:10:36.871Z",
          "wordCount": 607,
          "title": "A Distance-preserving Matrix Sketch. (arXiv:2009.03979v2 [cs.HC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01109",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Anand_P/0/1/0/all/0/1\">Pritam Anand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rastogi_R/0/1/0/all/0/1\">Reshma Rastogi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandra_S/0/1/0/all/0/1\">Suresh Chandra</a>",
          "description": "Recently, there have been several papers that discuss the extension of the\nPinball loss Support Vector Machine (Pin-SVM) model, originally proposed by\nHuang et al.,[1][2]. Pin-SVM classifier deals with the pinball loss function,\nwhich has been defined in terms of the parameter $\\tau$. The parameter $\\tau$\ncan take values in $[ -1,1]$. The existing Pin-SVM model requires to solve the\nsame optimization problem for all values of $\\tau$ in $[ -1,1]$. In this paper,\nwe improve the existing Pin-SVM model for the binary classification task. At\nfirst, we note that there is major difficulty in Pin-SVM model (Huang et al.\n[1]) for $ -1 \\leq \\tau < 0$. Specifically, we show that the Pin-SVM model\nrequires the solution of different optimization problem for $ -1 \\leq \\tau <\n0$. We further propose a unified model termed as Unified Pin-SVM which results\nin a QPP valid for all $-1\\leq \\tau \\leq 1$ and hence more convenient to use.\nThe proposed Unified Pin-SVM model can obtain a significant improvement in\naccuracy over the existing Pin-SVM model which has also been empirically\njustified by extensive numerical experiments with real-world datasets.",
          "link": "http://arxiv.org/abs/2106.01109",
          "publishedOn": "2021-06-03T02:10:36.854Z",
          "wordCount": 661,
          "title": "Improvement over Pinball Loss Support Vector Machine. (arXiv:2106.01109v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.15843",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Makinen_T/0/1/0/all/0/1\">T. Lucas Makinen</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Lancaster_L/0/1/0/all/0/1\">Lachlan Lancaster</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Villaescusa_Navarro_F/0/1/0/all/0/1\">Francisco Villaescusa-Navarro</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Melchior_P/0/1/0/all/0/1\">Peter Melchior</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Ho_S/0/1/0/all/0/1\">Shirley Ho</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Perreault_Levasseur_L/0/1/0/all/0/1\">Laurence Perreault-Levasseur</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Spergel_D/0/1/0/all/0/1\">David N. Spergel</a>",
          "description": "We seek to remove foreground contaminants from 21cm intensity mapping\nobservations. We demonstrate that a deep convolutional neural network (CNN)\nwith a UNet architecture and three-dimensional convolutions, trained on\nsimulated observations, can effectively separate frequency and spatial patterns\nof the cosmic neutral hydrogen (HI) signal from foregrounds in the presence of\nnoise. Cleaned maps recover cosmological clustering statistics within 10% at\nall relevant angular scales and frequencies. This amounts to a reduction in\nprediction variance of over an order of magnitude on small angular scales\n($\\ell > 300$), and improved accuracy for small radial scales ($k_{\\parallel} >\n0.17\\ \\rm h\\ Mpc^{-1})$ compared to standard Principal Component Analysis (PCA)\nmethods. We estimate posterior confidence intervals for the network's\nprediction by training an ensemble of UNets. Our approach demonstrates the\nfeasibility of analyzing 21cm intensity maps, as opposed to derived summary\nstatistics, for upcoming radio experiments, as long as the simulated foreground\nmodel is sufficiently realistic. We provide the code used for this analysis on\nGithub https://github.com/tlmakinen/deep21 as well as a browser-based tutorial\nfor the experiment and UNet model via the accompanying\nthis http URL Colab notebook.",
          "link": "http://arxiv.org/abs/2010.15843",
          "publishedOn": "2021-06-03T02:10:36.840Z",
          "wordCount": 662,
          "title": "deep21: a Deep Learning Method for 21cm Foreground Removal. (arXiv:2010.15843v2 [astro-ph.CO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.13145",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yifei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yaodong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yi Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuan Yao</a>",
          "description": "In this paper we introduce a provably stable architecture for Neural Ordinary\nDifferential Equations (ODEs) which achieves non-trivial adversarial robustness\nunder white-box adversarial attacks even when the network is trained naturally.\nFor most existing defense methods withstanding strong white-box attacks, to\nimprove robustness of neural networks, they need to be trained adversarially,\nhence have to strike a trade-off between natural accuracy and adversarial\nrobustness. Inspired by dynamical system theory, we design a stabilized neural\nODE network named SONet whose ODE blocks are skew-symmetric and proved to be\ninput-output stable. With natural training, SONet can achieve comparable\nrobustness with the state-of-the-art adversarial defense methods, without\nsacrificing natural accuracy. Even replacing only the first layer of a ResNet\nby such a ODE block can exhibit further improvement in robustness, e.g., under\nPGD-20 ($\\ell_\\infty=0.031$) attack on CIFAR-10 dataset, it achieves 91.57\\%\nand natural accuracy and 62.35\\% robust accuracy, while a counterpart\narchitecture of ResNet trained with TRADES achieves natural and robust accuracy\n76.29\\% and 45.24\\%, respectively. To understand possible reasons behind this\nsurprisingly good result, we further explore the possible mechanism underlying\nsuch an adversarial robustness. We show that the adaptive stepsize numerical\nODE solver, DOPRI5, has a gradient masking effect that fails the PGD attacks\nwhich are sensitive to gradient information of training loss; on the other\nhand, it cannot fool the CW attack of robust gradients and the SPSA attack that\nis gradient-free. This provides a new explanation that the adversarial\nrobustness of ODE-based networks mainly comes from the obfuscated gradients in\nnumerical ODE solvers.",
          "link": "http://arxiv.org/abs/2009.13145",
          "publishedOn": "2021-06-03T02:10:36.817Z",
          "wordCount": 722,
          "title": "Adversarial Robustness of Stabilized NeuralODEs Might be from Obfuscated Gradients. (arXiv:2009.13145v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.12019",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chatterji_N/0/1/0/all/0/1\">Niladri S. Chatterji</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Long_P/0/1/0/all/0/1\">Philip M. Long</a>",
          "description": "We prove bounds on the population risk of the maximum margin algorithm for\ntwo-class linear classification. For linearly separable training data, the\nmaximum margin algorithm has been shown in previous work to be equivalent to a\nlimit of training with logistic loss using gradient descent, as the training\nerror is driven to zero. We analyze this algorithm applied to random data\nincluding misclassification noise. Our assumptions on the clean data include\nthe case in which the class-conditional distributions are standard normal\ndistributions. The misclassification noise may be chosen by an adversary,\nsubject to a limit on the fraction of corrupted labels. Our bounds show that,\nwith sufficient over-parameterization, the maximum margin algorithm trained on\nnoisy data can achieve nearly optimal population risk.",
          "link": "http://arxiv.org/abs/2004.12019",
          "publishedOn": "2021-06-03T02:10:36.806Z",
          "wordCount": 604,
          "title": "Finite-sample Analysis of Interpolating Linear Classifiers in the Overparameterized Regime. (arXiv:2004.12019v4 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01048",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hayes_C/0/1/0/all/0/1\">Conor F. Hayes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verstraeten_T/0/1/0/all/0/1\">Timothy Verstraeten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roijers_D/0/1/0/all/0/1\">Diederik M. Roijers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Howley_E/0/1/0/all/0/1\">Enda Howley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mannion_P/0/1/0/all/0/1\">Patrick Mannion</a>",
          "description": "In many real-world scenarios, the utility of a user is derived from the\nsingle execution of a policy. In this case, to apply multi-objective\nreinforcement learning, the expected utility of the returns must be optimised.\nVarious scenarios exist where a user's preferences over objectives (also known\nas the utility function) are unknown or difficult to specify. In such\nscenarios, a set of optimal policies must be learned. However, settings where\nthe expected utility must be maximised have been largely overlooked by the\nmulti-objective reinforcement learning community and, as a consequence, a set\nof optimal solutions has yet to be defined. In this paper we address this\nchallenge by proposing first-order stochastic dominance as a criterion to build\nsolution sets to maximise expected utility. We also propose a new dominance\ncriterion, known as expected scalarised returns (ESR) dominance, that extends\nfirst-order stochastic dominance to allow a set of optimal policies to be\nlearned in practice. We then define a new solution concept called the ESR set,\nwhich is a set of policies that are ESR dominant. Finally, we define a new\nmulti-objective distributional tabular reinforcement learning (MOT-DRL)\nalgorithm to learn the ESR set in a multi-objective multi-armed bandit setting.",
          "link": "http://arxiv.org/abs/2106.01048",
          "publishedOn": "2021-06-03T02:10:36.800Z",
          "wordCount": 638,
          "title": "Expected Scalarised Returns Dominance: A New Solution Concept for Multi-Objective Decision Making. (arXiv:2106.01048v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01085",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1\">Jaehong Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madaan_D/0/1/0/all/0/1\">Divyam Madaan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1\">Eunho Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>",
          "description": "A dataset is a shred of crucial evidence to describe a task. However, each\ndata point in the dataset does not have the same potential, as some of the data\npoints can be more representative or informative than others. This unequal\nimportance among the data points may have a large impact in rehearsal-based\ncontinual learning, where we store a subset of the training examples (coreset)\nto be replayed later to alleviate catastrophic forgetting. In continual\nlearning, the quality of the samples stored in the coreset directly affects the\nmodel's effectiveness and efficiency. The coreset selection problem becomes\neven more important under realistic settings, such as imbalanced continual\nlearning or noisy data scenarios. To tackle this problem, we propose Online\nCoreset Selection (OCS), a simple yet effective method that selects the most\nrepresentative and informative coreset at each iteration and trains them in an\nonline manner. Our proposed method maximizes the model's adaptation to a target\ndataset while selecting high-affinity samples to past tasks, which directly\ninhibits catastrophic forgetting. We validate the effectiveness of our coreset\nselection mechanism over various standard, imbalanced, and noisy datasets\nagainst strong continual learning baselines, demonstrating that it improves\ntask adaptation and prevents catastrophic forgetting in a sample-efficient\nmanner.",
          "link": "http://arxiv.org/abs/2106.01085",
          "publishedOn": "2021-06-03T02:10:36.787Z",
          "wordCount": 632,
          "title": "Online Coreset Selection for Rehearsal-based Continual Learning. (arXiv:2106.01085v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2007.14573",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yuexiang Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yaliang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_B/0/1/0/all/0/1\">Bolin Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurel_N/0/1/0/all/0/1\">Nezihe Merve G&#xfc;rel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Ce Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1\">Wei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>",
          "description": "High-order interactive features capture the correlation between different\ncolumns and thus are promising to enhance various learning tasks on ubiquitous\ntabular data. To automate the generation of interactive features, existing\nworks either explicitly traverse the feature space or implicitly express the\ninteractions via intermediate activations of some designed models. These two\nkinds of methods show that there is essentially a trade-off between feature\ninterpretability and search efficiency. To possess both of their merits, we\npropose a novel method named Feature Interaction Via Edge Search (FIVES), which\nformulates the task of interactive feature generation as searching for edges on\nthe defined feature graph. Specifically, we first present our theoretical\nevidence that motivates us to search for useful interactive features with\nincreasing order. Then we instantiate this search strategy by optimizing both a\ndedicated graph neural network (GNN) and the adjacency tensor associated with\nthe defined feature graph. In this way, the proposed FIVES method simplifies\nthe time-consuming traversal as a typical training course of GNN and enables\nexplicit feature generation according to the learned adjacency tensor.\nExperimental results on both benchmark and real-world datasets show the\nadvantages of FIVES over several state-of-the-art methods. Moreover, the\ninteractive features identified by FIVES are deployed on the recommender system\nof Taobao, a worldwide leading e-commerce platform. Results of an online A/B\ntesting further verify the effectiveness of the proposed method FIVES, and we\nfurther provide FIVES as AI utilities for the customers of Alibaba Cloud.",
          "link": "http://arxiv.org/abs/2007.14573",
          "publishedOn": "2021-06-03T02:10:36.783Z",
          "wordCount": 721,
          "title": "FIVES: Feature Interaction Via Edge Search for Large-Scale Tabular Data. (arXiv:2007.14573v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.01795",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Krishna_K/0/1/0/all/0/1\">Kundan Krishna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khosla_S/0/1/0/all/0/1\">Sopan Khosla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bigham_J/0/1/0/all/0/1\">Jeffrey P. Bigham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1\">Zachary C. Lipton</a>",
          "description": "Following each patient visit, physicians draft long semi-structured clinical\nsummaries called SOAP notes. While invaluable to clinicians and researchers,\ncreating digital SOAP notes is burdensome, contributing to physician burnout.\nIn this paper, we introduce the first complete pipelines to leverage deep\nsummarization models to generate these notes based on transcripts of\nconversations between physicians and patients. After exploring a spectrum of\nmethods across the extractive-abstractive spectrum, we propose Cluster2Sent, an\nalgorithm that (i) extracts important utterances relevant to each summary\nsection; (ii) clusters together related utterances; and then (iii) generates\none summary sentence per cluster. Cluster2Sent outperforms its purely\nabstractive counterpart by 8 ROUGE-1 points, and produces significantly more\nfactual and coherent sentences as assessed by expert human evaluators. For\nreproducibility, we demonstrate similar benefits on the publicly available AMI\ndataset. Our results speak to the benefits of structuring summaries into\nsections and annotating supporting evidence when constructing summarization\ncorpora.",
          "link": "http://arxiv.org/abs/2005.01795",
          "publishedOn": "2021-06-03T02:10:36.771Z",
          "wordCount": 642,
          "title": "Generating SOAP Notes from Doctor-Patient Conversations Using Modular Summarization Techniques. (arXiv:2005.01795v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01098",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+OBray_L/0/1/0/all/0/1\">Leslie O&#x27;Bray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horn_M/0/1/0/all/0/1\">Max Horn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rieck_B/0/1/0/all/0/1\">Bastian Rieck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borgwardt_K/0/1/0/all/0/1\">Karsten Borgwardt</a>",
          "description": "Graph generative models are a highly active branch of machine learning. Given\nthe steady development of new models of ever-increasing complexity, it is\nnecessary to provide a principled way to evaluate and compare them. In this\npaper, we enumerate the desirable criteria for comparison metrics, discuss the\ndevelopment of such metrics, and provide a comparison of their respective\nexpressive power. We perform a systematic evaluation of the main metrics in use\ntoday, highlighting some of the challenges and pitfalls researchers\ninadvertently can run into. We then describe a collection of suitable metrics,\ngive recommendations as to their practical suitability, and analyse their\nbehaviour on synthetically generated perturbed graphs as well as on recently\nproposed graph generative models.",
          "link": "http://arxiv.org/abs/2106.01098",
          "publishedOn": "2021-06-03T02:10:36.766Z",
          "wordCount": 558,
          "title": "Evaluation Metrics for Graph Generative Models: Problems, Pitfalls, and Practical Solutions. (arXiv:2106.01098v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01070",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Si_N/0/1/0/all/0/1\">Nian Si</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Murthy_K/0/1/0/all/0/1\">Karthyek Murthy</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Blanchet_J/0/1/0/all/0/1\">Jose Blanchet</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_V/0/1/0/all/0/1\">Viet Anh Nguyen</a>",
          "description": "We present a statistical testing framework to detect if a given machine\nlearning classifier fails to satisfy a wide range of group fairness notions.\nThe proposed test is a flexible, interpretable, and statistically rigorous tool\nfor auditing whether exhibited biases are intrinsic to the algorithm or due to\nthe randomness in the data. The statistical challenges, which may arise from\nmultiple impact criteria that define group fairness and which are discontinuous\non model parameters, are conveniently tackled by projecting the empirical\nmeasure onto the set of group-fair probability models using optimal transport.\nThis statistic is efficiently computed using linear programming and its\nasymptotic distribution is explicitly obtained. The proposed framework can also\nbe used to test for testing composite fairness hypotheses and fairness with\nmultiple sensitive attributes. The optimal transport testing formulation\nimproves interpretability by characterizing the minimal covariate perturbations\nthat eliminate the bias observed in the audit.",
          "link": "http://arxiv.org/abs/2106.01070",
          "publishedOn": "2021-06-03T02:10:36.754Z",
          "wordCount": 595,
          "title": "Testing Group Fairness via Optimal Transport Projections. (arXiv:2106.01070v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2006.06963",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Marchant_N/0/1/0/all/0/1\">Neil G. Marchant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubinstein_B/0/1/0/all/0/1\">Benjamin I. P. Rubinstein</a>",
          "description": "Important tasks like record linkage and extreme classification demonstrate\nextreme class imbalance, with 1 minority instance to every 1 million or more\nmajority instances. Obtaining a sufficient sample of all classes, even just to\nachieve statistically-significant evaluation, is so challenging that most\ncurrent approaches yield poor estimates or incur impractical cost. Where\nimportance sampling has been levied against this challenge, restrictive\nconstraints are placed on performance metrics, estimates do not come with\nappropriate guarantees, or evaluations cannot adapt to incoming labels. This\npaper develops a framework for online evaluation based on adaptive importance\nsampling. Given a target performance metric and model for $p(y|x)$, the\nframework adapts a distribution over items to label in order to maximize\nstatistical precision. We establish strong consistency and a central limit\ntheorem for the resulting performance estimates, and instantiate our framework\nwith worked examples that leverage Dirichlet-tree models. Experiments\ndemonstrate an average MSE superior to state-of-the-art on fixed label budgets.",
          "link": "http://arxiv.org/abs/2006.06963",
          "publishedOn": "2021-06-03T02:10:36.748Z",
          "wordCount": 640,
          "title": "Needle in a Haystack: Label-Efficient Evaluation under Extreme Class Imbalance. (arXiv:2006.06963v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1911.03663",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kang_D/0/1/0/all/0/1\">Dongyeop Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hovy_E/0/1/0/all/0/1\">Eduard Hovy</a>",
          "description": "Every natural text is written in some style. Style is formed by a complex\ncombination of different stylistic factors, including formality markers,\nemotions, metaphors, etc. One cannot form a complete understanding of a text\nwithout considering these factors. The factors combine and co-vary in complex\nways to form styles. Studying the nature of the co-varying combinations sheds\nlight on stylistic language in general, sometimes called cross-style language\nunderstanding. This paper provides the benchmark corpus (xSLUE) that combines\nexisting datasets and collects a new one for sentence-level cross-style\nlanguage understanding and evaluation. The benchmark contains text in 15\ndifferent styles under the proposed four theoretical groupings: figurative,\npersonal, affective, and interpersonal groups. For valid evaluation, we collect\nan additional diagnostic set by annotating all 15 styles on the same text.\nUsing xSLUE, we propose three interesting cross-style applications in\nclassification, correlation, and generation. First, our proposed cross-style\nclassifier trained with multiple styles together helps improve overall\nclassification performance against individually-trained style classifiers.\nSecond, our study shows that some styles are highly dependent on each other in\nhuman-written text. Finally, we find that combinations of some contradictive\nstyles likely generate stylistically less appropriate text. We believe our\nbenchmark and case studies help explore interesting future directions for\ncross-style research. The preprocessed datasets and code are publicly\navailable.",
          "link": "http://arxiv.org/abs/1911.03663",
          "publishedOn": "2021-06-03T02:10:36.743Z",
          "wordCount": 686,
          "title": "Style is NOT a single variable: Case Studies for Cross-Style Language Understanding. (arXiv:1911.03663v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01096",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jianxin Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhijie Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hongxia Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhou Zhao</a>",
          "description": "Existing reasoning tasks often have an important assumption that the input\ncontents can be always accessed while reasoning, requiring unlimited storage\nresources and suffering from severe time delay on long sequences. To achieve\nefficient reasoning on long sequences with limited storage resources, memory\naugmented neural networks introduce a human-like write-read memory to compress\nand memorize the long input sequence in one pass, trying to answer subsequent\nqueries only based on the memory. But they have two serious drawbacks: 1) they\ncontinually update the memory from current information and inevitably forget\nthe early contents; 2) they do not distinguish what information is important\nand treat all contents equally. In this paper, we propose the Rehearsal Memory\n(RM) to enhance long-sequence memorization by self-supervised rehearsal with a\nhistory sampler. To alleviate the gradual forgetting of early information, we\ndesign self-supervised rehearsal training with recollection and familiarity\ntasks. Further, we design a history sampler to select informative fragments for\nrehearsal training, making the memory focus on the crucial information. We\nevaluate the performance of our rehearsal memory by the synthetic bAbI task and\nseveral downstream tasks, including text/video question answering and\nrecommendation on long sequences.",
          "link": "http://arxiv.org/abs/2106.01096",
          "publishedOn": "2021-06-03T02:10:36.737Z",
          "wordCount": 625,
          "title": "Learning to Rehearse in Long Sequence Memorization. (arXiv:2106.01096v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01092",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Reeve_H/0/1/0/all/0/1\">Henry W. J. Reeve</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaban_A/0/1/0/all/0/1\">Ata Kaban</a>",
          "description": "We present a framework for the theoretical analysis of ensembles of\nlow-complexity empirical risk minimisers trained on independent random\ncompressions of high-dimensional data. First we introduce a general\ndistribution-dependent upper-bound on the excess risk, framed in terms of a\nnatural notion of compressibility. This bound is independent of the dimension\nof the original data representation, and explains the in-built regularisation\neffect of the compressive approach. We then instantiate this general bound to\nclassification and regression tasks, considering Johnson-Lindenstrauss mappings\nas the compression scheme. For each of these tasks, our strategy is to develop\na tight upper bound on the compressibility function, and by doing so we\ndiscover distributional conditions of geometric nature under which the\ncompressive algorithm attains minimax-optimal rates up to at most\npoly-logarithmic factors. In the case of compressive classification, this is\nachieved with a mild geometric margin condition along with a flexible moment\ncondition that is significantly more general than the assumption of bounded\ndomain. In the case of regression with strongly convex smooth loss functions we\nfind that compressive regression is capable of exploiting spectral decay with\nnear-optimal guarantees. In addition, a key ingredient for our central upper\nbound is a high probability uniform upper bound on the integrated deviation of\ndependent empirical processes, which may be of independent interest.",
          "link": "http://arxiv.org/abs/2106.01092",
          "publishedOn": "2021-06-03T02:10:36.732Z",
          "wordCount": 643,
          "title": "Statistical optimality conditions for compressive ensembles. (arXiv:2106.01092v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.12983",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Tri Minh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quinn_T/0/1/0/all/0/1\">Thomas P Quinn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Thin Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1\">Truyen Tran</a>",
          "description": "Motivation: Many high-performance DTA models have been proposed, but they are\nmostly black-box and thus lack human interpretability. Explainable AI (XAI) can\nmake DTA models more trustworthy, and can also enable scientists to distill\nbiological knowledge from the models. Counterfactual explanation is one popular\napproach to explaining the behaviour of a deep neural network, which works by\nsystematically answering the question \"How would the model output change if the\ninputs were changed in this way?\". Most counterfactual explanation methods only\noperate on single input data. It remains an open problem how to extend\ncounterfactual-based XAI methods to DTA models, which have two inputs, one for\ndrug and one for target, that also happen to be discrete in nature.\n\nMethods: We propose a multi-agent reinforcement learning framework,\nMulti-Agent Counterfactual Drug target binding Affinity (MACDA), to generate\ncounterfactual explanations for the drug-protein complex. Our proposed\nframework provides human-interpretable counterfactual instances while\noptimizing both the input drug and target for counterfactual generation at the\nsame time.\n\nResults: We benchmark the proposed MACDA framework using the Davis dataset\nand find that our framework produces more parsimonious explanations with no\nloss in explanation validity, as measured by encoding similarity and QED. We\nthen present a case study involving ABL1 and Nilotinib to demonstrate how MACDA\ncan explain the behaviour of a DTA model in the underlying substructure\ninteraction between inputs in its prediction, revealing mechanisms that align\nwith prior domain knowledge.",
          "link": "http://arxiv.org/abs/2103.12983",
          "publishedOn": "2021-06-03T02:10:36.719Z",
          "wordCount": 697,
          "title": "Counterfactual Explanation with Multi-Agent Reinforcement Learning for Drug Target Prediction. (arXiv:2103.12983v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.08330",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yong Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bach_N/0/1/0/all/0/1\">Nguyen Bach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhongqiang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1\">Kewei Tu</a>",
          "description": "Recent work proposes a family of contextual embeddings that significantly\nimproves the accuracy of sequence labelers over non-contextual embeddings.\nHowever, there is no definite conclusion on whether we can build better\nsequence labelers by combining different kinds of embeddings in various\nsettings. In this paper, we conduct extensive experiments on 3 tasks over 18\ndatasets and 8 languages to study the accuracy of sequence labeling with\nvarious embedding concatenations and make three observations: (1) concatenating\nmore embedding variants leads to better accuracy in rich-resource and\ncross-domain settings and some conditions of low-resource settings; (2)\nconcatenating additional contextual sub-word embeddings with contextual\ncharacter embeddings hurts the accuracy in extremely low-resource settings; (3)\nbased on the conclusion of (1), concatenating additional similar contextual\nembeddings cannot lead to further improvements. We hope these conclusions can\nhelp people build stronger sequence labelers in various settings.",
          "link": "http://arxiv.org/abs/2009.08330",
          "publishedOn": "2021-06-03T02:10:36.713Z",
          "wordCount": 620,
          "title": "More Embeddings, Better Sequence Labelers?. (arXiv:2009.08330v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.09261",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bertsimas_D/0/1/0/all/0/1\">Dimitris Bertsimas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Digalakis_V/0/1/0/all/0/1\">Vassilis Digalakis Jr</a>",
          "description": "We present a novel approach for the problem of frequency estimation in data\nstreams that is based on optimization and machine learning. Contrary to\nstate-of-the-art streaming frequency estimation algorithms, which heavily rely\non random hashing to maintain the frequency distribution of the data steam\nusing limited storage, the proposed approach exploits an observed stream prefix\nto near-optimally hash elements and compress the target frequency distribution.\nWe develop an exact mixed-integer linear optimization formulation, which\nenables us to compute optimal or near-optimal hashing schemes for elements seen\nin the observed stream prefix; then, we use machine learning to hash unseen\nelements. Further, we develop an efficient block coordinate descent algorithm,\nwhich, as we empirically show, produces high quality solutions, and, in a\nspecial case, we are able to solve the proposed formulation exactly in linear\ntime using dynamic programming. We empirically evaluate the proposed approach\nboth on synthetic datasets and on real-world search query data. We show that\nthe proposed approach outperforms existing approaches by one to two orders of\nmagnitude in terms of its average (per element) estimation error and by 45-90%\nin terms of its expected magnitude of estimation error.",
          "link": "http://arxiv.org/abs/2007.09261",
          "publishedOn": "2021-06-03T02:10:36.708Z",
          "wordCount": 669,
          "title": "Frequency Estimation in Data Streams: Learning the Optimal Hashing Scheme. (arXiv:2007.09261v2 [cs.DS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.05656",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bai_B/0/1/0/all/0/1\">Bing Bai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liang_J/0/1/0/all/0/1\">Jian Liang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_G/0/1/0/all/0/1\">Guanhua Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_H/0/1/0/all/0/1\">Hao Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bai_K/0/1/0/all/0/1\">Kun Bai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_F/0/1/0/all/0/1\">Fei Wang</a>",
          "description": "Attention-based methods have played important roles in model interpretations,\nwhere the calculated attention weights are expected to highlight the critical\nparts of inputs~(e.g., keywords in sentences). However, recent research found\nthat attention-as-importance interpretations often do not work as we expected.\nFor example, learned attention weights sometimes highlight less meaningful\ntokens like \"[SEP]\", \",\", and \".\", and are frequently uncorrelated with other\nfeature importance indicators like gradient-based measures. A recent debate\nover whether attention is an explanation or not has drawn considerable\ninterest. In this paper, we demonstrate that one root cause of this phenomenon\nis the combinatorial shortcuts, which means that, in addition to the\nhighlighted parts, the attention weights themselves may carry extra information\nthat could be utilized by downstream models after attention layers. As a\nresult, the attention weights are no longer pure importance indicators. We\ntheoretically analyze combinatorial shortcuts, design one intuitive experiment\nto show their existence, and propose two methods to mitigate this issue. We\nconduct empirical studies on attention-based interpretation models. The results\nshow that the proposed methods can effectively improve the interpretability of\nattention mechanisms.",
          "link": "http://arxiv.org/abs/2006.05656",
          "publishedOn": "2021-06-03T02:10:36.701Z",
          "wordCount": 650,
          "title": "Why is Attention Not So Interpretable?. (arXiv:2006.05656v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.11660",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Greenberg_I/0/1/0/all/0/1\">Ido Greenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mannor_S/0/1/0/all/0/1\">Shie Mannor</a>",
          "description": "In many RL applications, once training ends, it is vital to detect any\ndeterioration in the agent performance as soon as possible. Furthermore, it\noften has to be done without modifying the policy and under minimal assumptions\nregarding the environment. In this paper, we address this problem by focusing\ndirectly on the rewards and testing for degradation. We consider an episodic\nframework, where the rewards within each episode are not independent, nor\nidentically-distributed, nor Markov. We present this problem as a multivariate\nmean-shift detection problem with possibly partial observations. We define the\nmean-shift in a way corresponding to deterioration of a temporal signal (such\nas the rewards), and derive a test for this problem with optimal statistical\npower. Empirically, on deteriorated rewards in control problems (generated\nusing various environment modifications), the test is demonstrated to be more\npowerful than standard tests - often by orders of magnitude. We also suggest a\nnovel Bootstrap mechanism for False Alarm Rate control (BFAR), applicable to\nepisodic (non-i.i.d) signal and allowing our test to run sequentially in an\nonline manner. Our method does not rely on a learned model of the environment,\nis entirely external to the agent, and in fact can be applied to detect changes\nor drifts in any episodic signal.",
          "link": "http://arxiv.org/abs/2010.11660",
          "publishedOn": "2021-06-03T02:10:36.690Z",
          "wordCount": 652,
          "title": "Detecting Rewards Deterioration in Episodic Reinforcement Learning. (arXiv:2010.11660v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.01845",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ruiz_F/0/1/0/all/0/1\">Francisco J. R. Ruiz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Titsias_M/0/1/0/all/0/1\">Michalis K. Titsias</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cemgil_T/0/1/0/all/0/1\">Taylan Cemgil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doucet_A/0/1/0/all/0/1\">Arnaud Doucet</a>",
          "description": "The variational auto-encoder (VAE) is a deep latent variable model that has\ntwo neural networks in an autoencoder-like architecture; one of them\nparameterizes the model's likelihood. Fitting its parameters via maximum\nlikelihood (ML) is challenging since the computation of the marginal likelihood\ninvolves an intractable integral over the latent space; thus the VAE is trained\ninstead by maximizing a variational lower bound. Here, we develop a ML training\nscheme for VAEs by introducing unbiased estimators of the log-likelihood\ngradient. We obtain the estimators by augmenting the latent space with a set of\nimportance samples, similarly to the importance weighted auto-encoder (IWAE),\nand then constructing a Markov chain Monte Carlo coupling procedure on this\naugmented space. We provide the conditions under which the estimators can be\ncomputed in finite time and with finite variance. We show experimentally that\nVAEs fitted with unbiased estimators exhibit better predictive performance.",
          "link": "http://arxiv.org/abs/2010.01845",
          "publishedOn": "2021-06-03T02:10:36.675Z",
          "wordCount": 624,
          "title": "Unbiased Gradient Estimation for Variational Auto-Encoders using Coupled Markov Chains. (arXiv:2010.01845v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01317",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yichen Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celikyilmaz_A/0/1/0/all/0/1\">Asli Celikyilmaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smolensky_P/0/1/0/all/0/1\">Paul Smolensky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soulos_P/0/1/0/all/0/1\">Paul Soulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_S/0/1/0/all/0/1\">Sudha Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palangi_H/0/1/0/all/0/1\">Hamid Palangi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fernandez_R/0/1/0/all/0/1\">Roland Fernandez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_C/0/1/0/all/0/1\">Caitlin Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>",
          "description": "Abstractive summarization, the task of generating a concise summary of input\ndocuments, requires: (1) reasoning over the source document to determine the\nsalient pieces of information scattered across the long document, and (2)\ncomposing a cohesive text by reconstructing these salient facts into a shorter\nsummary that faithfully reflects the complex relations connecting these facts.\nIn this paper, we adapt TP-TRANSFORMER (Schlag et al., 2019), an architecture\nthat enriches the original Transformer (Vaswani et al., 2017) with the\nexplicitly compositional Tensor Product Representation (TPR), for the task of\nabstractive summarization. The key feature of our model is a structural bias\nthat we introduce by encoding two separate representations for each token to\nrepresent the syntactic structure (with role vectors) and semantic content\n(with filler vectors) separately. The model then binds the role and filler\nvectors into the TPR as the layer output. We argue that the structured\nintermediate representations enable the model to take better control of the\ncontents (salient facts) and structures (the syntax that connects the facts)\nwhen generating the summary. Empirically, we show that our TP-TRANSFORMER\noutperforms the Transformer and the original TP-TRANSFORMER significantly on\nseveral abstractive summarization datasets based on both automatic and human\nevaluations. On several syntactic and semantic probing tasks, we demonstrate\nthe emergent structural information in the role vectors and improved syntactic\ninterpretability in the TPR layer outputs. Code and models are available at\nhttps://github.com/jiangycTarheel/TPT-Summ.",
          "link": "http://arxiv.org/abs/2106.01317",
          "publishedOn": "2021-06-03T02:10:36.593Z",
          "wordCount": 687,
          "title": "Enriching Transformers with Structured Tensor-Product Representations for Abstractive Summarization. (arXiv:2106.01317v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/1905.08671",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Yesilli_M/0/1/0/all/0/1\">Melih C. Yesilli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Khasawneh_F/0/1/0/all/0/1\">Firas A. Khasawneh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Otto_A/0/1/0/all/0/1\">Andreas Otto</a>",
          "description": "Machining processes are most accurately described using complex dynamical\nsystems that include nonlinearities, time delays, and stochastic effects. Due\nto the nature of these models as well as the practical challenges which include\ntime-varying parameters, the transition from numerical/analytical modeling of\nmachining to the analysis of real cutting signals remains challenging. Some\nstudies have focused on studying the time series of cutting processes using\nmachine learning algorithms with the goal of identifying and predicting\nundesirable vibrations during machining referred to as chatter. These tools\ntypically decompose the signal using Wavelet Packet Transforms (WPT) or\nEnsemble Empirical Mode Decomposition (EEMD). However, these methods require a\nsignificant overhead in identifying the feature vectors before a classifier can\nbe trained. In this study, we present an alternative approach based on\nfeaturizing the time series of the cutting process using its topological\nfeatures. We first embed the time series as a point cloud using Takens\nembedding. We then utilize Support Vector Machine, Logistic Regression, Random\nForest and Gradient Boosting classifier combined with feature vectors derived\nfrom persistence diagrams, a tool from persistent homology, to encode chatter's\ndistinguishing characteristics. We present the results for several choices of\nthe topological feature vectors, and we compare our results to the WPT and EEMD\nmethods using experimental turning data. Our results show that in two out of\nfour cutting configurations the TDA-based features yield accuracies as high as\n97%. We also show that combining Bezier curve approximation method and parallel\ncomputing can reduce runtime for persistence diagram computation of a single\ntime series to less than a second thus making our approach suitable for online\nchatter detection.",
          "link": "http://arxiv.org/abs/1905.08671",
          "publishedOn": "2021-06-03T02:10:36.569Z",
          "wordCount": 771,
          "title": "Topological Feature Vectors for Chatter Detection in Turning Processes. (arXiv:1905.08671v3 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1904.06984",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Safran_I/0/1/0/all/0/1\">Itay Safran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eldan_R/0/1/0/all/0/1\">Ronen Eldan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shamir_O/0/1/0/all/0/1\">Ohad Shamir</a>",
          "description": "Existing depth separation results for constant-depth networks essentially\nshow that certain radial functions in $\\mathbb{R}^d$, which can be easily\napproximated with depth $3$ networks, cannot be approximated by depth $2$\nnetworks, even up to constant accuracy, unless their size is exponential in\n$d$. However, the functions used to demonstrate this are rapidly oscillating,\nwith a Lipschitz parameter scaling polynomially with the dimension $d$ (or\nequivalently, by scaling the function, the hardness result applies to\n$\\mathcal{O}(1)$-Lipschitz functions only when the target accuracy $\\epsilon$\nis at most $\\text{poly}(1/d)$). In this paper, we study whether such depth\nseparations might still hold in the natural setting of\n$\\mathcal{O}(1)$-Lipschitz radial functions, when $\\epsilon$ does not scale\nwith $d$. Perhaps surprisingly, we show that the answer is negative: In\ncontrast to the intuition suggested by previous work, it \\emph{is} possible to\napproximate $\\mathcal{O}(1)$-Lipschitz radial functions with depth $2$, size\n$\\text{poly}(d)$ networks, for every constant $\\epsilon$. We complement it by\nshowing that approximating such functions is also possible with depth $2$, size\n$\\text{poly}(1/\\epsilon)$ networks, for every constant $d$. Finally, we show\nthat it is not possible to have polynomial dependence in both $d,1/\\epsilon$\nsimultaneously. Overall, our results indicate that in order to show depth\nseparations for expressing $\\mathcal{O}(1)$-Lipschitz functions with constant\naccuracy -- if at all possible -- one would need fundamentally different\ntechniques than existing ones in the literature.",
          "link": "http://arxiv.org/abs/1904.06984",
          "publishedOn": "2021-06-03T02:10:36.562Z",
          "wordCount": 691,
          "title": "Depth Separations in Neural Networks: What is Actually Being Separated?. (arXiv:1904.06984v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01352",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qureshi_A/0/1/0/all/0/1\">Ahmed H. Qureshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mousavian_A/0/1/0/all/0/1\">Arsalan Mousavian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paxton_C/0/1/0/all/0/1\">Chris Paxton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yip_M/0/1/0/all/0/1\">Michael C. Yip</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fox_D/0/1/0/all/0/1\">Dieter Fox</a>",
          "description": "Robots will be expected to manipulate a wide variety of objects in complex\nand arbitrary ways as they become more widely used in human environments. As\nsuch, the rearrangement of objects has been noted to be an important benchmark\nfor AI capabilities in recent years. We propose NeRP (Neural Rearrangement\nPlanning), a deep learning based approach for multi-step neural object\nrearrangement planning which works with never-before-seen objects, that is\ntrained on simulation data, and generalizes to the real world. We compare NeRP\nto several naive and model-based baselines, demonstrating that our approach is\nmeasurably better and can efficiently arrange unseen objects in fewer steps and\nwith less planning time. Finally, we demonstrate it on several challenging\nrearrangement problems in the real world.",
          "link": "http://arxiv.org/abs/2106.01352",
          "publishedOn": "2021-06-03T02:10:36.536Z",
          "wordCount": 554,
          "title": "NeRP: Neural Rearrangement Planning for Unknown Objects. (arXiv:2106.01352v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2002.06557",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zalcberg_G/0/1/0/all/0/1\">Gad Zalcberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiesel_A/0/1/0/all/0/1\">Ami Wiesel</a>",
          "description": "We consider Fair Principal Component Analysis (FPCA) and search for a low\ndimensional subspace that spans multiple target vectors in a fair manner. FPCA\nis defined as a non-concave maximization of the worst projected target norm\nwithin a given set. The problem arises in filter design in signal processing,\nand when incorporating fairness into dimensionality reduction schemes. The\nstate of the art approach to FPCA is via semidefinite relaxation and involves a\npolynomial yet computationally expensive optimization. To allow scalability, we\npropose to address FPCA using naive sub-gradient descent. We analyze the\nlandscape of the underlying optimization in the case of orthogonal targets. We\nprove that the landscape is benign and that all local minima are globally\noptimal. Interestingly, the SDR approach leads to sub-optimal solutions in this\nsimple case. Finally, we discuss the equivalence between orthogonal FPCA and\nthe design of normalized tight frames.",
          "link": "http://arxiv.org/abs/2002.06557",
          "publishedOn": "2021-06-03T02:10:36.531Z",
          "wordCount": 594,
          "title": "Fair Principal Component Analysis and Filter Design. (arXiv:2002.06557v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1909.04261",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Xie_W/0/1/0/all/0/1\">Wei Xie</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_B/0/1/0/all/0/1\">Bo Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_C/0/1/0/all/0/1\">Cheng Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xie_D/0/1/0/all/0/1\">Dongming Xie</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Auclair_J/0/1/0/all/0/1\">Jared Auclair</a>",
          "description": "While biomanufacturing plays a significant role in supporting the economy and\nensuring public health, it faces critical challenges, including complexity,\nhigh variability, lengthy lead time, and very limited process data, especially\nfor personalized new cell and gene biotherapeutics. Driven by these challenges,\nwe propose an interpretable semantic bioprocess probabilistic knowledge graph\nand develop a game theory based risk and sensitivity analyses for production\nprocess to facilitate quality-by-design and stability control. Specifically, by\nexploring the causal relationships and interactions of critical process\nparameters and quality attributes (CPPs/CQAs), we create a Bayesian network\nbased probabilistic knowledge graph characterizing the complex causal\ninterdependencies of all factors. Then, we introduce a Shapley value based\nsensitivity analysis, which can correctly quantify the variation contribution\nfrom each input factor on the outputs (i.e., productivity, product quality).\nSince the bioprocess model coefficients are learned from limited process\nobservations, we derive the Bayesian posterior distribution to quantify model\nuncertainty and further develop the Shapley value based sensitivity analysis to\nevaluate the impact of estimation uncertainty from each set of model\ncoefficients. Therefore, the proposed bioprocess risk and sensitivity analyses\ncan identify the bottlenecks, guide the reliable process specifications and the\nmost \"informative\" data collection, and improve production stability.",
          "link": "http://arxiv.org/abs/1909.04261",
          "publishedOn": "2021-06-03T02:10:36.467Z",
          "wordCount": 690,
          "title": "Interpretable Biomanufacturing Process Risk and Sensitivity Analyses for Quality-by-Design and Stability Control. (arXiv:1909.04261v4 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01342",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Somepalli_G/0/1/0/all/0/1\">Gowthami Somepalli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldblum_M/0/1/0/all/0/1\">Micah Goldblum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwarzschild_A/0/1/0/all/0/1\">Avi Schwarzschild</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bruss_C/0/1/0/all/0/1\">C. Bayan Bruss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1\">Tom Goldstein</a>",
          "description": "Tabular data underpins numerous high-impact applications of machine learning\nfrom fraud detection to genomics and healthcare. Classical approaches to\nsolving tabular problems, such as gradient boosting and random forests, are\nwidely used by practitioners. However, recent deep learning methods have\nachieved a degree of performance competitive with popular techniques. We devise\na hybrid deep learning approach to solving tabular data problems. Our method,\nSAINT, performs attention over both rows and columns, and it includes an\nenhanced embedding method. We also study a new contrastive self-supervised\npre-training method for use when labels are scarce. SAINT consistently improves\nperformance over previous deep learning methods, and it even outperforms\ngradient boosting methods, including XGBoost, CatBoost, and LightGBM, on\naverage over a variety of benchmark tasks.",
          "link": "http://arxiv.org/abs/2106.01342",
          "publishedOn": "2021-06-03T02:10:36.462Z",
          "wordCount": 567,
          "title": "SAINT: Improved Neural Networks for Tabular Data via Row Attention and Contrastive Pre-Training. (arXiv:2106.01342v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2001.07417",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fernandez_Loria_C/0/1/0/all/0/1\">Carlos Fern&#xe1;ndez-Lor&#xed;a</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Provost_F/0/1/0/all/0/1\">Foster Provost</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xintian Han</a>",
          "description": "We examine counterfactual explanations for explaining the decisions made by\nmodel-based AI systems. The counterfactual approach we consider defines an\nexplanation as a set of the system's data inputs that causally drives the\ndecision (i.e., changing the inputs in the set changes the decision) and is\nirreducible (i.e., changing any subset of the inputs does not change the\ndecision). We (1) demonstrate how this framework may be used to provide\nexplanations for decisions made by general, data-driven AI systems that may\nincorporate features with arbitrary data types and multiple predictive models,\nand (2) propose a heuristic procedure to find the most useful explanations\ndepending on the context. We then contrast counterfactual explanations with\nmethods that explain model predictions by weighting features according to their\nimportance (e.g., SHAP, LIME) and present two fundamental reasons why we should\ncarefully consider whether importance-weight explanations are well-suited to\nexplain system decisions. Specifically, we show that (i) features that have a\nlarge importance weight for a model prediction may not affect the corresponding\ndecision, and (ii) importance weights are insufficient to communicate whether\nand how features influence decisions. We demonstrate this with several concise\nexamples and three detailed case studies that compare the counterfactual\napproach with SHAP to illustrate various conditions under which counterfactual\nexplanations explain data-driven decisions better than importance weights.",
          "link": "http://arxiv.org/abs/2001.07417",
          "publishedOn": "2021-06-03T02:10:36.457Z",
          "wordCount": 698,
          "title": "Explaining Data-Driven Decisions made by AI Systems: The Counterfactual Approach. (arXiv:2001.07417v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01345",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lili Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_K/0/1/0/all/0/1\">Kevin Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajeswaran_A/0/1/0/all/0/1\">Aravind Rajeswaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kimin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grover_A/0/1/0/all/0/1\">Aditya Grover</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laskin_M/0/1/0/all/0/1\">Michael Laskin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivas_A/0/1/0/all/0/1\">Aravind Srinivas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mordatch_I/0/1/0/all/0/1\">Igor Mordatch</a>",
          "description": "We present a framework that abstracts Reinforcement Learning (RL) as a\nsequence modeling problem. This allows us to draw upon the simplicity and\nscalability of the Transformer architecture, and associated advances in\nlanguage modeling such as GPT-x and BERT. In particular, we present Decision\nTransformer, an architecture that casts the problem of RL as conditional\nsequence modeling. Unlike prior approaches to RL that fit value functions or\ncompute policy gradients, Decision Transformer simply outputs the optimal\nactions by leveraging a causally masked Transformer. By conditioning an\nautoregressive model on the desired return (reward), past states, and actions,\nour Decision Transformer model can generate future actions that achieve the\ndesired return. Despite its simplicity, Decision Transformer matches or exceeds\nthe performance of state-of-the-art model-free offline RL baselines on Atari,\nOpenAI Gym, and Key-to-Door tasks.",
          "link": "http://arxiv.org/abs/2106.01345",
          "publishedOn": "2021-06-03T02:10:36.422Z",
          "wordCount": 580,
          "title": "Decision Transformer: Reinforcement Learning via Sequence Modeling. (arXiv:2106.01345v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2002.11985",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ganesh_P/0/1/0/all/0/1\">Prakhar Ganesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_X/0/1/0/all/0/1\">Xin Lou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1\">Mohammad Ali Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sajjad_H/0/1/0/all/0/1\">Hassan Sajjad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1\">Preslav Nakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Deming Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winslett_M/0/1/0/all/0/1\">Marianne Winslett</a>",
          "description": "Pre-trained Transformer-based models have achieved state-of-the-art\nperformance for various Natural Language Processing (NLP) tasks. However, these\nmodels often have billions of parameters, and, thus, are too resource-hungry\nand computation-intensive to suit low-capability devices or applications with\nstrict latency requirements. One potential remedy for this is model\ncompression, which has attracted a lot of research attention. Here, we\nsummarize the research in compressing Transformers, focusing on the especially\npopular BERT model. In particular, we survey the state of the art in\ncompression for BERT, we clarify the current best practices for compressing\nlarge-scale Transformer models, and we provide insights into the workings of\nvarious methods. Our categorization and analysis also shed light on promising\nfuture research directions for achieving lightweight, accurate, and generic NLP\nmodels.",
          "link": "http://arxiv.org/abs/2002.11985",
          "publishedOn": "2021-06-03T02:10:36.417Z",
          "wordCount": 612,
          "title": "Compressing Large-Scale Transformer-Based Models: A Case Study on BERT. (arXiv:2002.11985v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01257",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Durmus_A/0/1/0/all/0/1\">Alain Durmus</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Moulines_E/0/1/0/all/0/1\">Eric Moulines</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Naumov_A/0/1/0/all/0/1\">Alexey Naumov</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Samsonov_S/0/1/0/all/0/1\">Sergey Samsonov</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Scaman_K/0/1/0/all/0/1\">Kevin Scaman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wai_H/0/1/0/all/0/1\">Hoi-To Wai</a>",
          "description": "This paper provides a non-asymptotic analysis of linear stochastic\napproximation (LSA) algorithms with fixed stepsize. This family of methods\narises in many machine learning tasks and is used to obtain approximate\nsolutions of a linear system $\\bar{A}\\theta = \\bar{b}$ for which $\\bar{A}$ and\n$\\bar{b}$ can only be accessed through random estimates $\\{({\\bf A}_n, {\\bf\nb}_n): n \\in \\mathbb{N}^*\\}$. Our analysis is based on new results regarding\nmoments and high probability bounds for products of matrices which are shown to\nbe tight. We derive high probability bounds on the performance of LSA under\nweaker conditions on the sequence $\\{({\\bf A}_n, {\\bf b}_n): n \\in\n\\mathbb{N}^*\\}$ than previous works. However, in contrast, we establish\npolynomial concentration bounds with order depending on the stepsize. We show\nthat our conclusions cannot be improved without additional assumptions on the\nsequence of random matrices $\\{{\\bf A}_n: n \\in \\mathbb{N}^*\\}$, and in\nparticular that no Gaussian or exponential high probability bounds can hold.\nFinally, we pay a particular attention to establishing bounds with sharp order\nwith respect to the number of iterations and the stepsize and whose leading\nterms contain the covariance matrices appearing in the central limit theorems.",
          "link": "http://arxiv.org/abs/2106.01257",
          "publishedOn": "2021-06-03T02:10:36.412Z",
          "wordCount": 642,
          "title": "Tight High Probability Bounds for Linear Stochastic Approximation with Fixed Stepsize. (arXiv:2106.01257v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01325",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lindner_D/0/1/0/all/0/1\">David Lindner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heidari_H/0/1/0/all/0/1\">Hoda Heidari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1\">Andreas Krause</a>",
          "description": "Machine Learning (ML) increasingly informs the allocation of opportunities to\nindividuals and communities in areas such as lending, education, employment,\nand beyond. Such decisions often impact their subjects' future characteristics\nand capabilities in an a priori unknown fashion. The decision-maker, therefore,\nfaces exploration-exploitation dilemmas akin to those in multi-armed bandits.\nFollowing prior work, we model communities as arms. To capture the long-term\neffects of ML-based allocation decisions, we study a setting in which the\nreward from each arm evolves every time the decision-maker pulls that arm. We\nfocus on reward functions that are initially increasing in the number of pulls\nbut may become (and remain) decreasing after a certain point. We argue that an\nacceptable sequential allocation of opportunities must take an arm's potential\nfor growth into account. We capture these considerations through the notion of\npolicy regret, a much stronger notion than the often-studied external regret,\nand present an algorithm with provably sub-linear policy regret for\nsufficiently long time horizons. We empirically compare our algorithm with\nseveral baselines and find that it consistently outperforms them, in particular\nfor long time horizons.",
          "link": "http://arxiv.org/abs/2106.01325",
          "publishedOn": "2021-06-03T02:10:36.405Z",
          "wordCount": 627,
          "title": "Addressing the Long-term Impact of ML Decisions via Policy Regret. (arXiv:2106.01325v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01315",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jing Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yushun Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zheng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mietchen_D/0/1/0/all/0/1\">Daniel Mietchen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jundong Li</a>",
          "description": "To mitigate the spread of COVID-19 pandemic, decision-makers and public\nauthorities have announced various non-pharmaceutical policies. Analyzing the\ncausal impact of these policies in reducing the spread of COVID-19 is important\nfor future policy-making. The main challenge here is the existence of\nunobserved confounders (e.g., vigilance of residents). Besides, as the\nconfounders may be time-varying during COVID-19 (e.g., vigilance of residents\nchanges in the course of the pandemic), it is even more difficult to capture\nthem. In this paper, we study the problem of assessing the causal effects of\ndifferent COVID-19 related policies on the outbreak dynamics in different\ncounties at any given time period. To this end, we integrate data about\ndifferent COVID-19 related policies (treatment) and outbreak dynamics (outcome)\nfor different United States counties over time and analyze them with respect to\nvariables that can infer the confounders, including the covariates of different\ncounties, their relational information and historical information. Based on\nthese data, we develop a neural network based causal effect estimation\nframework which leverages above information in observational data and learns\nthe representations of time-varying (unobserved) confounders. In this way, it\nenables us to quantify the causal impact of policies at different\ngranularities, ranging from a category of policies with a certain goal to a\nspecific policy type in this category. Besides, experimental results also\nindicate the effectiveness of our proposed framework in capturing the\nconfounders for quantifying the causal impact of different policies. More\nspecifically, compared with several baseline methods, our framework captures\nthe outbreak dynamics more accurately, and our assessment of policies is more\nconsistent with existing epidemiological studies of COVID-19.",
          "link": "http://arxiv.org/abs/2106.01315",
          "publishedOn": "2021-06-03T02:10:36.400Z",
          "wordCount": 770,
          "title": "Assessing the Causal Impact of COVID-19 Related Policies on Outbreak Dynamics: A Case Study in the US. (arXiv:2106.01315v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01364",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1\">Jong-Chyi Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maji_S/0/1/0/all/0/1\">Subhransu Maji</a>",
          "description": "Semi-iNat is a challenging dataset for semi-supervised classification with a\nlong-tailed distribution of classes, fine-grained categories, and domain shifts\nbetween labeled and unlabeled data. This dataset is behind the second iteration\nof the semi-supervised recognition challenge to be held at the FGVC8 workshop\nat CVPR 2021. Different from the previous one, this dataset (i) includes images\nof species from different kingdoms in the natural taxonomy, (ii) is at a larger\nscale --- with 810 in-class and 1629 out-of-class species for a total of 330k\nimages, and (iii) does not provide in/out-of-class labels, but provides coarse\ntaxonomic labels (kingdom and phylum) for the unlabeled images. This document\ndescribes baseline results and the details of the dataset which is available\nhere: \\url{https://github.com/cvl-umass/semi-inat-2021}.",
          "link": "http://arxiv.org/abs/2106.01364",
          "publishedOn": "2021-06-03T02:10:36.395Z",
          "wordCount": 563,
          "title": "The Semi-Supervised iNaturalist Challenge at the FGVC8 Workshop. (arXiv:2106.01364v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01254",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Resnick_P/0/1/0/all/0/1\">Paul Resnick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_Y/0/1/0/all/0/1\">Yuqing Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schoenebeck_G/0/1/0/all/0/1\">Grant Schoenebeck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weninger_T/0/1/0/all/0/1\">Tim Weninger</a>",
          "description": "In many classification tasks, the ground truth is either noisy or subjective.\nExamples include: which of two alternative paper titles is better? is this\ncomment toxic? what is the political leaning of this news article? We refer to\nsuch tasks as survey settings because the ground truth is defined through a\nsurvey of one or more human raters. In survey settings, conventional\nmeasurements of classifier accuracy such as precision, recall, and\ncross-entropy confound the quality of the classifier with the level of\nagreement among human raters. Thus, they have no meaningful interpretation on\ntheir own. We describe a procedure that, given a dataset with predictions from\na classifier and K ratings per item, rescales any accuracy measure into one\nthat has an intuitive interpretation. The key insight is to score the\nclassifier not against the best proxy for the ground truth, such as a majority\nvote of the raters, but against a single human rater at a time. That score can\nbe compared to other predictors' scores, in particular predictors created by\ncombining labels from several other human raters. The survey equivalence of any\nclassifier is the minimum number of raters needed to produce the same expected\nscore as that found for the classifier.",
          "link": "http://arxiv.org/abs/2106.01254",
          "publishedOn": "2021-06-03T02:10:36.385Z",
          "wordCount": 642,
          "title": "Survey Equivalence: A Procedure for Measuring Classifier Accuracy Against Human Labels. (arXiv:2106.01254v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01135",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aznag_A/0/1/0/all/0/1\">Abdellah Aznag</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_V/0/1/0/all/0/1\">Vineet Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perivier_N/0/1/0/all/0/1\">Noemie Perivier</a>",
          "description": "We consider a dynamic assortment selection problem where a seller has a fixed\ninventory of $N$ substitutable products and faces an unknown demand that\narrives sequentially over $T$ periods. In each period, the seller needs to\ndecide on the assortment of products (of cardinality at most $K$) to offer to\nthe customers. The customer's response follows an unknown multinomial logit\nmodel (MNL) with parameters $v$. The goal of the seller is to maximize the\ntotal expected revenue given the fixed initial inventory of $N$ products. We\ngive a policy that achieves a regret of $\\tilde O\\left(K \\sqrt{K N T}\\left(1 +\n\\frac{\\sqrt{v_{\\max}}}{q_{\\min}}\\text{OPT}\\right) \\right)$ under a mild\nassumption on the model parameters. In particular, our policy achieves a\nnear-optimal $\\tilde O(\\sqrt{T})$ regret in the large inventory setting.\n\nOur policy builds upon the UCB-based approach for MNL-bandit without\ninventory constraints in [1] and addresses the inventory constraints through an\nexponentially sized LP for which we present a tractable approximation while\nkeeping the $\\tilde O(\\sqrt{T})$ regret bound.",
          "link": "http://arxiv.org/abs/2106.01135",
          "publishedOn": "2021-06-03T02:10:36.372Z",
          "wordCount": 582,
          "title": "MNL-Bandit with Knapsacks. (arXiv:2106.01135v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01336",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kamath_G/0/1/0/all/0/1\">Gautam Kamath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xingtu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Huanyu Zhang</a>",
          "description": "We study stochastic convex optimization with heavy-tailed data under the\nconstraint of differential privacy. Most prior work on this problem is\nrestricted to the case where the loss function is Lipschitz. Instead, as\nintroduced by Wang, Xiao, Devadas, and Xu, we study general convex loss\nfunctions with the assumption that the distribution of gradients has bounded\n$k$-th moments. We provide improved upper bounds on the excess population risk\nunder approximate differential privacy of\n$\\tilde{O}\\left(\\sqrt{\\frac{d}{n}}+\\left(\\frac{d}{\\epsilon\nn}\\right)^{\\frac{k-1}{k}}\\right)$ and\n$\\tilde{O}\\left(\\frac{d}{n}+\\left(\\frac{d}{\\epsilon\nn}\\right)^{\\frac{2k-2}{k}}\\right)$ for convex and strongly convex loss\nfunctions, respectively. We also prove nearly-matching lower bounds under the\nconstraint of pure differential privacy, giving strong evidence that our bounds\nare tight.",
          "link": "http://arxiv.org/abs/2106.01336",
          "publishedOn": "2021-06-03T02:10:36.342Z",
          "wordCount": 558,
          "title": "Improved Rates for Differentially Private Stochastic Convex Optimization with Heavy-Tailed Data. (arXiv:2106.01336v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01216",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kandemir_M/0/1/0/all/0/1\">Melih Kandemir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akgul_A/0/1/0/all/0/1\">Abdullah Akg&#xfc;l</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haussmann_M/0/1/0/all/0/1\">Manuel Haussmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Unal_G/0/1/0/all/0/1\">Gozde Unal</a>",
          "description": "A probabilistic classifier with reliable predictive uncertainties i) fits\nsuccessfully to the target domain data, ii) provides calibrated class\nprobabilities in difficult regions of the target domain (e.g. class overlap),\nand iii) accurately identifies queries coming out of the target domain and\nreject them. We introduce an original combination of evidential deep learning,\nneural processes, and neural Turing machines capable of providing all three\nessential properties mentioned above for total uncertainty quantification. We\nobserve our method on three image classification benchmarks and two neural net\narchitectures to consistently give competitive or superior scores with respect\nto multiple uncertainty quantification metrics against state-of-the-art methods\nexplicitly tailored to one or a few of them. Our unified solution delivers an\nimplementation-friendly and computationally efficient recipe for safety\nclearance and provides intellectual economy to an investigation of algorithmic\nroots of epistemic awareness in deep neural nets.",
          "link": "http://arxiv.org/abs/2106.01216",
          "publishedOn": "2021-06-03T02:10:36.333Z",
          "wordCount": 555,
          "title": "Evidential Turing Processes. (arXiv:2106.01216v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01282",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gallagher_I/0/1/0/all/0/1\">Ian Gallagher</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Jones_A/0/1/0/all/0/1\">Andrew Jones</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rubin_Delanchy_P/0/1/0/all/0/1\">Patrick Rubin-Delanchy</a>",
          "description": "We consider the problem of embedding a dynamic network, to obtain\ntime-evolving vector representations of each node, which can then be used to\ndescribe the changes in behaviour of a single node, one or more communities, or\nthe entire graph. Given this open-ended remit, we wish to guarantee stability\nin the spatio-temporal positioning of the nodes: assigning the same position,\nup to noise, to nodes behaving similarly at a given time (cross-sectional\nstability) and a constant position, up to noise, to a single node behaving\nsimilarly across different times (longitudinal stability). These properties are\ndefined formally within a generic dynamic latent position model. By showing how\nthis model can be recast as a multilayer random dot product graph, we\ndemonstrate that unfolded adjacency spectral embedding satisfies both stability\nconditions, allowing, for example, spatio-temporal clustering under the dynamic\nstochastic block model. We also show how alternative methods, such as omnibus,\nindependent or time-averaged spectral embedding, lack one or the other form of\nstability.",
          "link": "http://arxiv.org/abs/2106.01282",
          "publishedOn": "2021-06-03T02:10:36.327Z",
          "wordCount": 598,
          "title": "Spectral embedding for dynamic networks with stability guarantees. (arXiv:2106.01282v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01124",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Liu_J/0/1/0/all/0/1\">Jun Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mei_K/0/1/0/all/0/1\">Kai Mei</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ma_D/0/1/0/all/0/1\">Dongtang Ma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wei_J/0/1/0/all/0/1\">Jibo Wei</a>",
          "description": "Deep Neural Network (DNN)-based physical layer techniques are attracting\nconsiderable interest due to their potential to enhance communication systems.\nHowever, most studies in the physical layer have tended to focus on the\nimplement of DNN but not to theoretically understand how does a DNN work in a\ncommunication system. In this letter, we aim to quantitatively analyse why DNNs\ncan achieve comparable performance in the physical layer comparing with\ntraditional techniques and its cost in terms of computational complexity. We\nfurther investigate and also experimentally validate how information is flown\nin a DNN-based communication system under the information theoretic concepts.",
          "link": "http://arxiv.org/abs/2106.01124",
          "publishedOn": "2021-06-03T02:10:36.314Z",
          "wordCount": 557,
          "title": "Opening the Black Box of Deep Neural Networks in Physical Layer Communication. (arXiv:2106.01124v1 [eess.SP])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01132",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dufumier_B/0/1/0/all/0/1\">Benoit Dufumier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gori_P/0/1/0/all/0/1\">Pietro Gori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Battaglia_I/0/1/0/all/0/1\">Ilaria Battaglia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Victor_J/0/1/0/all/0/1\">Julie Victor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grigis_A/0/1/0/all/0/1\">Antoine Grigis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duchesnay_E/0/1/0/all/0/1\">Edouard Duchesnay</a>",
          "description": "Deep Learning (DL) and specifically CNN models have become a de facto method\nfor a wide range of vision tasks, outperforming traditional machine learning\n(ML) methods. Consequently, they drew a lot of attention in the neuroimaging\nfield in particular for phenotype prediction or computer-aided diagnosis.\nHowever, most of the current studies often deal with small single-site cohorts,\nalong with a specific pre-processing pipeline and custom CNN architectures,\nwhich make them difficult to compare to. We propose an extensive benchmark of\nrecent state-of-the-art (SOTA) 3D CNN, evaluating also the benefits of data\naugmentation and deep ensemble learning, on both Voxel-Based Morphometry (VBM)\npre-processing and quasi-raw images. Experiments were conducted on a large\nmulti-site 3D brain anatomical MRI data-set comprising N=10k scans on 3\nchallenging tasks: age prediction, sex classification, and schizophrenia\ndiagnosis. We found that all models provide significantly better predictions\nwith VBM images than quasi-raw data. This finding evolved as the training set\napproaches 10k samples where quasi-raw data almost reach the performance of\nVBM. Moreover, we showed that linear models perform comparably with SOTA CNN on\nVBM data. We also demonstrated that DenseNet and tiny-DenseNet, a lighter\nversion that we proposed, provide a good compromise in terms of performance in\nall data regime. Therefore, we suggest to employ them as the architectures by\ndefault. Critically, we also showed that current CNN are still very biased\ntowards the acquisition site, even when trained with N=10k multi-site images.\nIn this context, VBM pre-processing provides an efficient way to limit this\nsite effect. Surprisingly, we did not find any clear benefit from data\naugmentation techniques. Finally, we proved that deep ensemble learning is well\nsuited to re-calibrate big CNN models without sacrificing performance.",
          "link": "http://arxiv.org/abs/2106.01132",
          "publishedOn": "2021-06-03T02:10:36.302Z",
          "wordCount": 744,
          "title": "Benchmarking CNN on 3D Anatomical Brain MRI: Architectures, Data Augmentation and Deep Ensemble Learning. (arXiv:2106.01132v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01260",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Whiteley_N/0/1/0/all/0/1\">Nick Whiteley</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gray_A/0/1/0/all/0/1\">Annie Gray</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rubin_Delanchy_P/0/1/0/all/0/1\">Patrick Rubin-Delanchy</a>",
          "description": "Given a graph or similarity matrix, we consider the problem of recovering a\nnotion of true distance between the nodes, and so their true positions. Through\nnew insights into the manifold geometry underlying a generic latent position\nmodel, we show that this can be accomplished in two steps: matrix\nfactorisation, followed by nonlinear dimension reduction. This combination is\neffective because the point cloud obtained in the first step lives close to a\nmanifold in which latent distance is encoded as geodesic distance. Hence, a\nnonlinear dimension reduction tool, approximating geodesic distance, can\nrecover the latent positions, up to a simple transformation. We give a detailed\naccount of the case where spectral embedding is used, followed by Isomap, and\nprovide encouraging experimental evidence for other combinations of techniques.",
          "link": "http://arxiv.org/abs/2106.01260",
          "publishedOn": "2021-06-03T02:10:36.280Z",
          "wordCount": 564,
          "title": "Matrix factorisation and the interpretation of geodesic distance. (arXiv:2106.01260v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01151",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bjorck_J/0/1/0/all/0/1\">Johan Bjorck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomes_C/0/1/0/all/0/1\">Carla P. Gomes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weinberger_K/0/1/0/all/0/1\">Kilian Q. Weinberger</a>",
          "description": "In computer vision and natural language processing, innovations in model\narchitecture that lead to increases in model capacity have reliably translated\ninto gains in performance. In stark contrast with this trend, state-of-the-art\nreinforcement learning (RL) algorithms often use only small MLPs, and gains in\nperformance typically originate from algorithmic innovations. It is natural to\nhypothesize that small datasets in RL necessitate simple models to avoid\noverfitting; however, this hypothesis is untested. In this paper we investigate\nhow RL agents are affected by exchanging the small MLPs with larger modern\nnetworks with skip connections and normalization, focusing specifically on soft\nactor-critic (SAC) algorithms. We verify, empirically, that na\\\"ively adopting\nsuch architectures leads to instabilities and poor performance, likely\ncontributing to the popularity of simple models in practice. However, we show\nthat dataset size is not the limiting factor, and instead argue that intrinsic\ninstability from the actor in SAC taking gradients through the critic is the\nculprit. We demonstrate that a simple smoothing method can mitigate this issue,\nwhich enables stable training with large modern architectures. After smoothing,\nlarger models yield dramatic performance improvements for state-of-the-art\nagents -- suggesting that more \"easy\" gains may be had by focusing on model\narchitectures in addition to algorithmic innovations.",
          "link": "http://arxiv.org/abs/2106.01151",
          "publishedOn": "2021-06-03T02:10:36.274Z",
          "wordCount": 622,
          "title": "Towards Deeper Deep Reinforcement Learning. (arXiv:2106.01151v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01114",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Rioual_Y/0/1/0/all/0/1\">Yohann Rioual</a> (1), <a href=\"http://arxiv.org/find/eess/1/au:+Moullec_Y/0/1/0/all/0/1\">Yannick Le Moullec</a> (2), <a href=\"http://arxiv.org/find/eess/1/au:+Laurent_J/0/1/0/all/0/1\">Johann Laurent</a> (1), <a href=\"http://arxiv.org/find/eess/1/au:+Khan_M/0/1/0/all/0/1\">Muhidul Islam Khan</a> (2), <a href=\"http://arxiv.org/find/eess/1/au:+Diguet_J/0/1/0/all/0/1\">Jean-Philippe Diguet</a> (3) ((1) Lab-STICC, University Bretagne Sud, (2) Thomas Johann Seebeck Department of Electronics, Tallinn University of Technology, (3) IRL CNRS CROSSING)",
          "description": "Interest in remote monitoring has grown thanks to recent advancements in\nInternet-of-Things (IoT) paradigms. New applications have emerged, using small\ndevices called sensor nodes capable of collecting data from the environment and\nprocessing it. However, more and more data are processed and transmitted with\nlonger operational periods. At the same, the battery technologies have not\nimproved fast enough to cope with these increasing needs. This makes the energy\nconsumption issue increasingly challenging and thus, miniaturized energy\nharvesting devices have emerged to complement traditional energy sources.\nNevertheless, the harvested energy fluctuates significantly during the node\noperation, increasing uncertainty in actually available energy resources.\nRecently, approaches in energy management have been developed, in particular\nusing reinforcement learning approaches. However, in reinforcement learning,\nthe algorithm's performance relies greatly on the reward function. In this\npaper, we present two contributions. First, we explore five different reward\nfunctions to identify the most suitable variables to use in such functions to\nobtain the desired behaviour. Experiments were conducted using the Q-learning\nalgorithm to adjust the energy consumption depending on the energy harvested.\nResults with the five reward functions illustrate how the choice thereof\nimpacts the energy consumption of the node. Secondly, we propose two additional\nreward functions able to find the compromise between energy consumption and a\nnode performance using a non-fixed balancing parameter. Our simulation results\nshow that the proposed reward functions adjust the node's performance depending\non the battery level and reduce the learning time.",
          "link": "http://arxiv.org/abs/2106.01114",
          "publishedOn": "2021-06-03T02:10:36.268Z",
          "wordCount": 721,
          "title": "Design and Comparison of Reward Functions in Reinforcement Learning for Energy Management of Sensor Nodes. (arXiv:2106.01114v1 [eess.SY])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01128",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Scetbon_M/0/1/0/all/0/1\">Meyer Scetbon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peyre_G/0/1/0/all/0/1\">Gabriel Peyr&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cuturi_M/0/1/0/all/0/1\">Marco Cuturi</a>",
          "description": "The ability to compare and align related datasets living in heterogeneous\nspaces plays an increasingly important role in machine learning. The\nGromov-Wasserstein (GW) formalism can help tackle this problem. Its main goal\nis to seek an assignment (more generally a coupling matrix) that can register\npoints across otherwise incomparable datasets. As a non-convex and quadratic\ngeneralization of optimal transport (OT), GW is NP-hard. Yet, heuristics are\nknown to work reasonably well in practice, the state of the art approach being\nto solve a sequence of nested regularized OT problems. While popular, that\nheuristic remains too costly to scale, with cubic complexity in the number of\nsamples $n$. We show in this paper how a recent variant of the Sinkhorn\nalgorithm can substantially speed up the resolution of GW. That variant\nrestricts the set of admissible couplings to those admitting a low rank\nfactorization as the product of two sub-couplings. By updating alternatively\neach sub-coupling, our algorithm computes a stationary point of the problem in\nquadratic time with respect to the number of samples. When cost matrices have\nthemselves low rank, our algorithm has time complexity $\\mathcal{O}(n)$. We\ndemonstrate the efficiency of our method on simulated and real data.",
          "link": "http://arxiv.org/abs/2106.01128",
          "publishedOn": "2021-06-03T02:10:36.262Z",
          "wordCount": 628,
          "title": "Linear-Time Gromov Wasserstein Distances using Low Rank Couplings and Costs. (arXiv:2106.01128v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01202",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Fermanian_A/0/1/0/all/0/1\">Adeline Fermanian</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Marion_P/0/1/0/all/0/1\">Pierre Marion</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vert_J/0/1/0/all/0/1\">Jean-Philippe Vert</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Biau_G/0/1/0/all/0/1\">G&#xe9;rard Biau</a>",
          "description": "Building on the interpretation of a recurrent neural network (RNN) as a\ncontinuous-time neural differential equation, we show, under appropriate\nconditions, that the solution of a RNN can be viewed as a linear function of a\nspecific feature set of the input sequence, known as the signature. This\nconnection allows us to frame a RNN as a kernel method in a suitable\nreproducing kernel Hilbert space. As a consequence, we obtain theoretical\nguarantees on generalization and stability for a large class of recurrent\nnetworks. Our results are illustrated on simulated datasets.",
          "link": "http://arxiv.org/abs/2106.01202",
          "publishedOn": "2021-06-03T02:10:36.246Z",
          "wordCount": 528,
          "title": "Framing RNN as a kernel method: A neural ODE approach. (arXiv:2106.01202v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01258",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xingyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banks_A/0/1/0/all/0/1\">Alec Banks</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cox_V/0/1/0/all/0/1\">Victoria Cox</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flynn_D/0/1/0/all/0/1\">David Flynn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schewe_S/0/1/0/all/0/1\">Sven Schewe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xiaowei Huang</a>",
          "description": "The utilisation of Deep Learning (DL) is advancing into increasingly more\nsophisticated applications. While it shows great potential to provide\ntransformational capabilities, DL also raises new challenges regarding its\nreliability in critical functions. In this paper, we present a model-agnostic\nreliability assessment method for DL classifiers, based on evidence from\nrobustness evaluation and the operational profile (OP) of a given application.\nWe partition the input space into small cells and then \"assemble\" their\nrobustness (to the ground truth) according to the OP, where estimators on the\ncells' robustness and OPs are provided. Reliability estimates in terms of the\nprobability of misclassification per input (pmi) can be derived together with\nconfidence levels. A prototype tool is demonstrated with simplified case\nstudies. Model assumptions and extension to real-world applications are also\ndiscussed. While our model easily uncovers the inherent difficulties of\nassessing the DL dependability (e.g. lack of data with ground truth and\nscalability issues), we provide preliminary/compromised solutions to advance in\nthis research direction.",
          "link": "http://arxiv.org/abs/2106.01258",
          "publishedOn": "2021-06-03T02:10:36.241Z",
          "wordCount": 619,
          "title": "Assessing the Reliability of Deep Learning Classifiers Through Robustness Evaluation and Operational Profiles. (arXiv:2106.01258v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01143",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Li_M/0/1/0/all/0/1\">Matthew Li</a>, <a href=\"http://arxiv.org/find/math/1/au:+Demanet_L/0/1/0/all/0/1\">Laurent Demanet</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zepeda_Nunez_L/0/1/0/all/0/1\">Leonardo Zepeda-N&#xfa;&#xf1;ez</a>",
          "description": "We propose an end-to-end deep learning framework that comprehensively solves\nthe inverse wave scattering problem across all length scales. Our framework\nconsists of the newly introduced wide-band butterfly network coupled with a\nsimple training procedure that dynamically injects noise during training. While\nour trained network provides competitive results in classical imaging regimes,\nmost notably it also succeeds in the super-resolution regime where other\ncomparable methods fail. This encompasses both (i) reconstruction of scatterers\nwith sub-wavelength geometric features, and (ii) accurate imaging when two or\nmore scatterers are separated by less than the classical diffraction limit. We\ndemonstrate these properties are retained even in the presence of strong noise\nand extend to scatterers not previously seen in the training set. In addition,\nour network is straightforward to train requiring no restarts and has an online\nruntime that is an order of magnitude faster than optimization-based\nalgorithms. We perform experiments with a variety of wave scattering mediums\nand we demonstrate that our proposed framework outperforms both classical\ninversion and competing network architectures that specialize in oscillatory\nwave scattering data.",
          "link": "http://arxiv.org/abs/2106.01143",
          "publishedOn": "2021-06-03T02:10:36.149Z",
          "wordCount": 626,
          "title": "Accurate and Robust Deep Learning Framework for Solving Wave-Based Inverse Problems in the Super-Resolution Regime. (arXiv:2106.01143v1 [math.NA])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00897",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xue_W/0/1/0/all/0/1\">Wanqi Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Youzhi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuxin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinrun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1\">Bo An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeo_C/0/1/0/all/0/1\">Chai Kiat Yeo</a>",
          "description": "Securing networked infrastructures is important in the real world. The\nproblem of deploying security resources to protect against an attacker in\nnetworked domains can be modeled as Network Security Games (NSGs).\nUnfortunately, existing approaches, including the deep learning-based\napproaches, are inefficient to solve large-scale extensive-form NSGs. In this\npaper, we propose a novel learning paradigm, NSG-NFSP, to solve large-scale\nextensive-form NSGs based on Neural Fictitious Self-Play (NFSP). Our main\ncontributions include: i) reforming the best response (BR) policy network in\nNFSP to be a mapping from action-state pair to action-value, to make the\ncalculation of BR possible in NSGs; ii) converting the average policy network\nof an NFSP agent into a metric-based classifier, helping the agent to assign\ndistributions only on legal actions rather than all actions; iii) enabling NFSP\nwith high-level actions, which can benefit training efficiency and stability in\nNSGs; and iv) leveraging information contained in graphs of NSGs by learning\nefficient graph node embeddings. Our algorithm significantly outperforms\nstate-of-the-art algorithms in both scalability and solution quality.",
          "link": "http://arxiv.org/abs/2106.00897",
          "publishedOn": "2021-06-03T02:10:36.138Z",
          "wordCount": 626,
          "title": "Solving Large-Scale Extensive-Form Network Security Games via Neural Fictitious Self-Play. (arXiv:2106.00897v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00808",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Saengkyongam_S/0/1/0/all/0/1\">Sorawit Saengkyongam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thams_N/0/1/0/all/0/1\">Nikolaj Thams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1\">Jonas Peters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfister_N/0/1/0/all/0/1\">Niklas Pfister</a>",
          "description": "In the past decade, contextual bandit and reinforcement learning algorithms\nhave been successfully used in various interactive learning systems such as\nonline advertising, recommender systems, and dynamic pricing. However, they\nhave yet to be widely adopted in high-stakes application domains, such as\nhealthcare. One reason may be that existing approaches assume that the\nunderlying mechanisms are static in the sense that they do not change over time\nor over different environments. In many real world systems, however, the\nmechanisms are subject to shifts across environments which may invalidate the\nstatic environment assumption. In this paper, we tackle the problem of\nenvironmental shifts under the framework of offline contextual bandits. We view\nthe environmental shift problem through the lens of causality and propose\nmulti-environment contextual bandits that allow for changes in the underlying\nmechanisms. We adopt the concept of invariance from the causality literature\nand introduce the notion of policy invariance. We argue that policy invariance\nis only relevant if unobserved confounders are present and show that, in that\ncase, an optimal invariant policy is guaranteed, under certain assumptions, to\ngeneralize across environments. Our results do not only provide a solution to\nthe environmental shift problem but also establish concrete connections among\ncausality, invariance and contextual bandits.",
          "link": "http://arxiv.org/abs/2106.00808",
          "publishedOn": "2021-06-03T02:10:36.133Z",
          "wordCount": 635,
          "title": "Invariant Policy Learning: A Causal Perspective. (arXiv:2106.00808v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00984",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yunfeng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_G/0/1/0/all/0/1\">Guoxian Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1\">Zhongmin Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1\">Lizhen Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Domeniconi_C/0/1/0/all/0/1\">Carlotta Domeniconi</a>",
          "description": "Partial-label learning (PLL) generally focuses on inducing a noise-tolerant\nmulti-class classifier by training on overly-annotated samples, each of which\nis annotated with a set of labels, but only one is the valid label. A basic\npromise of existing PLL solutions is that there are sufficient partial-label\n(PL) samples for training. However, it is more common than not to have just few\nPL samples at hand when dealing with new tasks. Furthermore, existing few-shot\nlearning algorithms assume precise labels of the support set; as such,\nirrelevant labels may seriously mislead the meta-learner and thus lead to a\ncompromised performance. How to enable PLL under a few-shot learning setting is\nan important problem, but not yet well studied. In this paper, we introduce an\napproach called FsPLL (Few-shot PLL). FsPLL first performs adaptive distance\nmetric learning by an embedding network and rectifying prototypes on the tasks\npreviously encountered. Next, it calculates the prototype of each class of a\nnew task in the embedding network. An unseen example can then be classified via\nits distance to each prototype. Experimental results on widely-used few-shot\ndatasets (Omniglot and miniImageNet) demonstrate that our FsPLL can achieve a\nsuperior performance than the state-of-the-art methods across different\nsettings, and it needs fewer samples for quickly adapting to new tasks.",
          "link": "http://arxiv.org/abs/2106.00984",
          "publishedOn": "2021-06-03T02:10:36.127Z",
          "wordCount": 649,
          "title": "Few-Shot Partial-Label Learning. (arXiv:2106.00984v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00999",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Krouka_M/0/1/0/all/0/1\">Mounssif Krouka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elgabli_A/0/1/0/all/0/1\">Anis Elgabli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Issaid_C/0/1/0/all/0/1\">Chaouki ben Issaid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bennis_M/0/1/0/all/0/1\">Mehdi Bennis</a>",
          "description": "Split-learning (SL) has recently gained popularity due to its inherent\nprivacy-preserving capabilities and ability to enable collaborative inference\nfor devices with limited computational power. Standard SL algorithms assume an\nideal underlying digital communication system and ignore the problem of scarce\ncommunication bandwidth. However, for a large number of agents, limited\nbandwidth resources, and time-varying communication channels, the communication\nbandwidth can become the bottleneck. To address this challenge, in this work,\nwe propose a novel SL framework to solve the remote inference problem that\nintroduces an additional layer at the agent side and constrains the choices of\nthe weights and the biases to ensure over the air aggregation. Hence, the\nproposed approach maintains constant communication cost with respect to the\nnumber of agents enabling remote inference under limited bandwidth. Numerical\nresults show that our proposed algorithm significantly outperforms the digital\nimplementation in terms of communication-efficiency, especially as the number\nof agents grows large.",
          "link": "http://arxiv.org/abs/2106.00999",
          "publishedOn": "2021-06-03T02:10:36.111Z",
          "wordCount": 597,
          "title": "Communication-Efficient Split Learning Based on Analog Communication and Over the Air Aggregation. (arXiv:2106.00999v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00906",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Heaton_H/0/1/0/all/0/1\">Howard Heaton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McKenzie_D/0/1/0/all/0/1\">Daniel McKenzie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qiuwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_S/0/1/0/all/0/1\">Samy Wu Fung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Osher_S/0/1/0/all/0/1\">Stanley Osher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_W/0/1/0/all/0/1\">Wotao Yin</a>",
          "description": "Systems of interacting agents can often be modeled as contextual games, where\nthe context encodes additional information, beyond the control of any agent\n(e.g. weather for traffic and fiscal policy for market economies). In such\nsystems, the most likely outcome is given by a Nash equilibrium. In many\npractical settings, only game equilibria are observed, while the optimal\nparameters for a game model are unknown. This work introduces Nash Fixed Point\nNetworks (N-FPNs), a class of implicit-depth neural networks that output Nash\nequilibria of contextual games. The N-FPN architecture fuses data-driven\nmodeling with provided constraints. Given equilibrium observations of a\ncontextual game, N-FPN parameters are learnt to predict equilibria outcomes\ngiven only the context. We present an end-to-end training scheme for N-FPNs\nthat is simple and memory efficient to implement with existing\nautodifferentiation tools. N-FPNs also exploit a novel constraint decoupling\nscheme to avoid costly projections. Provided numerical examples show the\nefficacy of N-FPNs on atomic and non-atomic games (e.g. traffic routing).",
          "link": "http://arxiv.org/abs/2106.00906",
          "publishedOn": "2021-06-03T02:10:36.087Z",
          "wordCount": 603,
          "title": "Learn to Predict Equilibria via Fixed Point Networks. (arXiv:2106.00906v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00786",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hase_P/0/1/0/all/0/1\">Peter Hase</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_H/0/1/0/all/0/1\">Harry Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>",
          "description": "Feature importance (FI) estimates are a popular form of explanation, and they\nare commonly created and evaluated by computing the change in model confidence\ncaused by removing certain input features at test time. For example, in the\nstandard Sufficiency metric, only the top-k most important tokens are kept. In\nthis paper, we study several under-explored dimensions of FI-based\nexplanations, providing conceptual and empirical improvements for this form of\nexplanation. First, we advance a new argument for why it can be problematic to\nremove features from an input when creating or evaluating explanations: the\nfact that these counterfactual inputs are out-of-distribution (OOD) to models\nimplies that the resulting explanations are socially misaligned. The crux of\nthe problem is that the model prior and random weight initialization influence\nthe explanations (and explanation metrics) in unintended ways. To resolve this\nissue, we propose a simple alteration to the model training process, which\nresults in more socially aligned explanations and metrics. Second, we compare\namong five approaches for removing features from model inputs. We find that\nsome methods produce more OOD counterfactuals than others, and we make\nrecommendations for selecting a feature-replacement function. Finally, we\nintroduce four search-based methods for identifying FI explanations and compare\nthem to strong baselines, including LIME, Integrated Gradients, and random\nsearch. On experiments with six diverse text classification datasets, we find\nthat the only method that consistently outperforms random search is a Parallel\nLocal Search that we introduce. Improvements over the second-best method are as\nlarge as 5.4 points for Sufficiency and 17 points for Comprehensiveness. All\nsupporting code is publicly available at\nhttps://github.com/peterbhase/ExplanationSearch.",
          "link": "http://arxiv.org/abs/2106.00786",
          "publishedOn": "2021-06-03T02:10:36.081Z",
          "wordCount": 711,
          "title": "Search Methods for Sufficient, Socially-Aligned Feature Importance Explanations with In-Distribution Counterfactuals. (arXiv:2106.00786v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00948",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Keyang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_T/0/1/0/all/0/1\">Tongzheng Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shikun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yihao Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a>",
          "description": "Deployed real-world machine learning applications are often subject to\nuncontrolled and even potentially malicious inputs. Those out-of-domain inputs\ncan lead to unpredictable outputs and sometimes catastrophic safety issues.\nPrior studies on out-of-domain detection require in-domain task labels and are\nlimited to supervised classification scenarios. Our work tackles the problem of\ndetecting out-of-domain samples with only unsupervised in-domain data. We\nutilize the latent representations of pre-trained transformers and propose a\nsimple yet effective method to transform features across all layers to\nconstruct out-of-domain detectors efficiently. Two domain-specific fine-tuning\napproaches are further proposed to boost detection accuracy. Our empirical\nevaluations of related methods on two datasets validate that our method greatly\nimproves out-of-domain detection ability in a more general scenario.",
          "link": "http://arxiv.org/abs/2106.00948",
          "publishedOn": "2021-06-03T02:10:36.076Z",
          "wordCount": 558,
          "title": "Unsupervised Out-of-Domain Detection via Pre-trained Transformers. (arXiv:2106.00948v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00910",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bhandari_V/0/1/0/all/0/1\">Vedant Bhandari</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kayacan_E/0/1/0/all/0/1\">Erkan Kayacan</a>",
          "description": "This paper demonstrates the applicability of the combination of concurrent\nlearning as a tool for parameter estimation and non-parametric Gaussian Process\nfor online disturbance learning. A control law is developed by using both\ntechniques sequentially in the context of feedback linearization. The\nconcurrent learning algorithm estimates the system parameters of structured\nuncertainty without requiring persistent excitation, which are used in the\ndesign of the feedback linearization law. Then, a non-parametric Gaussian\nProcess learns unstructured uncertainty. The closed-loop system stability for\nthe nth-order system is proven using the Lyapunov stability theorem. The\nsimulation results show that the tracking error is minimized (i) when true\nvalues of model parameters have not been provided, (ii) in the presence of\ndisturbances introduced once the parameters have converged to their true values\nand (iii) when system parameters have not converged to their true values in the\npresence of disturbances.",
          "link": "http://arxiv.org/abs/2106.00910",
          "publishedOn": "2021-06-03T02:10:36.072Z",
          "wordCount": 587,
          "title": "Concurrent Learning Based Tracking Control of Nonlinear Systems using Gaussian Process. (arXiv:2106.00910v1 [eess.SY])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00925",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yunqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Furui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhitang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lian_Q/0/1/0/all/0/1\">Qing Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Shoubo Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1\">Jianye Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yik-Chung Wu</a>",
          "description": "Domain generalization aims to learn knowledge invariant across different\ndistributions while semantically meaningful for downstream tasks from multiple\nsource domains, to improve the model's generalization ability on unseen target\ndomains. The fundamental objective is to understand the underlying \"invariance\"\nbehind these observational distributions and such invariance has been shown to\nhave a close connection to causality. While many existing approaches make use\nof the property that causal features are invariant across domains, we consider\nthe causal invariance of the average causal effect of the features to the\nlabels. This invariance regularizes our training approach in which\ninterventions are performed on features to enforce stability of the causal\nprediction by the classifier across domains. Our work thus sheds some light on\nthe domain generalization problem by introducing invariance of the mechanisms\ninto the learning process. Experiments on several benchmark datasets\ndemonstrate the performance of the proposed method against SOTAs.",
          "link": "http://arxiv.org/abs/2106.00925",
          "publishedOn": "2021-06-03T02:10:36.052Z",
          "wordCount": 585,
          "title": "Contrastive ACE: Domain Generalization Through Alignment of Causal Mechanisms. (arXiv:2106.00925v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00774",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Alvarez_Melis_D/0/1/0/all/0/1\">David Alvarez-Melis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schiff_Y/0/1/0/all/0/1\">Yair Schiff</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mroueh_Y/0/1/0/all/0/1\">Youssef Mroueh</a>",
          "description": "Gradient flows are a powerful tool for optimizing functionals in general\nmetric spaces, including the space of probabilities endowed with the\nWasserstein metric. A typical approach to solving this optimization problem\nrelies on its connection to the dynamic formulation of optimal transport and\nthe celebrated Jordan-Kinderlehrer-Otto (JKO) scheme. However, this formulation\ninvolves optimization over convex functions, which is challenging, especially\nin high dimensions. In this work, we propose an approach that relies on the\nrecently introduced input-convex neural networks (ICNN) to parameterize the\nspace of convex functions in order to approximate the JKO scheme, as well as in\ndesigning functionals over measures that enjoy convergence guarantees. We\nderive a computationally efficient implementation of this JKO-ICNN framework\nand use various experiments to demonstrate its feasibility and validity in\napproximating solutions of low-dimensional partial differential equations with\nknown solutions. We also explore the use of our JKO-ICNN approach in high\ndimensions with an experiment in controlled generation for molecular discovery.",
          "link": "http://arxiv.org/abs/2106.00774",
          "publishedOn": "2021-06-03T02:10:36.047Z",
          "wordCount": 598,
          "title": "Optimizing Functionals on the Space of Probabilities with Input Convex Neural Networks. (arXiv:2106.00774v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00769",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1\">Mike Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1\">Noah Goodman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1\">Stefano Ermon</a>",
          "description": "In traditional software programs, we take for granted how easy it is to debug\ncode by tracing program logic from variables back to input, apply unit tests\nand assertion statements to block erroneous behavior, and compose programs\ntogether. But as the programs we write grow more complex, it becomes hard to\napply traditional software to applications like computer vision or natural\nlanguage. Although deep learning programs have demonstrated strong performance\non these applications, they sacrifice many of the functionalities of\ntraditional software programs. In this paper, we work towards bridging the\nbenefits of traditional and deep learning programs by jointly training a\ngenerative model to constrain neural network activations to \"decode\" back to\ninputs. Doing so enables practitioners to probe and track information encoded\nin activation(s), apply assertion-like constraints on what information is\nencoded in an activation, and compose separate neural networks together in a\nplug-and-play fashion. In our experiments, we demonstrate applications of\ndecodable representations to out-of-distribution detection, adversarial\nexamples, calibration, and fairness -- while matching standard neural networks\nin accuracy.",
          "link": "http://arxiv.org/abs/2106.00769",
          "publishedOn": "2021-06-03T02:10:36.042Z",
          "wordCount": 604,
          "title": "Improving Compositionality of Neural Networks by Decoding Representations to Inputs. (arXiv:2106.00769v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00810",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Russo_A/0/1/0/all/0/1\">Alessio Russo</a>",
          "description": "Recent successes in the Machine Learning community have led to a steep\nincrease in the number of papers submitted to conferences. This increase made\nmore prominent some of the issues that affect the current review process used\nby these conferences. The review process has several issues that may undermine\nthe nature of scientific research, which is of being fully objective,\napolitical, unbiased and free of misconduct (such as plagiarism, cheating,\nimproper influence, and other improprieties). In this work, we study the\nproblem of reviewers' recruitment, infringements of the double-blind process,\nfraudulent behaviors, biases in numerical ratings, and the appendix phenomenon\n(i.e., the fact that it is becoming more common to publish results in the\nappendix section of a paper). For each of these problems, we provide a short\ndescription and possible solutions. The goal of this work is to raise awareness\nin the Machine Learning community regarding these issues.",
          "link": "http://arxiv.org/abs/2106.00810",
          "publishedOn": "2021-06-03T02:10:36.038Z",
          "wordCount": 576,
          "title": "Some Ethical Issues in the Review Process of Machine Learning Conferences. (arXiv:2106.00810v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00872",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kaushik_D/0/1/0/all/0/1\">Divyansh Kaushik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiela_D/0/1/0/all/0/1\">Douwe Kiela</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1\">Zachary C. Lipton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yih_W/0/1/0/all/0/1\">Wen-tau Yih</a>",
          "description": "In adversarial data collection (ADC), a human workforce interacts with a\nmodel in real time, attempting to produce examples that elicit incorrect\npredictions. Researchers hope that models trained on these more challenging\ndatasets will rely less on superficial patterns, and thus be less brittle.\nHowever, despite ADC's intuitive appeal, it remains unclear when training on\nadversarial datasets produces more robust models. In this paper, we conduct a\nlarge-scale controlled study focused on question answering, assigning workers\nat random to compose questions either (i) adversarially (with a model in the\nloop); or (ii) in the standard fashion (without a model). Across a variety of\nmodels and datasets, we find that models trained on adversarial data usually\nperform better on other adversarial datasets but worse on a diverse collection\nof out-of-domain evaluation sets. Finally, we provide a qualitative analysis of\nadversarial (vs standard) data, identifying key differences and offering\nguidance for future research.",
          "link": "http://arxiv.org/abs/2106.00872",
          "publishedOn": "2021-06-03T02:10:36.019Z",
          "wordCount": 607,
          "title": "On the Efficacy of Adversarial Data Collection for Question Answering: Results from a Large-Scale Randomized Study. (arXiv:2106.00872v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00967",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hy_T/0/1/0/all/0/1\">Truong Son Hy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kondor_R/0/1/0/all/0/1\">Risi Kondor</a>",
          "description": "In this paper, we propose Multiresolution Graph Networks (MGN) and\nMultiresolution Graph Variational Autoencoders (MGVAE) to learn and generate\ngraphs in a multiresolution and equivariant manner. At each resolution level,\nMGN employs higher order message passing to encode the graph while learning to\npartition it into mutually exclusive clusters and coarsening into a lower\nresolution. MGVAE constructs a hierarchical generative model based on MGN to\nvariationally autoencode the hierarchy of coarsened graphs. Our proposed\nframework is end-to-end permutation equivariant with respect to node ordering.\nOur methods have been successful with several generative tasks including link\nprediction on citation graphs, unsupervised molecular representation learning\nto predict molecular properties, molecular generation, general graph generation\nand graph-based image generation.",
          "link": "http://arxiv.org/abs/2106.00967",
          "publishedOn": "2021-06-03T02:10:36.014Z",
          "wordCount": 541,
          "title": "Multiresolution Graph Variational Autoencoder. (arXiv:2106.00967v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00958",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Almeida_D/0/1/0/all/0/1\">Diogo Almeida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winter_C/0/1/0/all/0/1\">Clemens Winter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaremba_W/0/1/0/all/0/1\">Wojciech Zaremba</a>",
          "description": "A core issue with learning to optimize neural networks has been the lack of\ngeneralization to real world problems. To address this, we describe a system\ndesigned from a generalization-first perspective, learning to update optimizer\nhyperparameters instead of model parameters directly using novel features,\nactions, and a reward function. This system outperforms Adam at all neural\nnetwork tasks including on modalities not seen during training. We achieve 2x\nspeedups on ImageNet, and a 2.5x speedup on a language modeling task using over\n5 orders of magnitude more compute than the training tasks.",
          "link": "http://arxiv.org/abs/2106.00958",
          "publishedOn": "2021-06-03T02:10:36.010Z",
          "wordCount": 527,
          "title": "A Generalizable Approach to Learning Optimizers. (arXiv:2106.00958v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00952",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dang_T/0/1/0/all/0/1\">Tuan-Anh Nguyen Dang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1\">Dat-Thanh Nguyen</a>",
          "description": "Information extraction from document images has received a lot of attention\nrecently, due to the need for digitizing a large volume of unstructured\ndocuments such as invoices, receipts, bank transfers, etc. In this paper, we\npropose a novel deep learning architecture for end-to-end information\nextraction on the 2D character-grid embedding of the document, namely the\n\\textit{Multi-Stage Attentional U-Net}. To effectively capture the textual and\nspatial relations between 2D elements, our model leverages a specialized\nmulti-stage encoder-decoders design, in conjunction with efficient uses of the\nself-attention mechanism and the box convolution. Experimental results on\ndifferent datasets show that our model outperforms the baseline U-Net\narchitecture by a large margin while using 40\\% fewer parameters. Moreover, it\nalso significantly improved the baseline in erroneous OCR and limited training\ndata scenario, thus becomes practical for real-world applications.",
          "link": "http://arxiv.org/abs/2106.00952",
          "publishedOn": "2021-06-03T02:10:36.004Z",
          "wordCount": 590,
          "title": "End-to-End Information Extraction by Character-Level Embedding and Multi-Stage Attentional U-Net. (arXiv:2106.00952v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00827",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bunch_E/0/1/0/all/0/1\">Eric Bunch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kline_J/0/1/0/all/0/1\">Jeffery Kline</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dickinson_D/0/1/0/all/0/1\">Daniel Dickinson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhat_S/0/1/0/all/0/1\">Suhaas Bhat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_G/0/1/0/all/0/1\">Glenn Fung</a>",
          "description": "Metric space magnitude, an active field of research in algebraic topology, is\na scalar quantity that summarizes the effective number of distinct points that\nlive in a general metric space. The {\\em weighting vector} is a closely-related\nconcept that captures, in a nontrivial way, much of the underlying geometry of\nthe original metric space. Recent work has demonstrated that when the metric\nspace is Euclidean, the weighting vector serves as an effective tool for\nboundary detection. We recast this result and show the weighting vector may be\nviewed as a solution to a kernelized SVM. As one consequence, we apply this new\ninsight to the task of outlier detection, and we demonstrate performance that\nis competitive or exceeds performance of state-of-the-art techniques on\nbenchmark data sets. Under mild assumptions, we show the weighting vector,\nwhich has computational cost of matrix inversion, can be efficiently\napproximated in linear time. We show how nearest neighbor methods can\napproximate solutions to the minimization problems defined by SVMs.",
          "link": "http://arxiv.org/abs/2106.00827",
          "publishedOn": "2021-06-03T02:10:35.999Z",
          "wordCount": 618,
          "title": "Weighting vectors for machine learning: numerical harmonic analysis applied to boundary detection. (arXiv:2106.00827v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00909",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Veldt_N/0/1/0/all/0/1\">Nate Veldt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benson_A/0/1/0/all/0/1\">Austin R. Benson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kleinberg_J/0/1/0/all/0/1\">Jon Kleinberg</a>",
          "description": "Finding dense subgraphs of a large graph is a standard problem in graph\nmining that has been studied extensively both for its theoretical richness and\nits many practical applications. In this paper we introduce a new family of\ndense subgraph objectives, parameterized by a single parameter $p$, based on\ncomputing generalized means of degree sequences of a subgraph. Our objective\ncaptures both the standard densest subgraph problem and the maximum $k$-core as\nspecial cases, and provides a way to interpolate between and extrapolate beyond\nthese two objectives when searching for other notions of dense subgraphs. In\nterms of algorithmic contributions, we first show that our objective can be\nminimized in polynomial time for all $p \\geq 1$ using repeated submodular\nminimization. A major contribution of our work is analyzing the performance of\ndifferent types of peeling algorithms for dense subgraphs both in theory and\npractice. We prove that the standard peeling algorithm can perform arbitrarily\npoorly on our generalized objective, but we then design a more sophisticated\npeeling method which for $p \\geq 1$ has an approximation guarantee that is\nalways at least $1/2$ and converges to 1 as $p \\rightarrow \\infty$. In\npractice, we show that this algorithm obtains extremely good approximations to\nthe optimal solution, scales to large graphs, and highlights a range of\ndifferent meaningful notions of density on graphs coming from numerous domains.\nFurthermore, it is typically able to approximate the densest subgraph problem\nbetter than the standard peeling algorithm, by better accounting for how the\nremoval of one node affects other nodes in its neighborhood.",
          "link": "http://arxiv.org/abs/2106.00909",
          "publishedOn": "2021-06-03T02:10:35.984Z",
          "wordCount": 697,
          "title": "The Generalized Mean Densest Subgraph Problem. (arXiv:2106.00909v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00845",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Omoniwa_B/0/1/0/all/0/1\">Babatunji Omoniwa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galkin_B/0/1/0/all/0/1\">Boris Galkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dusparic_I/0/1/0/all/0/1\">Ivana Dusparic</a>",
          "description": "Unmanned aerial vehicles serving as aerial base stations (UAV-BSs) can be\ndeployed to provide wireless connectivity to ground devices in events of\nincreased network demand, points-of-failure in existing infrastructure, or\ndisasters. However, it is challenging to conserve the energy of UAVs during\nprolonged coverage tasks, considering their limited on-board battery capacity.\nReinforcement learning-based (RL) approaches have been previously used to\nimprove energy utilization of multiple UAVs, however, a central cloud\ncontroller is assumed to have complete knowledge of the end-devices' locations,\ni.e., the controller periodically scans and sends updates for UAV\ndecision-making. This assumption is impractical in dynamic network environments\nwith mobile ground devices. To address this problem, we propose a decentralized\nQ-learning approach, where each UAV-BS is equipped with an autonomous agent\nthat maximizes the connectivity to ground devices while improving its energy\nutilization. Experimental results show that the proposed design significantly\noutperforms the centralized approaches in jointly maximizing the number of\nconnected ground devices and the energy utilization of the UAV-BSs.",
          "link": "http://arxiv.org/abs/2106.00845",
          "publishedOn": "2021-06-03T02:10:35.979Z",
          "wordCount": 609,
          "title": "Energy-aware placement optimization of UAV base stations via decentralized multi-agent Q-learning. (arXiv:2106.00845v1 [cs.MA])"
        },
        {
          "id": "http://arxiv.org/abs/2102.01189",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Youzhi Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_K/0/1/0/all/0/1\">Keqiang Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1\">Shuiwang Ji</a>",
          "description": "We consider the problem of molecular graph generation using deep models.\nWhile graphs are discrete, most existing methods use continuous latent\nvariables, resulting in inaccurate modeling of discrete graph structures. In\nthis work, we propose GraphDF, a novel discrete latent variable model for\nmolecular graph generation based on normalizing flow methods. GraphDF uses\ninvertible modulo shift transforms to map discrete latent variables to graph\nnodes and edges. We show that the use of discrete latent variables reduces\ncomputational costs and eliminates the negative effect of dequantization.\nComprehensive experimental results show that GraphDF outperforms prior methods\non random generation, property optimization, and constrained optimization\ntasks.",
          "link": "http://arxiv.org/abs/2102.01189",
          "publishedOn": "2021-06-03T02:10:35.967Z",
          "wordCount": 563,
          "title": "GraphDF: A Discrete Flow Model for Molecular Graph Generation. (arXiv:2102.01189v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00797",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vono_M/0/1/0/all/0/1\">Maxime Vono</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plassier_V/0/1/0/all/0/1\">Vincent Plassier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durmus_A/0/1/0/all/0/1\">Alain Durmus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dieuleveut_A/0/1/0/all/0/1\">Aymeric Dieuleveut</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moulines_E/0/1/0/all/0/1\">Eric Moulines</a>",
          "description": "Federated learning aims at conducting inference when data are decentralised\nand locally stored on several clients, under two main constraints: data\nownership and communication overhead. In this paper, we address these issues\nunder the Bayesian paradigm. To this end, we propose a novel Markov chain Monte\nCarlo algorithm coined \\texttt{QLSD} built upon quantised versions of\nstochastic gradient Langevin dynamics. To improve performance in a big data\nregime, we introduce variance-reduced alternatives of our methodology referred\nto as \\texttt{QLSD}$^\\star$ and \\texttt{QLSD}$^{++}$. We provide both\nnon-asymptotic and asymptotic convergence guarantees for the proposed\nalgorithms and illustrate their benefits on several federated learning\nbenchmarks.",
          "link": "http://arxiv.org/abs/2106.00797",
          "publishedOn": "2021-06-03T02:10:35.961Z",
          "wordCount": 544,
          "title": "QLSD: Quantised Langevin stochastic dynamics for Bayesian federated learning. (arXiv:2106.00797v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01153",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Urbann_O/0/1/0/all/0/1\">Oliver Urbann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bredtmann_O/0/1/0/all/0/1\">Oliver Bredtmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Otten_M/0/1/0/all/0/1\">Maximilian Otten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richter_J/0/1/0/all/0/1\">Jan-Philip Richter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bauer_T/0/1/0/all/0/1\">Thilo Bauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zibriczky_D/0/1/0/all/0/1\">David Zibriczky</a>",
          "description": "This paper presents an approach for tracking in a surveillance scenario.\nTypical aspects for this scenario are a 24/7 operation with a static camera\nmounted above the height of a human with many objects or people. The Multiple\nObject Tracking Benchmark 20 (MOT20) reflects this scenario best. We can show\nthat our approach is real-time capable on this benchmark and outperforms all\nother real-time capable approaches in HOTA, MOTA, and IDF1. We achieve this by\ncontributing a fast Siamese network reformulated for linear runtime (instead of\nquadratic) to generate fingerprints from detections. Thus, it is possible to\nassociate the detections to Kalman filters based on multiple tracking specific\nratings: Cosine similarity of fingerprints, Intersection over Union, and pixel\ndistance ratio in the image.",
          "link": "http://arxiv.org/abs/2106.01153",
          "publishedOn": "2021-06-03T02:10:35.898Z",
          "wordCount": 561,
          "title": "Online and Real-Time Tracking in a Surveillance Scenario. (arXiv:2106.01153v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00901",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kajino_H/0/1/0/all/0/1\">Hiroshi Kajino</a>",
          "description": "This paper is concerned about a learning algorithm for a probabilistic model\nof spiking neural networks (SNNs). Jimenez Rezende & Gerstner (2014) proposed a\nstochastic variational inference algorithm to train SNNs with hidden neurons.\nThe algorithm updates the variational distribution using the score function\ngradient estimator, whose high variance often impedes the whole learning\nalgorithm. This paper presents an alternative gradient estimator for SNNs based\non the path-wise gradient estimator. The main technical difficulty is a lack of\na general method to differentiate a realization of an arbitrary point process,\nwhich is necessary to derive the path-wise gradient estimator. We develop a\ndifferentiable point process, which is the technical highlight of this paper,\nand apply it to derive the path-wise gradient estimator for SNNs. We\ninvestigate the effectiveness of our gradient estimator through numerical\nsimulation.",
          "link": "http://arxiv.org/abs/2106.00901",
          "publishedOn": "2021-06-03T02:10:35.856Z",
          "wordCount": 576,
          "title": "A Differentiable Point Process with Its Application to Spiking Neural Networks. (arXiv:2106.00901v1 [cs.NE])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01100",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Pohl_M/0/1/0/all/0/1\">Michel Pohl</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Uesaka_M/0/1/0/all/0/1\">Mitsuru Uesaka</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Takahashi_H/0/1/0/all/0/1\">Hiroyuki Takahashi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Demachi_K/0/1/0/all/0/1\">Kazuyuki Demachi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chhatkuli_R/0/1/0/all/0/1\">Ritu Bhusal Chhatkuli</a>",
          "description": "During lung cancer radiotherapy, the position of infrared reflective objects\non the chest can be recorded to estimate the tumor location. However,\nradiotherapy systems usually have a latency inherent to robot control\nlimitations that impedes the radiation delivery precision. Not taking this\nphenomenon into account may cause unwanted damage to healthy tissues and lead\nto side effects such as radiation pneumonitis. In this research, we use nine\nobservation records of the three-dimensional position of three external markers\non the chest and abdomen of healthy individuals breathing during intervals from\n73s to 222s. The sampling frequency is equal to 10Hz and the amplitudes of the\nrecorded trajectories range from 6mm to 40mm in the superior-inferior\ndirection. We forecast the location of each marker simultaneously with a\nhorizon value (the time interval in advance for which the prediction is made)\nbetween 0.1s and 2.0s, using a recurrent neural network (RNN) trained with\nunbiased online recurrent optimization (UORO). We compare its performance with\nan RNN trained with real-time recurrent learning, least mean squares (LMS), and\noffline linear regression. Training and cross-validation are performed during\nthe first minute of each sequence. On average, UORO achieves the lowest\nroot-mean-square (RMS) and maximum error, equal respectively to 1.3mm and\n8.8mm, with a prediction time per time step lower than 2.8ms (Dell Intel core\ni9-9900K 3.60Ghz). Linear regression has the lowest RMS error for the horizon\nvalues 0.1s and 0.2s, followed by LMS for horizon values between 0.3s and 0.5s,\nand UORO for horizon values greater than 0.6s.",
          "link": "http://arxiv.org/abs/2106.01100",
          "publishedOn": "2021-06-03T02:10:35.827Z",
          "wordCount": 737,
          "title": "Prediction of the Position of External Markers Using a Recurrent Neural Network Trained With Unbiased Online Recurrent Optimization for Safe Lung Cancer Radiotherapy. (arXiv:2106.01100v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.08019",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bello_K/0/1/0/all/0/1\">Kevin Bello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ke_C/0/1/0/all/0/1\">Chuyang Ke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Honorio_J/0/1/0/all/0/1\">Jean Honorio</a>",
          "description": "Performing inference in graphs is a common task within several machine\nlearning problems, e.g., image segmentation, community detection, among others.\nFor a given undirected connected graph, we tackle the statistical problem of\nexactly recovering an unknown ground-truth binary labeling of the nodes from a\nsingle corrupted observation of each edge. Such problem can be formulated as a\nquadratic combinatorial optimization problem over the boolean hypercube, where\nit has been shown before that one can (with high probability and in polynomial\ntime) exactly recover the ground-truth labeling of graphs that have an\nisoperimetric number that grows with respect to the number of nodes (e.g.,\ncomplete graphs, regular expanders). In this work, we apply a powerful\nhierarchy of relaxations, known as the sum-of-squares (SoS) hierarchy, to the\ncombinatorial problem. Motivated by empirical evidence on the improvement in\nexact recoverability, we center our attention on the degree-4 SoS relaxation\nand set out to understand the origin of such improvement from a graph\ntheoretical perspective. We show that the solution of the dual of the relaxed\nproblem is related to finding edge weights of the Johnson and Kneser graphs,\nwhere the weights fulfill the SoS constraints and intuitively allow the input\ngraph to increase its algebraic connectivity. Finally, as byproduct of our\nanalysis, we derive a novel Cheeger-type lower bound for the algebraic\nconnectivity of graphs with signed edge weights.",
          "link": "http://arxiv.org/abs/2102.08019",
          "publishedOn": "2021-06-03T02:10:35.817Z",
          "wordCount": 700,
          "title": "A Thorough View of Exact Inference in Graphs from the Degree-4 Sum-of-Squares Hierarchy. (arXiv:2102.08019v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.01414",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yong Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1\">Kewei Tu</a>",
          "description": "This paper presents the system used in our submission to the \\textit{IWPT\n2020 Shared Task}. Our system is a graph-based parser with second-order\ninference. For the low-resource Tamil corpus, we specially mixed the training\ndata of Tamil with other languages and significantly improved the performance\nof Tamil. Due to our misunderstanding of the submission requirements, we\nsubmitted graphs that are not connected, which makes our system only rank\n\\textbf{6th} over 10 teams. However, after we fixed this problem, our system is\n0.6 ELAS higher than the team that ranked \\textbf{1st} in the official results.",
          "link": "http://arxiv.org/abs/2006.01414",
          "publishedOn": "2021-06-03T02:10:35.812Z",
          "wordCount": 590,
          "title": "Enhanced Universal Dependency Parsing with Second-Order Inference and Mixture of Training Data. (arXiv:2006.01414v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03654",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yong Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bach_N/0/1/0/all/0/1\">Nguyen Bach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhongqiang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1\">Kewei Tu</a>",
          "description": "Recent advances in Named Entity Recognition (NER) show that document-level\ncontexts can significantly improve model performance. In many application\nscenarios, however, such contexts are not available. In this paper, we propose\nto find external contexts of a sentence by retrieving and selecting a set of\nsemantically relevant texts through a search engine, with the original sentence\nas the query. We find empirically that the contextual representations computed\non the retrieval-based input view, constructed through the concatenation of a\nsentence and its external contexts, can achieve significantly improved\nperformance compared to the original input view based only on the sentence.\nFurthermore, we can improve the model performance of both input views by\nCooperative Learning, a training method that encourages the two input views to\nproduce similar contextual representations or output label distributions.\nExperiments show that our approach can achieve new state-of-the-art performance\non 8 NER data sets across 5 domains.",
          "link": "http://arxiv.org/abs/2105.03654",
          "publishedOn": "2021-06-03T02:10:35.788Z",
          "wordCount": 632,
          "title": "Improving Named Entity Recognition by External Context Retrieving and Cooperative Learning. (arXiv:2105.03654v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08304",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Cerquides_J/0/1/0/all/0/1\">Jesus Cerquides</a>",
          "description": "In this paper we leverage on probability over Riemannian manifolds to rethink\nthe interpretation of priors and posteriors in Bayesian inference. The main\nmindshift is to move away from the idea that \"a prior distribution establishes\na probability distribution over the parameters of our model\" to the idea that\n\"a prior distribution establishes a probability distribution over probability\ndistributions\". To do that we assume that our probabilistic model is a\nRiemannian manifold with the Fisher metric. Under this mindset, any\ndistribution over probability distributions should be \"intrinsic\", that is,\ninvariant to the specific parametrization which is selected for the manifold.\nWe exemplify our ideas through a simple analysis of distributions over the\nmanifold of Bernoulli distributions. One of the major shortcomings of maximum a\nposteriori estimates is that they depend on the parametrization. Based on the\nunderstanding developed here, we can define the maximum a posteriori estimate\nwhich is independent of the parametrization.",
          "link": "http://arxiv.org/abs/2105.08304",
          "publishedOn": "2021-06-03T02:10:35.782Z",
          "wordCount": 600,
          "title": "Parametrization invariant interpretation of priors and posteriors. (arXiv:2105.08304v2 [math.ST] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.08973",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Look_A/0/1/0/all/0/1\">Andreas Look</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kandemir_M/0/1/0/all/0/1\">Melih Kandemir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1\">Jan Peters</a>",
          "description": "Neural Stochastic Differential Equations (NSDEs) model the drift and\ndiffusion functions of a stochastic process as neural networks. While NSDEs are\nknown to predict time series accurately, their uncertainty quantification\nproperties remain unexplored. Currently, there are no approximate inference\nmethods, which allow flexible models and provide at the same time high quality\nuncertainty estimates at a reasonable computational cost. Existing SDE\ninference methods either make overly restrictive assumptions, e.g. linearity,\nor rely on Monte Carlo integration that requires many samples at prediction\ntime for reliable uncertainty quantification. However, many real-world safety\ncritical applications necessitate highly expressive models that can quantify\nprediction uncertainty at affordable computational cost. We introduce a\nvariational inference scheme that approximates the posterior distribution of a\nNSDE governing a latent state space by a deterministic chain of operations. We\napproximate the intractable data fit term of the evidence lower bound by a\nnovel bidimensional moment matching algorithm: vertical along the neural net\nlayers and horizontal along the time direction. Our algorithm achieves\nuncertainty calibration scores that can be matched by its sampling-based\ncounterparts only at significantly higher computation cost, while providing as\naccurate forecasts on system dynamics.",
          "link": "http://arxiv.org/abs/2006.08973",
          "publishedOn": "2021-06-03T02:10:35.777Z",
          "wordCount": 661,
          "title": "Deterministic Variational Inference for Neural SDEs. (arXiv:2006.08973v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.08431",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lorraine_J/0/1/0/all/0/1\">Jonathan Lorraine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Acuna_D/0/1/0/all/0/1\">David Acuna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vicol_P/0/1/0/all/0/1\">Paul Vicol</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duvenaud_D/0/1/0/all/0/1\">David Duvenaud</a>",
          "description": "We generalize gradient descent with momentum for optimization in\ndifferentiable games to have complex-valued momentum. We give theoretical\nmotivation for our method by proving convergence on bilinear zero-sum games for\nsimultaneous and alternating updates. Our method gives real-valued parameter\nupdates, making it a drop-in replacement for standard optimizers. We\nempirically demonstrate that complex-valued momentum can improve convergence in\nrealistic adversarial games - like generative adversarial networks - by showing\nwe can find better solutions with an almost identical computational cost. We\nalso show a practical generalization to a complex-valued Adam variant, which we\nuse to train BigGAN to better inception scores on CIFAR-10.",
          "link": "http://arxiv.org/abs/2102.08431",
          "publishedOn": "2021-06-03T02:10:35.747Z",
          "wordCount": 558,
          "title": "Complex Momentum for Optimization in Games. (arXiv:2102.08431v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.09559",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oskarsdottir_M/0/1/0/all/0/1\">Mar&#xed;a &#xd3;skarsd&#xf3;ttir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bravo_C/0/1/0/all/0/1\">Cristi&#xe1;n Bravo</a>",
          "description": "We present a multilayer network model for credit risk assessment. Our model\naccounts for multiple connections between borrowers (such as their geographic\nlocation and their economic activity) and allows for explicitly modelling the\ninteraction between connected borrowers. We develop a multilayer personalized\nPageRank algorithm that allows quantifying the strength of the default exposure\nof any borrower in the network. We test our methodology in an agricultural\nlending framework, where it has been suspected for a long time default\ncorrelates between borrowers when they are subject to the same structural\nrisks. Our results show there are significant predictive gains just by\nincluding centrality multilayer network information in the model, and these\ngains are increased by more complex information such as the multilayer PageRank\nvariables. The results suggest default risk is highest when an individual is\nconnected to many defaulters, but this risk is mitigated by the size of the\nneighbourhood of the individual, showing both default risk and financial\nstability propagate throughout the network.",
          "link": "http://arxiv.org/abs/2010.09559",
          "publishedOn": "2021-06-03T02:10:35.732Z",
          "wordCount": 633,
          "title": "Multilayer Network Analysis for Improved Credit Risk Prediction. (arXiv:2010.09559v3 [cs.SI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00750",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tonekaboni_S/0/1/0/all/0/1\">Sana Tonekaboni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eytan_D/0/1/0/all/0/1\">Danny Eytan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldenberg_A/0/1/0/all/0/1\">Anna Goldenberg</a>",
          "description": "Time series are often complex and rich in information but sparsely labeled\nand therefore challenging to model. In this paper, we propose a self-supervised\nframework for learning generalizable representations for non-stationary time\nseries. Our approach, called Temporal Neighborhood Coding (TNC), takes\nadvantage of the local smoothness of a signal's generative process to define\nneighborhoods in time with stationary properties. Using a debiased contrastive\nobjective, our framework learns time series representations by ensuring that in\nthe encoding space, the distribution of signals from within a neighborhood is\ndistinguishable from the distribution of non-neighboring signals. Our\nmotivation stems from the medical field, where the ability to model the dynamic\nnature of time series data is especially valuable for identifying, tracking,\nand predicting the underlying patients' latent states in settings where\nlabeling data is practically impossible. We compare our method to recently\ndeveloped unsupervised representation learning approaches and demonstrate\nsuperior performance on clustering and classification tasks for multiple\ndatasets.",
          "link": "http://arxiv.org/abs/2106.00750",
          "publishedOn": "2021-06-03T02:10:35.717Z",
          "wordCount": 592,
          "title": "Unsupervised Representation Learning for Time Series with Temporal Neighborhood Coding. (arXiv:2106.00750v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00885",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_F/0/1/0/all/0/1\">Fengzhuo Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tan_V/0/1/0/all/0/1\">Vincent Y. F. Tan</a>",
          "description": "We consider learning the structures of Gaussian latent tree models with\nvector observations when a subset of them are arbitrarily corrupted. First, we\npresent the sample complexities of Recursive Grouping (RG) and Chow-Liu\nRecursive Grouping (CLRG) without the assumption that the effective depth is\nbounded in the number of observed nodes, significantly generalizing the results\nin Choi et al. (2011). We show that Chow-Liu initialization in CLRG greatly\nreduces the sample complexity of RG from being exponential in the diameter of\nthe tree to only logarithmic in the diameter for the hidden Markov model (HMM).\nSecond, we robustify RG, CLRG, Neighbor Joining (NJ) and Spectral NJ (SNJ) by\nusing the truncated inner product. These robustified algorithms can tolerate a\nnumber of corruptions up to the square root of the number of clean samples.\nFinally, we derive the first known instance-dependent impossibility result for\nstructure learning of latent trees. The optimalities of the robust version of\nCLRG and NJ are verified by comparing their sample complexities and the\nimpossibility result.",
          "link": "http://arxiv.org/abs/2106.00885",
          "publishedOn": "2021-06-03T02:10:35.711Z",
          "wordCount": 604,
          "title": "Robustifying Algorithms of Learning Latent Trees with Vector Variables. (arXiv:2106.00885v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2002.06716",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Martin_C/0/1/0/all/0/1\">Charles H. Martin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tongsu/0/1/0/all/0/1\">Tongsu</a> (Serena) <a href=\"http://arxiv.org/find/cs/1/au:+Peng/0/1/0/all/0/1\">Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahoney_M/0/1/0/all/0/1\">Michael W. Mahoney</a>",
          "description": "In many applications, one works with neural network models trained by someone\nelse. For such pretrained models, one may not have access to training data or\ntest data. Moreover, one may not know details about the model, e.g., the\nspecifics of the training data, the loss function, the hyperparameter values,\netc. Given one or many pretrained models, it is a challenge to say anything\nabout the expected performance or quality of the models. Here, we address this\nchallenge by providing a detailed meta-analysis of hundreds of\npublicly-available pretrained models. We examine norm based capacity control\nmetrics as well as power law based metrics from the recently-developed Theory\nof Heavy-Tailed Self Regularization. We find that norm based metrics correlate\nwell with reported test accuracies for well-trained models, but that they often\ncannot distinguish well-trained versus poorly-trained models. We also find that\npower law based metrics can do much better -- quantitatively better at\ndiscriminating among series of well-trained models with a given architecture;\nand qualitatively better at discriminating well-trained versus poorly-trained\nmodels. These methods can be used to identify when a pretrained neural network\nhas problems that cannot be detected simply by examining training/test\naccuracies.",
          "link": "http://arxiv.org/abs/2002.06716",
          "publishedOn": "2021-06-03T02:10:35.706Z",
          "wordCount": 690,
          "title": "Predicting trends in the quality of state-of-the-art neural networks without access to training or testing data. (arXiv:2002.06716v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00886",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kawano_K/0/1/0/all/0/1\">Keisuke Kawano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koide_S/0/1/0/all/0/1\">Satoshi Koide</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Otaki_K/0/1/0/all/0/1\">Keisuke Otaki</a>",
          "description": "We consider a general task called partial Wasserstein covering with the goal\nof emulating a large dataset (e.g., application dataset) using a small dataset\n(e.g., development dataset) in terms of the empirical distribution by selecting\na small subset from a candidate dataset and adding it to the small dataset. We\nmodel this task as a discrete optimization problem with partial Wasserstein\ndivergence as an objective function. Although this problem is NP-hard, we prove\nthat it has the submodular property, allowing us to use a greedy algorithm with\na 0.63 approximation. However, the greedy algorithm is still inefficient\nbecause it requires linear programming for each objective function evaluation.\nTo overcome this difficulty, we propose quasi-greedy algorithms for\nacceleration, which consist of a series of techniques such as sensitivity\nanalysis based on strong duality and the so-called $C$-transform in the optimal\ntransport field. Experimentally, we demonstrate that we can efficiently make\ntwo datasets similar in terms of partial Wasserstein divergence, including\ndriving scene datasets.",
          "link": "http://arxiv.org/abs/2106.00886",
          "publishedOn": "2021-06-03T02:10:35.701Z",
          "wordCount": 578,
          "title": "Partial Wasserstein Covering. (arXiv:2106.00886v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00881",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rosato_A/0/1/0/all/0/1\">Antonello Rosato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panella_M/0/1/0/all/0/1\">Massimo Panella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kleyko_D/0/1/0/all/0/1\">Denis Kleyko</a>",
          "description": "In the supervised learning domain, considering the recent prevalence of\nalgorithms with high computational cost, the attention is steering towards\nsimpler, lighter, and less computationally extensive training and inference\napproaches. In particular, randomized algorithms are currently having a\nresurgence, given their generalized elementary approach. By using randomized\nneural networks, we study distributed classification, which can be employed in\nsituations were data cannot be stored at a central location nor shared. We\npropose a more efficient solution for distributed classification by making use\nof a lossy compression approach applied when sharing the local classifiers with\nother agents. This approach originates from the framework of hyperdimensional\ncomputing, and is adapted herein. The results of experiments on a collection of\ndatasets demonstrate that the proposed approach has usually higher accuracy\nthan local classifiers and getting close to the benchmark - the centralized\nclassifier. This work can be considered as the first step towards analyzing the\nvariegated horizon of distributed randomized neural networks.",
          "link": "http://arxiv.org/abs/2106.00881",
          "publishedOn": "2021-06-03T02:10:35.696Z",
          "wordCount": 597,
          "title": "Hyperdimensional Computing for Efficient Distributed Classification with Randomized Neural Networks. (arXiv:2106.00881v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01009",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yiqiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Wang Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_X/0/1/0/all/0/1\">Xin Qin</a>",
          "description": "The success of machine learning applications often needs a large quantity of\ndata. Recently, federated learning (FL) is attracting increasing attention due\nto the demand for data privacy and security, especially in the medical field.\nHowever, the performance of existing FL approaches often deteriorates when\nthere exist domain shifts among clients, and few previous works focus on\npersonalization in healthcare. In this article, we propose FedHealth 2, an\nextension of FedHealth \\cite{chen2020fedhealth} to tackle domain shifts and get\npersonalized models for local clients. FedHealth 2 obtains the client\nsimilarities via a pretrained model, and then it averages all weighted models\nwith preserving local batch normalization. Wearable activity recognition and\nCOVID-19 auxiliary diagnosis experiments have evaluated that FedHealth 2 can\nachieve better accuracy (10%+ improvement for activity recognition) and\npersonalized healthcare without compromising privacy and security.",
          "link": "http://arxiv.org/abs/2106.01009",
          "publishedOn": "2021-06-03T02:10:35.654Z",
          "wordCount": 618,
          "title": "FedHealth 2: Weighted Federated Transfer Learning via Batch Normalization for Personalized Healthcare. (arXiv:2106.01009v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00839",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bertsimas_D/0/1/0/all/0/1\">Dimitris Bertsimas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orfanoudaki_A/0/1/0/all/0/1\">Agni Orfanoudaki</a>",
          "description": "As machine learning algorithms start to get integrated into the\ndecision-making process of companies and organizations, insurance products will\nbe developed to protect their owners from risk. We introduce the concept of\nalgorithmic insurance and present a quantitative framework to enable the\npricing of the derived insurance contracts. We propose an optimization\nformulation to estimate the risk exposure and price for a binary classification\nmodel. Our approach outlines how properties of the model, such as accuracy,\ninterpretability and generalizability, can influence the insurance contract\nevaluation. To showcase a practical implementation of the proposed framework,\nwe present a case study of medical malpractice in the context of breast cancer\ndetection. Our analysis focuses on measuring the effect of the model parameters\non the expected financial loss and identifying the aspects of algorithmic\nperformance that predominantly affect the price of the contract.",
          "link": "http://arxiv.org/abs/2106.00839",
          "publishedOn": "2021-06-03T02:10:35.649Z",
          "wordCount": 559,
          "title": "Pricing Algorithmic Insurance. (arXiv:2106.00839v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00736",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mokrov_P/0/1/0/all/0/1\">Petr Mokrov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korotin_A/0/1/0/all/0/1\">Alexander Korotin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lingxiao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Genevay_A/0/1/0/all/0/1\">Aude Genevay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Solomon_J/0/1/0/all/0/1\">Justin Solomon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burnaev_E/0/1/0/all/0/1\">Evgeny Burnaev</a>",
          "description": "Wasserstein gradient flows provide a powerful means of understanding and\nsolving many diffusion equations. Specifically, Fokker-Planck equations, which\nmodel the diffusion of probability measures, can be understood as gradient\ndescent over entropy functionals in Wasserstein space. This equivalence,\nintroduced by Jordan, Kinderlehrer and Otto, inspired the so-called JKO scheme\nto approximate these diffusion processes via an implicit discretization of the\ngradient flow in Wasserstein space. Solving the optimization problem associated\nto each JKO step, however, presents serious computational challenges. We\nintroduce a scalable method to approximate Wasserstein gradient flows, targeted\nto machine learning applications. Our approach relies on input-convex neural\nnetworks (ICNNs) to discretize the JKO steps, which can be optimized by\nstochastic gradient descent. Unlike previous work, our method does not require\ndomain discretization or particle simulation. As a result, we can sample from\nthe measure at each time step of the diffusion and compute its probability\ndensity. We demonstrate our algorithm's performance by computing diffusions\nfollowing the Fokker-Planck equation and apply it to unnormalized density\nsampling as well as nonlinear filtering.",
          "link": "http://arxiv.org/abs/2106.00736",
          "publishedOn": "2021-06-03T02:10:35.623Z",
          "wordCount": 593,
          "title": "Large-Scale Wasserstein Gradient Flows. (arXiv:2106.00736v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.01696",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roh_Y/0/1/0/all/0/1\">Yuji Roh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kangwook Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whang_S/0/1/0/all/0/1\">Steven Euijong Whang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suh_C/0/1/0/all/0/1\">Changho Suh</a>",
          "description": "Training a fair machine learning model is essential to prevent demographic\ndisparity. Existing techniques for improving model fairness require broad\nchanges in either data preprocessing or model training, rendering themselves\ndifficult-to-adopt for potentially already complex machine learning systems. We\naddress this problem via the lens of bilevel optimization. While keeping the\nstandard training algorithm as an inner optimizer, we incorporate an outer\noptimizer so as to equip the inner problem with an additional functionality:\nAdaptively selecting minibatch sizes for the purpose of improving model\nfairness. Our batch selection algorithm, which we call FairBatch, implements\nthis optimization and supports prominent fairness measures: equal opportunity,\nequalized odds, and demographic parity. FairBatch comes with a significant\nimplementation benefit -- it does not require any modification to data\npreprocessing or model training. For instance, a single-line change of PyTorch\ncode for replacing batch selection part of model training suffices to employ\nFairBatch. Our experiments conducted both on synthetic and benchmark real data\ndemonstrate that FairBatch can provide such functionalities while achieving\ncomparable (or even greater) performances against the state of the arts.\nFurthermore, FairBatch can readily improve fairness of any pre-trained model\nsimply via fine-tuning. It is also compatible with existing batch selection\ntechniques intended for different purposes, such as faster convergence, thus\ngracefully achieving multiple purposes.",
          "link": "http://arxiv.org/abs/2012.01696",
          "publishedOn": "2021-06-03T02:10:35.606Z",
          "wordCount": 686,
          "title": "FairBatch: Batch Selection for Model Fairness. (arXiv:2012.01696v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00757",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Vecchio_A/0/1/0/all/0/1\">Alice Del Vecchio</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Deac_A/0/1/0/all/0/1\">Andreea Deac</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lio_P/0/1/0/all/0/1\">Pietro Li&#xf2;</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Velickovic_P/0/1/0/all/0/1\">Petar Veli&#x10d;kovi&#x107;</a>",
          "description": "Antibodies are proteins in the immune system which bind to antigens to detect\nand neutralise them. The binding sites in an antibody-antigen interaction are\nknown as the paratope and epitope, respectively, and the prediction of these\nregions is key to vaccine and synthetic antibody development. Contrary to prior\nart, we argue that paratope and epitope predictors require asymmetric\ntreatment, and propose distinct neural message passing architectures that are\ngeared towards the specific aspects of paratope and epitope prediction,\nrespectively. We obtain significant improvements on both tasks, setting the new\nstate-of-the-art and recovering favourable qualitative predictions on antigens\nof relevance to COVID-19.",
          "link": "http://arxiv.org/abs/2106.00757",
          "publishedOn": "2021-06-03T02:10:35.601Z",
          "wordCount": 582,
          "title": "Neural message passing for joint paratope-epitope prediction. (arXiv:2106.00757v1 [q-bio.QM])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00761",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Besta_M/0/1/0/all/0/1\">Maciej Besta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grob_R/0/1/0/all/0/1\">Raphael Grob</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miglioli_C/0/1/0/all/0/1\">Cesare Miglioli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bernold_N/0/1/0/all/0/1\">Nicola Bernold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwasniewski_G/0/1/0/all/0/1\">Grzegorz Kwasniewski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gjini_G/0/1/0/all/0/1\">Gabriel Gjini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanakagiri_R/0/1/0/all/0/1\">Raghavendra Kanakagiri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ashkboos_S/0/1/0/all/0/1\">Saleh Ashkboos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gianinazzi_L/0/1/0/all/0/1\">Lukas Gianinazzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dryden_N/0/1/0/all/0/1\">Nikoli Dryden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoefler_T/0/1/0/all/0/1\">Torsten Hoefler</a>",
          "description": "Link prediction is one of the central problems in graph mining. However,\nrecent studies highlight the importance of the higher-order network analysis,\nwhere complex structures called motifs are the first-class citizens. We\nillustrate that existing link prediction schemes fail to predict the appearance\nof complex motifs in graph data. To address this issue, we propose a general\nmotif prediction problem. We establish the theoretical foundation of motif\nprediction and we propose several heuristics that, for a fixed set of nodes in\na graph and a specified motif, assess the chances for this motif to appear. To\nmake the scores realistic, our heuristics - among others - consider\ncorrelations between links, i.e., the potential impact of some arriving links\non the appearance of other parts of a given motif. Finally, for highest\naccuracy, we develop a graph neural network (GNN) architecture for motif\nprediction. Our architecture offers vertex features and sampling schemes that\ncapture the rich structural properties of motifs. While our heuristics are fast\nand do not need any training, using GNNs ensures highest accuracy when\npredicting the arrival of complex graph structures, both dense (e.g.,\nk-cliques) and sparse (e.g., k-stars). Importantly, its advantages over schemes\nbased on uncorrelated link prediction increase with the increasing motif size\nand complexity. We also successfully apply our architecture for predicting more\narbitrary clusters and communities, illustrating its potential for graph mining\nbeyond motif analysis.",
          "link": "http://arxiv.org/abs/2106.00761",
          "publishedOn": "2021-06-03T02:10:35.585Z",
          "wordCount": 673,
          "title": "Motif Prediction with Graph Neural Networks. (arXiv:2106.00761v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00745",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abend_O/0/1/0/all/0/1\">Omri Abend</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choshen_L/0/1/0/all/0/1\">Leshem Choshen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikolaev_D/0/1/0/all/0/1\">Dmitry Nikolaev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rafaeli_O/0/1/0/all/0/1\">Ofek Rafaeli</a>",
          "description": "In this research paper, I will elaborate on a method to evaluate machine\ntranslation models based on their performance on underlying syntactical\nphenomena between English and Arabic languages. This method is especially\nimportant as such \"neural\" and \"machine learning\" are hard to fine-tune and\nchange. Thus, finding a way to evaluate them easily and diversely would greatly\nhelp the task of bettering them.",
          "link": "http://arxiv.org/abs/2106.00745",
          "publishedOn": "2021-06-03T02:10:35.576Z",
          "wordCount": 506,
          "title": "Part of Speech and Universal Dependency effects on English Arabic Machine Translation. (arXiv:2106.00745v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2010.05003",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1\">Kewei Tu</a>",
          "description": "In this paper, we propose second-order graph-based neural dependency parsing\nusing message passing and end-to-end neural networks. We empirically show that\nour approaches match the accuracy of very recent state-of-the-art second-order\ngraph-based neural dependency parsers and have significantly faster speed in\nboth training and testing. We also empirically show the advantage of\nsecond-order parsing over first-order parsing and observe that the usefulness\nof the head-selection structured constraint vanishes when using BERT embedding.",
          "link": "http://arxiv.org/abs/2010.05003",
          "publishedOn": "2021-06-03T02:10:35.564Z",
          "wordCount": 535,
          "title": "Second-Order Neural Dependency Parsing with Message Passing and End-to-End Training. (arXiv:2010.05003v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.00368",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1\">Yiling Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huazheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Stephen Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongning Wang</a>",
          "description": "Online Learning to Rank (OL2R) eliminates the need of explicit relevance\nannotation by directly optimizing the rankers from their interactions with\nusers. However, the required exploration drives it away from successful\npractices in offline learning to rank, which limits OL2R's empirical\nperformance and practical applicability. In this work, we propose to estimate a\npairwise learning to rank model online. In each round, candidate documents are\npartitioned and ranked according to the model's confidence on the estimated\npairwise rank order, and exploration is only performed on the uncertain pairs\nof documents, i.e., \\emph{divide-and-conquer}. Regret directly defined on the\nnumber of mis-ordered pairs is proven, which connects the online solution's\ntheoretical convergence with its expected ranking performance. Comparisons\nagainst an extensive list of OL2R baselines on two public learning to rank\nbenchmark datasets demonstrate the effectiveness of the proposed solution.",
          "link": "http://arxiv.org/abs/2103.00368",
          "publishedOn": "2021-06-03T02:10:35.559Z",
          "wordCount": 611,
          "title": "PairRank: Online Pairwise Learning to Rank by Divide-and-Conquer. (arXiv:2103.00368v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.15723",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1\">Tianyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fisch_A/0/1/0/all/0/1\">Adam Fisch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Danqi Chen</a>",
          "description": "The recent GPT-3 model (Brown et al., 2020) achieves remarkable few-shot\nperformance solely by leveraging a natural-language prompt and a few task\ndemonstrations as input context. Inspired by their findings, we study few-shot\nlearning in a more practical scenario, where we use smaller language models for\nwhich fine-tuning is computationally efficient. We present LM-BFF--better\nfew-shot fine-tuning of language models--a suite of simple and complementary\ntechniques for fine-tuning language models on a small number of annotated\nexamples. Our approach includes (1) prompt-based fine-tuning together with a\nnovel pipeline for automating prompt generation; and (2) a refined strategy for\ndynamically and selectively incorporating demonstrations into each context.\nFinally, we present a systematic evaluation for analyzing few-shot performance\non a range of NLP tasks, including classification and regression. Our\nexperiments demonstrate that our methods combine to dramatically outperform\nstandard fine-tuning procedures in this low resource setting, achieving up to\n30% absolute improvement, and 11% on average across all tasks. Our approach\nmakes minimal assumptions on task resources and domain expertise, and hence\nconstitutes a strong task-agnostic method for few-shot learning.",
          "link": "http://arxiv.org/abs/2012.15723",
          "publishedOn": "2021-06-03T02:10:35.538Z",
          "wordCount": 645,
          "title": "Making Pre-trained Language Models Better Few-shot Learners. (arXiv:2012.15723v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01138",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Thaler_S/0/1/0/all/0/1\">Stephan Thaler</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zavadlav_J/0/1/0/all/0/1\">Julija Zavadlav</a>",
          "description": "In molecular dynamics (MD), neural network (NN) potentials trained bottom-up\non quantum mechanical data have seen tremendous success recently. Top-down\napproaches that learn NN potentials directly from experimental data have\nreceived less attention, typically facing numerical and computational\nchallenges when backpropagating through MD simulations. We present the\nDifferentiable Trajectory Reweighting (DiffTRe) method, which bypasses\ndifferentiation through the MD simulation for time-independent observables.\nLeveraging thermodynamic perturbation theory, we avoid exploding gradients and\nachieve around 2 orders of magnitude speed-up in gradient computation for\ntop-down learning. We show effectiveness of DiffTRe in learning NN potentials\nfor an atomistic model of diamond and a coarse-grained model of water based on\ndiverse experimental observables including thermodynamic, structural and\nmechanical properties. Importantly, DiffTRe also generalizes bottom-up\nstructural coarse-graining methods such as iterative Boltzmann inversion to\narbitrary potentials. The presented method constitutes an important milestone\ntowards enriching NN potentials with experimental data, particularly when\naccurate bottom-up data is unavailable.",
          "link": "http://arxiv.org/abs/2106.01138",
          "publishedOn": "2021-06-03T02:10:35.525Z",
          "wordCount": 597,
          "title": "Learning neural network potentials from experimental data via Differentiable Trajectory Reweighting. (arXiv:2106.01138v1 [physics.chem-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2005.03788",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinshao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1\">Yang Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kodirov_E/0/1/0/all/0/1\">Elyor Kodirov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clifton_D/0/1/0/all/0/1\">David A. Clifton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Robertson_N/0/1/0/all/0/1\">Neil M. Robertson</a>",
          "description": "To train robust deep neural networks (DNNs), we systematically study several\ntarget modification approaches, which include output regularisation, self and\nnon-self label correction (LC). Two key issues are discovered: (1) Self LC is\nthe most appealing as it exploits its own knowledge and requires no extra\nmodels. However, how to automatically decide the trust degree of a learner as\ntraining goes is not well answered in the literature? (2) Some methods penalise\nwhile the others reward low-entropy predictions, prompting us to ask which one\nis better?\n\nTo resolve the first issue, taking two well-accepted propositions--deep\nneural networks learn meaningful patterns before fitting noise [3] and minimum\nentropy regularisation principle [10]--we propose a novel end-to-end method\nnamed ProSelfLC, which is designed according to learning time and entropy.\nSpecifically, given a data point, we progressively increase trust in its\npredicted label distribution versus its annotated one if a model has been\ntrained for enough time and the prediction is of low entropy (high confidence).\nFor the second issue, according to ProSelfLC, we empirically prove that it is\nbetter to redefine a meaningful low-entropy status and optimise the learner\ntoward it. This serves as a defence of entropy minimisation.\n\nWe demonstrate the effectiveness of ProSelfLC through extensive experiments\nin both clean and noisy settings. The source code is available at\nhttps://github.com/XinshaoAmosWang/ProSelfLC-CVPR2021.\n\nKeywords: entropy minimisation, maximum entropy, confidence penalty, self\nknowledge distillation, label correction, label noise, semi-supervised\nlearning, output regularisation",
          "link": "http://arxiv.org/abs/2005.03788",
          "publishedOn": "2021-06-03T02:10:35.372Z",
          "wordCount": 787,
          "title": "ProSelfLC: Progressive Self Label Correction for Training Robust Deep Neural Networks. (arXiv:2005.03788v6 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.00606",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Yuval_O/0/1/0/all/0/1\">Oren Yuval</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rosset_S/0/1/0/all/0/1\">Saharon Rosset</a>",
          "description": "We present a general methodology for using unlabeled data to design semi\nsupervised learning (SSL) variants of the Empirical Risk Minimization (ERM)\nlearning process. Focusing on generalized linear regression, we provide a\ncareful treatment of the effectiveness of the SSL to improve prediction\nperformance. The key ideas are carefully considering the null model as a\ncompetitor, and utilizing the unlabeled data to determine signal-noise\ncombinations where the SSL outperforms both the ERM learning and the null\nmodel. In the special case of linear regression with Gaussian covariates, we\nshow that the previously suggested semi-supervised estimator is in fact not\ncapable of improving on both the supervised estimator and the null model\nsimultaneously. However, the new estimator presented in this work, can achieve\nan improvement of $O(1/n)$ term over both competitors simultaneously. On the\nother hand, we show that in other scenarios, such as non-Gaussian covariates,\nmisspecified linear regression, or generalized linear regression with\nnon-linear link functions, having unlabeled data can derive substantial\nimprovement in practice by applying our suggested SSL approach. Moreover, it is\npossible to identify the situations where SSL improves prediction, by using the\nresults we establish throughout this work. This is shown empirically through\nextensive simulations.",
          "link": "http://arxiv.org/abs/2009.00606",
          "publishedOn": "2021-06-03T02:10:35.367Z",
          "wordCount": 661,
          "title": "Semi-Supervised Empirical Risk Minimization: When can unlabeled data improve prediction?. (arXiv:2009.00606v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.08808",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1\">Tianze Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fubiao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_P/0/1/0/all/0/1\">Pan Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chenfei Wang</a>",
          "description": "Recent advances have witnessed that value decomposed-based multi-agent\nreinforcement learning methods make an efficient performance in coordination\ntasks. Most current methods assume that agents can make communication to assist\ndecisions, which is impractical in some situations. In this paper, we propose a\nsemi-communication method to enable agents can exchange information without\ncommunication. Specifically, we introduce a group concept to help agents\nlearning a belief which is a type of consensus. With this consensus, adjacent\nagents tend to accomplish similar sub-tasks to achieve cooperation. We design a\nnovel agent structure named Belief in Graph Clustering(BGC), composed of an\nagent characteristic module, a belief module, and a fusion module. To represent\neach agent characteristic, we use an MLP-based characteristic module to\ngenerate agent unique features. Inspired by the neighborhood cognitive\nconsistency, we propose a group-based module to divide adjacent agents into a\nsmall group and minimize in-group agents' beliefs to accomplish similar\nsub-tasks. Finally, we use a hyper-network to merge these features and produce\nagent actions. To overcome the agent consistent problem brought by GAT, a split\nloss is introduced to distinguish different agents. Results reveal that the\nproposed method achieves a significant improvement in the SMAC benchmark.\nBecause of the group concept, our approach maintains excellent performance with\nan increase in the number of agents.",
          "link": "http://arxiv.org/abs/2008.08808",
          "publishedOn": "2021-06-03T02:10:35.361Z",
          "wordCount": 677,
          "title": "BGC: Multi-Agent Group Belief with Graph Clustering. (arXiv:2008.08808v3 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01357",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bortoli_V/0/1/0/all/0/1\">Valentin De Bortoli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Thornton_J/0/1/0/all/0/1\">James Thornton</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Heng_J/0/1/0/all/0/1\">Jeremy Heng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Doucet_A/0/1/0/all/0/1\">Arnaud Doucet</a>",
          "description": "Progressively applying Gaussian noise transforms complex data distributions\nto approximately Gaussian. Reversing this dynamic defines a generative model.\nWhen the forward noising process is given by a Stochastic Differential Equation\n(SDE), Song et al. (2021) demonstrate how the time inhomogeneous drift of the\nassociated reverse-time SDE may be estimated using score-matching. A limitation\nof this approach is that the forward-time SDE must be run for a sufficiently\nlong time for the final distribution to be approximately Gaussian. In contrast,\nsolving the Schr\\\"odinger Bridge problem (SB), i.e. an entropy-regularized\noptimal transport problem on path spaces, yields diffusions which generate\nsamples from the data distribution in finite time. We present Diffusion SB\n(DSB), an original approximation of the Iterative Proportional Fitting (IPF)\nprocedure to solve the SB problem, and provide theoretical analysis along with\ngenerative modeling experiments. The first DSB iteration recovers the\nmethodology proposed by Song et al. (2021), with the flexibility of using\nshorter time intervals, as subsequent DSB iterations reduce the discrepancy\nbetween the final-time marginal of the forward (resp. backward) SDE with\nrespect to the prior (resp. data) distribution. Beyond generative modeling, DSB\noffers a widely applicable computational optimal transport tool as the\ncontinuous state-space analogue of the popular Sinkhorn algorithm (Cuturi,\n2013).",
          "link": "http://arxiv.org/abs/2106.01357",
          "publishedOn": "2021-06-03T02:10:35.345Z",
          "wordCount": 640,
          "title": "Diffusion Schr\\\"odinger Bridge with Applications to Score-Based Generative Modeling. (arXiv:2106.01357v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01350",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanxiang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Izza_Y/0/1/0/all/0/1\">Yacine Izza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ignatiev_A/0/1/0/all/0/1\">Alexey Ignatiev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marques_Silva_J/0/1/0/all/0/1\">Joao Marques-Silva</a>",
          "description": "Recent work has shown that not only decision trees (DTs) may not be\ninterpretable but also proposed a polynomial-time algorithm for computing one\nPI-explanation of a DT. This paper shows that for a wide range of classifiers,\nglobally referred to as decision graphs, and which include decision trees and\nbinary decision diagrams, but also their multi-valued variants, there exist\npolynomial-time algorithms for computing one PI-explanation. In addition, the\npaper also proposes a polynomial-time algorithm for computing one contrastive\nexplanation. These novel algorithms build on explanation graphs (XpG's). XpG's\ndenote a graph representation that enables both theoretical and practically\nefficient computation of explanations for decision graphs. Furthermore, the\npaper pro- poses a practically efficient solution for the enumeration of\nexplanations, and studies the complexity of deciding whether a given feature is\nincluded in some explanation. For the concrete case of decision trees, the\npaper shows that the set of all contrastive explanations can be enumerated in\npolynomial time. Finally, the experimental results validate the practical\napplicability of the algorithms proposed in the paper on a wide range of\npublicly available benchmarks.",
          "link": "http://arxiv.org/abs/2106.01350",
          "publishedOn": "2021-06-03T02:10:35.339Z",
          "wordCount": 602,
          "title": "On Efficiently Explaining Graph-Based Classifiers. (arXiv:2106.01350v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00993",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jiawei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1\">Nan Jiang</a>",
          "description": "In this paper, we study the convergence properties of off-policy policy\nimprovement algorithms with state-action density ratio correction under\nfunction approximation setting, where the objective function is formulated as a\nmax-max-min optimization problem. We characterize the bias of the learning\nobjective and present two strategies with finite-time convergence guarantees.\nIn our first strategy, we present algorithm P-SREDA with convergence rate\n$O(\\epsilon^{-3})$, whose dependency on $\\epsilon$ is optimal. In our second\nstrategy, we propose a new off-policy actor-critic style algorithm named\nO-SPIM. We prove that O-SPIM converges to a stationary point with total\ncomplexity $O(\\epsilon^{-4})$, which matches the convergence rate of some\nrecent actor-critic algorithms in the on-policy setting.",
          "link": "http://arxiv.org/abs/2106.00993",
          "publishedOn": "2021-06-03T02:10:35.333Z",
          "wordCount": 544,
          "title": "On the Convergence Rate of Off-Policy Policy Optimization Methods with Density-Ratio Correction. (arXiv:2106.00993v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/1908.00045",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Safran_I/0/1/0/all/0/1\">Itay Safran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shamir_O/0/1/0/all/0/1\">Ohad Shamir</a>",
          "description": "We study the performance of stochastic gradient descent (SGD) on smooth and\nstrongly-convex finite-sum optimization problems. In contrast to the majority\nof existing theoretical works, which assume that individual functions are\nsampled with replacement, we focus here on popular but poorly-understood\nheuristics, which involve going over random permutations of the individual\nfunctions. This setting has been investigated in several recent works, but the\noptimal error rates remain unclear. In this paper, we provide lower bounds on\nthe expected optimization error with these heuristics (using SGD with any\nconstant step size), which elucidate their advantages and disadvantages. In\nparticular, we prove that after $k$ passes over $n$ individual functions, if\nthe functions are re-shuffled after every pass, the best possible optimization\nerror for SGD is at least $\\Omega\\left(1/(nk)^2+1/nk^3\\right)$, which partially\ncorresponds to recently derived upper bounds. Moreover, if the functions are\nonly shuffled once, then the lower bound increases to $\\Omega(1/nk^2)$. Since\nthere are strictly smaller upper bounds for repeated reshuffling, this proves\nan inherent performance gap between SGD with single shuffling and repeated\nshuffling. As a more minor contribution, we also provide a non-asymptotic\n$\\Omega(1/k^2)$ lower bound (independent of $n$) for the incremental gradient\nmethod, when no random shuffling takes place. Finally, we provide an indication\nthat our lower bounds are tight, by proving matching upper bounds for\nunivariate quadratic functions.",
          "link": "http://arxiv.org/abs/1908.00045",
          "publishedOn": "2021-06-03T02:10:35.320Z",
          "wordCount": 696,
          "title": "How Good is SGD with Random Shuffling?. (arXiv:1908.00045v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01021",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lasaulce_S/0/1/0/all/0/1\">Samson Lasaulce</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hennebel_M/0/1/0/all/0/1\">Martin Hennebel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saludjian_L/0/1/0/all/0/1\">Lucas Saludjian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panciatici_P/0/1/0/all/0/1\">Patrick Panciatici</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poor_H/0/1/0/all/0/1\">H. Vincent Poor</a>",
          "description": "Data clustering is an instrumental tool in the area of energy resource\nmanagement. One problem with conventional clustering is that it does not take\nthe final use of the clustered data into account, which may lead to a very\nsuboptimal use of energy or computational resources. When clustered data are\nused by a decision-making entity, it turns out that significant gains can be\nobtained by tailoring the clustering scheme to the final task performed by the\ndecision-making entity. The key to having good final performance is to\nautomatically extract the important attributes of the data space that are\ninherently relevant to the subsequent decision-making entity, and partition the\ndata space based on these attributes instead of partitioning the data space\nbased on predefined conventional metrics. For this purpose, we formulate the\nframework of decision-making oriented clustering and propose an algorithm\nproviding a decision-based partition of the data space and good representative\ndecisions. By applying this novel framework and algorithm to a typical problem\nof real-time pricing and that of power consumption scheduling, we obtain\nseveral insightful analytical results such as the expression of the best\nrepresentative price profiles for real-time pricing and a very significant\nreduction in terms of required clusters to perform power consumption scheduling\nas shown by our simulations.",
          "link": "http://arxiv.org/abs/2106.01021",
          "publishedOn": "2021-06-03T02:10:35.314Z",
          "wordCount": 656,
          "title": "Decision-making Oriented Clustering: Application to Pricing and Power Consumption Scheduling. (arXiv:2106.01021v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00995",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Krouka_M/0/1/0/all/0/1\">Mounssif Krouka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elgabli_A/0/1/0/all/0/1\">Anis Elgabli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Issaid_C/0/1/0/all/0/1\">Chaouki Ben Issaid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bennis_M/0/1/0/all/0/1\">Mehdi Bennis</a>",
          "description": "Today's intelligent applications can achieve high performance accuracy using\nmachine learning (ML) techniques, such as deep neural networks (DNNs).\nTraditionally, in a remote DNN inference problem, an edge device transmits raw\ndata to a remote node that performs the inference task. However, this may incur\nhigh transmission energy costs and puts data privacy at risk. In this paper, we\npropose a technique to reduce the total energy bill at the edge device by\nutilizing model compression and time-varying model split between the edge and\nremote nodes. The time-varying representation accounts for time-varying\nchannels and can significantly reduce the total energy at the edge device while\nmaintaining high accuracy (low loss). We implement our approach in an image\nclassification task using the MNIST dataset, and the system environment is\nsimulated as a trajectory navigation scenario to emulate different channel\nconditions. Numerical simulations show that our proposed solution results in\nminimal energy consumption and $CO_2$ emission compared to the considered\nbaselines while exhibiting robust performance across different channel\nconditions and bandwidth regime choices.",
          "link": "http://arxiv.org/abs/2106.00995",
          "publishedOn": "2021-06-03T02:10:35.309Z",
          "wordCount": 607,
          "title": "Energy-Efficient Model Compression and Splitting for Collaborative Inference Over Time-Varying Channels. (arXiv:2106.00995v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00942",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hakhamaneshi_K/0/1/0/all/0/1\">Kourosh Hakhamaneshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stojanovic_V/0/1/0/all/0/1\">Vladimir Stojanovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grover_A/0/1/0/all/0/1\">Aditya Grover</a>",
          "description": "The goal of Multi-task Bayesian Optimization (MBO) is to minimize the number\nof queries required to accurately optimize a target black-box function, given\naccess to offline evaluations of other auxiliary functions. When offline\ndatasets are large, the scalability of prior approaches comes at the expense of\nexpressivity and inference quality. We propose JUMBO, an MBO algorithm that\nsidesteps these limitations by querying additional data based on a combination\nof acquisition signals derived from training two Gaussian Processes (GP): a\ncold-GP operating directly in the input domain and a warm-GP that operates in\nthe feature space of a deep neural network pretrained using the offline data.\nSuch a decomposition can dynamically control the reliability of information\nderived from the online and offline data and the use of pretrained neural\nnetworks permits scalability to large offline datasets. Theoretically, we\nderive regret bounds for JUMBO and show that it achieves no-regret under\nconditions analogous to GP-UCB (Srinivas et. al. 2010). Empirically, we\ndemonstrate significant performance improvements over existing approaches on\ntwo real-world optimization problems: hyper-parameter optimization and\nautomated circuit design.",
          "link": "http://arxiv.org/abs/2106.00942",
          "publishedOn": "2021-06-03T02:10:35.304Z",
          "wordCount": 604,
          "title": "JUMBO: Scalable Multi-task Bayesian Optimization using Offline Data. (arXiv:2106.00942v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01176",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roknizadeh_M/0/1/0/all/0/1\">Maliheh Roknizadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naeen_H/0/1/0/all/0/1\">Hossein Monshizadeh Naeen</a>",
          "description": "One of the most significant current discussions in the field of data mining\nis classifying imbalanced data. In recent years, several ways are proposed such\nas algorithm level (internal) approaches, data level (external) techniques, and\ncost-sensitive methods. Although extensive research has been carried out on\nimbalanced data classification, however, several unsolved challenges remain\nsuch as no attention to the importance of samples to balance, determine the\nappropriate number of classifiers, and no optimization of classifiers in the\ncombination of classifiers. The purpose of this paper is to improve the\nefficiency of the ensemble method in the sampling of training data sets,\nespecially in the minority class, and to determine better basic classifiers for\ncombining classifiers than existing methods. We proposed a hybrid ensemble\nalgorithm based on Genetic Programming (GP) for two classes of imbalanced data\nclassification. In this study uses historical data from UCI Machine Learning\nRepository to assess minority classes in imbalanced datasets. The performance\nof our proposed algorithm is evaluated by Rapid-miner studio v.7.5.\nExperimental results show the performance of the proposed method on the\nspecified data sets in the size of the training set shows 40% and 50% better\naccuracy than other dimensions of the minority class prediction.",
          "link": "http://arxiv.org/abs/2106.01176",
          "publishedOn": "2021-06-03T02:10:35.298Z",
          "wordCount": 653,
          "title": "Hybrid Ensemble optimized algorithm based on Genetic Programming for imbalanced data classification. (arXiv:2106.01176v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01354",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1\">Swarnadeep Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yadav_P/0/1/0/all/0/1\">Prateek Yadav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>",
          "description": "We focus on a type of linguistic formal reasoning where the goal is to reason\nover explicit knowledge in the form of natural language facts and rules (Clark\net al., 2020). A recent work, named PRover (Saha et al., 2020), performs such\nreasoning by answering a question and also generating a proof graph that\nexplains the answer. However, compositional reasoning is not always unique and\nthere may be multiple ways of reaching the correct answer. Thus, in our work,\nwe address a new and challenging problem of generating multiple proof graphs\nfor reasoning over natural language rule-bases. Each proof provides a different\nrationale for the answer, thereby improving the interpretability of such\nreasoning systems. In order to jointly learn from all proof graphs and exploit\nthe correlations between multiple proofs for a question, we pose this task as a\nset generation problem over structured output spaces where each proof is\nrepresented as a directed graph. We propose two variants of a proof-set\ngeneration model, multiPRover. Our first model, Multilabel-multiPRover,\ngenerates a set of proofs via multi-label classification and implicit\nconditioning between the proofs; while the second model, Iterative-multiPRover,\ngenerates proofs iteratively by explicitly conditioning on the previously\ngenerated proofs. Experiments on multiple synthetic, zero-shot, and\nhuman-paraphrased datasets reveal that both multiPRover models significantly\noutperform PRover on datasets containing multiple gold proofs.\nIterative-multiPRover obtains state-of-the-art proof F1 in zero-shot scenarios\nwhere all examples have single correct proofs. It also generalizes better to\nquestions requiring higher depths of reasoning where multiple proofs are more\nfrequent. Our code and models are publicly available at\nhttps://github.com/swarnaHub/multiPRover",
          "link": "http://arxiv.org/abs/2106.01354",
          "publishedOn": "2021-06-03T02:10:35.293Z",
          "wordCount": 711,
          "title": "multiPRover: Generating Multiple Proofs for Improved Interpretability in Rule Reasoning. (arXiv:2106.01354v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00792",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Winterhalder_R/0/1/0/all/0/1\">Ramon Winterhalder</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bellagente_M/0/1/0/all/0/1\">Marco Bellagente</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nachman_B/0/1/0/all/0/1\">Benjamin Nachman</a>",
          "description": "Deep generative models are becoming widely used across science and industry\nfor a variety of purposes. A common challenge is achieving a precise implicit\nor explicit representation of the data probability density. Recent proposals\nhave suggested using classifier weights to refine the learned density of deep\ngenerative models. We extend this idea to all types of generative models and\nshow how latent space refinement via iterated generative modeling can\ncircumvent topological obstructions and improve precision. This methodology\nalso applies to cases were the target model is non-differentiable and has many\ninternal latent dimensions which must be marginalized over before refinement.\nWe demonstrate our Latent Space Refinement (LaSeR) protocol on a variety of\nexamples, focusing on the combinations of Normalizing Flows and Generative\nAdversarial Networks.",
          "link": "http://arxiv.org/abs/2106.00792",
          "publishedOn": "2021-06-03T02:10:35.287Z",
          "wordCount": 578,
          "title": "Latent Space Refinement for Deep Generative Models. (arXiv:2106.00792v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00842",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vosoughi_M/0/1/0/all/0/1\">M. Ali Vosoughi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wismuller_A/0/1/0/all/0/1\">Axel Wismuller</a>",
          "description": "Causal discovery, beyond the inference of a network as a collection of\nconnected dots, offers a crucial functionality in scientific discovery using\nartificial intelligence. The questions that arise in multiple domains, such as\nphysics, physiology, the strategic decision in uncertain environments with\nmultiple agents, climatology, among many others, have roots in causality and\nreasoning. It became apparent that many real-world temporal observations are\nnonlinearly related to each other. While the number of observations can be as\nhigh as millions of points, the number of temporal samples can be minimal due\nto ethical or practical reasons, leading to the curse-of-dimensionality in\nlarge-scale systems. This paper proposes a novel method using kernel principal\ncomponent analysis and pre-images to obtain nonlinear dependencies of\nmultivariate time-series data. We show that our method outperforms\nstate-of-the-art causal discovery methods when the observations are restricted\nby time and are nonlinearly related. Extensive simulations on both real-world\nand synthetic datasets with various topologies are provided to evaluate our\nproposed methods.",
          "link": "http://arxiv.org/abs/2106.00842",
          "publishedOn": "2021-06-03T02:10:35.282Z",
          "wordCount": 596,
          "title": "Leveraging Pre-Images to Discover Nonlinear Relationships in Multivariate Environments. (arXiv:2106.00842v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01121",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wild_V/0/1/0/all/0/1\">Veit Wild</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kanagawa_M/0/1/0/all/0/1\">Motonobu Kanagawa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sejdinovic_D/0/1/0/all/0/1\">Dino Sejdinovic</a>",
          "description": "We investigate the connections between sparse approximation methods for\nmaking kernel methods and Gaussian processes (GPs) scalable to massive data,\nfocusing on the Nystr\\\"om method and the Sparse Variational Gaussian Processes\n(SVGP). While sparse approximation methods for GPs and kernel methods share\nsome algebraic similarities, the literature lacks a deep understanding of how\nand why they are related. This is a possible obstacle for the communications\nbetween the GP and kernel communities, making it difficult to transfer results\nfrom one side to the other. Our motivation is to remove this possible obstacle,\nby clarifying the connections between the sparse approximations for GPs and\nkernel methods. In this work, we study the two popular approaches, the\nNystr\\\"om and SVGP approximations, in the context of a regression problem, and\nestablish various connections and equivalences between them. In particular, we\nprovide an RKHS interpretation of the SVGP approximation, and show that the\nEvidence Lower Bound of the SVGP contains the objective function of the\nNystr\\\"om approximation, revealing the origin of the algebraic equivalence\nbetween the two approaches. We also study recently established convergence\nresults for the SVGP and how they are related to the approximation quality of\nthe Nystr\\\"om method.",
          "link": "http://arxiv.org/abs/2106.01121",
          "publishedOn": "2021-06-03T02:10:35.247Z",
          "wordCount": 644,
          "title": "Connections and Equivalences between the Nystr\\\"om Method and Sparse Variational Gaussian Processes. (arXiv:2106.01121v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00858",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Navratil_J/0/1/0/all/0/1\">Jiri Navratil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elder_B/0/1/0/all/0/1\">Benjamin Elder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arnold_M/0/1/0/all/0/1\">Matthew Arnold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Soumya Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sattigeri_P/0/1/0/all/0/1\">Prasanna Sattigeri</a>",
          "description": "Accurate quantification of model uncertainty has long been recognized as a\nfundamental requirement for trusted AI. In regression tasks, uncertainty is\ntypically quantified using prediction intervals calibrated to a specific\noperating point, making evaluation and comparison across different studies\ndifficult. Our work leverages: (1) the concept of operating characteristics\ncurves and (2) the notion of a gain over a simple reference, to derive a novel\noperating point agnostic assessment methodology for prediction intervals. The\npaper describes the corresponding algorithm, provides a theoretical analysis,\nand demonstrates its utility in multiple scenarios. We argue that the proposed\nmethod addresses the current need for comprehensive assessment of prediction\nintervals and thus represents a valuable addition to the uncertainty\nquantification toolbox.",
          "link": "http://arxiv.org/abs/2106.00858",
          "publishedOn": "2021-06-03T02:10:35.236Z",
          "wordCount": 562,
          "title": "Uncertainty Characteristics Curves: A Systematic Assessment of Prediction Intervals. (arXiv:2106.00858v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00920",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Joshi_R/0/1/0/all/0/1\">Rishabh Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balachandran_V/0/1/0/all/0/1\">Vidhisha Balachandran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vashishth_S/0/1/0/all/0/1\">Shikhar Vashishth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Black_A/0/1/0/all/0/1\">Alan Black</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsvetkov_Y/0/1/0/all/0/1\">Yulia Tsvetkov</a>",
          "description": "To successfully negotiate a deal, it is not enough to communicate fluently:\npragmatic planning of persuasive negotiation strategies is essential. While\nmodern dialogue agents excel at generating fluent sentences, they still lack\npragmatic grounding and cannot reason strategically. We present DialoGraph, a\nnegotiation system that incorporates pragmatic strategies in a negotiation\ndialogue using graph neural networks. DialoGraph explicitly incorporates\ndependencies between sequences of strategies to enable improved and\ninterpretable prediction of next optimal strategies, given the dialogue\ncontext. Our graph-based method outperforms prior state-of-the-art negotiation\nmodels both in the accuracy of strategy/dialogue act prediction and in the\nquality of downstream dialogue response generation. We qualitatively show\nfurther benefits of learned strategy-graphs in providing explicit associations\nbetween effective negotiation strategies over the course of the dialogue,\nleading to interpretable and strategic dialogues.",
          "link": "http://arxiv.org/abs/2106.00920",
          "publishedOn": "2021-06-03T02:10:35.208Z",
          "wordCount": 575,
          "title": "DialoGraph: Incorporating Interpretable Strategy-Graph Networks into Negotiation Dialogues. (arXiv:2106.00920v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00922",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghiassian_S/0/1/0/all/0/1\">Sina Ghiassian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sutton_R/0/1/0/all/0/1\">Richard S. Sutton</a>",
          "description": "Off-policy prediction -- learning the value function for one policy from data\ngenerated while following another policy -- is one of the most challenging\nsubproblems in reinforcement learning. This paper presents empirical results\nwith eleven prominent off-policy learning algorithms that use linear function\napproximation: five Gradient-TD methods, two Emphatic-TD methods, Off-policy\nTD($\\lambda$), Vtrace, and versions of Tree Backup and ABQ modified to apply to\na prediction setting. Our experiments used the Collision task, a small\nidealized off-policy problem analogous to that of an autonomous car trying to\npredict whether it will collide with an obstacle. We assessed the performance\nof the algorithms according to their learning rate, asymptotic error level, and\nsensitivity to step-size and bootstrapping parameters. By these measures, the\neleven algorithms can be partially ordered on the Collision task. In the top\ntier, the two Emphatic-TD algorithms learned the fastest, reached the lowest\nerrors, and were robust to parameter settings. In the middle tier, the five\nGradient-TD algorithms and Off-policy TD($\\lambda$) were more sensitive to the\nbootstrapping parameter. The bottom tier comprised Vtrace, Tree Backup, and\nABQ; these algorithms were no faster and had higher asymptotic error than the\nothers. Our results are definitive for this task, though of course experiments\nwith more tasks are needed before an overall assessment of the algorithms'\nmerits can be made.",
          "link": "http://arxiv.org/abs/2106.00922",
          "publishedOn": "2021-06-03T02:10:35.200Z",
          "wordCount": 652,
          "title": "An Empirical Comparison of Off-policy Prediction Learning Algorithms on the Collision Task. (arXiv:2106.00922v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2104.08135",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Montufar_G/0/1/0/all/0/1\">Guido Mont&#xfa;far</a>, <a href=\"http://arxiv.org/find/math/1/au:+Ren_Y/0/1/0/all/0/1\">Yue Ren</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_L/0/1/0/all/0/1\">Leon Zhang</a>",
          "description": "We present results on the number of linear regions of the functions that can\nbe represented by artificial feedforward neural networks with maxout units. A\nrank-k maxout unit is a function computing the maximum of $k$ linear functions.\nFor networks with a single layer of maxout units, the linear regions correspond\nto the upper vertices of a Minkowski sum of polytopes. We obtain face counting\nformulas in terms of the intersection posets of tropical hypersurfaces or the\nnumber of upper faces of partial Minkowski sums, along with explicit sharp\nupper bounds for the number of regions for any input dimension, any number of\nunits, and any ranks, in the cases with and without biases. Based on these\nresults we also obtain asymptotically sharp upper bounds for networks with\nmultiple layers.",
          "link": "http://arxiv.org/abs/2104.08135",
          "publishedOn": "2021-06-03T02:10:35.196Z",
          "wordCount": 582,
          "title": "Sharp bounds for the number of regions of maxout networks and vertices of Minkowski sums. (arXiv:2104.08135v1 [math.CO] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.07246",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Minkai Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wujie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1\">Shitong Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1\">Chence Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_Bombarelli_R/0/1/0/all/0/1\">Rafael Gomez-Bombarelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jian Tang</a>",
          "description": "Predicting molecular conformations (or 3D structures) from molecular graphs\nis a fundamental problem in many applications. Most existing approaches are\nusually divided into two steps by first predicting the distances between atoms\nand then generating a 3D structure through optimizing a distance geometry\nproblem. However, the distances predicted with such two-stage approaches may\nnot be able to consistently preserve the geometry of local atomic\nneighborhoods, making the generated structures unsatisfying. In this paper, we\npropose an end-to-end solution for molecular conformation prediction called\nConfVAE based on the conditional variational autoencoder framework.\nSpecifically, the molecular graph is first encoded in a latent space, and then\nthe 3D structures are generated by solving a principled bilevel optimization\nprogram. Extensive experiments on several benchmark data sets prove the\neffectiveness of our proposed approach over existing state-of-the-art\napproaches. Code is available at\n\\url{https://github.com/MinkaiXu/ConfVAE-ICML21}.",
          "link": "http://arxiv.org/abs/2105.07246",
          "publishedOn": "2021-06-03T02:10:35.128Z",
          "wordCount": 613,
          "title": "An End-to-End Framework for Molecular Conformation Generation via Bilevel Programming. (arXiv:2105.07246v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.04026",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wilson_J/0/1/0/all/0/1\">James T. Wilson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Borovitskiy_V/0/1/0/all/0/1\">Viacheslav Borovitskiy</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Terenin_A/0/1/0/all/0/1\">Alexander Terenin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mostowsky_P/0/1/0/all/0/1\">Peter Mostowsky</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Deisenroth_M/0/1/0/all/0/1\">Marc Peter Deisenroth</a>",
          "description": "As Gaussian processes are used to answer increasingly complex questions,\nanalytic solutions become scarcer and scarcer. Monte Carlo methods act as a\nconvenient bridge for connecting intractable mathematical expressions with\nactionable estimates via sampling. Conventional approaches for simulating\nGaussian process posteriors view samples as draws from marginal distributions\nof process values at finite sets of input locations. This distribution-centric\ncharacterization leads to generative strategies that scale cubically in the\nsize of the desired random vector. These methods are prohibitively expensive in\ncases where we would, ideally, like to draw high-dimensional vectors or even\ncontinuous sample paths. In this work, we investigate a different line of\nreasoning: rather than focusing on distributions, we articulate Gaussian\nconditionals at the level of random variables. We show how this pathwise\ninterpretation of conditioning gives rise to a general family of approximations\nthat lend themselves to efficiently sampling Gaussian process posteriors.\nStarting from first principles, we derive these methods and analyze the\napproximation errors they introduce. We, then, ground these results by\nexploring the practical implications of pathwise conditioning in various\napplied settings, such as global optimization and reinforcement learning.",
          "link": "http://arxiv.org/abs/2011.04026",
          "publishedOn": "2021-06-03T02:10:35.087Z",
          "wordCount": 641,
          "title": "Pathwise Conditioning of Gaussian Processes. (arXiv:2011.04026v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01101",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vardi_G/0/1/0/all/0/1\">Gal Vardi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yehudai_G/0/1/0/all/0/1\">Gilad Yehudai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shamir_O/0/1/0/all/0/1\">Ohad Shamir</a>",
          "description": "We theoretically study the fundamental problem of learning a single neuron\nwith a bias term ($\\mathbf{x} \\mapsto \\sigma(<\\mathbf{w},\\mathbf{x}> + b)$) in\nthe realizable setting with the ReLU activation, using gradient descent.\nPerhaps surprisingly, we show that this is a significantly different and more\nchallenging problem than the bias-less case (which was the focus of previous\nworks on single neurons), both in terms of the optimization geometry as well as\nthe ability of gradient methods to succeed in some scenarios. We provide a\ndetailed study of this problem, characterizing the critical points of the\nobjective, demonstrating failure cases, and providing positive convergence\nguarantees under different sets of assumptions. To prove our results, we\ndevelop some tools which may be of independent interest, and improve previous\nresults on learning single neurons.",
          "link": "http://arxiv.org/abs/2106.01101",
          "publishedOn": "2021-06-03T02:10:35.066Z",
          "wordCount": 564,
          "title": "Learning a Single Neuron with Bias Using Gradient Descent. (arXiv:2106.01101v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01016",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lee_M/0/1/0/all/0/1\">Myoung Hoon Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moon_J/0/1/0/all/0/1\">Jun Moon</a>",
          "description": "In this paper, we propose SACHER (soft actor-critic (SAC) with hindsight\nexperience replay (HER)), which constitutes a class of deep reinforcement\nlearning (DRL) algorithms. SAC is known as an off-policy model-free DRL\nalgorithm based on the maximum entropy framework, which outperforms earlier DRL\nalgorithms in terms of exploration, robustness and learning performance.\nHowever, in SAC, maximizing the entropy-augmented objective may degrade the\noptimality of the learning outcomes. HER is known as a sample-efficient replay\nmethod that enhances the performance of off-policy DRL algorithms by allowing\nthem to learn from both failures and successes. We apply HER to SAC and propose\nSACHER to improve the learning performance of SAC. More precisely, SACHER\nachieves the desired optimal outcomes faster and more accurately than SAC,\nsince HER improves the sample efficiency of SAC. We apply SACHER to the\nnavigation and control problem of unmanned aerial vehicles (UAVs), where SACHER\ngenerates the optimal navigation path of the UAV under various obstacles in\noperation. Specifically, we show the effectiveness of SACHER in terms of the\ntracking error and cumulative reward in UAV operation by comparing them with\nthose of state-of-the-art DRL algorithms, SAC and DDPG. Note that SACHER in UAV\nnavigation and control problems can be applied to arbitrary models of UAVs.",
          "link": "http://arxiv.org/abs/2106.01016",
          "publishedOn": "2021-06-03T02:10:35.051Z",
          "wordCount": 665,
          "title": "Deep Reinforcement Learning-based UAV Navigation and Control: A Soft Actor-Critic with Hindsight Experience Replay Approach. (arXiv:2106.01016v1 [eess.SY])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00720",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Datta_A/0/1/0/all/0/1\">Arghya Datta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swamidass_S/0/1/0/all/0/1\">S. Joshua Swamidass</a>",
          "description": "In real world datasets, particular groups are under-represented, much rarer\nthan others, and machine learning classifiers will often preform worse on\nunder-represented populations. This problem is aggravated across many domains\nwhere datasets are class imbalanced, with a minority class far rarer than the\nmajority class. Naive approaches to handle under-representation and class\nimbalance include training sub-population specific classifiers that handle\nclass imbalance or training a global classifier that overlooks sub-population\ndisparities and aims to achieve high overall accuracy by handling class\nimbalance. In this study, we find that these approaches are vulnerable in class\nimbalanced datasets with minority sub-populations. We introduced Fair-Net, a\nbranched multitask neural network architecture that improves both\nclassification accuracy and probability calibration across identifiable\nsub-populations in class imbalanced datasets. Fair-Nets is a straightforward\nextension to the output layer and error function of a network, so can be\nincorporated in far more complex architectures. Empirical studies with three\nreal world benchmark datasets demonstrate that Fair-Net improves classification\nand calibration performance, substantially reducing performance disparity\nbetween gender and racial sub-populations.",
          "link": "http://arxiv.org/abs/2106.00720",
          "publishedOn": "2021-06-03T02:10:35.016Z",
          "wordCount": 602,
          "title": "Fair-Net: A Network Architecture For Reducing Performance Disparity Between Identifiable Sub-Populations. (arXiv:2106.00720v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00730",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baharav_T/0/1/0/all/0/1\">Tavor Z. Baharav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1\">Daniel L. Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolluri_K/0/1/0/all/0/1\">Kedarnath Kolluri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanghavi_S/0/1/0/all/0/1\">Sujay Sanghavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhillon_I/0/1/0/all/0/1\">Inderjit S. Dhillon</a>",
          "description": "Extreme multi-label classification (XMC) aims to learn a model that can tag\ndata points with a subset of relevant labels from an extremely large label set.\nReal world e-commerce applications like personalized recommendations and\nproduct advertising can be formulated as XMC problems, where the objective is\nto predict for a user a small subset of items from a catalog of several million\nproducts. For such applications, a common approach is to organize these labels\ninto a tree, enabling training and inference times that are logarithmic in the\nnumber of labels. While training a model once a label tree is available is well\nstudied, designing the structure of the tree is a difficult task that is not\nyet well understood, and can dramatically impact both model latency and\nstatistical performance. Existing approaches to tree construction fall at an\nextreme point, either optimizing exclusively for statistical performance, or\nfor latency. We propose an efficient information theory inspired algorithm to\nconstruct intermediary operating points that trade off between the benefits of\nboth. Our algorithm enables interpolation between these objectives, which was\nnot previously possible. We corroborate our theoretical analysis with numerical\nresults, showing that on the Wiki-500K benchmark dataset our method can reduce\na proxy for expected latency by up to 28% while maintaining the same accuracy\nas Parabel. On several datasets derived from e-commerce customer logs, our\nmodified label tree is able to improve this expected latency metric by up to\n20% while maintaining the same accuracy. Finally, we discuss challenges in\nrealizing these latency improvements in deployed models.",
          "link": "http://arxiv.org/abs/2106.00730",
          "publishedOn": "2021-06-03T02:10:34.877Z",
          "wordCount": 694,
          "title": "Enabling Efficiency-Precision Trade-offs for Label Trees in Extreme Classification. (arXiv:2106.00730v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00687",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dennler_N/0/1/0/all/0/1\">Nik Dennler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haessig_G/0/1/0/all/0/1\">Germain Haessig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cartiglia_M/0/1/0/all/0/1\">Matteo Cartiglia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Indiveri_G/0/1/0/all/0/1\">Giacomo Indiveri</a>",
          "description": "Vibration patterns yield valuable information about the health state of a\nrunning machine, which is commonly exploited in predictive maintenance tasks\nfor large industrial systems. However, the overhead, in terms of size,\ncomplexity and power budget, required by classical methods to exploit this\ninformation is often prohibitive for smaller-scale applications such as\nautonomous cars, drones or robotics. Here we propose a neuromorphic approach to\nperform vibration analysis using spiking neural networks that can be applied to\na wide range of scenarios. We present a spike-based end-to-end pipeline able to\ndetect system anomalies from vibration data, using building blocks that are\ncompatible with analog-digital neuromorphic circuits. This pipeline operates in\nan online unsupervised fashion, and relies on a cochlea model, on feedback\nadaptation and on a balanced spiking neural network. We show that the proposed\nmethod achieves state-of-the-art performance or better against two publicly\navailable data sets. Further, we demonstrate a working proof-of-concept\nimplemented on an asynchronous neuromorphic processor device. This work\nrepresents a significant step towards the design and implementation of\nautonomous low-power edge-computing devices for online vibration monitoring.",
          "link": "http://arxiv.org/abs/2106.00687",
          "publishedOn": "2021-06-03T02:10:34.748Z",
          "wordCount": 638,
          "title": "Online Detection of Vibration Anomalies Using Balanced Spiking Neural Networks. (arXiv:2106.00687v1 [cs.NE])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00717",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hamrouni_A/0/1/0/all/0/1\">Aymen Hamrouni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghazzai_H/0/1/0/all/0/1\">Hakim Ghazzai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alelyani_T/0/1/0/all/0/1\">Turki Alelyani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Massoud_Y/0/1/0/all/0/1\">Yehia Massoud</a>",
          "description": "Collaborative Mobile crowdsourcing (CMCS) allows entities, e.g., local\nauthorities or individuals, to hire a team of workers from the crowd of\nconnected people, to execute complex tasks. In this paper, we investigate two\ndifferent CMCS recruitment strategies allowing task requesters to form teams of\nsocially connected and skilled workers: i) a platform-based strategy where the\nplatform exploits its own knowledge about the workers to form a team and ii) a\nleader-based strategy where the platform designates a group leader that\nrecruits its own suitable team given its own knowledge about its Social Network\n(SN) neighbors. We first formulate the recruitment as an Integer Linear Program\n(ILP) that optimally forms teams according to four fuzzy-logic-based criteria:\nlevel of expertise, social relationship strength, recruitment cost, and\nrecruiter's confidence level. To cope with NP-hardness, we design a novel\nlow-complexity CMCS recruitment approach relying on Graph Neural Networks\n(GNNs), specifically graph embedding and clustering techniques, to shrink the\nworkers' search space and afterwards, exploiting a meta-heuristic genetic\nalgorithm to select appropriate workers. Simulation results applied on a\nreal-world dataset illustrate the performance of both proposed CMCS recruitment\napproaches. It is shown that our proposed low-complexity GNN-based recruitment\nalgorithm achieves close performances to those of the baseline ILP with\nsignificant computational time saving and ability to operate on large-scale\nmobile crowdsourcing platforms. It is also shown that compared to the\nleader-based strategy, the platform-based strategy recruits a more skilled team\nbut with lower SN relationships and higher cost.",
          "link": "http://arxiv.org/abs/2106.00717",
          "publishedOn": "2021-06-03T02:10:34.714Z",
          "wordCount": 697,
          "title": "Low Complexity Recruitment for Collaborative Mobile Crowdsourcing Using Graph Neural Networks. (arXiv:2106.00717v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00719",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meng_R/0/1/0/all/0/1\">Rui Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Herbie Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouchard_K/0/1/0/all/0/1\">Kristofer Bouchard</a>",
          "description": "Currently, multi-output Gaussian process regression models either do not\nmodel nonstationarity or are associated with severe computational burdens and\nstorage demands. Nonstationary multi-variate Gaussian process models (NMGP) use\na nonstationary covariance function with an input-dependent linear model of\ncoregionalisation to jointly model input-dependent correlation, scale, and\nsmoothness of outputs. Variational sparse approximation relies on inducing\npoints to enable scalable computations. Here, we take the best of both worlds:\nconsidering an inducing variable framework on the underlying latent functions\nin NMGP, we propose a novel model called the collaborative nonstationary\nGaussian process model(CNMGP). For CNMGP, we derive computationally tractable\nvariational bounds amenable to doubly stochastic variational inference.\nTogether, this allows us to model data in which outputs do not share a common\ninput set, with a computational complexity that is independent of the size of\nthe inputs and outputs. We illustrate the performance of our method on\nsynthetic data and three real datasets and show that our model generally\npro-vides better predictive performance than the state-of-the-art, and also\nprovides estimates of time-varying correlations that differ across outputs.",
          "link": "http://arxiv.org/abs/2106.00719",
          "publishedOn": "2021-06-03T02:10:34.709Z",
          "wordCount": 599,
          "title": "Collaborative Nonstationary Multivariate Gaussian Process Model. (arXiv:2106.00719v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00707",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Changnan Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1\">Haosen Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1\">Jiajun Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shihong Deng</a>",
          "description": "Policy-based reinforcement learning methods suffer from the policy collapse\nproblem. We find valued-based reinforcement learning methods with\n{\\epsilon}-greedy mechanism are capable of enjoying three characteristics,\nClosed-form Diversity, Objective-invariant Exploration and Adaptive Trade-off,\nwhich help value-based methods avoid the policy collapse problem. However,\nthere does not exist a parallel mechanism for policy-based methods that\nachieves all three characteristics. In this paper, we propose an entropy\nregularization free mechanism that is designed for policy-based methods, which\nachieves Closed-form Diversity, Objective-invariant Exploration and Adaptive\nTrade-off. Our experiments show that our mechanism is super sample-efficient\nfor policy-based methods and boosts a policy-based baseline to a new\nState-Of-The-Art on Arcade Learning Environment.",
          "link": "http://arxiv.org/abs/2106.00707",
          "publishedOn": "2021-06-03T02:10:34.698Z",
          "wordCount": 545,
          "title": "An Entropy Regularization Free Mechanism for Policy-based Reinforcement Learning. (arXiv:2106.00707v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00694",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maiti_A/0/1/0/all/0/1\">Anindita Maiti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoner_K/0/1/0/all/0/1\">Keegan Stoner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Halverson_J/0/1/0/all/0/1\">James Halverson</a>",
          "description": "Parameter-space and function-space provide two different duality frames in\nwhich to study neural networks. We demonstrate that symmetries of network\ndensities may be determined via dual computations of network correlation\nfunctions, even when the density is unknown and the network is not equivariant.\nSymmetry-via-duality relies on invariance properties of the correlation\nfunctions, which stem from the choice of network parameter distributions. Input\nand output symmetries of neural network densities are determined, which recover\nknown Gaussian process results in the infinite width limit. The mechanism may\nalso be utilized to determine symmetries during training, when parameters are\ncorrelated, as well as symmetries of the Neural Tangent Kernel. We demonstrate\nthat the amount of symmetry in the initialization density affects the accuracy\nof networks trained on Fashion-MNIST, and that symmetry breaking helps only\nwhen it is in the direction of ground truth.",
          "link": "http://arxiv.org/abs/2106.00694",
          "publishedOn": "2021-06-03T02:10:34.645Z",
          "wordCount": 580,
          "title": "Symmetry-via-Duality: Invariant Neural Network Densities from Parameter-Space Correlators. (arXiv:2106.00694v1 [cs.LG])"
        }
      ]
    }
  ],
  "cliVersion": "1.10.2"
}