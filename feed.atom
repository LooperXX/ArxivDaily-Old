<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://looperxx.github.io/ArxivDaily/index.html</id>
    <title>ArxivDaily</title>
    <updated>2021-05-22T12:07:06.551Z</updated>
    <generator>osmosfeed 1.7.2</generator>
    <link rel="alternate" href="https://looperxx.github.io/ArxivDaily/index.html"/>
    <link rel="self" href="https://looperxx.github.io/ArxivDaily/feed.atom"/>
    <entry>
        <title type="html"><![CDATA[Multiple Support Recovery Using Very Few Measurements Per Sample. (arXiv:2105.09855v1 [cs.IT])]]></title>
        <id>http://arxiv.org/abs/2105.09855</id>
        <link href="http://arxiv.org/abs/2105.09855"/>
        <updated>2021-05-22T06:24:29.909Z</updated>
        <summary type="html"><![CDATA[In the problem of multiple support recovery, we are given access to linear
measurements of multiple sparse samples in $\mathbb{R}^{d}$. These samples can
be partitioned into $\ell$ groups, with samples having the same support
belonging to the same group. For a given budget of $m$ measurements per sample,
the goal is to recover the $\ell$ underlying supports, in the absence of the
knowledge of group labels. We study this problem with a focus on the
measurement-constrained regime where $m$ is smaller than the…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ramesh_L/0/1/0/all/0/1"&gt;Lekshmi Ramesh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Murthy_C/0/1/0/all/0/1"&gt;Chandra R. Murthy&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tyagi_H/0/1/0/all/0/1"&gt;Himanshu Tyagi&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[UmlsBERT: Clinical Domain Knowledge Augmentation of Contextual Embeddings Using the Unified Medical Language System Metathesaurus. (arXiv:2010.10391v4 [cs.CL] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2010.10391</id>
        <link href="http://arxiv.org/abs/2010.10391"/>
        <updated>2021-05-22T06:24:29.878Z</updated>
        <summary type="html"><![CDATA[Contextual word embedding models, such as BioBERT and Bio_ClinicalBERT, have
achieved state-of-the-art results in biomedical natural language processing
tasks by focusing their pre-training process on domain-specific corpora.
However, such models do not take into consideration expert domain knowledge.

In this work, we introduced UmlsBERT, a contextual embedding model that
integrates domain knowledge during the pre-training process via a novel
knowledge augmentation strategy. More specifically, the augmenta…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Michalopoulos_G/0/1/0/all/0/1"&gt;George Michalopoulos&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"&gt;Yuanxin Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kaka_H/0/1/0/all/0/1"&gt;Hussam Kaka&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1"&gt;Helen Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1"&gt;Alexander Wong&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Computer Users Have Unique Yet Temporally Inconsistent Computer Usage Profiles. (arXiv:2105.09900v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09900</id>
        <link href="http://arxiv.org/abs/2105.09900"/>
        <updated>2021-05-22T06:24:29.870Z</updated>
        <summary type="html"><![CDATA[This paper investigates whether computer usage profiles comprised of
process-, network-, mouse- and keystroke-related events are unique and
temporally consistent in a naturalistic setting, discussing challenges and
opportunities of using such profiles in applications of continuous
authentication. We collected ecologically-valid computer usage profiles from 28
MS Windows 10 computer users over 8 weeks and submitted this data to
comprehensive machine learning analysis involving a diverse set of online and
off…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Giovanini_L/0/1/0/all/0/1"&gt;Luiz Giovanini&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ceschin_F/0/1/0/all/0/1"&gt;Fabr&amp;#xed;cio Ceschin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Silva_M/0/1/0/all/0/1"&gt;Mirela Silva&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1"&gt;Aokun Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kulkarni_R/0/1/0/all/0/1"&gt;Ramchandra Kulkarni&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Banda_S/0/1/0/all/0/1"&gt;Sanjay Banda&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lysaght_M/0/1/0/all/0/1"&gt;Madison Lysaght&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Qiao_H/0/1/0/all/0/1"&gt;Heng Qiao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sapountzis_N/0/1/0/all/0/1"&gt;Nikolaos Sapountzis&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1"&gt;Ruimin Sun&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Matthews_B/0/1/0/all/0/1"&gt;Brandon Matthews&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1"&gt;Dapeng Oliver Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gregio_A/0/1/0/all/0/1"&gt;Andr&amp;#xe9; Gr&amp;#xe9;gio&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Oliveira_D/0/1/0/all/0/1"&gt;Daniela Oliveira&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incentivized Bandit Learning with Self-Reinforcing User Preferences. (arXiv:2105.08869v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.08869</id>
        <link href="http://arxiv.org/abs/2105.08869"/>
        <updated>2021-05-22T06:24:29.717Z</updated>
        <summary type="html"><![CDATA[In this paper, we investigate a new multi-armed bandit (MAB) online learning
model that considers real-world phenomena in many recommender systems: (i) the
learning agent cannot pull the arms by itself and thus has to offer rewards to
users to incentivize arm-pulling indirectly; and (ii) if users with specific
arm preferences are well rewarded, they induce a "self-reinforcing" effect in
the sense that they will attract more users of similar arm preferences. Besides
addressing the tradeoff of exploration and…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1"&gt;Tianchen Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1"&gt;Jia Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Dong_C/0/1/0/all/0/1"&gt;Chaosheng Dong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1"&gt;Jingyuan Deng&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multi-Perspective Anomaly Detection. (arXiv:2105.09903v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09903</id>
        <link href="http://arxiv.org/abs/2105.09903"/>
        <updated>2021-05-22T06:24:29.711Z</updated>
        <summary type="html"><![CDATA[Multi-view classification is inspired by the behavior of humans, especially
when fine-grained features or in our case rarely occurring anomalies are to be
detected. Current contributions point to the problem of how high-dimensional
data can be fused. In this work, we build upon the deep support vector data
description algorithm and address multi-perspective anomaly detection using
three different fusion techniques i.e. early fusion, late fusion, and late
fusion with multiple decoders. We employ different au…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Madan_M/0/1/0/all/0/1"&gt;Manav Madan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jakob_P/0/1/0/all/0/1"&gt;Peter Jakob&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Schmid_Schirling_T/0/1/0/all/0/1"&gt;Tobias Schmid-Schirling&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Valada_A/0/1/0/all/0/1"&gt;Abhinav Valada&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[COVID-19 Detection in Computed Tomography Images with 2D and 3D Approaches. (arXiv:2105.08506v2 [eess.IV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.08506</id>
        <link href="http://arxiv.org/abs/2105.08506"/>
        <updated>2021-05-22T06:24:29.704Z</updated>
        <summary type="html"><![CDATA[Detecting COVID-19 in computed tomography (CT) or radiography images has been
proposed as a supplement to the definitive RT-PCR test. We present a deep
learning ensemble for detecting COVID-19 infection, combining slice-based (2D)
and volume-based (3D) approaches. The 2D system detects the infection on each
CT slice independently, combining them to obtain the patient-level decision via
different methods (averaging and long-short term memory networks). The 3D
system takes the whole CT volume to arrive to the…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Ahmed_S/0/1/0/all/0/1"&gt;Sara Atito Ali Ahmed&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Yavuz_M/0/1/0/all/0/1"&gt;Mehmet Can Yavuz&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Sen_M/0/1/0/all/0/1"&gt;Mehmet Umut Sen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Gulsen_F/0/1/0/all/0/1"&gt;Fatih Gulsen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Tutar_O/0/1/0/all/0/1"&gt;Onur Tutar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Korkmazer_B/0/1/0/all/0/1"&gt;Bora Korkmazer&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Samanci_C/0/1/0/all/0/1"&gt;Cesur Samanci&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Sirolu_S/0/1/0/all/0/1"&gt;Sabri Sirolu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Hamid_R/0/1/0/all/0/1"&gt;Rauf Hamid&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Eryurekli_A/0/1/0/all/0/1"&gt;Ali Ergun Eryurekli&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Mammadov_T/0/1/0/all/0/1"&gt;Toghrul Mammadov&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Yanikoglu_B/0/1/0/all/0/1"&gt;Berrin Yanikoglu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Explainable artificial intelligence for mechanics: physics-informing neural networks for constitutive models. (arXiv:2104.10683v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2104.10683</id>
        <link href="http://arxiv.org/abs/2104.10683"/>
        <updated>2021-05-22T06:24:29.650Z</updated>
        <summary type="html"><![CDATA[(Artificial) neural networks have become increasingly popular in mechanics as
means to accelerate computations with model order reduction techniques and as
universal models for a wide variety of materials. However, the major
disadvantage of neural networks remains: their numerous parameters are
challenging to interpret and explain. Thus, neural networks are often labeled
as black boxes, and their results often elude human interpretation. In
mechanics, the new and active field of physics-informed neural netw…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Koeppe_A/0/1/0/all/0/1"&gt;Arnd Koeppe&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bamer_F/0/1/0/all/0/1"&gt;Franz Bamer&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Selzer_M/0/1/0/all/0/1"&gt;Michael Selzer&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Nestler_B/0/1/0/all/0/1"&gt;Britta Nestler&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Markert_B/0/1/0/all/0/1"&gt;Bernd Markert&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[FedMood: Federated Learning on Mobile Health Data for Mood Detection. (arXiv:2102.09342v6 [cs.CY] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2102.09342</id>
        <link href="http://arxiv.org/abs/2102.09342"/>
        <updated>2021-05-22T06:24:29.629Z</updated>
        <summary type="html"><![CDATA[Depression is one of the most common mental illness problems, and the
symptoms shown by patients are not consistent, making it difficult to diagnose
in the process of clinical practice and pathological research. Although
researchers hope that artificial intelligence can contribute to the diagnosis
and treatment of depression, the traditional centralized machine learning needs
to aggregate patient data, and the data privacy of patients with mental illness
needs to be strictly confidential, which hinders mach…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1"&gt;Xiaohang Xu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1"&gt;Hao Peng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1"&gt;Lichao Sun&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bhuiyan_M/0/1/0/all/0/1"&gt;Md Zakirul Alam Bhuiyan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1"&gt;Lianzhong Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1"&gt;Lifang He&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Auto-Tuned Sim-to-Real Transfer. (arXiv:2104.07662v2 [cs.RO] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2104.07662</id>
        <link href="http://arxiv.org/abs/2104.07662"/>
        <updated>2021-05-22T06:24:29.611Z</updated>
        <summary type="html"><![CDATA[Policies trained in simulation often fail when transferred to the real world
due to the `reality gap' where the simulator is unable to accurately capture
the dynamics and visual properties of the real world. Current approaches to
tackle this problem, such as domain randomization, require prior knowledge and
engineering to determine how much to randomize system parameters in order to
learn a policy that is robust to sim-to-real transfer while also not being too
conservative. We propose a method for automatic…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1"&gt;Yuqing Du&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Watkins_O/0/1/0/all/0/1"&gt;Olivia Watkins&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1"&gt;Trevor Darrell&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1"&gt;Pieter Abbeel&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Pathak_D/0/1/0/all/0/1"&gt;Deepak Pathak&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Noise Estimation Is Not Optimal: How to Use Kalman Filter the Right Way. (arXiv:2104.02372v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2104.02372</id>
        <link href="http://arxiv.org/abs/2104.02372"/>
        <updated>2021-05-22T06:24:29.601Z</updated>
        <summary type="html"><![CDATA[Determining the noise parameters of a Kalman Filter (KF) has been studied for
decades. A huge body of research focuses on the task of estimation of the noise
under various conditions, since precise noise estimation is considered
equivalent to minimization of the filtering errors. However, we show that even
a small violation of the KF assumptions can significantly modify the effective
noise, breaking the equivalence between the tasks and making noise estimation
an inferior strategy. We show that such violati…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Greenberg_I/0/1/0/all/0/1"&gt;Ido Greenberg&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yannay_N/0/1/0/all/0/1"&gt;Netanel Yannay&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mannor_S/0/1/0/all/0/1"&gt;Shie Mannor&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How to send a real number using a single bit (and some shared randomness). (arXiv:2010.02331v4 [cs.DS] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2010.02331</id>
        <link href="http://arxiv.org/abs/2010.02331"/>
        <updated>2021-05-22T06:24:29.549Z</updated>
        <summary type="html"><![CDATA[We consider the fundamental problem of communicating an estimate of a real
number $x\in[0,1]$ using a single bit. A sender that knows $x$ chooses a value
$X\in\set{0,1}$ to transmit. In turn, a receiver estimates $x$ based on the
value of $X$. We consider both the biased and unbiased estimation problems and
aim to minimize the cost. For the biased case, the cost is the worst-case (over
the choice of $x$) expected squared error, which coincides with the variance if
the algorithm is required to be unbiased.

…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ben_Basat_R/0/1/0/all/0/1"&gt;Ran Ben-Basat&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mitzenmacher_M/0/1/0/all/0/1"&gt;Michael Mitzenmacher&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Vargaftik_S/0/1/0/all/0/1"&gt;Shay Vargaftik&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Low-Rank and Sparse Enhanced Tucker Decomposition for Tensor Completion. (arXiv:2010.00359v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2010.00359</id>
        <link href="http://arxiv.org/abs/2010.00359"/>
        <updated>2021-05-22T06:24:29.543Z</updated>
        <summary type="html"><![CDATA[Tensor completion refers to the task of estimating the missing data from an
incomplete measurement or observation, which is a core problem frequently
arising from the areas of big data analysis, computer vision, and network
engineering. Due to the multidimensional nature of high-order tensors, the
matrix approaches, e.g., matrix factorization and direct matricization of
tensors, are often not ideal for tensor completion and recovery. In this paper,
we introduce a unified low-rank and sparse enhanced Tucker …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Pan_C/0/1/0/all/0/1"&gt;Chenjian Pan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ling_C/0/1/0/all/0/1"&gt;Chen Ling&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1"&gt;Hongjin He&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Qi_L/0/1/0/all/0/1"&gt;Liqun Qi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1"&gt;Yanwei Xu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MoDL-QSM: Model-based Deep Learning for Quantitative Susceptibility Mapping. (arXiv:2101.08413v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2101.08413</id>
        <link href="http://arxiv.org/abs/2101.08413"/>
        <updated>2021-05-22T06:24:29.536Z</updated>
        <summary type="html"><![CDATA[Quantitative susceptibility mapping (QSM) has demonstrated great potential in
quantifying tissue susceptibility in various brain diseases. However, the
intrinsic ill-posed inverse problem relating the tissue phase to the underlying
susceptibility distribution affects the accuracy for quantifying tissue
susceptibility. Recently, deep learning has shown promising results to improve
accuracy by reducing the streaking artifacts. However, there exists a mismatch
between the observed phase and the theoretical for…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Feng_R/0/1/0/all/0/1"&gt;Ruimin Feng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1"&gt;Jiayi Zhao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1"&gt;He Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1"&gt;Baofeng Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1"&gt;Jie Feng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1"&gt;Yuting Shi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1"&gt;Ming Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1"&gt;Chunlei Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1"&gt;Yuyao Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhuang_J/0/1/0/all/0/1"&gt;Jie Zhuang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wei_H/0/1/0/all/0/1"&gt;Hongjiang Wei&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[tFold-TR: Combining Deep Learning Enhanced Hybrid Potential Energy for Template-Based Modelling Structure Refinement. (arXiv:2105.04350v2 [physics.bio-ph] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.04350</id>
        <link href="http://arxiv.org/abs/2105.04350"/>
        <updated>2021-05-22T06:24:29.527Z</updated>
        <summary type="html"><![CDATA[Proteins structure prediction has long been a grand challenge over the past
50 years, owing to its board scientific and application interests. There are
two major types of modelling algorithm, template-free modelling and
template-based modelling, which is suitable for easy prediction tasks, and is
widely adopted in computer aided drug discoveries for drug design and
screening. Although it has been several decades since its first edition, the
current template-based modeling approach suffers from two importan…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/physics/1/au:+Zheng_L/0/1/0/all/0/1"&gt;Liangzhen Zheng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Lan_H/0/1/0/all/0/1"&gt;Haidong Lan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Shen_T/0/1/0/all/0/1"&gt;Tao Shen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Wu_J/0/1/0/all/0/1"&gt;Jiaxiang Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Wang_S/0/1/0/all/0/1"&gt;Sheng Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Liu_W/0/1/0/all/0/1"&gt;Wei Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Huang_J/0/1/0/all/0/1"&gt;Junzhou Huang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MIN2Net: End-to-End Multi-Task Learning for Subject-Independent Motor Imagery EEG Classification. (arXiv:2102.03814v3 [eess.SP] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2102.03814</id>
        <link href="http://arxiv.org/abs/2102.03814"/>
        <updated>2021-05-22T06:24:29.521Z</updated>
        <summary type="html"><![CDATA[Advances in the motor imagery (MI)-based brain-computer interfaces (BCIs)
allow control of several applications by decoding neurophysiological phenomena,
which are usually recorded by electroencephalography (EEG) using a non-invasive
technique. Despite great advances in MI-based BCI, EEG rhythms are specific to
a subject and various changes over time. These issues point to significant
challenges to enhance the classification performance, especially in a
subject-independent manner. To overcome these challeng…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Autthasan_P/0/1/0/all/0/1"&gt;Phairot Autthasan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Chaisaen_R/0/1/0/all/0/1"&gt;Rattanaphon Chaisaen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Sudhawiyangkul_T/0/1/0/all/0/1"&gt;Thapanun Sudhawiyangkul&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Rangpong_P/0/1/0/all/0/1"&gt;Phurin Rangpong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Kiatthaveephong_S/0/1/0/all/0/1"&gt;Suktipol Kiatthaveephong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Dilokthanakul_N/0/1/0/all/0/1"&gt;Nat Dilokthanakul&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Bhakdisongkhram_G/0/1/0/all/0/1"&gt;Gun Bhakdisongkhram&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Phan_H/0/1/0/all/0/1"&gt;Huy Phan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Guan_C/0/1/0/all/0/1"&gt;Cuntai Guan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Wilaiprasitporn_T/0/1/0/all/0/1"&gt;Theerawit Wilaiprasitporn&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning-based attacks in Cyber-Physical Systems: Exploration, Detection, and Control Cost trade-offs. (arXiv:2011.10718v2 [eess.SY] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2011.10718</id>
        <link href="http://arxiv.org/abs/2011.10718"/>
        <updated>2021-05-22T06:24:29.513Z</updated>
        <summary type="html"><![CDATA[We study the problem of learning-based attacks in linear systems, where the
communication channel between the controller and the plant can be hijacked by a
malicious attacker. We assume the attacker learns the dynamics of the system
from observations, then overrides the controller's actuation signal, while
mimicking legitimate operation by providing fictitious sensor readings to the
controller. On the other hand, the controller is on a lookout to detect the
presence of the attacker and tries to enhance the …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Rangi_A/0/1/0/all/0/1"&gt;Anshuka Rangi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Khojasteh_M/0/1/0/all/0/1"&gt;Mohammad Javad Khojasteh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Franceschetti_M/0/1/0/all/0/1"&gt;Massimo Franceschetti&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Modeling the Field Value Variations and Field Interactions Simultaneously for Fraud Detection. (arXiv:2008.05600v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2008.05600</id>
        <link href="http://arxiv.org/abs/2008.05600"/>
        <updated>2021-05-22T06:24:29.497Z</updated>
        <summary type="html"><![CDATA[With the explosive growth of e-commerce, online transaction fraud has become
one of the biggest challenges for e-commerce platforms. The historical
behaviors of users provide rich information for digging into the users' fraud
risk. While considerable efforts have been made in this direction, a
long-standing challenge is how to effectively exploit internal user information
and provide explainable prediction results. In fact, the value variations of
same field from different events and the interactions of dif…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Xi_D/0/1/0/all/0/1"&gt;Dongbo Xi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Song_B/0/1/0/all/0/1"&gt;Bowen Song&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhuang_F/0/1/0/all/0/1"&gt;Fuzhen Zhuang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1"&gt;Yongchun Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1"&gt;Shuai Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1"&gt;Tianyi Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1"&gt;Yuan Qi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1"&gt;Qing He&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Predicting Human Trajectories by Learning and Matching Patterns. (arXiv:2104.10241v2 [cs.AI] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2104.10241</id>
        <link href="http://arxiv.org/abs/2104.10241"/>
        <updated>2021-05-22T06:24:29.490Z</updated>
        <summary type="html"><![CDATA[Thesis document of the degree of Master of Science in Robotics of Carnegie
Mellon University School of Computer Science.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1"&gt;Dapeng Zhao&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multilingual Offensive Language Identification for Low-resource Languages. (arXiv:2105.05996v3 [cs.CL] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.05996</id>
        <link href="http://arxiv.org/abs/2105.05996"/>
        <updated>2021-05-22T06:24:29.484Z</updated>
        <summary type="html"><![CDATA[Offensive content is pervasive in social media and a reason for concern to
companies and government organizations. Several studies have been recently
published investigating methods to detect the various forms of such content
(e.g. hate speech, cyberbullying, and cyberaggression). The clear majority of
these studies deal with English partially because most annotated datasets
available contain English data. In this paper, we take advantage of available
English datasets by applying cross-lingual contextual wo…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ranasinghe_T/0/1/0/all/0/1"&gt;Tharindu Ranasinghe&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zampieri_M/0/1/0/all/0/1"&gt;Marcos Zampieri&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Invertible DenseNets with Concatenated LipSwish. (arXiv:2102.02694v2 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2102.02694</id>
        <link href="http://arxiv.org/abs/2102.02694"/>
        <updated>2021-05-22T06:24:29.467Z</updated>
        <summary type="html"><![CDATA[We introduce Invertible Dense Networks (i-DenseNets), a more parameter
efficient extension of Residual Flows. The method relies on an analysis of the
Lipschitz continuity of the concatenation in DenseNets, where we enforce
invertibility of the network by satisfying the Lipschitz constant. Furthermore,
we propose a learnable weighted concatenation, which not only improves the
model performance but also indicates the importance of the concatenated
weighted representation. Additionally, we introduce the Concat…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Perugachi_Diaz_Y/0/1/0/all/0/1"&gt;Yura Perugachi-Diaz&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Tomczak_J/0/1/0/all/0/1"&gt;Jakub M. Tomczak&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Bhulai_S/0/1/0/all/0/1"&gt;Sandjai Bhulai&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Encoding Explanatory Knowledge for Zero-shot Science Question Answering. (arXiv:2105.05737v2 [cs.CL] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.05737</id>
        <link href="http://arxiv.org/abs/2105.05737"/>
        <updated>2021-05-22T06:24:29.460Z</updated>
        <summary type="html"><![CDATA[This paper describes N-XKT (Neural encoding based on eXplanatory Knowledge
Transfer), a novel method for the automatic transfer of explanatory knowledge
through neural encoding mechanisms. We demonstrate that N-XKT is able to
improve accuracy and generalization on science Question Answering (QA).
Specifically, by leveraging facts from background explanatory knowledge
corpora, the N-XKT model shows a clear improvement on zero-shot QA.
Furthermore, we show that N-XKT can be fine-tuned on a target QA dataset,
…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1"&gt;Zili Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Valentino_M/0/1/0/all/0/1"&gt;Marco Valentino&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Landers_D/0/1/0/all/0/1"&gt;Donal Landers&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Freitas_A/0/1/0/all/0/1"&gt;Andre Freitas&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Self-supervised Graph Neural Networks without explicit negative sampling. (arXiv:2103.14958v4 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2103.14958</id>
        <link href="http://arxiv.org/abs/2103.14958"/>
        <updated>2021-05-22T06:24:29.451Z</updated>
        <summary type="html"><![CDATA[Real world data is mostly unlabeled or only few instances are labeled.
Manually labeling data is a very expensive and daunting task. This calls for
unsupervised learning techniques that are powerful enough to achieve comparable
results as semi-supervised/supervised techniques. Contrastive self-supervised
learning has emerged as a powerful direction, in some cases outperforming
supervised techniques. In this study, we propose, SelfGNN, a novel contrastive
self-supervised graph neural network (GNN) without re…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Kefato_Z/0/1/0/all/0/1"&gt;Zekarias T. Kefato&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Girdzijauskas_S/0/1/0/all/0/1"&gt;Sarunas Girdzijauskas&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Capsule GAN for Prostate MRI Super-Resolution. (arXiv:2105.07495v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.07495</id>
        <link href="http://arxiv.org/abs/2105.07495"/>
        <updated>2021-05-22T06:24:29.445Z</updated>
        <summary type="html"><![CDATA[Prostate cancer is a very common disease among adult men. One in seven
Canadian men is diagnosed with this cancer in their lifetime. Super-Resolution
(SR) can facilitate early diagnosis and potentially save many lives. In this
paper, a robust and accurate model is proposed for prostate MRI SR. The model
is trained on the Prostate-Diagnosis and PROSTATEx datasets. The proposed model
outperformed the state-of-the-art prostate SR model in all similarity metrics
with notable margins. A new task-specific similar…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Majdabadi_M/0/1/0/all/0/1"&gt;Mahdiyar Molahasani Majdabadi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1"&gt;Younhee Choi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Deivalakshmi_S/0/1/0/all/0/1"&gt;S. Deivalakshmi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ko_S/0/1/0/all/0/1"&gt;Seokbum Ko&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Temporally Consistent Image-based Sun Tracking Algorithm for Solar Energy Forecasting Applications. (arXiv:2012.01059v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2012.01059</id>
        <link href="http://arxiv.org/abs/2012.01059"/>
        <updated>2021-05-22T06:24:29.439Z</updated>
        <summary type="html"><![CDATA[Improving irradiance forecasting is critical to further increase the share of
solar in the energy mix. On a short time scale, fish-eye cameras on the ground
are used to capture cloud displacements causing the local variability of the
electricity production. As most of the solar radiation comes directly from the
Sun, current forecasting approaches use its position in the image as a
reference to interpret the cloud cover dynamics. However, existing Sun tracking
methods rely on external data and a calibration …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Paletta_Q/0/1/0/all/0/1"&gt;Quentin Paletta&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lasenby_J/0/1/0/all/0/1"&gt;Joan Lasenby&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural networks with superexpressive activations and integer weights. (arXiv:2105.09917v1 [stat.ML])]]></title>
        <id>http://arxiv.org/abs/2105.09917</id>
        <link href="http://arxiv.org/abs/2105.09917"/>
        <updated>2021-05-22T06:24:29.431Z</updated>
        <summary type="html"><![CDATA[An example of an activation function $\sigma$ is given such that networks
with activations $\{\sigma, \lfloor\cdot\rfloor\}$, integer weights and a fixed
architecture depending on $d$ approximate continuous functions on $[0,1]^d$.
The range of integer weights required for $\varepsilon$-approximation of
H\"older continuous functions is derived, which leads to a convergence rate of
order $n^{\frac{-2\beta}{2\beta+d}}\log_2n$ for neural network regression
estimation of unknown $\beta$-H\"older continuous funct…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Beknazaryan_A/0/1/0/all/0/1"&gt;Aleksandr Beknazaryan&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SAFIN: Arbitrary Style Transfer With Self-Attentive Factorized Instance Normalization. (arXiv:2105.06129v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.06129</id>
        <link href="http://arxiv.org/abs/2105.06129"/>
        <updated>2021-05-22T06:24:29.424Z</updated>
        <summary type="html"><![CDATA[Artistic style transfer aims to transfer the style characteristics of one
image onto another image while retaining its content. Existing approaches
commonly leverage various normalization techniques, although these face
limitations in adequately transferring diverse textures to different spatial
locations. Self-Attention-based approaches have tackled this issue with partial
success but suffer from unwanted artifacts. Motivated by these observations,
this paper aims to combine the best of both worlds: self-a…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1"&gt;Aaditya Singh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hingane_S/0/1/0/all/0/1"&gt;Shreeshail Hingane&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gong_X/0/1/0/all/0/1"&gt;Xinyu Gong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1"&gt;Zhangyang Wang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Abductive Knowledge Induction From Raw Data. (arXiv:2010.03514v2 [cs.AI] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2010.03514</id>
        <link href="http://arxiv.org/abs/2010.03514"/>
        <updated>2021-05-22T06:24:29.418Z</updated>
        <summary type="html"><![CDATA[For many reasoning-heavy tasks involving raw inputs, it is challenging to
design an appropriate end-to-end learning pipeline. Neuro-Symbolic Learning,
divide the process into sub-symbolic perception and symbolic reasoning, trying
to utilise data-driven machine learning and knowledge-driven reasoning
simultaneously. However, they suffer from the exponential computational
complexity within the interface between these two components, where the
sub-symbolic learning model lacks direct supervision, and the symbo…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1"&gt;Wang-Zhou Dai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Muggleton_S/0/1/0/all/0/1"&gt;Stephen H. Muggleton&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The World as a Graph: Improving El Ni\~no Forecasts with Graph Neural Networks. (arXiv:2104.05089v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2104.05089</id>
        <link href="http://arxiv.org/abs/2104.05089"/>
        <updated>2021-05-22T06:24:29.404Z</updated>
        <summary type="html"><![CDATA[Deep learning-based models have recently outperformed state-of-the-art
seasonal forecasting models, such as for predicting El Ni\~no-Southern
Oscillation (ENSO). However, current deep learning models are based on
convolutional neural networks which are difficult to interpret and can fail to
model large-scale atmospheric patterns. In comparison, graph neural networks
(GNNs) are capable of modeling large-scale spatial dependencies and are more
interpretable due to the explicit modeling of information flow thr…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Cachay_S/0/1/0/all/0/1"&gt;Salva R&amp;#xfc;hling Cachay&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Erickson_E/0/1/0/all/0/1"&gt;Emma Erickson&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bucker_A/0/1/0/all/0/1"&gt;Arthur Fender C. Bucker&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Pokropek_E/0/1/0/all/0/1"&gt;Ernest Pokropek&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Potosnak_W/0/1/0/all/0/1"&gt;Willa Potosnak&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bire_S/0/1/0/all/0/1"&gt;Suyash Bire&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Osei_S/0/1/0/all/0/1"&gt;Salomey Osei&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lutjens_B/0/1/0/all/0/1"&gt;Bj&amp;#xf6;rn L&amp;#xfc;tjens&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Reproducibility Report: La-MAML: Look-ahead Meta Learning for Continual Learning. (arXiv:2102.05824v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2102.05824</id>
        <link href="http://arxiv.org/abs/2102.05824"/>
        <updated>2021-05-22T06:24:29.387Z</updated>
        <summary type="html"><![CDATA[The Continual Learning (CL) problem involves performing well on a sequence of
tasks under limited compute. Current algorithms in the domain are either slow,
offline or sensitive to hyper-parameters. La-MAML, an optimization-based
meta-learning algorithm claims to be better than other replay-based,
prior-based and meta-learning based approaches. According to the MER paper [1],
metrics to measure performance in the continual learning arena are Retained
Accuracy (RA) and Backward Transfer-Interference (BTI). L…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Joseph_J/0/1/0/all/0/1"&gt;Joel Joseph&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_A/0/1/0/all/0/1"&gt;Alex Gu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GraphReach: Position-Aware Graph Neural Network using Reachability Estimations. (arXiv:2008.09657v3 [cs.SI] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2008.09657</id>
        <link href="http://arxiv.org/abs/2008.09657"/>
        <updated>2021-05-22T06:24:29.361Z</updated>
        <summary type="html"><![CDATA[Majority of the existing graph neural networks (GNN) learn node embeddings
that encode their local neighborhoods but not their positions. Consequently,
two nodes that are vastly distant but located in similar local neighborhoods
map to similar embeddings in those networks. This limitation prevents accurate
performance in predictive tasks that rely on position information. In this
paper,we develop GraphReach, a position-aware inductive GNN that captures the
global positions of nodes through reachability esti…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Nishad_S/0/1/0/all/0/1"&gt;Sunil Nishad&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1"&gt;Shubhangi Agarwal&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_A/0/1/0/all/0/1"&gt;Arnab Bhattacharya&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ranu_S/0/1/0/all/0/1"&gt;Sayan Ranu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fully Convolutional Networks for Automatically Generating Image Masks to Train Mask R-CNN. (arXiv:2003.01383v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2003.01383</id>
        <link href="http://arxiv.org/abs/2003.01383"/>
        <updated>2021-05-22T06:24:29.354Z</updated>
        <summary type="html"><![CDATA[This paper proposes a novel automatically generating image masks method for
the state-of-the-art Mask R-CNN deep learning method. The Mask R-CNN method
achieves the best results in object detection until now, however, it is very
time-consuming and laborious to get the object Masks for training, the proposed
method is composed by a two-stage design, to automatically generating image
masks, the first stage implements a fully convolutional networks (FCN) based
segmentation network, the second stage network, a …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1"&gt;Hao Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Siebert_J/0/1/0/all/0/1"&gt;Jan Paul Siebert&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1"&gt;Xiangrong Xu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Review on Modern Computational Optimal Transport Methods with Applications in Biomedical Research. (arXiv:2008.02995v3 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2008.02995</id>
        <link href="http://arxiv.org/abs/2008.02995"/>
        <updated>2021-05-22T06:24:29.332Z</updated>
        <summary type="html"><![CDATA[Optimal transport has been one of the most exciting subjects in mathematics,
starting from the 18th century. As a powerful tool to transport between two
probability measures, optimal transport methods have been reinvigorated
nowadays in a remarkable proliferation of modern data science applications. To
meet the big data challenges, various computational tools have been developed
in the recent decade to accelerate the computation for optimal transport
methods. In this review, we present some cutting-edge com…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1"&gt;Jingyi Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Zhong_W/0/1/0/all/0/1"&gt;Wenxuan Zhong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Ma_P/0/1/0/all/0/1"&gt;Ping Ma&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A data-driven approach to the forecasting of ground-level ozone concentration. (arXiv:2012.00685v3 [physics.ao-ph] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2012.00685</id>
        <link href="http://arxiv.org/abs/2012.00685"/>
        <updated>2021-05-22T06:24:29.323Z</updated>
        <summary type="html"><![CDATA[The ability to forecast the concentration of air pollutants in an urban
region is crucial for decision-makers wishing to reduce the impact of pollution
on public health through active measures (e.g. temporary traffic closures). In
this study, we present a machine learning approach applied to the forecast of
the day-ahead maximum value of the ozone concentration for several geographical
locations in southern Switzerland. Due to the low density of measurement
stations and to the complex orography of the use c…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/physics/1/au:+Marvin_D/0/1/0/all/0/1"&gt;Dario Marvin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Nespoli_L/0/1/0/all/0/1"&gt;Lorenzo Nespoli&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Strepparava_D/0/1/0/all/0/1"&gt;Davide Strepparava&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Medici_V/0/1/0/all/0/1"&gt;Vasco Medici&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Artificial Neural Networks Jamming on the Beat. (arXiv:2007.06284v3 [eess.AS] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2007.06284</id>
        <link href="http://arxiv.org/abs/2007.06284"/>
        <updated>2021-05-22T06:24:29.301Z</updated>
        <summary type="html"><![CDATA[This paper addresses the issue of long-scale correlations that is
characteristic for symbolic music and is a challenge for modern generative
algorithms. It suggests a very simple workaround for this challenge, namely,
generation of a drum pattern that could be further used as a foundation for
melody generation. The paper presents a large dataset of drum patterns
alongside with corresponding melodies. It explores two possible methods for
drum pattern generation. Exploring a latent space of drum patterns one …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Tikhonov_A/0/1/0/all/0/1"&gt;Alexey Tikhonov&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Yamshchikov_I/0/1/0/all/0/1"&gt;Ivan P. Yamshchikov&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Physically-Consistent Generative Adversarial Networks for Coastal Flood Visualization. (arXiv:2104.04785v3 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2104.04785</id>
        <link href="http://arxiv.org/abs/2104.04785"/>
        <updated>2021-05-22T06:24:29.282Z</updated>
        <summary type="html"><![CDATA[As climate change increases the intensity of natural disasters, society needs
better tools for adaptation. Floods, for example, are the most frequent natural
disaster, and better tools for flood risk communication could increase the
support for flood-resilient infrastructure development. Our work aims to enable
more visual communication of large-scale climate impacts via visualizing the
output of coastal flood models as satellite imagery. We propose the first deep
learning pipeline to ensure physical-consis…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Lutjens_B/0/1/0/all/0/1"&gt;Bj&amp;#xf6;rn L&amp;#xfc;tjens&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Leshchinskiy_B/0/1/0/all/0/1"&gt;Brandon Leshchinskiy&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Requena_Mesa_C/0/1/0/all/0/1"&gt;Christian Requena-Mesa&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chishtie_F/0/1/0/all/0/1"&gt;Farrukh Chishtie&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Diaz_Rodriguez_N/0/1/0/all/0/1"&gt;Natalia D&amp;#xed;az-Rodr&amp;#xed;guez&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Boulais_O/0/1/0/all/0/1"&gt;Oc&amp;#xe9;ane Boulais&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sankaranarayanan_A/0/1/0/all/0/1"&gt;Aruna Sankaranarayanan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Pina_A/0/1/0/all/0/1"&gt;Aaron Pi&amp;#xf1;a&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1"&gt;Yarin Gal&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Raissi_C/0/1/0/all/0/1"&gt;Chedy Ra&amp;#xef;ssi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lavin_A/0/1/0/all/0/1"&gt;Alexander Lavin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Newman_D/0/1/0/all/0/1"&gt;Dava Newman&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Automated Machine Learning on Graphs: A Survey. (arXiv:2103.00742v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2103.00742</id>
        <link href="http://arxiv.org/abs/2103.00742"/>
        <updated>2021-05-22T06:24:29.275Z</updated>
        <summary type="html"><![CDATA[Machine learning on graphs has been extensively studied in both academic and
industry. However, as the literature on graph learning booms with a vast number
of emerging methods and techniques, it becomes increasingly difficult to
manually design the optimal machine learning algorithm for different
graph-related tasks. To solve this critical challenge, automated machine
learning (AutoML) on graphs which combines the strength of graph machine
learning and AutoML together, is gaining attention from the researc…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1"&gt;Ziwei Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1"&gt;Xin Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1"&gt;Wenwu Zhu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Variability of Artificial Neural Networks. (arXiv:2105.08911v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.08911</id>
        <link href="http://arxiv.org/abs/2105.08911"/>
        <updated>2021-05-22T06:24:29.253Z</updated>
        <summary type="html"><![CDATA[What makes an artificial neural network easier to train and more likely to
produce desirable solutions than other comparable networks? In this paper, we
provide a new angle to study such issues under the setting of a fixed number of
model parameters which in general is the most dominant cost factor. We
introduce a notion of variability and show that it correlates positively to the
activation ratio and negatively to a phenomenon called {Collapse to Constants}
(or C2C), which is closely related but not identi…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1"&gt;Yin Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1"&gt;Yueyao Yu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ADASYN-Random Forest Based Intrusion Detection Model. (arXiv:2105.04301v3 [cs.CR] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.04301</id>
        <link href="http://arxiv.org/abs/2105.04301"/>
        <updated>2021-05-22T06:24:29.210Z</updated>
        <summary type="html"><![CDATA[Intrusion detection has been a key topic in the field of cyber security, and
the common network threats nowadays have the characteristics of varieties and
variation. Considering the serious imbalance of intrusion detection datasets
will result in low classification performance on attack behaviors of small
sample size and difficulty to detect network attacks accurately and
efficiently, using Adaptive Synthetic Sampling (ADASYN) method to balance
datasets was proposed in this paper. In addition, Random Forest…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1"&gt;Zhewei Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1"&gt;Linyue Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1"&gt;Wenwen Yu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quantifying the Complexity of Standard Benchmarking Datasets for Long-Term Human Trajectory Prediction. (arXiv:2005.13934v4 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2005.13934</id>
        <link href="http://arxiv.org/abs/2005.13934"/>
        <updated>2021-05-22T06:24:29.201Z</updated>
        <summary type="html"><![CDATA[Methods to quantify the complexity of trajectory datasets are still a missing
piece in benchmarking human trajectory prediction models. In order to gain a
better understanding of the complexity of trajectory prediction tasks and
following the intuition, that more complex datasets contain more information,
an approach for quantifying the amount of information contained in a dataset
from a prototype-based dataset representation is proposed. The dataset
representation is obtained by first employing a non-trivi…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Hug_R/0/1/0/all/0/1"&gt;Ronny Hug&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Becker_S/0/1/0/all/0/1"&gt;Stefan Becker&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hubner_W/0/1/0/all/0/1"&gt;Wolfgang H&amp;#xfc;bner&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Arens_M/0/1/0/all/0/1"&gt;Michael Arens&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Knowledge Distillation: A Survey. (arXiv:2006.05525v7 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2006.05525</id>
        <link href="http://arxiv.org/abs/2006.05525"/>
        <updated>2021-05-22T06:24:29.183Z</updated>
        <summary type="html"><![CDATA[In recent years, deep neural networks have been successful in both industry
and academia, especially for computer vision tasks. The great success of deep
learning is mainly due to its scalability to encode large-scale data and to
maneuver billions of model parameters. However, it is a challenge to deploy
these cumbersome deep models on devices with limited resources, e.g., mobile
phones and embedded devices, not only because of the high computational
complexity but also the large storage requirements. To th…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Gou_J/0/1/0/all/0/1"&gt;Jianping Gou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1"&gt;Baosheng Yu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Maybank_S/0/1/0/all/0/1"&gt;Stephen John Maybank&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1"&gt;Dacheng Tao&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mondegreen: A Post-Processing Solution to Speech Recognition Error Correction for Voice Search Queries. (arXiv:2105.09930v1 [cs.SD])]]></title>
        <id>http://arxiv.org/abs/2105.09930</id>
        <link href="http://arxiv.org/abs/2105.09930"/>
        <updated>2021-05-22T06:24:29.159Z</updated>
        <summary type="html"><![CDATA[As more and more online search queries come from voice, automatic speech
recognition becomes a key component to deliver relevant search results. Errors
introduced by automatic speech recognition (ASR) lead to irrelevant search
results returned to the user, thus causing user dissatisfaction. In this paper,
we introduce an approach, Mondegreen, to correct voice queries in text space
without depending on audio signals, which may not always be available due to
system constraints or privacy or bandwidth (for exa…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Sodhi_S/0/1/0/all/0/1"&gt;Sukhdeep S. Sodhi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chio_E/0/1/0/all/0/1"&gt;Ellie Ka-In Chio&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jash_A/0/1/0/all/0/1"&gt;Ambarish Jash&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ontanon_S/0/1/0/all/0/1"&gt;Santiago Onta&amp;#xf1;&amp;#xf3;n&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Apte_A/0/1/0/all/0/1"&gt;Ajit Apte&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1"&gt;Ankit Kumar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jeje_A/0/1/0/all/0/1"&gt;Ayooluwakunmi Jeje&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kuzmin_D/0/1/0/all/0/1"&gt;Dima Kuzmin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Fung_H/0/1/0/all/0/1"&gt;Harry Fung&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1"&gt;Heng-Tze Cheng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Effrat_J/0/1/0/all/0/1"&gt;Jon Effrat&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bali_T/0/1/0/all/0/1"&gt;Tarush Bali&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jindal_N/0/1/0/all/0/1"&gt;Nitin Jindal&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cao_P/0/1/0/all/0/1"&gt;Pei Cao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1"&gt;Sarvjeet Singh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1"&gt;Senqiang Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Khan_T/0/1/0/all/0/1"&gt;Tameen Khan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wankhede_A/0/1/0/all/0/1"&gt;Amol Wankhede&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Alzantot_M/0/1/0/all/0/1"&gt;Moustafa Alzantot&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1"&gt;Allen Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chandra_T/0/1/0/all/0/1"&gt;Tushar Chandra&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Low-Latency Real-Time Non-Parallel Voice Conversion based on Cyclic Variational Autoencoder and Multiband WaveRNN with Data-Driven Linear Prediction. (arXiv:2105.09858v1 [cs.SD])]]></title>
        <id>http://arxiv.org/abs/2105.09858</id>
        <link href="http://arxiv.org/abs/2105.09858"/>
        <updated>2021-05-22T06:24:29.127Z</updated>
        <summary type="html"><![CDATA[This paper presents a low-latency real-time (LLRT) non-parallel voice
conversion (VC) framework based on cyclic variational autoencoder (CycleVAE)
and multiband WaveRNN with data-driven linear prediction (MWDLP). CycleVAE is a
robust non-parallel multispeaker spectral model, which utilizes a
speaker-independent latent space and a speaker-dependent code to generate
reconstructed/converted spectral features given the spectral features of an
input speaker. On the other hand, MWDLP is an efficient and a high-qu…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Tobing_P/0/1/0/all/0/1"&gt;Patrick Lumban Tobing&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Toda_T/0/1/0/all/0/1"&gt;Tomoki Toda&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The MAMe Dataset: On the relevance of High Resolution and Variable Shape image properties. (arXiv:2007.13693v3 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2007.13693</id>
        <link href="http://arxiv.org/abs/2007.13693"/>
        <updated>2021-05-22T06:24:29.120Z</updated>
        <summary type="html"><![CDATA[In the image classification task, the most common approach is to resize all
images in a dataset to a unique shape, while reducing their precision to a size
which facilitates experimentation at scale. This practice has benefits from a
computational perspective, but it entails negative side-effects on performance
due to loss of information and image deformation. In this work we introduce the
MAMe dataset, an image classification dataset with remarkable high resolution
and variable shape properties. The goal o…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Pares_F/0/1/0/all/0/1"&gt;Ferran Par&amp;#xe9;s&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Arias_Duart_A/0/1/0/all/0/1"&gt;Anna Arias-Duart&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Garcia_Gasulla_D/0/1/0/all/0/1"&gt;Dario Garcia-Gasulla&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Campo_Frances_G/0/1/0/all/0/1"&gt;Gema Campo-Franc&amp;#xe9;s&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Viladrich_N/0/1/0/all/0/1"&gt;Nina Viladrich&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ayguade_E/0/1/0/all/0/1"&gt;Eduard Ayguad&amp;#xe9;&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Labarta_J/0/1/0/all/0/1"&gt;Jes&amp;#xfa;s Labarta&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning high-dimensional probability distributions using tree tensor networks. (arXiv:1912.07913v3 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/1912.07913</id>
        <link href="http://arxiv.org/abs/1912.07913"/>
        <updated>2021-05-22T06:24:29.113Z</updated>
        <summary type="html"><![CDATA[We consider the problem of the estimation of a high-dimensional probability
distribution from i.i.d. samples of the distribution using model classes of
functions in tree-based tensor formats, a particular case of tensor networks
associated with a dimension partition tree. The distribution is assumed to
admit a density with respect to a product measure, possibly discrete for
handling the case of discrete random variables.

After discussing the representation of classical model classes in tree-based
tensor fo…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Grelier_E/0/1/0/all/0/1"&gt;Erwan Grelier&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Nouy_A/0/1/0/all/0/1"&gt;Anthony Nouy&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Lebrun_R/0/1/0/all/0/1"&gt;R&amp;#xe9;gis Lebrun&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Quantized Model Parallelism for Graph-Augmented MLPs Based on Gradient-Free ADMM framework. (arXiv:2105.09837v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09837</id>
        <link href="http://arxiv.org/abs/2105.09837"/>
        <updated>2021-05-22T06:24:29.091Z</updated>
        <summary type="html"><![CDATA[The Graph Augmented Multi-layer Perceptron (GA-MLP) model is an attractive
alternative to Graph Neural Networks (GNNs). This is because it is resistant to
the over-smoothing problem, and deeper GA-MLP models yield better performance.
GA-MLP models are traditionally optimized by the Stochastic Gradient Descent
(SGD). However, SGD suffers from the layer dependency problem, which prevents
the gradients of different layers of GA-MLP models from being calculated in
parallel. In this paper, we propose a parallel …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1"&gt;Junxiang Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1"&gt;Hongyi Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chai_Z/0/1/0/all/0/1"&gt;Zheng Chai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"&gt;Yongchao Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1"&gt;Yue Cheng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1"&gt;Liang Zhao&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Personalized Fairness based on Causal Notion. (arXiv:2105.09829v1 [cs.IR])]]></title>
        <id>http://arxiv.org/abs/2105.09829</id>
        <link href="http://arxiv.org/abs/2105.09829"/>
        <updated>2021-05-22T06:24:29.083Z</updated>
        <summary type="html"><![CDATA[Recommender systems are gaining increasing and critical impacts on human and
society since a growing number of users use them for information seeking and
decision making. Therefore, it is crucial to address the potential unfairness
problems in recommendations. Just like users have personalized preferences on
items, users' demands for fairness are also personalized in many scenarios.
Therefore, it is important to provide personalized fair recommendations for
users to satisfy their personalized fairness deman…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1"&gt;Yunqi Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1"&gt;Hanxiong Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1"&gt;Shuyuan Xu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1"&gt;Yingqiang Ge&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1"&gt;Yongfeng Zhang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Explainable Activity Recognition for Smart Home Systems. (arXiv:2105.09787v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09787</id>
        <link href="http://arxiv.org/abs/2105.09787"/>
        <updated>2021-05-22T06:24:29.071Z</updated>
        <summary type="html"><![CDATA[Smart home environments are designed to provide services that help improve
the quality of life for the occupant via a variety of sensors and actuators
installed throughout the space. Many automated actions taken by a smart home
are governed by the output of an underlying activity recognition system.
However, activity recognition systems may not be perfectly accurate and
therefore inconsistencies in smart home operations can lead a user to wonder
"why did the smart home do that?" In this work, we build on in…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Das_D/0/1/0/all/0/1"&gt;Devleena Das&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Nishimura_Y/0/1/0/all/0/1"&gt;Yasutaka Nishimura&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Vivek_R/0/1/0/all/0/1"&gt;Rajan P. Vivek&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Takeda_N/0/1/0/all/0/1"&gt;Naoto Takeda&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Fish_S/0/1/0/all/0/1"&gt;Sean T. Fish&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ploetz_T/0/1/0/all/0/1"&gt;Thomas Ploetz&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chernova_S/0/1/0/all/0/1"&gt;Sonia Chernova&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Classification of Urban Morphology with Deep Learning: Application on Urban Vitality. (arXiv:2105.09908v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09908</id>
        <link href="http://arxiv.org/abs/2105.09908"/>
        <updated>2021-05-22T06:24:29.059Z</updated>
        <summary type="html"><![CDATA[There is a prevailing trend to study urban morphology quantitatively thanks
to the growing accessibility to various forms of spatial big data, increasing
computing power, and use cases benefiting from such information. The methods
developed up to now measure urban morphology with numerical indices describing
density, proportion, and mixture, but they do not directly represent
morphological features from human's visual and intuitive perspective. We take
the first step to bridge the gap by proposing a deep le…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1"&gt;Wangyang Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1"&gt;Abraham Noah Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Biljecki_F/0/1/0/all/0/1"&gt;Filip Biljecki&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Spatio-temporal Attention-based Model for Infant Movement Assessment from Videos. (arXiv:2105.09783v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09783</id>
        <link href="http://arxiv.org/abs/2105.09783"/>
        <updated>2021-05-22T06:24:28.964Z</updated>
        <summary type="html"><![CDATA[The absence or abnormality of fidgety movements of joints or limbs is
strongly indicative of cerebral palsy in infants. Developing computer-based
methods for assessing infant movements in videos is pivotal for improved
cerebral palsy screening. Most existing methods use appearance-based features
and are thus sensitive to strong but irrelevant signals caused by background
clutter or a moving camera. Moreover, these features are computed over the
whole frame, thus they measure gross whole body movements rathe…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Nguyen_Thai_B/0/1/0/all/0/1"&gt;Binh Nguyen-Thai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Le_V/0/1/0/all/0/1"&gt;Vuong Le&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Morgan_C/0/1/0/all/0/1"&gt;Catherine Morgan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Badawi_N/0/1/0/all/0/1"&gt;Nadia Badawi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1"&gt;Truyen Tran&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Venkatesh_S/0/1/0/all/0/1"&gt;Svetha Venkatesh&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Distributed Adaptive Nearest Neighbor Classifier: Algorithm and Theory. (arXiv:2105.09788v1 [stat.ML])]]></title>
        <id>http://arxiv.org/abs/2105.09788</id>
        <link href="http://arxiv.org/abs/2105.09788"/>
        <updated>2021-05-22T06:24:28.954Z</updated>
        <summary type="html"><![CDATA[When data is of an extraordinarily large size or physically stored in
different locations, the distributed nearest neighbor (NN) classifier is an
attractive tool for classification. We propose a novel distributed adaptive NN
classifier for which the number of nearest neighbors is a tuning parameter
stochastically chosen by a data-driven criterion. An early stopping rule is
proposed when searching for the optimal tuning parameter, which not only speeds
up the computation but also improves the finite sample p…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Liu_R/0/1/0/all/0/1"&gt;Ruiqi Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Xu_G/0/1/0/all/0/1"&gt;Ganggang Xu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Shang_Z/0/1/0/all/0/1"&gt;Zuofeng Shang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Covid-19 Detection from Chest X-ray and Patient Metadata using Graph Convolutional Neural Networks. (arXiv:2105.09720v1 [eess.IV])]]></title>
        <id>http://arxiv.org/abs/2105.09720</id>
        <link href="http://arxiv.org/abs/2105.09720"/>
        <updated>2021-05-22T06:24:28.949Z</updated>
        <summary type="html"><![CDATA[The novel corona virus (Covid-19) has introduced significant challenges due
to its rapid spreading nature through respiratory transmission. As a result,
there is a huge demand for Artificial Intelligence (AI) based quick disease
diagnosis methods as an alternative to high demand tests such as Polymerase
Chain Reaction (PCR). Chest X-ray (CXR) Image analysis is such cost-effective
radiography technique due to resource availability and quick screening. But, a
sufficient and systematic data collection that is …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Mudiyanselage_T/0/1/0/all/0/1"&gt;Thosini Bamunu Mudiyanselage&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Senanayake_N/0/1/0/all/0/1"&gt;Nipuna Senanayake&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Ji_C/0/1/0/all/0/1"&gt;Chunyan Ji&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Pan_Y/0/1/0/all/0/1"&gt;Yi Pan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1"&gt;Yanqing Zhang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DeepAVO: Efficient Pose Refining with Feature Distilling for Deep Visual Odometry. (arXiv:2105.09899v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09899</id>
        <link href="http://arxiv.org/abs/2105.09899"/>
        <updated>2021-05-22T06:24:28.942Z</updated>
        <summary type="html"><![CDATA[The technology for Visual Odometry (VO) that estimates the position and
orientation of the moving object through analyzing the image sequences captured
by on-board cameras, has been well investigated with the rising interest in
autonomous driving. This paper studies monocular VO from the perspective of
Deep Learning (DL). Unlike most current learning-based methods, our approach,
called DeepAVO, is established on the intuition that features contribute
discriminately to different motion patterns. Specifically…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_R/0/1/0/all/0/1"&gt;Ran Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1"&gt;Mingkun Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1"&gt;Wang Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Song_R/0/1/0/all/0/1"&gt;Rujun Song&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yan_B/0/1/0/all/0/1"&gt;Bo Yan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xiao_Z/0/1/0/all/0/1"&gt;Zhuoling Xiao&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bidirectional LSTM-CRF Attention-based Model for Chinese Word Segmentation. (arXiv:2105.09681v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09681</id>
        <link href="http://arxiv.org/abs/2105.09681"/>
        <updated>2021-05-22T06:24:28.936Z</updated>
        <summary type="html"><![CDATA[Chinese word segmentation (CWS) is the basic of Chinese natural language
processing (NLP). The quality of word segmentation will directly affect the
rest of NLP tasks. Recently, with the artificial intelligence tide rising
again, Long Short-Term Memory (LSTM) neural network, as one of easily modeling
in sequence, has been widely utilized in various kinds of NLP tasks, and
functions well. Attention mechanism is an ingenious method to solve the memory
compression problem on LSTM. Furthermore, inspired by the …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1"&gt;Chen Jin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1"&gt;Zhuangwei Shi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1"&gt;Weihua Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1"&gt;Yanbu Guo&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DEHB: Evolutionary Hyberband for Scalable, Robust and Efficient Hyperparameter Optimization. (arXiv:2105.09821v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09821</id>
        <link href="http://arxiv.org/abs/2105.09821"/>
        <updated>2021-05-22T06:24:28.917Z</updated>
        <summary type="html"><![CDATA[Modern machine learning algorithms crucially rely on several design decisions
to achieve strong performance, making the problem of Hyperparameter
Optimization (HPO) more important than ever. Here, we combine the advantages of
the popular bandit-based HPO method Hyperband (HB) and the evolutionary search
approach of Differential Evolution (DE) to yield a new HPO method which we call
DEHB. Comprehensive results on a very broad range of HPO problems, as well as a
wide range of tabular benchmarks from neural ar…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Awad_N/0/1/0/all/0/1"&gt;Noor Awad&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mallik_N/0/1/0/all/0/1"&gt;Neeratyoy Mallik&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1"&gt;Frank Hutter&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fed-EINI: An Efficient and Interpretable Inference Framework for Decision Tree Ensembles in Federated Learning. (arXiv:2105.09540v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09540</id>
        <link href="http://arxiv.org/abs/2105.09540"/>
        <updated>2021-05-22T06:24:28.910Z</updated>
        <summary type="html"><![CDATA[The increasing concerns about data privacy and security drives the emergence
of a new field of studying privacy-preserving machine learning from isolated
data sources, i.e., \textit{federated learning}. Vertical federated learning,
where different parties hold different features for common users, has a great
potential of driving a more variety of business cooperation among enterprises
in different fields. Decision tree models especially decision tree ensembles
are a class of widely applied powerful machine …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1"&gt;Xiaolin Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1"&gt;Shuai Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1"&gt;Kai Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Fan_H/0/1/0/all/0/1"&gt;Hao Fan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1"&gt;Zejin Feng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1"&gt;Zhong Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1"&gt;Hu Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"&gt;Yongji Wang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep learning in physics: a study of dielectric quasi-cubic particles in a uniform electric field. (arXiv:2105.09866v1 [physics.class-ph])]]></title>
        <id>http://arxiv.org/abs/2105.09866</id>
        <link href="http://arxiv.org/abs/2105.09866"/>
        <updated>2021-05-22T06:24:28.903Z</updated>
        <summary type="html"><![CDATA[Solving physics problems for which we know the equations, boundary conditions
and symmetries can be done by deep learning. The constraints can be either
imposed as terms in a loss function or used to formulate a neural ansatz. In
the present case study, we calculate the induced field inside and outside a
dielectric cube placed in a uniform electric field, wherein the dielectric
mismatch at edges and corners of the cube makes accurate calculations
numerically challenging. The electric potential is expressed …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/physics/1/au:+Wang_Z/0/1/0/all/0/1"&gt;Zhe Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Guet_C/0/1/0/all/0/1"&gt;Claude Guet&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Improved Neuronal Ensemble Inference with Generative Model and MCMC. (arXiv:2105.09679v1 [cond-mat.dis-nn])]]></title>
        <id>http://arxiv.org/abs/2105.09679</id>
        <link href="http://arxiv.org/abs/2105.09679"/>
        <updated>2021-05-22T06:24:28.897Z</updated>
        <summary type="html"><![CDATA[Neuronal ensemble inference is a significant problem in the study of
biological neural networks. Various methods have been proposed for ensemble
inference from experimental data of neuronal activity. Among them, Bayesian
inference approach with generative model was proposed recently. However, this
method requires large computational cost for appropriate inference. In this
work, we give an improved Bayesian inference algorithm by modifying update rule
in Markov chain Monte Carlo method and introducing the id…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cond-mat/1/au:+Kimura_S/0/1/0/all/0/1"&gt;Shun Kimura&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cond-mat/1/au:+Ota_K/0/1/0/all/0/1"&gt;Keisuke Ota&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cond-mat/1/au:+Takeda_K/0/1/0/all/0/1"&gt;Koujin Takeda&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Contrastive Learning for Many-to-many Multilingual Neural Machine Translation. (arXiv:2105.09501v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2105.09501</id>
        <link href="http://arxiv.org/abs/2105.09501"/>
        <updated>2021-05-22T06:24:28.890Z</updated>
        <summary type="html"><![CDATA[Existing multilingual machine translation approaches mainly focus on
English-centric directions, while the non-English directions still lag behind.
In this work, we aim to build a many-to-many translation system with an
emphasis on the quality of non-English language directions. Our intuition is
based on the hypothesis that a universal cross-language representation leads to
better multilingual translation performance. To this end, we propose \method, a
training method to obtain a single unified multilingual…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1"&gt;Xiao Pan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1"&gt;Mingxuan Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1"&gt;Liwei Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1"&gt;Lei Li&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Negational Symmetry of Quantum Neural Networks for Binary Pattern Classification. (arXiv:2105.09580v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09580</id>
        <link href="http://arxiv.org/abs/2105.09580"/>
        <updated>2021-05-22T06:24:28.868Z</updated>
        <summary type="html"><![CDATA[Entanglement is a physical phenomenon, which has fueled recent successes of
quantum algorithms. Although quantum neural networks (QNNs) have shown
promising results in solving simple machine learning tasks recently, for the
time being, the effect of entanglement in QNNs and the behavior of QNNs in
binary pattern classification are still underexplored. In this work, we provide
some theoretical insight into the properties of QNNs by presenting and
analyzing a new form of invariance embedded in QNNs for both q…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Dong_N/0/1/0/all/0/1"&gt;Nanqing Dong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kampffmeyer_M/0/1/0/all/0/1"&gt;Michael Kampffmeyer&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Voiculescu_I/0/1/0/all/0/1"&gt;Irina Voiculescu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1"&gt;Eric Xing&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[High-Fidelity and Low-Latency Universal Neural Vocoder based on Multiband WaveRNN with Data-Driven Linear Prediction for Discrete Waveform Modeling. (arXiv:2105.09856v1 [cs.SD])]]></title>
        <id>http://arxiv.org/abs/2105.09856</id>
        <link href="http://arxiv.org/abs/2105.09856"/>
        <updated>2021-05-22T06:24:28.861Z</updated>
        <summary type="html"><![CDATA[This paper presents a novel high-fidelity and low-latency universal neural
vocoder framework based on multiband WaveRNN with data-driven linear prediction
for discrete waveform modeling (MWDLP). MWDLP employs a coarse-fine bit WaveRNN
architecture for 10-bit mu-law waveform modeling. A sparse gated recurrent unit
with a relatively large size of hidden units is utilized, while the multiband
modeling is deployed to achieve real-time low-latency usage. A novel technique
for data-driven linear prediction (LP) w…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Tobing_P/0/1/0/all/0/1"&gt;Patrick Lumban Tobing&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Toda_T/0/1/0/all/0/1"&gt;Tomoki Toda&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Physics-informed neural networks (PINNs) for fluid mechanics: A review. (arXiv:2105.09506v1 [physics.flu-dyn])]]></title>
        <id>http://arxiv.org/abs/2105.09506</id>
        <link href="http://arxiv.org/abs/2105.09506"/>
        <updated>2021-05-22T06:24:28.847Z</updated>
        <summary type="html"><![CDATA[Despite the significant progress over the last 50 years in simulating flow
problems using numerical discretization of the Navier-Stokes equations (NSE),
we still cannot incorporate seamlessly noisy data into existing algorithms,
mesh-generation is complex, and we cannot tackle high-dimensional problems
governed by parametrized NSE. Moreover, solving inverse flow problems is often
prohibitively expensive and requires complex and expensive formulations and new
computer codes. Here, we review flow physics-info…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/physics/1/au:+Cai_S/0/1/0/all/0/1"&gt;Shengze Cai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Mao_Z/0/1/0/all/0/1"&gt;Zhiping Mao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Wang_Z/0/1/0/all/0/1"&gt;Zhicheng Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Yin_M/0/1/0/all/0/1"&gt;Minglang Yin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Karniadakis_G/0/1/0/all/0/1"&gt;George Em Karniadakis&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Monte Carlo Filtering Objectives: A New Family of Variational Objectives to Learn Generative Model and Neural Adaptive Proposal for Time Series. (arXiv:2105.09801v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09801</id>
        <link href="http://arxiv.org/abs/2105.09801"/>
        <updated>2021-05-22T06:24:28.841Z</updated>
        <summary type="html"><![CDATA[Learning generative models and inferring latent trajectories have shown to be
challenging for time series due to the intractable marginal likelihoods of
flexible generative models. It can be addressed by surrogate objectives for
optimization. We propose Monte Carlo filtering objectives (MCFOs), a family of
variational objectives for jointly learning parametric generative models and
amortized adaptive importance proposals of time series. MCFOs extend the
choices of likelihood estimators beyond Sequential Mon…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1"&gt;Shuangshuang Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ding_S/0/1/0/all/0/1"&gt;Sihao Ding&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Karayiannidis_Y/0/1/0/all/0/1"&gt;Yiannis Karayiannidis&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bjorkman_M/0/1/0/all/0/1"&gt;M&amp;#xe5;rten Bj&amp;#xf6;rkman&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Preference Random Walk Algorithm for Link Prediction through Mutual Influence Nodes in Complex Networks. (arXiv:2105.09494v1 [cs.SI])]]></title>
        <id>http://arxiv.org/abs/2105.09494</id>
        <link href="http://arxiv.org/abs/2105.09494"/>
        <updated>2021-05-22T06:24:28.834Z</updated>
        <summary type="html"><![CDATA[Predicting links in complex networks has been one of the essential topics
within the realm of data mining and science discovery over the past few years.
This problem remains an attempt to identify future, deleted, and redundant
links using the existing links in a graph. Local random walk is considered to
be one of the most well-known algorithms in the category of quasi-local
methods. It traverses the network using the traditional random walk with a
limited number of steps, randomly selecting one adjacent no…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Berahmand_K/0/1/0/all/0/1"&gt;Kamal Berahmand&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Nasiri_E/0/1/0/all/0/1"&gt;Elahe Nasiri&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Forouzandeh_S/0/1/0/all/0/1"&gt;Saman Forouzandeh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1"&gt;Yuefeng Li&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An Exact Poly-Time Membership-Queries Algorithm for Extraction a three-Layer ReLU Network. (arXiv:2105.09673v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09673</id>
        <link href="http://arxiv.org/abs/2105.09673"/>
        <updated>2021-05-22T06:24:28.807Z</updated>
        <summary type="html"><![CDATA[As machine learning increasingly becomes more prevalent in our everyday life,
many organizations offer neural-networks based services as a black-box. The
reasons for hiding a learning model may vary: e.g., preventing copying of its
behavior or keeping back an adversarial from reverse-engineering its mechanism
and revealing sensitive information about its training data.

However, even as a black-box, some information can still be discovered by
specific queries. In this work, we show a polynomial-time algorit…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Daniely_A/0/1/0/all/0/1"&gt;Amit Daniely&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Granot_E/0/1/0/all/0/1"&gt;Elad Granot&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Navigation Turing Test (NTT): Learning to Evaluate Human-Like Navigation. (arXiv:2105.09637v1 [cs.AI])]]></title>
        <id>http://arxiv.org/abs/2105.09637</id>
        <link href="http://arxiv.org/abs/2105.09637"/>
        <updated>2021-05-22T06:24:28.786Z</updated>
        <summary type="html"><![CDATA[A key challenge on the path to developing agents that learn complex
human-like behavior is the need to quickly and accurately quantify
human-likeness. While human assessments of such behavior can be highly
accurate, speed and scalability are limited. We address these limitations
through a novel automated Navigation Turing Test (ANTT) that learns to predict
human judgments of human-likeness. We demonstrate the effectiveness of our
automated NTT on a navigation task in a complex 3D environment. We investigate…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Devlin_S/0/1/0/all/0/1"&gt;Sam Devlin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Georgescu_R/0/1/0/all/0/1"&gt;Raluca Georgescu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Momennejad_I/0/1/0/all/0/1"&gt;Ida Momennejad&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Rzepecki_J/0/1/0/all/0/1"&gt;Jaroslaw Rzepecki&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zuniga_E/0/1/0/all/0/1"&gt;Evelyn Zuniga&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Costello_G/0/1/0/all/0/1"&gt;Gavin Costello&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Leroy_G/0/1/0/all/0/1"&gt;Guy Leroy&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Shaw_A/0/1/0/all/0/1"&gt;Ali Shaw&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hofmann_K/0/1/0/all/0/1"&gt;Katja Hofmann&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nonlinear Hawkes Process with Gaussian Process Self Effects. (arXiv:2105.09618v1 [stat.ML])]]></title>
        <id>http://arxiv.org/abs/2105.09618</id>
        <link href="http://arxiv.org/abs/2105.09618"/>
        <updated>2021-05-22T06:24:28.780Z</updated>
        <summary type="html"><![CDATA[Traditionally, Hawkes processes are used to model time--continuous point
processes with history dependence. Here we propose an extended model where the
self--effects are of both excitatory and inhibitory type and follow a Gaussian
Process. Whereas previous work either relies on a less flexible
parameterization of the model, or requires a large amount of data, our
formulation allows for both a flexible model and learning when data are scarce.
We continue the line of work of Bayesian inference for Hawkes proc…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Malem_Shinitski_N/0/1/0/all/0/1"&gt;Noa Malem-Shinitski&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Ojeda_C/0/1/0/all/0/1"&gt;Cesar Ojeda&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Opper_M/0/1/0/all/0/1"&gt;Manfred Opper&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[TF-IDF vs Word Embeddings for Morbidity Identification in Clinical Notes: An Initial Study. (arXiv:2105.09632v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2105.09632</id>
        <link href="http://arxiv.org/abs/2105.09632"/>
        <updated>2021-05-22T06:24:28.774Z</updated>
        <summary type="html"><![CDATA[Today, we are seeing an ever-increasing number of clinical notes that contain
clinical results, images, and textual descriptions of patient's health state.
All these data can be analyzed and employed to cater novel services that can
help people and domain experts with their common healthcare tasks. However,
many technologies such as Deep Learning and tools like Word Embeddings have
started to be investigated only recently, and many challenges remain open when
it comes to healthcare domain applications. To a…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Dessi_D/0/1/0/all/0/1"&gt;Danilo Dessi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Helaoui_R/0/1/0/all/0/1"&gt;Rim Helaoui&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1"&gt;Vivek Kumar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Recupero_D/0/1/0/all/0/1"&gt;Diego Reforgiato Recupero&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Riboni_D/0/1/0/all/0/1"&gt;Daniele Riboni&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quantifying sources of uncertainty in drug discovery predictions with probabilistic models. (arXiv:2105.09474v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09474</id>
        <link href="http://arxiv.org/abs/2105.09474"/>
        <updated>2021-05-22T06:24:28.767Z</updated>
        <summary type="html"><![CDATA[Knowing the uncertainty in a prediction is critical when making expensive
investment decisions and when patient safety is paramount, but machine learning
(ML) models in drug discovery typically provide only a single best estimate and
ignore all sources of uncertainty. Predictions from these models may therefore
be over-confident, which can put patients at risk and waste resources when
compounds that are destined to fail are further developed. Probabilistic
predictive models (PPMs) can incorporate uncertaint…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Lazic_S/0/1/0/all/0/1"&gt;Stanley E. Lazic&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Williams_D/0/1/0/all/0/1"&gt;Dominic P. Williams&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Stochastic Composite Augmented Lagrangian Method For Reinforcement Learning. (arXiv:2105.09716v1 [math.OC])]]></title>
        <id>http://arxiv.org/abs/2105.09716</id>
        <link href="http://arxiv.org/abs/2105.09716"/>
        <updated>2021-05-22T06:24:28.752Z</updated>
        <summary type="html"><![CDATA[In this paper, we consider the linear programming (LP) formulation for deep
reinforcement learning. The number of the constraints depends on the size of
state and action spaces, which makes the problem intractable in large or
continuous environments. The general augmented Lagrangian method suffers the
double-sampling obstacle in solving the LP. Namely, the conditional
expectations originated from the constraint functions and the quadratic
penalties in the augmented Lagrangian function impose difficulties in…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Li_Y/0/1/0/all/0/1"&gt;Yongfeng Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Zhao_M/0/1/0/all/0/1"&gt;Mingming Zhao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Chen_W/0/1/0/all/0/1"&gt;Weijie Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Wen_Z/0/1/0/all/0/1"&gt;Zaiwen Wen&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[See, Hear, Read: Leveraging Multimodality with Guided Attention for Abstractive Text Summarization. (arXiv:2105.09601v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09601</id>
        <link href="http://arxiv.org/abs/2105.09601"/>
        <updated>2021-05-22T06:24:28.735Z</updated>
        <summary type="html"><![CDATA[In recent years, abstractive text summarization with multimodal inputs has
started drawing attention due to its ability to accumulate information from
different source modalities and generate a fluent textual summary. However,
existing methods use short videos as the visual modality and short summary as
the ground-truth, therefore, perform poorly on lengthy videos and long
ground-truth summary. Additionally, there exists no benchmark dataset to
generalize this task on videos of varying lengths. In this pape…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Atri_Y/0/1/0/all/0/1"&gt;Yash Kumar Atri&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Pramanick_S/0/1/0/all/0/1"&gt;Shraman Pramanick&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Goyal_V/0/1/0/all/0/1"&gt;Vikram Goyal&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chakraborty_T/0/1/0/all/0/1"&gt;Tanmoy Chakraborty&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Explainable Health Risk Predictor with Transformer-based Medicare Claim Encoder. (arXiv:2105.09428v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09428</id>
        <link href="http://arxiv.org/abs/2105.09428"/>
        <updated>2021-05-22T06:24:28.726Z</updated>
        <summary type="html"><![CDATA[In 2019, The Centers for Medicare and Medicaid Services (CMS) launched an
Artificial Intelligence (AI) Health Outcomes Challenge seeking solutions to
predict risk in value-based care for incorporation into CMS Innovation Center
payment and service delivery models. Recently, modern language models have
played key roles in a number of health related tasks. This paper presents, to
the best of our knowledge, the first application of these models to patient
readmission prediction. To facilitate this, we create a…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Lahlou_C/0/1/0/all/0/1"&gt;Chuhong Lahlou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Crayton_A/0/1/0/all/0/1"&gt;Ancil Crayton&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Trier_C/0/1/0/all/0/1"&gt;Caroline Trier&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Willett_E/0/1/0/all/0/1"&gt;Evan Willett&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[User Label Leakage from Gradients in Federated Learning. (arXiv:2105.09369v1 [cs.CR])]]></title>
        <id>http://arxiv.org/abs/2105.09369</id>
        <link href="http://arxiv.org/abs/2105.09369"/>
        <updated>2021-05-22T06:24:28.720Z</updated>
        <summary type="html"><![CDATA[Federated learning enables multiple users to build a joint model by sharing
their model updates (gradients), while their raw data remains local on their
devices. In contrast to the common belief that this provides privacy benefits,
we here add to the very recent results on privacy risks when sharing gradients.
Specifically, we propose Label Leakage from Gradients (LLG), a novel attack to
extract the labels of the users' training data from their shared gradients. The
attack exploits the direction and magnitu…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wainakh_A/0/1/0/all/0/1"&gt;Aidmar Wainakh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ventola_F/0/1/0/all/0/1"&gt;Fabrizio Ventola&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mussig_T/0/1/0/all/0/1"&gt;Till M&amp;#xfc;&amp;#xdf;ig&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Keim_J/0/1/0/all/0/1"&gt;Jens Keim&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cordero_C/0/1/0/all/0/1"&gt;Carlos Garcia Cordero&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zimmer_E/0/1/0/all/0/1"&gt;Ephraim Zimmer&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Grube_T/0/1/0/all/0/1"&gt;Tim Grube&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1"&gt;Kristian Kersting&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Muhlhauser_M/0/1/0/all/0/1"&gt;Max M&amp;#xfc;hlh&amp;#xe4;user&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Simple Transparent Adversarial Examples. (arXiv:2105.09685v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09685</id>
        <link href="http://arxiv.org/abs/2105.09685"/>
        <updated>2021-05-22T06:24:28.702Z</updated>
        <summary type="html"><![CDATA[There has been a rise in the use of Machine Learning as a Service (MLaaS)
Vision APIs as they offer multiple services including pre-built models and
algorithms, which otherwise take a huge amount of resources if built from
scratch. As these APIs get deployed for high-stakes applications, it's very
important that they are robust to different manipulations. Recent works have
only focused on typical adversarial attacks when evaluating the robustness of
vision APIs. We propose two new aspects of adversarial ima…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Borkar_J/0/1/0/all/0/1"&gt;Jaydeep Borkar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1"&gt;Pin-Yu Chen&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Logarithmic landscape and power-law escape rate of SGD. (arXiv:2105.09557v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09557</id>
        <link href="http://arxiv.org/abs/2105.09557"/>
        <updated>2021-05-22T06:24:28.696Z</updated>
        <summary type="html"><![CDATA[Stochastic gradient descent (SGD) undergoes complicated multiplicative noise
for the mean-square loss. We use this property of the SGD noise to derive a
stochastic differential equation (SDE) with simpler additive noise by
performing a non-uniform transformation of the time variable. In the SDE, the
gradient of the loss is replaced by that of the logarithmized loss.
Consequently, we show that, near a local or global minimum, the stationary
distribution $P_\mathrm{ss}(\theta)$ of the network parameters $\the…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Mori_T/0/1/0/all/0/1"&gt;Takashi Mori&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ziyin_L/0/1/0/all/0/1"&gt;Liu Ziyin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1"&gt;Kangqiao Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ueda_M/0/1/0/all/0/1"&gt;Masahito Ueda&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[VOILA: Visual-Observation-Only Imitation Learning for Autonomous Navigation. (arXiv:2105.09371v1 [cs.RO])]]></title>
        <id>http://arxiv.org/abs/2105.09371</id>
        <link href="http://arxiv.org/abs/2105.09371"/>
        <updated>2021-05-22T06:24:28.689Z</updated>
        <summary type="html"><![CDATA[While imitation learning for vision based autonomous mobile robot navigation
has recently received a great deal of attention in the research community,
existing approaches typically require state action demonstrations that were
gathered using the deployment platform. However, what if one cannot easily
outfit their platform to record these demonstration signals or worse yet the
demonstrator does not have access to the platform at all? Is imitation learning
for vision based autonomous navigation even possible…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Karnan_H/0/1/0/all/0/1"&gt;Haresh Karnan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Warnell_G/0/1/0/all/0/1"&gt;Garrett Warnell&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1"&gt;Xuesu Xiao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Stone_P/0/1/0/all/0/1"&gt;Peter Stone&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Localization and Control of Magnetic Suture Needles in Cluttered Surgical Site with Blood and Tissue. (arXiv:2105.09481v1 [cs.RO])]]></title>
        <id>http://arxiv.org/abs/2105.09481</id>
        <link href="http://arxiv.org/abs/2105.09481"/>
        <updated>2021-05-22T06:24:28.683Z</updated>
        <summary type="html"><![CDATA[Real-time visual localization of needles is necessary for various surgical
applications, including surgical automation and visual feedback. In this study
we investigate localization and autonomous robotic control of needles in the
context of our magneto-suturing system. Our system holds the potential for
surgical manipulation with the benefit of minimal invasiveness and reduced
patient side effects. However, the non-linear magnetic fields produce
unintuitive forces and demand delicate position-based control…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Pryor_W/0/1/0/all/0/1"&gt;Will Pryor&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Barnoy_Y/0/1/0/all/0/1"&gt;Yotam Barnoy&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Raval_S/0/1/0/all/0/1"&gt;Suraj Raval&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1"&gt;Xiaolong Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mair_L/0/1/0/all/0/1"&gt;Lamar Mair&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lerner_D/0/1/0/all/0/1"&gt;Daniel Lerner&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Erin_O/0/1/0/all/0/1"&gt;Onder Erin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hager_G/0/1/0/all/0/1"&gt;Gregory D. Hager&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Diaz_Mercado_Y/0/1/0/all/0/1"&gt;Yancy Diaz-Mercado&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Krieger_A/0/1/0/all/0/1"&gt;Axel Krieger&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Manual Evaluation Matters: Reviewing Test Protocols of Distantly Supervised Relation Extraction. (arXiv:2105.09543v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2105.09543</id>
        <link href="http://arxiv.org/abs/2105.09543"/>
        <updated>2021-05-22T06:24:28.666Z</updated>
        <summary type="html"><![CDATA[Distantly supervised (DS) relation extraction (RE) has attracted much
attention in the past few years as it can utilize large-scale auto-labeled
data. However, its evaluation has long been a problem: previous works either
took costly and inconsistent methods to manually examine a small sample of
model predictions, or directly test models on auto-labeled data -- which, by
our check, produce as much as 53% wrong labels at the entity pair level in the
popular NYT10 dataset. This problem has not only led to ina…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1"&gt;Tianyu Gao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1"&gt;Xu Han&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Qiu_K/0/1/0/all/0/1"&gt;Keyue Qiu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1"&gt;Yuzhuo Bai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1"&gt;Zhiyu Xie&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1"&gt;Yankai Lin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1"&gt;Zhiyuan Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1"&gt;Peng Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1"&gt;Maosong Sun&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1"&gt;Jie Zhou&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generative Adversarial Neural Architecture Search. (arXiv:2105.09356v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09356</id>
        <link href="http://arxiv.org/abs/2105.09356"/>
        <updated>2021-05-22T06:24:28.660Z</updated>
        <summary type="html"><![CDATA[Despite the empirical success of neural architecture search (NAS) in deep
learning applications, the optimality, reproducibility and cost of NAS schemes
remain hard to assess. In this paper, we propose Generative Adversarial NAS
(GA-NAS) with theoretically provable convergence guarantees, promoting
stability and reproducibility in neural architecture search. Inspired by
importance sampling, GA-NAS iteratively fits a generator to previously
discovered top architectures, thus increasingly focusing on importan…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Rezaei_S/0/1/0/all/0/1"&gt;Seyed Saeed Changiz Rezaei&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Han_F/0/1/0/all/0/1"&gt;Fred X. Han&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Niu_D/0/1/0/all/0/1"&gt;Di Niu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Salameh_M/0/1/0/all/0/1"&gt;Mohammad Salameh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mills_K/0/1/0/all/0/1"&gt;Keith Mills&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lian_S/0/1/0/all/0/1"&gt;Shuo Lian&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1"&gt;Wei Lu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jui_S/0/1/0/all/0/1"&gt;Shangling Jui&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DeepCAD: A Deep Generative Network for Computer-Aided Design Models. (arXiv:2105.09492v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09492</id>
        <link href="http://arxiv.org/abs/2105.09492"/>
        <updated>2021-05-22T06:24:28.647Z</updated>
        <summary type="html"><![CDATA[Deep generative models of 3D shapes have received a great deal of research
interest. Yet, almost all of them generate discrete shape representations, such
as voxels, point clouds, and polygon meshes. We present the first 3D generative
model for a drastically different shape representation -- describing a shape as
a sequence of computer-aided design (CAD) operations. Unlike meshes and point
clouds, CAD models encode the user creation process of 3D shapes, widely used
in numerous industrial and engineering de…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1"&gt;Rundi Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1"&gt;Chang Xiao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1"&gt;Changxi Zheng&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI-Decision Support System Interface Using Cancer Related Data for Lung Cancer Prognosis. (arXiv:2105.09471v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09471</id>
        <link href="http://arxiv.org/abs/2105.09471"/>
        <updated>2021-05-22T06:24:28.632Z</updated>
        <summary type="html"><![CDATA[Until the beginning of 2021, lung cancer is known to be the most common
cancer in the world. The disease is common due to factors such as occupational
exposure, smoking and environmental pollution. The early diagnosis and
treatment of the disease is of great importance as well as the prevention of
the causes that cause the disease. The study was planned to create a web
interface that works with machine learning algorithms to predict prognosis
using lung cancer clinical and gene expression in the GDC data po…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Leblebici_A/0/1/0/all/0/1"&gt;Asim Leblebici&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gesoglu_O/0/1/0/all/0/1"&gt;Omer Gesoglu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Basbinar_Y/0/1/0/all/0/1"&gt;Yasemin Basbinar&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Heterogeneous Contrastive Learning. (arXiv:2105.09401v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09401</id>
        <link href="http://arxiv.org/abs/2105.09401"/>
        <updated>2021-05-22T06:24:28.549Z</updated>
        <summary type="html"><![CDATA[With the advent of big data across multiple high-impact applications, we are
often facing the challenge of complex heterogeneity. The newly collected data
usually consist of multiple modalities and characterized with multiple labels,
thus exhibiting the co-existence of multiple types of heterogeneity. Although
state-of-the-art techniques are good at modeling the complex heterogeneity with
sufficient label information, such label information can be quite expensive to
obtain in real applications, leading to s…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1"&gt;Lecheng Zheng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1"&gt;Yada Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1"&gt;Jingrui He&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xiong_J/0/1/0/all/0/1"&gt;Jinjun Xiong&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Proximal Learning for Individualized Treatment Regimes Under Unmeasured Confounding. (arXiv:2105.01187v2 [stat.ME] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.01187</id>
        <link href="http://arxiv.org/abs/2105.01187"/>
        <updated>2021-05-22T06:24:28.526Z</updated>
        <summary type="html"><![CDATA[Data-driven individualized decision making has recently received increasing
research interests. Most existing methods rely on the assumption of no
unmeasured confounding, which unfortunately cannot be ensured in practice
especially in observational studies. Motivated by the recent proposed proximal
causal inference, we develop several proximal learning approaches to estimating
optimal individualized treatment regimes (ITRs) in the presence of unmeasured
confounding. In particular, we establish several ident…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Qi_Z/0/1/0/all/0/1"&gt;Zhengling Qi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Miao_R/0/1/0/all/0/1"&gt;Rui Miao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Zhang_X/0/1/0/all/0/1"&gt;Xiaoke Zhang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning and Information in Stochastic Networks and Queues. (arXiv:2105.08769v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.08769</id>
        <link href="http://arxiv.org/abs/2105.08769"/>
        <updated>2021-05-22T06:24:28.504Z</updated>
        <summary type="html"><![CDATA[We review the role of information and learning in the stability and
optimization of queueing systems. In recent years, techniques from supervised
learning, bandit learning and reinforcement learning have been applied to
queueing systems supported by increasing role of information in decision
making. We present observations and new results that help rationalize the
application of these areas to queueing systems.

We prove that the MaxWeight and BackPressure policies are an application of
Blackwell's Approach…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Walton_N/0/1/0/all/0/1"&gt;Neil Walton&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1"&gt;Kuang Xu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[COVID-19 Lung Lesion Segmentation Using a Sparsely Supervised Mask R-CNN on Chest X-rays Automatically Computed from Volumetric CTs. (arXiv:2105.08147v2 [eess.IV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.08147</id>
        <link href="http://arxiv.org/abs/2105.08147"/>
        <updated>2021-05-22T06:24:28.497Z</updated>
        <summary type="html"><![CDATA[Chest X-rays of coronavirus disease 2019 (COVID-19) patients are frequently
obtained to determine the extent of lung disease and are a valuable source of
data for creating artificial intelligence models. Most work to date assessing
disease severity on chest imaging has focused on segmenting computed tomography
(CT) images; however, given that CTs are performed much less frequently than
chest X-rays for COVID-19 patients, automated lung lesion segmentation on chest
X-rays could be clinically valuable. There …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Ramesh_V/0/1/0/all/0/1"&gt;Vignav Ramesh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Rister_B/0/1/0/all/0/1"&gt;Blaine Rister&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Rubin_D/0/1/0/all/0/1"&gt;Daniel L. Rubin&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Using Machine Learning Techniques to Identify Key Risk Factors for Diabetes and Undiagnosed Diabetes. (arXiv:2105.09379v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09379</id>
        <link href="http://arxiv.org/abs/2105.09379"/>
        <updated>2021-05-22T06:24:28.490Z</updated>
        <summary type="html"><![CDATA[This paper reviews a wide selection of machine learning models built to
predict both the presence of diabetes and the presence of undiagnosed diabetes
using eight years of National Health and Nutrition Examination Survey (NHANES)
data. Models are tuned and compared via their Brier Scores. The most relevant
variables of the best performing models are then compared. A Support Vector
Machine with a linear kernel performed best for predicting diabetes, returning
a Brier score of 0.0654 and an AUROC of 0.9235 on…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Adler_A/0/1/0/all/0/1"&gt;Avraham Adler&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[CURE: Code-Aware Neural Machine Translation for Automatic Program Repair. (arXiv:2103.00073v3 [cs.SE] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2103.00073</id>
        <link href="http://arxiv.org/abs/2103.00073"/>
        <updated>2021-05-22T06:24:28.471Z</updated>
        <summary type="html"><![CDATA[Automatic program repair (APR) is crucial to improve software reliability.
Recently, neural machine translation (NMT) techniques have been used to fix
software bugs automatically. While promising, these approaches have two major
limitations. Their search space often does not contain the correct fix, and
their search strategy ignores software knowledge such as strict code syntax.
Due to these limitations, existing NMT-based techniques underperform the best
template-based approaches.

We propose CURE, a new N…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1"&gt;Nan Jiang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lutellier_T/0/1/0/all/0/1"&gt;Thibaud Lutellier&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tan_L/0/1/0/all/0/1"&gt;Lin Tan&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Superpixel-based Domain-Knowledge Infusion in Computer Vision. (arXiv:2105.09448v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09448</id>
        <link href="http://arxiv.org/abs/2105.09448"/>
        <updated>2021-05-22T06:24:28.465Z</updated>
        <summary type="html"><![CDATA[Superpixels are higher-order perceptual groups of pixels in an image, often
carrying much more information than raw pixels. There is an inherent relational
structure to the relationship among different superpixels of an image. This
relational information can convey some form of domain information about the
image, e.g. relationship between superpixels representing two eyes in a cat
image. Our interest in this paper is to construct computer vision models,
specifically those based on Deep Neural Networks (DNNs…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chhablani_G/0/1/0/all/0/1"&gt;Gunjan Chhablani&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1"&gt;Abheesht Sharma&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Pandey_H/0/1/0/all/0/1"&gt;Harshit Pandey&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Dash_T/0/1/0/all/0/1"&gt;Tirtharaj Dash&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Practical One-Shot Federated Learning for Cross-Silo Setting. (arXiv:2010.01017v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2010.01017</id>
        <link href="http://arxiv.org/abs/2010.01017"/>
        <updated>2021-05-22T06:24:28.458Z</updated>
        <summary type="html"><![CDATA[Federated learning enables multiple parties to collaboratively learn a model
without exchanging their data. While most existing federated learning
algorithms need many rounds to converge, one-shot federated learning (i.e.,
federated learning with a single communication round) is a promising approach
to make federated learning applicable in cross-silo setting in practice.
However, existing one-shot algorithms only support specific models and do not
provide any privacy guarantees, which significantly limit th…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1"&gt;Qinbin Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1"&gt;Bingsheng He&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1"&gt;Dawn Song&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimal Approximation Rates and Metric Entropy of ReLU$^k$ and Cosine Networks. (arXiv:2101.12365v5 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2101.12365</id>
        <link href="http://arxiv.org/abs/2101.12365"/>
        <updated>2021-05-22T06:24:28.451Z</updated>
        <summary type="html"><![CDATA[This article addresses several fundamental issues associated with the
approximation theory of neural networks, including the characterization of
approximation spaces, the determination of the metric entropy of these spaces,
and approximation rates of neural networks. For any activation function
$\sigma$, we show that the largest Banach space of functions which can be
efficiently approximated by the corresponding shallow neural networks is the
space whose norm is given by the gauge of the closed convex hull …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Siegel_J/0/1/0/all/0/1"&gt;Jonathan W. Siegel&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Xu_J/0/1/0/all/0/1"&gt;Jinchao Xu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Does Standard Backpropagation Forget Less Catastrophically Than Adam?. (arXiv:2102.07686v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2102.07686</id>
        <link href="http://arxiv.org/abs/2102.07686"/>
        <updated>2021-05-22T06:24:28.445Z</updated>
        <summary type="html"><![CDATA[Catastrophic forgetting remains a severe hindrance to the broad application
of artificial neural networks (ANNs), however, it continues to be a poorly
understood phenomenon. Despite the extensive amount of work on catastrophic
forgetting, we argue that it is still unclear how exactly the phenomenon should
be quantified, and, moreover, to what degree all of the choices we make when
designing learning systems affect the amount of catastrophic forgetting. We use
various testbeds from the reinforcement learning…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ashley_D/0/1/0/all/0/1"&gt;Dylan R. Ashley&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ghiassian_S/0/1/0/all/0/1"&gt;Sina Ghiassian&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sutton_R/0/1/0/all/0/1"&gt;Richard S. Sutton&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Be Causal: De-biasing Social Network Confounding in Recommendation. (arXiv:2105.07775v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.07775</id>
        <link href="http://arxiv.org/abs/2105.07775"/>
        <updated>2021-05-22T06:24:28.422Z</updated>
        <summary type="html"><![CDATA[In recommendation systems, the existence of the missing-not-at-random (MNAR)
problem results in the selection bias issue, degrading the recommendation
performance ultimately. A common practice to address MNAR is to treat missing
entries from the so-called "exposure" perspective, i.e., modeling how an item
is exposed (provided) to a user. Most of the existing approaches use heuristic
models or re-weighting strategy on observed ratings to mimic the
missing-at-random setting. However, little research has been …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1"&gt;Qian Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1"&gt;Xiangmeng Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1"&gt;Guandong Xu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An IoT-Based Framework for Remote Fall Monitoring. (arXiv:2105.09461v1 [cs.NI])]]></title>
        <id>http://arxiv.org/abs/2105.09461</id>
        <link href="http://arxiv.org/abs/2105.09461"/>
        <updated>2021-05-22T06:24:28.411Z</updated>
        <summary type="html"><![CDATA[Fall detection is a serious healthcare issue that needs to be solved. Falling
without quick medical intervention would lower the chances of survival for the
elderly, especially if living alone. Hence, the need is there for developing
fall detection algorithms with high accuracy. This paper presents a novel
IoT-based system for fall detection that includes a sensing device transmitting
data to a mobile application through a cloud-connected gateway device. Then,
the focus is shifted to the algorithmic aspect …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Al_Kababji_A/0/1/0/all/0/1"&gt;Ayman Al-Kababji&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Amira_A/0/1/0/all/0/1"&gt;Abbes Amira&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bensaali_F/0/1/0/all/0/1"&gt;Faycal Bensaali&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jarouf_A/0/1/0/all/0/1"&gt;Abdulah Jarouf&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Shidqi_L/0/1/0/all/0/1"&gt;Lisan Shidqi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Djelouat_H/0/1/0/all/0/1"&gt;Hamza Djelouat&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multi-Head Attention: Collaborate Instead of Concatenate. (arXiv:2006.16362v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2006.16362</id>
        <link href="http://arxiv.org/abs/2006.16362"/>
        <updated>2021-05-22T06:24:28.405Z</updated>
        <summary type="html"><![CDATA[Attention layers are widely used in natural language processing (NLP) and are
beginning to influence computer vision architectures. Training very large
transformer models allowed significant improvement in both fields, but once
trained, these networks show symptoms of over-parameterization. For instance,
it is known that many attention heads can be pruned without impacting accuracy.
This work aims to enhance current understanding on how multiple heads interact.
Motivated by the observation that attention he…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Cordonnier_J/0/1/0/all/0/1"&gt;Jean-Baptiste Cordonnier&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Loukas_A/0/1/0/all/0/1"&gt;Andreas Loukas&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1"&gt;Martin Jaggi&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Measuring Coding Challenge Competence With APPS. (arXiv:2105.09938v1 [cs.SE])]]></title>
        <id>http://arxiv.org/abs/2105.09938</id>
        <link href="http://arxiv.org/abs/2105.09938"/>
        <updated>2021-05-22T06:24:28.399Z</updated>
        <summary type="html"><![CDATA[While programming is one of the most broadly applicable skills in modern
society, modern machine learning models still cannot code solutions to basic
problems. It can be difficult to accurately assess code generation performance,
and there has been surprisingly little work on evaluating code generation in a
way that is both flexible and rigorous. To meet this challenge, we introduce
APPS, a benchmark for code generation. Unlike prior work in more restricted
settings, our benchmark measures the ability of mo…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Hendrycks_D/0/1/0/all/0/1"&gt;Dan Hendrycks&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Basart_S/0/1/0/all/0/1"&gt;Steven Basart&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kadavath_S/0/1/0/all/0/1"&gt;Saurav Kadavath&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mazeika_M/0/1/0/all/0/1"&gt;Mantas Mazeika&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Arora_A/0/1/0/all/0/1"&gt;Akul Arora&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Guo_E/0/1/0/all/0/1"&gt;Ethan Guo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Burns_C/0/1/0/all/0/1"&gt;Collin Burns&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Puranik_S/0/1/0/all/0/1"&gt;Samir Puranik&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1"&gt;Horace He&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1"&gt;Dawn Song&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Steinhardt_J/0/1/0/all/0/1"&gt;Jacob Steinhardt&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Robust Pruning at Initialization. (arXiv:2002.08797v5 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2002.08797</id>
        <link href="http://arxiv.org/abs/2002.08797"/>
        <updated>2021-05-22T06:24:28.391Z</updated>
        <summary type="html"><![CDATA[Overparameterized Neural Networks (NN) display state-of-the-art performance.
However, there is a growing need for smaller, energy-efficient, neural networks
tobe able to use machine learning applications on devices with limited
computational resources. A popular approach consists of using pruning
techniques. While these techniques have traditionally focused on pruning
pre-trained NN (LeCun et al.,1990; Hassibi et al., 1993), recent work by Lee et
al. (2018) has shown promising results when pruning at initia…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Hayou_S/0/1/0/all/0/1"&gt;Soufiane Hayou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Ton_J/0/1/0/all/0/1"&gt;Jean-Francois Ton&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Doucet_A/0/1/0/all/0/1"&gt;Arnaud Doucet&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Teh_Y/0/1/0/all/0/1"&gt;Yee Whye Teh&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Minimum-Delay Adaptation in Non-Stationary Reinforcement Learning via Online High-Confidence Change-Point Detection. (arXiv:2105.09452v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09452</id>
        <link href="http://arxiv.org/abs/2105.09452"/>
        <updated>2021-05-22T06:24:28.374Z</updated>
        <summary type="html"><![CDATA[Non-stationary environments are challenging for reinforcement learning
algorithms. If the state transition and/or reward functions change based on
latent factors, the agent is effectively tasked with optimizing a behavior that
maximizes performance over a possibly infinite random sequence of Markov
Decision Processes (MDPs), each of which drawn from some unknown distribution.
We call each such MDP a context. Most related works make strong assumptions
such as knowledge about the distribution over contexts, t…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Alegre_L/0/1/0/all/0/1"&gt;Lucas N. Alegre&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bazzan_A/0/1/0/all/0/1"&gt;Ana L. C. Bazzan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Silva_B/0/1/0/all/0/1"&gt;Bruno C. da Silva&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Aggregate Learning for Mixed Frequency Data. (arXiv:2105.09579v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09579</id>
        <link href="http://arxiv.org/abs/2105.09579"/>
        <updated>2021-05-22T06:24:28.368Z</updated>
        <summary type="html"><![CDATA[Large and acute economic shocks such as the 2007-2009 financial crisis and
the current COVID-19 infections rapidly change the economic environment. In
such a situation, the importance of real-time economic analysis using
alternative datais emerging. Alternative data such as search query and location
data are closer to real-time and richer than official statistics that are
typically released once a month in an aggregated form. We take advantage of
spatio-temporal granularity of alternative data and propose a…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Toda_T/0/1/0/all/0/1"&gt;Takamichi Toda&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Moriwaki_D/0/1/0/all/0/1"&gt;Daisuke Moriwaki&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ota_K/0/1/0/all/0/1"&gt;Kazuhiro Ota&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pruning of Deep Spiking Neural Networks through Gradient Rewiring. (arXiv:2105.04916v2 [cs.NE] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.04916</id>
        <link href="http://arxiv.org/abs/2105.04916"/>
        <updated>2021-05-22T06:24:28.360Z</updated>
        <summary type="html"><![CDATA[Spiking Neural Networks (SNNs) have been attached great importance due to
their biological plausibility and high energy-efficiency on neuromorphic chips.
As these chips are usually resource-constrained, the compression of SNNs is
thus crucial along the road of practical use of SNNs. Most existing methods
directly apply pruning approaches in artificial neural networks (ANNs) to SNNs,
which ignore the difference between ANNs and SNNs, thus limiting the
performance of the pruned SNNs. Besides, these methods ar…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1"&gt;Yanqi Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1"&gt;Zhaofei Yu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Fang_W/0/1/0/all/0/1"&gt;Wei Fang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1"&gt;Tiejun Huang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1"&gt;Yonghong Tian&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep learning for solution and inversion of structural mechanics and vibrations. (arXiv:2105.09477v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09477</id>
        <link href="http://arxiv.org/abs/2105.09477"/>
        <updated>2021-05-22T06:24:28.333Z</updated>
        <summary type="html"><![CDATA[Deep learning has been the most popular machine learning method in the last
few years. In this chapter, we present the application of deep learning and
physics-informed neural networks concerning structural mechanics and vibration
problems. Demonstration problems involve de-noising data, solution to
time-dependent ordinary and partial differential equations, and characterizing
the system's response for a given data.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Haghighat_E/0/1/0/all/0/1"&gt;Ehsan Haghighat&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bekar_A/0/1/0/all/0/1"&gt;Ali Can Bekar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Madenci_E/0/1/0/all/0/1"&gt;Erdogan Madenci&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Juanes_R/0/1/0/all/0/1"&gt;Ruben Juanes&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Separation of Powers in Federated Learning. (arXiv:2105.09400v1 [cs.CR])]]></title>
        <id>http://arxiv.org/abs/2105.09400</id>
        <link href="http://arxiv.org/abs/2105.09400"/>
        <updated>2021-05-22T06:24:28.327Z</updated>
        <summary type="html"><![CDATA[Federated Learning (FL) enables collaborative training among mutually
distrusting parties. Model updates, rather than training data, are concentrated
and fused in a central aggregation server. A key security challenge in FL is
that an untrustworthy or compromised aggregation process might lead to
unforeseeable information leakage. This challenge is especially acute due to
recently demonstrated attacks that have reconstructed large fractions of
training data from ostensibly "sanitized" model updates.

In thi…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1"&gt;Pau-Chen Cheng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Eykholt_K/0/1/0/all/0/1"&gt;Kevin Eykholt&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_Z/0/1/0/all/0/1"&gt;Zhongshu Gu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jamjoom_H/0/1/0/all/0/1"&gt;Hani Jamjoom&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jayaram_K/0/1/0/all/0/1"&gt;K. R. Jayaram&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Valdez_E/0/1/0/all/0/1"&gt;Enriquillo Valdez&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Verma_A/0/1/0/all/0/1"&gt;Ashish Verma&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Kronecker neural networks: A general framework for neural networks with adaptive activation functions. (arXiv:2105.09513v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09513</id>
        <link href="http://arxiv.org/abs/2105.09513"/>
        <updated>2021-05-22T06:24:28.249Z</updated>
        <summary type="html"><![CDATA[We propose a new type of neural networks, Kronecker neural networks (KNNs),
that form a general framework for neural networks with adaptive activation
functions. KNNs employ the Kronecker product, which provides an efficient way
of constructing a very wide network while keeping the number of parameters low.
Our theoretical analysis reveals that under suitable conditions, KNNs induce a
faster decay of the loss than that by the feed-forward networks. This is also
empirically verified through a set of computat…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Jagtap_A/0/1/0/all/0/1"&gt;Ameya D. Jagtap&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Shin_Y/0/1/0/all/0/1"&gt;Yeonjong Shin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1"&gt;Kenji Kawaguchi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Karniadakis_G/0/1/0/all/0/1"&gt;George Em Karniadakis&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Exploring The Limits Of Data Augmentation For Retinal Vessel Segmentation. (arXiv:2105.09365v1 [eess.IV])]]></title>
        <id>http://arxiv.org/abs/2105.09365</id>
        <link href="http://arxiv.org/abs/2105.09365"/>
        <updated>2021-05-22T06:24:28.242Z</updated>
        <summary type="html"><![CDATA[Retinal Vessel Segmentation is important for diagnosis of various diseases.
The research on retinal vessel segmentation focuses mainly on improvement of
the segmentation model which is usually based on U-Net architecture. In our
study we use the U-Net architecture and we rely on heavy data augmentation in
order to achieve better performance. The success of the data augmentation
relies on successfully addressing the problem of input images. By analyzing
input images and performing the augmentation accordingl…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Uysal_E/0/1/0/all/0/1"&gt;Enes Sadi Uysal&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Bilici_M/0/1/0/all/0/1"&gt;M.&amp;#x15e;afak Bilici&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Zaza_B/0/1/0/all/0/1"&gt;B. Selin Zaza&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Ozgenc_M/0/1/0/all/0/1"&gt;M. Yi&amp;#x11f;it &amp;#xd6;zgen&amp;#xe7;&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Boyar_O/0/1/0/all/0/1"&gt;Onur Boyar&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AutoML to Date and Beyond: Challenges and Opportunities. (arXiv:2010.10777v4 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2010.10777</id>
        <link href="http://arxiv.org/abs/2010.10777"/>
        <updated>2021-05-22T06:24:28.235Z</updated>
        <summary type="html"><![CDATA[As big data becomes ubiquitous across domains, and more and more stakeholders
aspire to make the most of their data, demand for machine learning tools has
spurred researchers to explore the possibilities of automated machine learning
(AutoML). AutoML tools aim to make machine learning accessible for non-machine
learning experts (domain experts), to improve the efficiency of machine
learning, and to accelerate machine learning research. But although automation
and efficiency are among AutoML's main selling p…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Santu_S/0/1/0/all/0/1"&gt;Shubhra Kanti Karmaker Santu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hassan_M/0/1/0/all/0/1"&gt;Md. Mahadi Hassan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Smith_M/0/1/0/all/0/1"&gt;Micah J. Smith&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1"&gt;Lei Xu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhai_C/0/1/0/all/0/1"&gt;ChengXiang Zhai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Veeramachaneni_K/0/1/0/all/0/1"&gt;Kalyan Veeramachaneni&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Variational Data Assimilation with a Learned Inverse Observation Operator. (arXiv:2102.11192v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2102.11192</id>
        <link href="http://arxiv.org/abs/2102.11192"/>
        <updated>2021-05-22T06:24:28.228Z</updated>
        <summary type="html"><![CDATA[Variational data assimilation optimizes for an initial state of a dynamical
system such that its evolution fits observational data. The physical model can
subsequently be evolved into the future to make predictions. This principle is
a cornerstone of large scale forecasting applications such as numerical weather
prediction. As such, it is implemented in current operational systems of
weather forecasting agencies across the globe. However, finding a good initial
state poses a difficult optimization problem i…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Frerix_T/0/1/0/all/0/1"&gt;Thomas Frerix&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kochkov_D/0/1/0/all/0/1"&gt;Dmitrii Kochkov&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Smith_J/0/1/0/all/0/1"&gt;Jamie A. Smith&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cremers_D/0/1/0/all/0/1"&gt;Daniel Cremers&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Brenner_M/0/1/0/all/0/1"&gt;Michael P. Brenner&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hoyer_S/0/1/0/all/0/1"&gt;Stephan Hoyer&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Data-driven Thermal Anomaly Detection for Batteries using Unsupervised Shape Clustering. (arXiv:2103.08796v2 [eess.SY] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2103.08796</id>
        <link href="http://arxiv.org/abs/2103.08796"/>
        <updated>2021-05-22T06:24:28.210Z</updated>
        <summary type="html"><![CDATA[For electric vehicles (EV) and energy storage (ES) batteries, thermal runaway
is a critical issue as it can lead to uncontrollable fires or even explosions.
Thermal anomaly detection can identify problematic battery packs that may
eventually undergo thermal runaway. However, there are common challenges like
data unavailability, environment and configuration variations, and battery
aging. We propose a data-driven method to detect battery thermal anomaly based
on comparing shape-similarity between thermal mea…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Li_X/0/1/0/all/0/1"&gt;Xiaojun Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1"&gt;Jianwei Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Abdollahi_A/0/1/0/all/0/1"&gt;Ali Abdollahi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Jones_T/0/1/0/all/0/1"&gt;Trevor Jones&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[FastCorrect: Fast Error Correction with Edit Alignment for Automatic Speech Recognition. (arXiv:2105.03842v2 [cs.CL] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.03842</id>
        <link href="http://arxiv.org/abs/2105.03842"/>
        <updated>2021-05-22T06:24:28.204Z</updated>
        <summary type="html"><![CDATA[Error correction techniques have been used to refine the output sentences
from automatic speech recognition (ASR) models and achieve a lower word error
rate (WER) than original ASR outputs. Previous works usually use a
sequence-to-sequence model to correct an ASR output sentence autoregressively,
which causes large latency and cannot be deployed in online ASR services. A
straightforward solution to reduce latency, inspired by non-autoregressive
(NAR) neural machine translation, is to use an NAR sequence gen…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Leng_Y/0/1/0/all/0/1"&gt;Yichong Leng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1"&gt;Xu Tan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1"&gt;Linchen Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1"&gt;Jin Xu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1"&gt;Renqian Luo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1"&gt;Linquan Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1"&gt;Tao Qin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1"&gt;Xiang-Yang Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lin_E/0/1/0/all/0/1"&gt;Ed Lin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1"&gt;Tie-Yan Liu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Data-Efficient Reinforcement Learning with Self-Predictive Representations. (arXiv:2007.05929v4 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2007.05929</id>
        <link href="http://arxiv.org/abs/2007.05929"/>
        <updated>2021-05-22T06:24:28.196Z</updated>
        <summary type="html"><![CDATA[While deep reinforcement learning excels at solving tasks where large amounts
of data can be collected through virtually unlimited interaction with the
environment, learning from limited interaction remains a key challenge. We
posit that an agent can learn more efficiently if we augment reward
maximization with self-supervised objectives based on structure in its visual
input and sequential interaction with the environment. Our method,
Self-Predictive Representations(SPR), trains an agent to predict its own…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Schwarzer_M/0/1/0/all/0/1"&gt;Max Schwarzer&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Anand_A/0/1/0/all/0/1"&gt;Ankesh Anand&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Goel_R/0/1/0/all/0/1"&gt;Rishab Goel&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hjelm_R/0/1/0/all/0/1"&gt;R Devon Hjelm&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Courville_A/0/1/0/all/0/1"&gt;Aaron Courville&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bachman_P/0/1/0/all/0/1"&gt;Philip Bachman&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Value Function is All You Need: A Unified Learning Framework for Ride Hailing Platforms. (arXiv:2105.08791v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.08791</id>
        <link href="http://arxiv.org/abs/2105.08791"/>
        <updated>2021-05-22T06:24:28.189Z</updated>
        <summary type="html"><![CDATA[Large ride-hailing platforms, such as DiDi, Uber and Lyft, connect tens of
thousands of vehicles in a city to millions of ride demands throughout the day,
providing great promises for improving transportation efficiency through the
tasks of order dispatching and vehicle repositioning. Existing studies,
however, usually consider the two tasks in simplified settings that hardly
address the complex interactions between the two, the real-time fluctuations
between supply and demand, and the necessary coordinatio…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1"&gt;Xiaocheng Tang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1"&gt;Fan Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1"&gt;Zhiwei Qin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"&gt;Yansheng Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Shi_D/0/1/0/all/0/1"&gt;Dingyuan Shi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Song_B/0/1/0/all/0/1"&gt;Bingchen Song&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tong_Y/0/1/0/all/0/1"&gt;Yongxin Tong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1"&gt;Hongtu Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1"&gt;Jieping Ye&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fundamental limits and algorithms for sparse linear regression with sublinear sparsity. (arXiv:2101.11156v3 [cs.IT] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2101.11156</id>
        <link href="http://arxiv.org/abs/2101.11156"/>
        <updated>2021-05-22T06:24:28.182Z</updated>
        <summary type="html"><![CDATA[We establish exact asymptotic expressions for the normalized mutual
information and minimum mean-square-error (MMSE) of sparse linear regression in
the sub-linear sparsity regime. Our result is achieved by a generalization of
the adaptive interpolation method in Bayesian inference for linear regimes to
sub-linear ones. A modification of the well-known approximate message passing
algorithm to approach the MMSE fundamental limit is also proposed, and its
state evolution is rigorously analysed. Our results sho…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Truong_L/0/1/0/all/0/1"&gt;Lan V. Truong&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Unknown from Correlations: Graph Neural Network for Inter-novel-protein Interaction Prediction. (arXiv:2105.06709v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.06709</id>
        <link href="http://arxiv.org/abs/2105.06709"/>
        <updated>2021-05-22T06:24:28.162Z</updated>
        <summary type="html"><![CDATA[The study of multi-type Protein-Protein Interaction (PPI) is fundamental for
understanding biological processes from a systematic perspective and revealing
disease mechanisms. Existing methods suffer from significant performance
degradation when tested in unseen dataset. In this paper, we investigate the
problem and find that it is mainly attributed to the poor performance for
inter-novel-protein interaction prediction. However, current evaluations
overlook the inter-novel-protein interactions, and thus fai…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Lv_G/0/1/0/all/0/1"&gt;Guofeng Lv&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1"&gt;Zhiqiang Hu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bi_Y/0/1/0/all/0/1"&gt;Yanguang Bi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1"&gt;Shaoting Zhang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Graph-Based Behavior-Aware Recommendation for Interactive News. (arXiv:1812.00002v2 [cs.IR] UPDATED)]]></title>
        <id>http://arxiv.org/abs/1812.00002</id>
        <link href="http://arxiv.org/abs/1812.00002"/>
        <updated>2021-05-22T06:24:28.151Z</updated>
        <summary type="html"><![CDATA[Interactive news recommendation has been launched and attracted much
attention recently. In this scenario, user's behavior evolves from single click
behavior to multiple behaviors including like, comment, share etc. However,
most of the existing methods still use single click behavior as the unique
criterion of judging user's preferences. Further, although heterogeneous graphs
have been applied in different areas, a proper way to construct a heterogeneous
graph for interactive news data with an appropriate …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1"&gt;Mingyuan Ma&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Na_S/0/1/0/all/0/1"&gt;Sen Na&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1"&gt;Hongyu Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1"&gt;Congzhou Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1"&gt;Jin Xu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Surrogate gradients for analog neuromorphic computing. (arXiv:2006.07239v3 [cs.NE] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2006.07239</id>
        <link href="http://arxiv.org/abs/2006.07239"/>
        <updated>2021-05-22T06:24:28.143Z</updated>
        <summary type="html"><![CDATA[To rapidly process temporal information at a low metabolic cost, biological
neurons integrate inputs as an analog sum but communicate with spikes, binary
events in time. Analog neuromorphic hardware uses the same principles to
emulate spiking neural networks with exceptional energy-efficiency. However,
instantiating high-performing spiking networks on such hardware remains a
significant challenge due to device mismatch and the lack of efficient training
algorithms. Here, we introduce a general in-the-loop l…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Cramer_B/0/1/0/all/0/1"&gt;Benjamin Cramer&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Billaudelle_S/0/1/0/all/0/1"&gt;Sebastian Billaudelle&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kanya_S/0/1/0/all/0/1"&gt;Simeon Kanya&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Leibfried_A/0/1/0/all/0/1"&gt;Aron Leibfried&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Grubl_A/0/1/0/all/0/1"&gt;Andreas Gr&amp;#xfc;bl&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Karasenko_V/0/1/0/all/0/1"&gt;Vitali Karasenko&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Pehle_C/0/1/0/all/0/1"&gt;Christian Pehle&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Schreiber_K/0/1/0/all/0/1"&gt;Korbinian Schreiber&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Stradmann_Y/0/1/0/all/0/1"&gt;Yannik Stradmann&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Weis_J/0/1/0/all/0/1"&gt;Johannes Weis&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Schemmel_J/0/1/0/all/0/1"&gt;Johannes Schemmel&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zenke_F/0/1/0/all/0/1"&gt;Friedemann Zenke&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[EiGLasso for Scalable Sparse Kronecker-Sum Inverse Covariance Estimation. (arXiv:2105.09872v1 [stat.ML])]]></title>
        <id>http://arxiv.org/abs/2105.09872</id>
        <link href="http://arxiv.org/abs/2105.09872"/>
        <updated>2021-05-22T06:24:28.136Z</updated>
        <summary type="html"><![CDATA[In many real-world problems, complex dependencies are present both among
samples and among features. The Kronecker sum or the Cartesian product of two
graphs, each modeling dependencies across features and across samples, has been
used as an inverse covariance matrix for a matrix-variate Gaussian
distribution, as an alternative to a Kronecker-product inverse covariance
matrix, due to its more intuitive sparse structure. However, the existing
methods for sparse Kronecker-sum inverse covariance estimation are…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Yoon_J/0/1/0/all/0/1"&gt;Jun Ho Yoon&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Kim_S/0/1/0/all/0/1"&gt;Seyoung Kim&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dual-side Sparse Tensor Core. (arXiv:2105.09564v1 [cs.AR])]]></title>
        <id>http://arxiv.org/abs/2105.09564</id>
        <link href="http://arxiv.org/abs/2105.09564"/>
        <updated>2021-05-22T06:24:28.129Z</updated>
        <summary type="html"><![CDATA[Leveraging sparsity in deep neural network (DNN) models is promising for
accelerating model inference. Yet existing GPUs can only leverage the sparsity
from weights but not activations, which are dynamic, unpredictable, and hence
challenging to exploit. In this work, we propose a novel architecture to
efficiently harness the dual-side sparsity (i.e., weight and activation
sparsity). We take a systematic approach to understand the (dis)advantages of
previous sparsity-related architectures and propose a novel…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"&gt;Yang Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1"&gt;Chen Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1"&gt;Zhiqiang Xie&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1"&gt;Cong Guo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1"&gt;Yunxin Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Leng_J/0/1/0/all/0/1"&gt;Jingwen Leng&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Semi-supervised, Topology-Aware Segmentation of Tubular Structures from Live Imaging 3D Microscopy. (arXiv:2105.09737v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09737</id>
        <link href="http://arxiv.org/abs/2105.09737"/>
        <updated>2021-05-22T06:24:28.111Z</updated>
        <summary type="html"><![CDATA[Motivated by a challenging tubular network segmentation task, this paper
tackles two commonly encountered problems in biomedical imaging: Topological
consistency of the segmentation, and limited annotations. We propose a
topological score which measures both topological and geometric consistency
between the predicted and ground truth segmentations, applied for model
selection and validation. We apply our topological score in three scenarios: i.
a U-net ii. a U-net pretrained on an autoencoder, and iii. a se…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Arnavaz_K/0/1/0/all/0/1"&gt;Kasra Arnavaz&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Krause_O/0/1/0/all/0/1"&gt;Oswin Krause&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Krivokapic_J/0/1/0/all/0/1"&gt;Jelena M. Krivokapic&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Heilmann_S/0/1/0/all/0/1"&gt;Silja Heilmann&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Baerentzen_J/0/1/0/all/0/1"&gt;Jakob Andreas B&amp;#xe6;rentzen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Nyeng_P/0/1/0/all/0/1"&gt;Pia Nyeng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Feragen_A/0/1/0/all/0/1"&gt;Aasa Feragen&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Flexible Compositional Learning of Structured Visual Concepts. (arXiv:2105.09848v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09848</id>
        <link href="http://arxiv.org/abs/2105.09848"/>
        <updated>2021-05-22T06:24:28.105Z</updated>
        <summary type="html"><![CDATA[Humans are highly efficient learners, with the ability to grasp the meaning
of a new concept from just a few examples. Unlike popular computer vision
systems, humans can flexibly leverage the compositional structure of the visual
world, understanding new concepts as combinations of existing concepts. In the
current paper, we study how people learn different types of visual
compositions, using abstract visual forms with rich relational structure. We
find that people can make meaningful compositional generali…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1"&gt;Yanli Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lake_B/0/1/0/all/0/1"&gt;Brenden M. Lake&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ensemble machine learning approach for screening of coronary heart disease based on echocardiography and risk factors. (arXiv:2105.09670v1 [stat.ML])]]></title>
        <id>http://arxiv.org/abs/2105.09670</id>
        <link href="http://arxiv.org/abs/2105.09670"/>
        <updated>2021-05-22T06:24:28.098Z</updated>
        <summary type="html"><![CDATA[Background: Extensive clinical evidence suggests that a preventive screening
of coronary heart disease (CHD) at an earlier stage can greatly reduce the
mortality rate. We use 64 two-dimensional speckle tracking echocardiography
(2D-STE) features and seven clinical features to predict whether one has CHD.
Methods: We develop a machine learning approach that integrates a number of
popular classification methods together by model stacking, and generalize the
traditional stacking method to a two-step stacking m…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1"&gt;Jingyi Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Zhu_H/0/1/0/all/0/1"&gt;Huolan Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1"&gt;Yongkai Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Yang_C/0/1/0/all/0/1"&gt;Chenguang Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Cheng_H/0/1/0/all/0/1"&gt;Huimin Cheng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1"&gt;Yi Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Zhong_W/0/1/0/all/0/1"&gt;Wenxuan Zhong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Wang_F/0/1/0/all/0/1"&gt;Fang Wang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the $\alpha$-lazy version of Markov chains in estimation and testing problems. (arXiv:2105.09536v1 [stat.ML])]]></title>
        <id>http://arxiv.org/abs/2105.09536</id>
        <link href="http://arxiv.org/abs/2105.09536"/>
        <updated>2021-05-22T06:24:28.070Z</updated>
        <summary type="html"><![CDATA[We formulate extendibility of the minimax one-trajectory length of several
statistical Markov chains inference problems and give sufficient conditions for
both the possibility and impossibility of such extensions. We follow up and
apply this framework to recently published results on learning and identity
testing of ergodic Markov chains. In particular, we show that for some of the
aforementioned results, we can omit the aperiodicity requirement by simulating
an $\alpha$-lazy version of the original process…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Fried_S/0/1/0/all/0/1"&gt;Sela Fried&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Wolfer_G/0/1/0/all/0/1"&gt;Geoffrey Wolfer&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the Parameterized Complexity of Polytree Learning. (arXiv:2105.09675v1 [cs.DS])]]></title>
        <id>http://arxiv.org/abs/2105.09675</id>
        <link href="http://arxiv.org/abs/2105.09675"/>
        <updated>2021-05-22T06:24:28.056Z</updated>
        <summary type="html"><![CDATA[A Bayesian network is a directed acyclic graph that represents statistical
dependencies between variables of a joint probability distribution. A
fundamental task in data science is to learn a Bayesian network from observed
data. \textsc{Polytree Learning} is the problem of learning an optimal Bayesian
network that fulfills the additional property that its underlying undirected
graph is a forest. In this work, we revisit the complexity of \textsc{Polytree
Learning}. We show that \textsc{Polytree Learning} ca…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Gruttemeier_N/0/1/0/all/0/1"&gt;Niels Gr&amp;#xfc;ttemeier&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Komusiewicz_C/0/1/0/all/0/1"&gt;Christian Komusiewicz&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Morawietz_N/0/1/0/all/0/1"&gt;Nils Morawietz&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Decomposing reverse-mode automatic differentiation. (arXiv:2105.09469v1 [cs.PL])]]></title>
        <id>http://arxiv.org/abs/2105.09469</id>
        <link href="http://arxiv.org/abs/2105.09469"/>
        <updated>2021-05-22T06:24:28.049Z</updated>
        <summary type="html"><![CDATA[We decompose reverse-mode automatic differentiation into (forward-mode)
linearization followed by transposition. Doing so isolates the essential
difference between forward- and reverse-mode AD, and simplifies their joint
implementation. In particular, once forward-mode AD rules are defined for every
primitive operation in a source language, only linear primitives require an
additional transposition rule in order to arrive at a complete reverse-mode AD
implementation. This is how reverse-mode AD is written i…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Frostig_R/0/1/0/all/0/1"&gt;Roy Frostig&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Johnson_M/0/1/0/all/0/1"&gt;Matthew J. Johnson&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Maclaurin_D/0/1/0/all/0/1"&gt;Dougal Maclaurin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Paszke_A/0/1/0/all/0/1"&gt;Adam Paszke&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Radul_A/0/1/0/all/0/1"&gt;Alexey Radul&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[L1 Regression with Lewis Weights Subsampling. (arXiv:2105.09433v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09433</id>
        <link href="http://arxiv.org/abs/2105.09433"/>
        <updated>2021-05-22T06:24:28.029Z</updated>
        <summary type="html"><![CDATA[We consider the problem of finding an approximate solution to $\ell_1$
regression while only observing a small number of labels. Given an $n \times d$
unlabeled data matrix $X$, we must choose a small set of $m \ll n$ rows to
observe the labels of, then output an estimate $\widehat{\beta}$ whose error on
the original problem is within a $1 + \varepsilon$ factor of optimal. We show
that sampling from $X$ according to its Lewis weights and outputting the
empirical minimizer succeeds with probability $1-\delta…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Parulekar_A/0/1/0/all/0/1"&gt;Aditya Parulekar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Parulekar_A/0/1/0/all/0/1"&gt;Advait Parulekar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Price_E/0/1/0/all/0/1"&gt;Eric Price&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Graph Sanitation with Application to Node Classification. (arXiv:2105.09384v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09384</id>
        <link href="http://arxiv.org/abs/2105.09384"/>
        <updated>2021-05-22T06:24:28.022Z</updated>
        <summary type="html"><![CDATA[The past decades have witnessed the prosperity of graph mining, with a
multitude of sophisticated models and algorithms designed for various mining
tasks, such as ranking, classification, clustering and anomaly detection.
Generally speaking, the vast majority of the existing works aim to answer the
following question, that is, given a graph, what is the best way to mine it? In
this paper, we introduce the graph sanitation problem, to answer an orthogonal
question. That is, given a mining task and an initial…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1"&gt;Zhe Xu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tong_H/0/1/0/all/0/1"&gt;Hanghang Tong&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Distribution Agnostic Symbolic Representations for Time Series Dimensionality Reduction and Online Anomaly Detection. (arXiv:2105.09592v1 [cs.IR])]]></title>
        <id>http://arxiv.org/abs/2105.09592</id>
        <link href="http://arxiv.org/abs/2105.09592"/>
        <updated>2021-05-22T06:24:28.014Z</updated>
        <summary type="html"><![CDATA[Due to the importance of the lower bounding distances and the attractiveness
of symbolic representations, the family of symbolic aggregate approximations
(SAX) has been used extensively for encoding time series data. However, typical
SAX-based methods rely on two restrictive assumptions; the Gaussian
distribution and equiprobable symbols. This paper proposes two novel
data-driven SAX-based symbolic representations, distinguished by their
discretization steps. The first representation, oriented for general d…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Bountrogiannis_K/0/1/0/all/0/1"&gt;Konstantinos Bountrogiannis&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tzagkarakis_G/0/1/0/all/0/1"&gt;George Tzagkarakis&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tsakalides_P/0/1/0/all/0/1"&gt;Panagiotis Tsakalides&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Speech & Song Emotion Recognition Using Multilayer Perceptron and Standard Vector Machine. (arXiv:2105.09406v1 [cs.SD])]]></title>
        <id>http://arxiv.org/abs/2105.09406</id>
        <link href="http://arxiv.org/abs/2105.09406"/>
        <updated>2021-05-22T06:24:27.993Z</updated>
        <summary type="html"><![CDATA[Herein, we have compared the performance of SVM and MLP in emotion
recognition using speech and song channels of the RAVDESS dataset. We have
undertaken a journey to extract various audio features, identify optimal
scaling strategy and hyperparameter for our models. To increase sample size, we
have performed audio data augmentation and addressed data imbalance using
SMOTE. Our data indicate that optimised SVM outperforms MLP with an accuracy of
82 compared to 75%. Following data augmentation, the performanc…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Javaheri_B/0/1/0/all/0/1"&gt;Behzad Javaheri&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DistTune: Distributed Fine-Grained Adaptive Traffic Speed Prediction for Growing Transportation Networks. (arXiv:2105.09421v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09421</id>
        <link href="http://arxiv.org/abs/2105.09421"/>
        <updated>2021-05-22T06:24:27.976Z</updated>
        <summary type="html"><![CDATA[Over the past decade, many approaches have been introduced for traffic speed
prediction. However, providing fine-grained, accurate, time-efficient, and
adaptive traffic speed prediction for a growing transportation network where
the size of the network keeps increasing and new traffic detectors are
constantly deployed has not been well studied. To address this issue, this
paper presents DistTune based on Long Short-Term Memory (LSTM) and the
Nelder-Mead method. Whenever encountering an unprocessed detector,…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1"&gt;Ming-Chang Lee&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1"&gt;Jia-Chun Lin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gran_E/0/1/0/all/0/1"&gt;Ernst Gunnar Gran&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Review of Autonomous Road Vehicle Integrated Approaches to an Emergency Obstacle Avoidance Maneuver. (arXiv:2105.09446v1 [cs.RO])]]></title>
        <id>http://arxiv.org/abs/2105.09446</id>
        <link href="http://arxiv.org/abs/2105.09446"/>
        <updated>2021-05-22T06:24:27.969Z</updated>
        <summary type="html"><![CDATA[As passenger vehicle technologies have advanced, so have their capabilities
to avoid obstacles, especially with developments in tires, suspensions,
steering, as well as safety technologies like ABS, ESC, and more recently, ADAS
systems. However, environments around passenger vehicles have also become more
complex, and dangerous. There have previously been studies that outline driver
tendencies and performance capabilities when attempting to avoid obstacles
while driving passenger vehicles. Now that autonomo…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Lowe_E/0/1/0/all/0/1"&gt;Evan Lowe&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Guvenc_L/0/1/0/all/0/1"&gt;Levent Guven&amp;#xe7;&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unsupervised Discriminative Learning of Sounds for Audio Event Classification. (arXiv:2105.09279v2 [cs.SD] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.09279</id>
        <link href="http://arxiv.org/abs/2105.09279"/>
        <updated>2021-05-22T06:24:27.936Z</updated>
        <summary type="html"><![CDATA[Recent progress in network-based audio event classification has shown the
benefit of pre-training models on visual data such as ImageNet. While this
process allows knowledge transfer across different domains, training a model on
large-scale visual datasets is time consuming. On several audio event
classification benchmarks, we show a fast and effective alternative that
pre-trains the model unsupervised, only on audio data and yet delivers on-par
performance with ImageNet pre-training. Furthermore, we show t…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Hornauer_S/0/1/0/all/0/1"&gt;Sascha Hornauer&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1"&gt;Ke Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1"&gt;Stella X. Yu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ghaffarzadegan_S/0/1/0/all/0/1"&gt;Shabnam Ghaffarzadegan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ren_L/0/1/0/all/0/1"&gt;Liu Ren&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Deep Learning-Accelerated Data Assimilation and Forecasting Workflow for Commercial-Scale Geologic Carbon Storage. (arXiv:2105.09468v1 [physics.geo-ph])]]></title>
        <id>http://arxiv.org/abs/2105.09468</id>
        <link href="http://arxiv.org/abs/2105.09468"/>
        <updated>2021-05-22T06:24:27.908Z</updated>
        <summary type="html"><![CDATA[Fast assimilation of monitoring data to update forecasts of pressure buildup
and carbon dioxide (CO2) plume migration under geologic uncertainties is a
challenging problem in geologic carbon storage. The high computational cost of
data assimilation with a high-dimensional parameter space impedes fast
decision-making for commercial-scale reservoir management. We propose to
leverage physical understandings of porous medium flow behavior with deep
learning techniques to develop a fast history matching-reservoi…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/physics/1/au:+Tang_H/0/1/0/all/0/1"&gt;Hewei Tang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Fu_P/0/1/0/all/0/1"&gt;Pengcheng Fu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Sherman_C/0/1/0/all/0/1"&gt;Christopher S. Sherman&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Zhang_J/0/1/0/all/0/1"&gt;Jize Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Ju_X/0/1/0/all/0/1"&gt;Xin Ju&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Hamon_F/0/1/0/all/0/1"&gt;Fran&amp;#xe7;ois Hamon&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Azzolina_N/0/1/0/all/0/1"&gt;Nicholas A. Azzolina&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Burton_Kelly_M/0/1/0/all/0/1"&gt;Matthew Burton-Kelly&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Morris_J/0/1/0/all/0/1"&gt;Joseph P. Morris&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multi-Person Extreme Motion Prediction with Cross-Interaction Attention. (arXiv:2105.08825v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.08825</id>
        <link href="http://arxiv.org/abs/2105.08825"/>
        <updated>2021-05-22T06:24:27.902Z</updated>
        <summary type="html"><![CDATA[Human motion prediction aims to forecast future human poses given a sequence
of past 3D skeletons. While this problem has recently received increasing
attention, it has mostly been tackled for single humans in isolation. In this
paper we explore this problem from a novel perspective, involving humans
performing collaborative tasks. We assume that the input of our system are two
sequences of past skeletons for two interacting persons, and we aim to predict
the future motion for each of them. For this purpose…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1"&gt;Wen Guo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bie_X/0/1/0/all/0/1"&gt;Xiaoyu Bie&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Alameda_Pineda_X/0/1/0/all/0/1"&gt;Xavier Alameda-Pineda&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Moreno_Noguer_F/0/1/0/all/0/1"&gt;Francesc Moreno-Noguer&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Physics-Constrained Deep Learning Model for Simulating Multiphase Flow in 3D Heterogeneous Porous Media. (arXiv:2105.09467v1 [physics.geo-ph])]]></title>
        <id>http://arxiv.org/abs/2105.09467</id>
        <link href="http://arxiv.org/abs/2105.09467"/>
        <updated>2021-05-22T06:24:27.895Z</updated>
        <summary type="html"><![CDATA[In this work, an efficient physics-constrained deep learning model is
developed for solving multiphase flow in 3D heterogeneous porous media. The
model fully leverages the spatial topology predictive capability of
convolutional neural networks, and is coupled with an efficient
continuity-based smoother to predict flow responses that need spatial
continuity. Furthermore, the transient regions are penalized to steer the
training process such that the model can accurately capture flow in these
regions. The mod…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/physics/1/au:+Yan_B/0/1/0/all/0/1"&gt;Bicheng Yan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Harp_D/0/1/0/all/0/1"&gt;Dylan Robert Harp&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Chen_B/0/1/0/all/0/1"&gt;Bailian Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Pawar_R/0/1/0/all/0/1"&gt;Rajesh Pawar&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Audio-Driven Emotional Video Portraits. (arXiv:2104.07452v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2104.07452</id>
        <link href="http://arxiv.org/abs/2104.07452"/>
        <updated>2021-05-22T06:24:27.879Z</updated>
        <summary type="html"><![CDATA[Despite previous success in generating audio-driven talking heads, most of
the previous studies focus on the correlation between speech content and the
mouth shape. Facial emotion, which is one of the most important features on
natural human faces, is always neglected in their methods. In this work, we
present Emotional Video Portraits (EVP), a system for synthesizing high-quality
video portraits with vivid emotional dynamics driven by audios. Specifically,
we propose the Cross-Reconstructed Emotion Disenta…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ji_X/0/1/0/all/0/1"&gt;Xinya Ji&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1"&gt;Hang Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1"&gt;Kaisiyuan Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1"&gt;Wayne Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Loy_C/0/1/0/all/0/1"&gt;Chen Change Loy&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1"&gt;Xun Cao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1"&gt;Feng Xu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[COVID-19 Lung Lesion Segmentation Using a Sparsely Supervised Mask R-CNN on Chest X-rays Automatically Computed from Volumetric CTs. (arXiv:2105.08147v2 [eess.IV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.08147</id>
        <link href="http://arxiv.org/abs/2105.08147"/>
        <updated>2021-05-22T06:24:27.862Z</updated>
        <summary type="html"><![CDATA[Chest X-rays of coronavirus disease 2019 (COVID-19) patients are frequently
obtained to determine the extent of lung disease and are a valuable source of
data for creating artificial intelligence models. Most work to date assessing
disease severity on chest imaging has focused on segmenting computed tomography
(CT) images; however, given that CTs are performed much less frequently than
chest X-rays for COVID-19 patients, automated lung lesion segmentation on chest
X-rays could be clinically valuable. There …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Ramesh_V/0/1/0/all/0/1"&gt;Vignav Ramesh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Rister_B/0/1/0/all/0/1"&gt;Blaine Rister&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Rubin_D/0/1/0/all/0/1"&gt;Daniel L. Rubin&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[COVID-19 Detection in Computed Tomography Images with 2D and 3D Approaches. (arXiv:2105.08506v2 [eess.IV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.08506</id>
        <link href="http://arxiv.org/abs/2105.08506"/>
        <updated>2021-05-22T06:24:27.850Z</updated>
        <summary type="html"><![CDATA[Detecting COVID-19 in computed tomography (CT) or radiography images has been
proposed as a supplement to the definitive RT-PCR test. We present a deep
learning ensemble for detecting COVID-19 infection, combining slice-based (2D)
and volume-based (3D) approaches. The 2D system detects the infection on each
CT slice independently, combining them to obtain the patient-level decision via
different methods (averaging and long-short term memory networks). The 3D
system takes the whole CT volume to arrive to the…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Ahmed_S/0/1/0/all/0/1"&gt;Sara Atito Ali Ahmed&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Yavuz_M/0/1/0/all/0/1"&gt;Mehmet Can Yavuz&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Sen_M/0/1/0/all/0/1"&gt;Mehmet Umut Sen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Gulsen_F/0/1/0/all/0/1"&gt;Fatih Gulsen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Tutar_O/0/1/0/all/0/1"&gt;Onur Tutar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Korkmazer_B/0/1/0/all/0/1"&gt;Bora Korkmazer&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Samanci_C/0/1/0/all/0/1"&gt;Cesur Samanci&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Sirolu_S/0/1/0/all/0/1"&gt;Sabri Sirolu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Hamid_R/0/1/0/all/0/1"&gt;Rauf Hamid&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Eryurekli_A/0/1/0/all/0/1"&gt;Ali Ergun Eryurekli&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Mammadov_T/0/1/0/all/0/1"&gt;Toghrul Mammadov&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Yanikoglu_B/0/1/0/all/0/1"&gt;Berrin Yanikoglu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Physically-Consistent Generative Adversarial Networks for Coastal Flood Visualization. (arXiv:2104.04785v3 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2104.04785</id>
        <link href="http://arxiv.org/abs/2104.04785"/>
        <updated>2021-05-22T06:24:27.834Z</updated>
        <summary type="html"><![CDATA[As climate change increases the intensity of natural disasters, society needs
better tools for adaptation. Floods, for example, are the most frequent natural
disaster, and better tools for flood risk communication could increase the
support for flood-resilient infrastructure development. Our work aims to enable
more visual communication of large-scale climate impacts via visualizing the
output of coastal flood models as satellite imagery. We propose the first deep
learning pipeline to ensure physical-consis…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Lutjens_B/0/1/0/all/0/1"&gt;Bj&amp;#xf6;rn L&amp;#xfc;tjens&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Leshchinskiy_B/0/1/0/all/0/1"&gt;Brandon Leshchinskiy&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Requena_Mesa_C/0/1/0/all/0/1"&gt;Christian Requena-Mesa&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chishtie_F/0/1/0/all/0/1"&gt;Farrukh Chishtie&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Diaz_Rodriguez_N/0/1/0/all/0/1"&gt;Natalia D&amp;#xed;az-Rodr&amp;#xed;guez&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Boulais_O/0/1/0/all/0/1"&gt;Oc&amp;#xe9;ane Boulais&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sankaranarayanan_A/0/1/0/all/0/1"&gt;Aruna Sankaranarayanan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Pina_A/0/1/0/all/0/1"&gt;Aaron Pi&amp;#xf1;a&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1"&gt;Yarin Gal&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Raissi_C/0/1/0/all/0/1"&gt;Chedy Ra&amp;#xef;ssi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lavin_A/0/1/0/all/0/1"&gt;Alexander Lavin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Newman_D/0/1/0/all/0/1"&gt;Dava Newman&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Balancing Robustness and Sensitivity using Feature Contrastive Learning. (arXiv:2105.09394v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09394</id>
        <link href="http://arxiv.org/abs/2105.09394"/>
        <updated>2021-05-22T06:24:27.827Z</updated>
        <summary type="html"><![CDATA[It is generally believed that robust training of extremely large networks is
critical to their success in real-world applications. However, when taken to
the extreme, methods that promote robustness can hurt the model's sensitivity
to rare or underrepresented patterns. In this paper, we discuss this trade-off
between sensitivity and robustness to natural (non-adversarial) perturbations
by introducing two notions: contextual feature utility and contextual feature
sensitivity. We propose Feature Contrastive L…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1"&gt;Seungyeon Kim&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Glasner_D/0/1/0/all/0/1"&gt;Daniel Glasner&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ramalingam_S/0/1/0/all/0/1"&gt;Srikumar Ramalingam&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1"&gt;Cho-Jui Hsieh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Papineni_K/0/1/0/all/0/1"&gt;Kishore Papineni&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1"&gt;Sanjiv Kumar&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Camouflaged Instance Segmentation In-The-Wild: Dataset And Benchmark Suite. (arXiv:2103.17123v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2103.17123</id>
        <link href="http://arxiv.org/abs/2103.17123"/>
        <updated>2021-05-22T06:24:27.801Z</updated>
        <summary type="html"><![CDATA[This paper pushes the envelope on camouflaged regions to decompose them into
meaningful components, namely, camouflaged instances. To promote the new task
of camouflaged instance segmentation in-the-wild, we introduce a new dataset,
namely CAMO++, by extending our preliminary CAMO dataset (camouflaged object
segmentation) in terms of quantity and diversity. The new dataset substantially
increases the number of images with hierarchical pixel-wise ground-truths. We
also provide a benchmark suite for the task …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1"&gt;Trung-Nghia Le&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1"&gt;Yubo Cao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1"&gt;Tan-Cong Nguyen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Le_M/0/1/0/all/0/1"&gt;Minh-Quan Le&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1"&gt;Khanh-Duy Nguyen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Do_T/0/1/0/all/0/1"&gt;Thanh-Toan Do&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tran_M/0/1/0/all/0/1"&gt;Minh-Triet Tran&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1"&gt;Tam V. Nguyen&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Machine-learning based methodologies for 3d x-ray measurement, characterization and optimization for buried structures in advanced ic packages. (arXiv:2103.04838v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2103.04838</id>
        <link href="http://arxiv.org/abs/2103.04838"/>
        <updated>2021-05-22T06:24:27.794Z</updated>
        <summary type="html"><![CDATA[For over 40 years lithographic silicon scaling has driven circuit integration
and performance improvement in the semiconductor industry. As silicon scaling
slows down, the industry is increasingly dependent on IC package technologies
to contribute to further circuit integration and performance improvements. This
is a paradigm shift and requires the IC package industry to reduce the size and
increase the density of internal interconnects on a scale which has never been
done before. Traditional package charac…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Pahwa_R/0/1/0/all/0/1"&gt;Ramanpreet S Pahwa&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ho_S/0/1/0/all/0/1"&gt;Soon Wee Ho&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Qin_R/0/1/0/all/0/1"&gt;Ren Qin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chang_R/0/1/0/all/0/1"&gt;Richard Chang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Min_O/0/1/0/all/0/1"&gt;Oo Zaw Min&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jie_W/0/1/0/all/0/1"&gt;Wang Jie&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Rao_V/0/1/0/all/0/1"&gt;Vempati Srinivasa Rao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Nwe_T/0/1/0/all/0/1"&gt;Tin Lay Nwe&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1"&gt;Yanjing Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Neumann_J/0/1/0/all/0/1"&gt;Jens Timo Neumann&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Pichumani_R/0/1/0/all/0/1"&gt;Ramani Pichumani&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gregorich_T/0/1/0/all/0/1"&gt;Thomas Gregorich&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Seismic Fault Segmentation via 3D-CNN Training by a Few 2D Slices Labels. (arXiv:2105.03857v3 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.03857</id>
        <link href="http://arxiv.org/abs/2105.03857"/>
        <updated>2021-05-22T06:24:27.788Z</updated>
        <summary type="html"><![CDATA[Detection faults in seismic data is a crucial step for seismic structural
interpretation, reservoir characterization and well placement. Some recent
works regard it as an image segmentation task. The task of image segmentation
requires huge labels, especially 3D seismic data, which has a complex structure
and lots of noise. Therefore, its annotation requires expert experience and a
huge workload. In this study, we present {\lambda}-BCE and {\lambda}-smooth
L1loss to effectively train 3D-CNN by some slices f…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Dou_Y/0/1/0/all/0/1"&gt;YiMin Dou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1"&gt;Kewen Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1"&gt;Jianbing Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1"&gt;Xiao Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xi_Y/0/1/0/all/0/1"&gt;Yingjie Xi&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DeepDebug: Fixing Python Bugs Using Stack Traces, Backtranslation, and Code Skeletons. (arXiv:2105.09352v1 [cs.SE])]]></title>
        <id>http://arxiv.org/abs/2105.09352</id>
        <link href="http://arxiv.org/abs/2105.09352"/>
        <updated>2021-05-22T06:24:27.776Z</updated>
        <summary type="html"><![CDATA[The joint task of bug localization and program repair is an integral part of
the software development process. In this work we present DeepDebug, an
approach to automated debugging using large, pretrained transformers. We begin
by training a bug-creation model on reversed commit data for the purpose of
generating synthetic bugs. We apply these synthetic bugs toward two ends.
First, we directly train a backtranslation model on all functions from 200K
repositories. Next, we focus on 10K repositories for which…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Drain_D/0/1/0/all/0/1"&gt;Dawn Drain&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Clement_C/0/1/0/all/0/1"&gt;Colin B. Clement&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Serrato_G/0/1/0/all/0/1"&gt;Guillermo Serrato&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sundaresan_N/0/1/0/all/0/1"&gt;Neel Sundaresan&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Auto-Tuned Sim-to-Real Transfer. (arXiv:2104.07662v2 [cs.RO] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2104.07662</id>
        <link href="http://arxiv.org/abs/2104.07662"/>
        <updated>2021-05-22T06:24:27.770Z</updated>
        <summary type="html"><![CDATA[Policies trained in simulation often fail when transferred to the real world
due to the `reality gap' where the simulator is unable to accurately capture
the dynamics and visual properties of the real world. Current approaches to
tackle this problem, such as domain randomization, require prior knowledge and
engineering to determine how much to randomize system parameters in order to
learn a policy that is robust to sim-to-real transfer while also not being too
conservative. We propose a method for automatic…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1"&gt;Yuqing Du&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Watkins_O/0/1/0/all/0/1"&gt;Olivia Watkins&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1"&gt;Trevor Darrell&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1"&gt;Pieter Abbeel&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Pathak_D/0/1/0/all/0/1"&gt;Deepak Pathak&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Temporally Consistent Image-based Sun Tracking Algorithm for Solar Energy Forecasting Applications. (arXiv:2012.01059v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2012.01059</id>
        <link href="http://arxiv.org/abs/2012.01059"/>
        <updated>2021-05-22T06:24:27.762Z</updated>
        <summary type="html"><![CDATA[Improving irradiance forecasting is critical to further increase the share of
solar in the energy mix. On a short time scale, fish-eye cameras on the ground
are used to capture cloud displacements causing the local variability of the
electricity production. As most of the solar radiation comes directly from the
Sun, current forecasting approaches use its position in the image as a
reference to interpret the cloud cover dynamics. However, existing Sun tracking
methods rely on external data and a calibration …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Paletta_Q/0/1/0/all/0/1"&gt;Quentin Paletta&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lasenby_J/0/1/0/all/0/1"&gt;Joan Lasenby&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MoDL-QSM: Model-based Deep Learning for Quantitative Susceptibility Mapping. (arXiv:2101.08413v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2101.08413</id>
        <link href="http://arxiv.org/abs/2101.08413"/>
        <updated>2021-05-22T06:24:27.731Z</updated>
        <summary type="html"><![CDATA[Quantitative susceptibility mapping (QSM) has demonstrated great potential in
quantifying tissue susceptibility in various brain diseases. However, the
intrinsic ill-posed inverse problem relating the tissue phase to the underlying
susceptibility distribution affects the accuracy for quantifying tissue
susceptibility. Recently, deep learning has shown promising results to improve
accuracy by reducing the streaking artifacts. However, there exists a mismatch
between the observed phase and the theoretical for…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Feng_R/0/1/0/all/0/1"&gt;Ruimin Feng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1"&gt;Jiayi Zhao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1"&gt;He Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1"&gt;Baofeng Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1"&gt;Jie Feng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1"&gt;Yuting Shi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1"&gt;Ming Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1"&gt;Chunlei Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1"&gt;Yuyao Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhuang_J/0/1/0/all/0/1"&gt;Jie Zhuang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wei_H/0/1/0/all/0/1"&gt;Hongjiang Wei&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SAFIN: Arbitrary Style Transfer With Self-Attentive Factorized Instance Normalization. (arXiv:2105.06129v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.06129</id>
        <link href="http://arxiv.org/abs/2105.06129"/>
        <updated>2021-05-22T06:24:27.717Z</updated>
        <summary type="html"><![CDATA[Artistic style transfer aims to transfer the style characteristics of one
image onto another image while retaining its content. Existing approaches
commonly leverage various normalization techniques, although these face
limitations in adequately transferring diverse textures to different spatial
locations. Self-Attention-based approaches have tackled this issue with partial
success but suffer from unwanted artifacts. Motivated by these observations,
this paper aims to combine the best of both worlds: self-a…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1"&gt;Aaditya Singh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hingane_S/0/1/0/all/0/1"&gt;Shreeshail Hingane&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gong_X/0/1/0/all/0/1"&gt;Xinyu Gong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1"&gt;Zhangyang Wang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pruning of Deep Spiking Neural Networks through Gradient Rewiring. (arXiv:2105.04916v2 [cs.NE] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.04916</id>
        <link href="http://arxiv.org/abs/2105.04916"/>
        <updated>2021-05-22T06:24:27.696Z</updated>
        <summary type="html"><![CDATA[Spiking Neural Networks (SNNs) have been attached great importance due to
their biological plausibility and high energy-efficiency on neuromorphic chips.
As these chips are usually resource-constrained, the compression of SNNs is
thus crucial along the road of practical use of SNNs. Most existing methods
directly apply pruning approaches in artificial neural networks (ANNs) to SNNs,
which ignore the difference between ANNs and SNNs, thus limiting the
performance of the pruned SNNs. Besides, these methods ar…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1"&gt;Yanqi Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1"&gt;Zhaofei Yu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Fang_W/0/1/0/all/0/1"&gt;Wei Fang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1"&gt;Tiejun Huang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1"&gt;Yonghong Tian&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Which Parts determine the Impression of the Font?. (arXiv:2103.14216v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2103.14216</id>
        <link href="http://arxiv.org/abs/2103.14216"/>
        <updated>2021-05-22T06:24:27.670Z</updated>
        <summary type="html"><![CDATA[Various fonts give different impressions, such as legible, rough, and
comic-text.This paper aims to analyze the correlation between the local shapes,
or parts, and the impression of fonts. By focusing on local shapes instead of
the whole letter shape, we can realize letter-shape independent and more
general analysis. The analysis is performed by newly combining SIFT and
DeepSets, to extract an arbitrary number of essential parts from a particular
font and aggregate them to infer the font impressions by nonl…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ueda_M/0/1/0/all/0/1"&gt;Masaya Ueda&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kimura_A/0/1/0/all/0/1"&gt;Akisato Kimura&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Uchida_S/0/1/0/all/0/1"&gt;Seiichi Uchida&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quantifying the Complexity of Standard Benchmarking Datasets for Long-Term Human Trajectory Prediction. (arXiv:2005.13934v4 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2005.13934</id>
        <link href="http://arxiv.org/abs/2005.13934"/>
        <updated>2021-05-22T06:24:27.664Z</updated>
        <summary type="html"><![CDATA[Methods to quantify the complexity of trajectory datasets are still a missing
piece in benchmarking human trajectory prediction models. In order to gain a
better understanding of the complexity of trajectory prediction tasks and
following the intuition, that more complex datasets contain more information,
an approach for quantifying the amount of information contained in a dataset
from a prototype-based dataset representation is proposed. The dataset
representation is obtained by first employing a non-trivi…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Hug_R/0/1/0/all/0/1"&gt;Ronny Hug&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Becker_S/0/1/0/all/0/1"&gt;Stefan Becker&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hubner_W/0/1/0/all/0/1"&gt;Wolfgang H&amp;#xfc;bner&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Arens_M/0/1/0/all/0/1"&gt;Michael Arens&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Objects as Extreme Points. (arXiv:2104.14066v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2104.14066</id>
        <link href="http://arxiv.org/abs/2104.14066"/>
        <updated>2021-05-22T06:24:27.658Z</updated>
        <summary type="html"><![CDATA[Object detection can be regarded as a pixel clustering task, and its boundary
is determined by four extreme points (leftmost, top, rightmost, and bottom).
However, most studies focus on the center or corner points of the object, which
are actually conditional results of the extreme points. In this paper, we
present an Extreme-Point-Prediction-Based object detector (EPP-Net), which
directly regresses the relative displacement vector between each pixel and the
four extreme points. We also propose a new metric…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1"&gt;Yang Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1"&gt;Min Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Meng_B/0/1/0/all/0/1"&gt;Bo Meng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1"&gt;Zihao Huang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1"&gt;Junxing Ren&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sun_D/0/1/0/all/0/1"&gt;Degang Sun&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MIN2Net: End-to-End Multi-Task Learning for Subject-Independent Motor Imagery EEG Classification. (arXiv:2102.03814v3 [eess.SP] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2102.03814</id>
        <link href="http://arxiv.org/abs/2102.03814"/>
        <updated>2021-05-22T06:24:27.651Z</updated>
        <summary type="html"><![CDATA[Advances in the motor imagery (MI)-based brain-computer interfaces (BCIs)
allow control of several applications by decoding neurophysiological phenomena,
which are usually recorded by electroencephalography (EEG) using a non-invasive
technique. Despite great advances in MI-based BCI, EEG rhythms are specific to
a subject and various changes over time. These issues point to significant
challenges to enhance the classification performance, especially in a
subject-independent manner. To overcome these challeng…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Autthasan_P/0/1/0/all/0/1"&gt;Phairot Autthasan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Chaisaen_R/0/1/0/all/0/1"&gt;Rattanaphon Chaisaen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Sudhawiyangkul_T/0/1/0/all/0/1"&gt;Thapanun Sudhawiyangkul&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Rangpong_P/0/1/0/all/0/1"&gt;Phurin Rangpong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Kiatthaveephong_S/0/1/0/all/0/1"&gt;Suktipol Kiatthaveephong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Dilokthanakul_N/0/1/0/all/0/1"&gt;Nat Dilokthanakul&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Bhakdisongkhram_G/0/1/0/all/0/1"&gt;Gun Bhakdisongkhram&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Phan_H/0/1/0/all/0/1"&gt;Huy Phan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Guan_C/0/1/0/all/0/1"&gt;Cuntai Guan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Wilaiprasitporn_T/0/1/0/all/0/1"&gt;Theerawit Wilaiprasitporn&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multiple Simultaneous Pseudo Image Classification with Random Fields and a Deep Belief Network for Disease Indication. (arXiv:2104.10762v2 [eess.IV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2104.10762</id>
        <link href="http://arxiv.org/abs/2104.10762"/>
        <updated>2021-05-22T06:24:27.631Z</updated>
        <summary type="html"><![CDATA[We show how to use random field theory in a supervised, energy-based model
for multiple pseudo image classification of 2D integer matrices. In the model,
each row of a 2D integer matrix is a pseudo image where a local receptive field
focuses on multiple portions of individual rows for simultaneous learning. The
model is used for a classification task consisting of presence of patient
biomarkers indicative of a particular disease.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Murphy_R/0/1/0/all/0/1"&gt;Robert A. Murphy&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Where Do Deep Fakes Look? Synthetic Face Detection via Gaze Tracking. (arXiv:2101.01165v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2101.01165</id>
        <link href="http://arxiv.org/abs/2101.01165"/>
        <updated>2021-05-22T06:24:27.625Z</updated>
        <summary type="html"><![CDATA[Following the recent initiatives for the democratization of AI, deep fake
generators have become increasingly popular and accessible, causing dystopian
scenarios towards social erosion of trust. A particular domain, such as
biological signals, attracted attention towards detection methods that are
capable of exploiting authenticity signatures in real videos that are not yet
faked by generative approaches. In this paper, we first propose several
prominent eye and gaze features that deep fakes exhibit differe…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Demir_I/0/1/0/all/0/1"&gt;Ilke Demir&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ciftci_U/0/1/0/all/0/1"&gt;Umur A. Ciftci&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Semi-Supervised Learning for Bone Mineral Density Estimation in Hip X-ray Images. (arXiv:2103.13482v2 [eess.IV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2103.13482</id>
        <link href="http://arxiv.org/abs/2103.13482"/>
        <updated>2021-05-22T06:24:27.618Z</updated>
        <summary type="html"><![CDATA[Bone mineral density (BMD) is a clinically critical indicator of
osteoporosis, usually measured by dual-energy X-ray absorptiometry (DEXA). Due
to the limited accessibility of DEXA machines and examinations, osteoporosis is
often under-diagnosed and under-treated, leading to increased fragility
fracture risks. Thus it is highly desirable to obtain BMDs with alternative
cost-effective and more accessible medical imaging examinations such as X-ray
plain films. In this work, we formulate the BMD estimation fro…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Zheng_K/0/1/0/all/0/1"&gt;Kang Zheng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1"&gt;Yirui Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Zhou_X/0/1/0/all/0/1"&gt;Xiaoyun Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Wang_F/0/1/0/all/0/1"&gt;Fakai Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Lu_L/0/1/0/all/0/1"&gt;Le Lu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Lin_C/0/1/0/all/0/1"&gt;Chihung Lin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Huang_L/0/1/0/all/0/1"&gt;Lingyun Huang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Xie_G/0/1/0/all/0/1"&gt;Guotong Xie&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Xiao_J/0/1/0/all/0/1"&gt;Jing Xiao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Kuo_C/0/1/0/all/0/1"&gt;Chang-Fu Kuo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Miao_S/0/1/0/all/0/1"&gt;Shun Miao&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Empirical Analysis of Image Caption Generation using Deep Learning. (arXiv:2105.09906v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09906</id>
        <link href="http://arxiv.org/abs/2105.09906"/>
        <updated>2021-05-22T06:24:27.612Z</updated>
        <summary type="html"><![CDATA[Automated image captioning is one of the applications of Deep Learning which
involves fusion of work done in computer vision and natural language
processing, and it is typically performed using Encoder-Decoder architectures.
In this project, we have implemented and experimented with various flavors of
multi-modal image captioning networks where ResNet101, DenseNet121 and VGG19
based CNN Encoders and Attention based LSTM Decoders were explored. We have
studied the effect of beam size and the use of pretraine…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_A/0/1/0/all/0/1"&gt;Aditya Bhattacharya&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Girishekar_E/0/1/0/all/0/1"&gt;Eshwar Shamanna Girishekar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Deshpande_P/0/1/0/all/0/1"&gt;Padmakar Anil Deshpande&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Decade Survey of Content Based Image Retrieval using Deep Learning. (arXiv:2012.00641v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2012.00641</id>
        <link href="http://arxiv.org/abs/2012.00641"/>
        <updated>2021-05-22T06:24:27.606Z</updated>
        <summary type="html"><![CDATA[The content based image retrieval aims to find the similar images from a
large scale dataset against a query image. Generally, the similarity between
the representative features of the query image and dataset images is used to
rank the images for retrieval. In early days, various hand designed feature
descriptors have been investigated based on the visual cues such as color,
texture, shape, etc. that represent the images. However, the deep learning has
emerged as a dominating alternative of hand-designed fe…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Dubey_S/0/1/0/all/0/1"&gt;Shiv Ram Dubey&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Trained Trajectory based Automated Parking System using Visual SLAM on Surround View Cameras. (arXiv:2001.02161v3 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2001.02161</id>
        <link href="http://arxiv.org/abs/2001.02161"/>
        <updated>2021-05-22T06:24:27.599Z</updated>
        <summary type="html"><![CDATA[Automated Parking is becoming a standard feature in modern vehicles. Existing
parking systems build a local map to be able to plan for maneuvering towards a
detected slot. Next generation parking systems have an use case where they
build a persistent map of the environment where the car is frequently parked,
say for example, home parking or office parking. The pre-built map helps in
re-localizing the vehicle better when its trying to park the next time. This is
achieved by augmenting the parking system with…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Tripathi_N/0/1/0/all/0/1"&gt;Nivedita Tripathi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yogamani_S/0/1/0/all/0/1"&gt;Senthil Yogamani&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The MAMe Dataset: On the relevance of High Resolution and Variable Shape image properties. (arXiv:2007.13693v3 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2007.13693</id>
        <link href="http://arxiv.org/abs/2007.13693"/>
        <updated>2021-05-22T06:24:27.578Z</updated>
        <summary type="html"><![CDATA[In the image classification task, the most common approach is to resize all
images in a dataset to a unique shape, while reducing their precision to a size
which facilitates experimentation at scale. This practice has benefits from a
computational perspective, but it entails negative side-effects on performance
due to loss of information and image deformation. In this work we introduce the
MAMe dataset, an image classification dataset with remarkable high resolution
and variable shape properties. The goal o…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Pares_F/0/1/0/all/0/1"&gt;Ferran Par&amp;#xe9;s&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Arias_Duart_A/0/1/0/all/0/1"&gt;Anna Arias-Duart&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Garcia_Gasulla_D/0/1/0/all/0/1"&gt;Dario Garcia-Gasulla&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Campo_Frances_G/0/1/0/all/0/1"&gt;Gema Campo-Franc&amp;#xe9;s&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Viladrich_N/0/1/0/all/0/1"&gt;Nina Viladrich&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ayguade_E/0/1/0/all/0/1"&gt;Eduard Ayguad&amp;#xe9;&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Labarta_J/0/1/0/all/0/1"&gt;Jes&amp;#xfa;s Labarta&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Remote Pulse Estimation in the Presence of Face Masks. (arXiv:2101.04096v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2101.04096</id>
        <link href="http://arxiv.org/abs/2101.04096"/>
        <updated>2021-05-22T06:24:27.570Z</updated>
        <summary type="html"><![CDATA[Remote photoplethysmography (rPPG), a family of techniques for monitoring
blood volume changes, may be especially useful for widespread contactless
health monitoring using face video from consumer-grade visible-light cameras.
The COVID-19 pandemic has caused the widespread use of protective face masks.
We found that occlusions from cloth face masks increased the mean absolute
error of heart rate estimation by more than 80\% when deploying methods
designed on unmasked faces. We show that augmenting unmasked …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Speth_J/0/1/0/all/0/1"&gt;Jeremy Speth&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Vance_N/0/1/0/all/0/1"&gt;Nathan Vance&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Flynn_P/0/1/0/all/0/1"&gt;Patrick Flynn&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bowyer_K/0/1/0/all/0/1"&gt;Kevin Bowyer&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Czajka_A/0/1/0/all/0/1"&gt;Adam Czajka&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Visual Object Recognition in Indoor Environments Using Topologically Persistent Features. (arXiv:2010.03196v4 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2010.03196</id>
        <link href="http://arxiv.org/abs/2010.03196"/>
        <updated>2021-05-22T06:24:27.562Z</updated>
        <summary type="html"><![CDATA[Object recognition in unseen indoor environments remains a challenging
problem for visual perception of mobile robots. In this letter, we propose the
use of topologically persistent features, which rely on the objects' shape
information, to address this challenge. In particular, we extract two kinds of
features, namely, sparse persistence image (PI) and amplitude, by applying
persistent homology to multi-directional height function-based filtrations of
the cubical complexes representing the object segmentat…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Samani_E/0/1/0/all/0/1"&gt;Ekta U. Samani&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1"&gt;Xingjian Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Banerjee_A/0/1/0/all/0/1"&gt;Ashis G. Banerjee&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Face, Body, Voice: Video Person-Clustering with Multiple Modalities. (arXiv:2105.09939v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09939</id>
        <link href="http://arxiv.org/abs/2105.09939"/>
        <updated>2021-05-22T06:24:27.555Z</updated>
        <summary type="html"><![CDATA[The objective of this work is person-clustering in videos -- grouping
characters according to their identity. Previous methods focus on the narrower
task of face-clustering, and for the most part ignore other cues such as the
person's voice, their overall appearance (hair, clothes, posture), and the
editing structure of the videos. Similarly, most current datasets evaluate only
the task of face-clustering, rather than person-clustering. This limits their
applicability to downstream applications such as stor…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Brown_A/0/1/0/all/0/1"&gt;Andrew Brown&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kalogeiton_V/0/1/0/all/0/1"&gt;Vicky Kalogeiton&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zisserman_A/0/1/0/all/0/1"&gt;Andrew Zisserman&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AnaXNet: Anatomy Aware Multi-label Finding Classification in Chest X-ray. (arXiv:2105.09937v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09937</id>
        <link href="http://arxiv.org/abs/2105.09937"/>
        <updated>2021-05-22T06:24:27.531Z</updated>
        <summary type="html"><![CDATA[Radiologists usually observe anatomical regions of chest X-ray images as well
as the overall image before making a decision. However, most existing deep
learning models only look at the entire X-ray image for classification, failing
to utilize important anatomical information. In this paper, we propose a novel
multi-label chest X-ray classification model that accurately classifies the
image finding and also localizes the findings to their correct anatomical
regions. Specifically, our model consists of two m…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Agu_N/0/1/0/all/0/1"&gt;Nkechinyere N. Agu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1"&gt;Joy T. Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chao_H/0/1/0/all/0/1"&gt;Hanqing Chao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lourentzou_I/0/1/0/all/0/1"&gt;Ismini Lourentzou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1"&gt;Arjun Sharma&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Moradi_M/0/1/0/all/0/1"&gt;Mehdi Moradi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yan_P/0/1/0/all/0/1"&gt;Pingkun Yan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hendler_J/0/1/0/all/0/1"&gt;James Hendler&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BodyPressure -- Inferring Body Pose and Contact Pressure from a Depth Image. (arXiv:2105.09936v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09936</id>
        <link href="http://arxiv.org/abs/2105.09936"/>
        <updated>2021-05-22T06:24:27.523Z</updated>
        <summary type="html"><![CDATA[Contact pressure between the human body and its surroundings has important
implications. For example, it plays a role in comfort, safety, posture, and
health. We present a method that infers contact pressure between a human body
and a mattress from a depth image. Specifically, we focus on using a depth
image from a downward facing camera to infer pressure on a body at rest in bed
occluded by bedding, which is directly applicable to the prevention of pressure
injuries in healthcare. Our approach involves aug…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Clever_H/0/1/0/all/0/1"&gt;Henry M. Clever&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Grady_P/0/1/0/all/0/1"&gt;Patrick Grady&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Turk_G/0/1/0/all/0/1"&gt;Greg Turk&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kemp_C/0/1/0/all/0/1"&gt;Charles C. Kemp&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DeepAVO: Efficient Pose Refining with Feature Distilling for Deep Visual Odometry. (arXiv:2105.09899v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09899</id>
        <link href="http://arxiv.org/abs/2105.09899"/>
        <updated>2021-05-22T06:24:27.516Z</updated>
        <summary type="html"><![CDATA[The technology for Visual Odometry (VO) that estimates the position and
orientation of the moving object through analyzing the image sequences captured
by on-board cameras, has been well investigated with the rising interest in
autonomous driving. This paper studies monocular VO from the perspective of
Deep Learning (DL). Unlike most current learning-based methods, our approach,
called DeepAVO, is established on the intuition that features contribute
discriminately to different motion patterns. Specifically…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_R/0/1/0/all/0/1"&gt;Ran Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1"&gt;Mingkun Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1"&gt;Wang Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Song_R/0/1/0/all/0/1"&gt;Rujun Song&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yan_B/0/1/0/all/0/1"&gt;Bo Yan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xiao_Z/0/1/0/all/0/1"&gt;Zhuoling Xiao&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Probing the Effect of Selection Bias on NN Generalization with a Thought Experiment. (arXiv:2105.09934v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09934</id>
        <link href="http://arxiv.org/abs/2105.09934"/>
        <updated>2021-05-22T06:24:27.509Z</updated>
        <summary type="html"><![CDATA[Learned networks in the domain of visual recognition and cognition impress in
part because even though they are trained with datasets many orders of
magnitude smaller than the full population of possible images, they exhibit
sufficient generalization to be applicable to new and previously unseen data.
Although many have examined issues regarding generalization from several
perspectives, we wondered If a network is trained with a biased dataset that
misses particular samples corresponding to some defining do…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Tsotsos_J/0/1/0/all/0/1"&gt;John K. Tsotsos&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1"&gt;Jun Luo&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[POCFormer: A Lightweight Transformer Architecture for Detection of COVID-19 Using Point of Care Ultrasound. (arXiv:2105.09913v1 [eess.IV])]]></title>
        <id>http://arxiv.org/abs/2105.09913</id>
        <link href="http://arxiv.org/abs/2105.09913"/>
        <updated>2021-05-22T06:24:27.501Z</updated>
        <summary type="html"><![CDATA[The rapid and seemingly endless expansion of COVID-19 can be traced back to
the inefficiency and shortage of testing kits that offer accurate results in a
timely manner. An emerging popular technique, which adopts improvements made in
mobile ultrasound technology, allows for healthcare professionals to conduct
rapid screenings on a large scale. We present an image-based solution that aims
at automating the testing process which allows for rapid mass testing to be
conducted with or without a trained medical …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Perera_S/0/1/0/all/0/1"&gt;Shehan Perera&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Adhikari_S/0/1/0/all/0/1"&gt;Srikar Adhikari&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Yilmaz_A/0/1/0/all/0/1"&gt;Alper Yilmaz&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Biologically Inspired Semantic Lateral Connectivity for Convolutional Neural Networks. (arXiv:2105.09830v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09830</id>
        <link href="http://arxiv.org/abs/2105.09830"/>
        <updated>2021-05-22T06:24:27.478Z</updated>
        <summary type="html"><![CDATA[Lateral connections play an important role for sensory processing in visual
cortex by supporting discriminable neuronal responses even to highly similar
features. In the present work, we show that establishing a biologically
inspired Mexican hat lateral connectivity profile along the filter domain can
significantly improve the classification accuracy of a variety of lightweight
convolutional neural networks without the addition of trainable network
parameters. Moreover, we demonstrate that it is possible to…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Weidler_T/0/1/0/all/0/1"&gt;Tonio Weidler&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lehnen_J/0/1/0/all/0/1"&gt;Julian Lehnen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Denman_Q/0/1/0/all/0/1"&gt;Quinton Denman&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sebok_D/0/1/0/all/0/1"&gt;D&amp;#xe1;vid Seb&amp;#x151;k&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Weiss_G/0/1/0/all/0/1"&gt;Gerhard Weiss&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Driessens_K/0/1/0/all/0/1"&gt;Kurt Driessens&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Senden_M/0/1/0/all/0/1"&gt;Mario Senden&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Flexible Compositional Learning of Structured Visual Concepts. (arXiv:2105.09848v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09848</id>
        <link href="http://arxiv.org/abs/2105.09848"/>
        <updated>2021-05-22T06:24:27.416Z</updated>
        <summary type="html"><![CDATA[Humans are highly efficient learners, with the ability to grasp the meaning
of a new concept from just a few examples. Unlike popular computer vision
systems, humans can flexibly leverage the compositional structure of the visual
world, understanding new concepts as combinations of existing concepts. In the
current paper, we study how people learn different types of visual
compositions, using abstract visual forms with rich relational structure. We
find that people can make meaningful compositional generali…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1"&gt;Yanli Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lake_B/0/1/0/all/0/1"&gt;Brenden M. Lake&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Efficient and Robust LiDAR-Based End-to-End Navigation. (arXiv:2105.09932v1 [cs.RO])]]></title>
        <id>http://arxiv.org/abs/2105.09932</id>
        <link href="http://arxiv.org/abs/2105.09932"/>
        <updated>2021-05-22T06:24:27.404Z</updated>
        <summary type="html"><![CDATA[Deep learning has been used to demonstrate end-to-end neural network learning
for autonomous vehicle control from raw sensory input. While LiDAR sensors
provide reliably accurate information, existing end-to-end driving solutions
are mainly based on cameras since processing 3D data requires a large memory
footprint and computation cost. On the other hand, increasing the robustness of
these systems is also critical; however, even estimating the model's
uncertainty is very challenging due to the cost of sampl…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1"&gt;Zhijian Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Amini_A/0/1/0/all/0/1"&gt;Alexander Amini&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1"&gt;Sibo Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Karaman_S/0/1/0/all/0/1"&gt;Sertac Karaman&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1"&gt;Song Han&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Rus_D/0/1/0/all/0/1"&gt;Daniela Rus&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PLSM: A Parallelized Liquid State Machine for Unintentional Action Detection. (arXiv:2105.09909v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09909</id>
        <link href="http://arxiv.org/abs/2105.09909"/>
        <updated>2021-05-22T06:24:27.392Z</updated>
        <summary type="html"><![CDATA[Reservoir Computing (RC) offers a viable option to deploy AI algorithms on
low-end embedded system platforms. Liquid State Machine (LSM) is a bio-inspired
RC model that mimics the cortical microcircuits and uses spiking neural
networks (SNN) that can be directly realized on neuromorphic hardware. In this
paper, we present a novel Parallelized LSM (PLSM) architecture that
incorporates spatio-temporal read-out layer and semantic constraints on model
output. To the best of our knowledge, such a formulation has…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Das_D/0/1/0/all/0/1"&gt;Dipayan Das&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_S/0/1/0/all/0/1"&gt;Saumik Bhattacharya&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Pal_U/0/1/0/all/0/1"&gt;Umapada Pal&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chanda_S/0/1/0/all/0/1"&gt;Sukalpa Chanda&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pedestrian Intention Prediction: A Multi-task Perspective. (arXiv:2010.10270v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2010.10270</id>
        <link href="http://arxiv.org/abs/2010.10270"/>
        <updated>2021-05-22T06:24:27.385Z</updated>
        <summary type="html"><![CDATA[In order to be globally deployed, autonomous cars must guarantee the safety
of pedestrians. This is the reason why forecasting pedestrians' intentions
sufficiently in advance is one of the most critical and challenging tasks for
autonomous vehicles. This work tries to solve this problem by jointly
predicting the intention and visual states of pedestrians. In terms of visual
states, whereas previous work focused on x-y coordinates, we will also predict
the size and indeed the whole bounding box of the pedest…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Bouhsain_S/0/1/0/all/0/1"&gt;Smail Ait Bouhsain&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Saadatnejad_S/0/1/0/all/0/1"&gt;Saeed Saadatnejad&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Alahi_A/0/1/0/all/0/1"&gt;Alexandre Alahi&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fully Convolutional Networks for Automatically Generating Image Masks to Train Mask R-CNN. (arXiv:2003.01383v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2003.01383</id>
        <link href="http://arxiv.org/abs/2003.01383"/>
        <updated>2021-05-22T06:24:27.293Z</updated>
        <summary type="html"><![CDATA[This paper proposes a novel automatically generating image masks method for
the state-of-the-art Mask R-CNN deep learning method. The Mask R-CNN method
achieves the best results in object detection until now, however, it is very
time-consuming and laborious to get the object Masks for training, the proposed
method is composed by a two-stage design, to automatically generating image
masks, the first stage implements a fully convolutional networks (FCN) based
segmentation network, the second stage network, a …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1"&gt;Hao Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Siebert_J/0/1/0/all/0/1"&gt;Jan Paul Siebert&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1"&gt;Xiangrong Xu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Anchor-based Plain Net for Mobile Image Super-Resolution. (arXiv:2105.09750v1 [eess.IV])]]></title>
        <id>http://arxiv.org/abs/2105.09750</id>
        <link href="http://arxiv.org/abs/2105.09750"/>
        <updated>2021-05-22T06:24:27.283Z</updated>
        <summary type="html"><![CDATA[Along with the rapid development of real-world applications, higher
requirements on the accuracy and efficiency of image super-resolution (SR) are
brought forward. Though existing methods have achieved remarkable success, the
majority of them demand plenty of computational resources and large amount of
RAM, and thus they can not be well applied to mobile device. In this paper, we
aim at designing efficient architecture for 8-bit quantization and deploy it on
mobile device. First, we conduct an experiment ab…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Du_Z/0/1/0/all/0/1"&gt;Zongcai Du&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Liu_J/0/1/0/all/0/1"&gt;Jie Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Tang_J/0/1/0/all/0/1"&gt;Jie Tang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Wu_G/0/1/0/all/0/1"&gt;Gangshan Wu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Robust Pruning at Initialization. (arXiv:2002.08797v5 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2002.08797</id>
        <link href="http://arxiv.org/abs/2002.08797"/>
        <updated>2021-05-22T06:24:27.185Z</updated>
        <summary type="html"><![CDATA[Overparameterized Neural Networks (NN) display state-of-the-art performance.
However, there is a growing need for smaller, energy-efficient, neural networks
tobe able to use machine learning applications on devices with limited
computational resources. A popular approach consists of using pruning
techniques. While these techniques have traditionally focused on pruning
pre-trained NN (LeCun et al.,1990; Hassibi et al., 1993), recent work by Lee et
al. (2018) has shown promising results when pruning at initia…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Hayou_S/0/1/0/all/0/1"&gt;Soufiane Hayou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Ton_J/0/1/0/all/0/1"&gt;Jean-Francois Ton&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Doucet_A/0/1/0/all/0/1"&gt;Arnaud Doucet&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Teh_Y/0/1/0/all/0/1"&gt;Yee Whye Teh&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multi-Perspective Anomaly Detection. (arXiv:2105.09903v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09903</id>
        <link href="http://arxiv.org/abs/2105.09903"/>
        <updated>2021-05-22T06:24:27.178Z</updated>
        <summary type="html"><![CDATA[Multi-view classification is inspired by the behavior of humans, especially
when fine-grained features or in our case rarely occurring anomalies are to be
detected. Current contributions point to the problem of how high-dimensional
data can be fused. In this work, we build upon the deep support vector data
description algorithm and address multi-perspective anomaly detection using
three different fusion techniques i.e. early fusion, late fusion, and late
fusion with multiple decoders. We employ different au…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Madan_M/0/1/0/all/0/1"&gt;Manav Madan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jakob_P/0/1/0/all/0/1"&gt;Peter Jakob&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Schmid_Schirling_T/0/1/0/all/0/1"&gt;Tobias Schmid-Schirling&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Valada_A/0/1/0/all/0/1"&gt;Abhinav Valada&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Covid-19 Detection from Chest X-ray and Patient Metadata using Graph Convolutional Neural Networks. (arXiv:2105.09720v1 [eess.IV])]]></title>
        <id>http://arxiv.org/abs/2105.09720</id>
        <link href="http://arxiv.org/abs/2105.09720"/>
        <updated>2021-05-22T06:24:27.124Z</updated>
        <summary type="html"><![CDATA[The novel corona virus (Covid-19) has introduced significant challenges due
to its rapid spreading nature through respiratory transmission. As a result,
there is a huge demand for Artificial Intelligence (AI) based quick disease
diagnosis methods as an alternative to high demand tests such as Polymerase
Chain Reaction (PCR). Chest X-ray (CXR) Image analysis is such cost-effective
radiography technique due to resource availability and quick screening. But, a
sufficient and systematic data collection that is …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Mudiyanselage_T/0/1/0/all/0/1"&gt;Thosini Bamunu Mudiyanselage&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Senanayake_N/0/1/0/all/0/1"&gt;Nipuna Senanayake&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Ji_C/0/1/0/all/0/1"&gt;Chunyan Ji&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Pan_Y/0/1/0/all/0/1"&gt;Yi Pan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1"&gt;Yanqing Zhang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Joint Face Image Restoration and Frontalization for Recognition. (arXiv:2105.09907v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09907</id>
        <link href="http://arxiv.org/abs/2105.09907"/>
        <updated>2021-05-22T06:24:27.103Z</updated>
        <summary type="html"><![CDATA[In real-world scenarios, many factors may harm face recognition performance,
e.g., large pose, bad illumination,low resolution, blur and noise. To address
these challenges, previous efforts usually first restore the low-quality faces
to high-quality ones and then perform face recognition. However, most of these
methods are stage-wise, which is sub-optimal and deviates from the reality. In
this paper, we address all these challenges jointly for unconstrained face
recognition. We propose an Multi-Degradation …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Tu_X/0/1/0/all/0/1"&gt;Xiaoguang Tu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1"&gt;Jian Zhao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1"&gt;Qiankun Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ai_W/0/1/0/all/0/1"&gt;Wenjie Ai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Guo_G/0/1/0/all/0/1"&gt;Guodong Guo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1"&gt;Zhifeng Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1"&gt;Wei Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1"&gt;Jiashi Feng&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Semi-supervised, Topology-Aware Segmentation of Tubular Structures from Live Imaging 3D Microscopy. (arXiv:2105.09737v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09737</id>
        <link href="http://arxiv.org/abs/2105.09737"/>
        <updated>2021-05-22T06:24:27.095Z</updated>
        <summary type="html"><![CDATA[Motivated by a challenging tubular network segmentation task, this paper
tackles two commonly encountered problems in biomedical imaging: Topological
consistency of the segmentation, and limited annotations. We propose a
topological score which measures both topological and geometric consistency
between the predicted and ground truth segmentations, applied for model
selection and validation. We apply our topological score in three scenarios: i.
a U-net ii. a U-net pretrained on an autoencoder, and iii. a se…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Arnavaz_K/0/1/0/all/0/1"&gt;Kasra Arnavaz&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Krause_O/0/1/0/all/0/1"&gt;Oswin Krause&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Krivokapic_J/0/1/0/all/0/1"&gt;Jelena M. Krivokapic&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Heilmann_S/0/1/0/all/0/1"&gt;Silja Heilmann&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Baerentzen_J/0/1/0/all/0/1"&gt;Jakob Andreas B&amp;#xe6;rentzen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Nyeng_P/0/1/0/all/0/1"&gt;Pia Nyeng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Feragen_A/0/1/0/all/0/1"&gt;Aasa Feragen&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Weakly-Supervised Physically Unconstrained Gaze Estimation. (arXiv:2105.09803v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09803</id>
        <link href="http://arxiv.org/abs/2105.09803"/>
        <updated>2021-05-22T06:24:27.088Z</updated>
        <summary type="html"><![CDATA[A major challenge for physically unconstrained gaze estimation is acquiring
training data with 3D gaze annotations for in-the-wild and outdoor scenarios.
In contrast, videos of human interactions in unconstrained environments are
abundantly available and can be much more easily annotated with frame-level
activity labels. In this work, we tackle the previously unexplored problem of
weakly-supervised gaze estimation from videos of human interactions. We
leverage the insight that strong gaze-related geometric …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Kothari_R/0/1/0/all/0/1"&gt;Rakshit Kothari&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mello_S/0/1/0/all/0/1"&gt;Shalini De Mello&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Iqbal_U/0/1/0/all/0/1"&gt;Umar Iqbal&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Byeon_W/0/1/0/all/0/1"&gt;Wonmin Byeon&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1"&gt;Seonwook Park&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kautz_J/0/1/0/all/0/1"&gt;Jan Kautz&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DeepDarts: Modeling Keypoints as Objects for Automatic Scorekeeping in Darts using a Single Camera. (arXiv:2105.09880v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09880</id>
        <link href="http://arxiv.org/abs/2105.09880"/>
        <updated>2021-05-22T06:24:27.082Z</updated>
        <summary type="html"><![CDATA[Existing multi-camera solutions for automatic scorekeeping in steel-tip darts
are very expensive and thus inaccessible to most players. Motivated to develop
a more accessible low-cost solution, we present a new approach to keypoint
detection and apply it to predict dart scores from a single image taken from
any camera angle. This problem involves detecting multiple keypoints that may
be of the same class and positioned in close proximity to one another. The
widely adopted framework for regressing keypoints …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+McNally_W/0/1/0/all/0/1"&gt;William McNally&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Walters_P/0/1/0/all/0/1"&gt;Pascale Walters&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Vats_K/0/1/0/all/0/1"&gt;Kanav Vats&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1"&gt;Alexander Wong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+McPhee_J/0/1/0/all/0/1"&gt;John McPhee&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Egocentric Activity Recognition and Localization on a 3D Map. (arXiv:2105.09544v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09544</id>
        <link href="http://arxiv.org/abs/2105.09544"/>
        <updated>2021-05-22T06:24:27.075Z</updated>
        <summary type="html"><![CDATA[Given a video captured from a first person perspective and recorded in a
familiar environment, can we recognize what the person is doing and identify
where the action occurs in the 3D space? We address this challenging problem of
jointly recognizing and localizing actions of a mobile user on a known 3D map
from egocentric videos. To this end, we propose a novel deep probabilistic
model. Our model takes the inputs of a Hierarchical Volumetric Representation
(HVR) of the environment and an egocentric video, i…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1"&gt;Miao Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1"&gt;Lingni Ma&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Somasundaram_K/0/1/0/all/0/1"&gt;Kiran Somasundaram&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1"&gt;Yin Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Grauman_K/0/1/0/all/0/1"&gt;Kristen Grauman&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Rehg_J/0/1/0/all/0/1"&gt;James M. Rehg&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1"&gt;Chao Li&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An Attractor-Guided Neural Networks for Skeleton-Based Human Motion Prediction. (arXiv:2105.09711v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09711</id>
        <link href="http://arxiv.org/abs/2105.09711"/>
        <updated>2021-05-22T06:24:27.057Z</updated>
        <summary type="html"><![CDATA[Joint relation modeling is a curial component in human motion prediction.
Most existing methods tend to design skeletal-based graphs to build the
relations among joints, where local interactions between joint pairs are well
learned. However, the global coordination of all joints, which reflects human
motion's balance property, is usually weakened because it is learned from part
to whole progressively and asynchronously. Thus, the final predicted motions
are sometimes unnatural. To tackle this issue, we lear…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ding_P/0/1/0/all/0/1"&gt;Pengxiang Ding&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1"&gt;Jianqin Yin&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AGSFCOS: Based on attention mechanism and Scale-Equalizing pyramid network of object detection. (arXiv:2105.09596v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09596</id>
        <link href="http://arxiv.org/abs/2105.09596"/>
        <updated>2021-05-22T06:24:27.049Z</updated>
        <summary type="html"><![CDATA[Recently, the anchor-free object detection model has shown great potential
for accuracy and speed to exceed anchor-based object detection. Therefore, two
issues are mainly studied in this article: (1) How to let the backbone network
in the anchor-free object detection model learn feature extraction? (2) How to
make better use of the feature pyramid network? In order to solve the above
problems, Experiments show that our model has a certain improvement in accuracy
compared with the current popular detection …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1"&gt;Li Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xiang_W/0/1/0/all/0/1"&gt;Wei Xiang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xue_R/0/1/0/all/0/1"&gt;Ruhui Xue&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zou_K/0/1/0/all/0/1"&gt;Kaida Zou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1"&gt;Laili Zhu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An Empirical Study of Vehicle Re-Identification on the AI City Challenge. (arXiv:2105.09701v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09701</id>
        <link href="http://arxiv.org/abs/2105.09701"/>
        <updated>2021-05-22T06:24:27.042Z</updated>
        <summary type="html"><![CDATA[This paper introduces our solution for the Track2 in AI City Challenge 2021
(AICITY21). The Track2 is a vehicle re-identification (ReID) task with both the
real-world data and synthetic data. We mainly focus on four points, i.e.
training data, unsupervised domain-adaptive (UDA) training, post-processing,
model ensembling in this challenge. (1) Both cropping training data and using
synthetic data can help the model learn more discriminative features. (2) Since
there is a new scenario in the test set that dos…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1"&gt;Hao Luo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1"&gt;Weihua Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1"&gt;Xianzhe Xu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1"&gt;Jianyang Gu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1"&gt;Yuqi Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1"&gt;Chong Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1"&gt;Yiqi Jiang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1"&gt;Shuting He&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1"&gt;Fan Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1"&gt;Hao Li&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DPN-SENet:A self-attention mechanism neural network for detection and diagnosis of COVID-19 from chest x-ray images. (arXiv:2105.09683v1 [eess.IV])]]></title>
        <id>http://arxiv.org/abs/2105.09683</id>
        <link href="http://arxiv.org/abs/2105.09683"/>
        <updated>2021-05-22T06:24:27.028Z</updated>
        <summary type="html"><![CDATA[Background and Objective: The new type of coronavirus is also called
COVID-19. It began to spread at the end of 2019 and has now spread across the
world. Until October 2020, It has infected around 37 million people and claimed
about 1 million lives. We propose a deep learning model that can help
radiologists and clinicians use chest X-rays to diagnose COVID-19 cases and
show the diagnostic features of pneumonia. Methods: The approach in this study
is: 1) we propose a data enhancement method to increase the …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Cheng_B/0/1/0/all/0/1"&gt;Bo Cheng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Xue_R/0/1/0/all/0/1"&gt;Ruhui Xue&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Yang_H/0/1/0/all/0/1"&gt;Hang Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Zhu_L/0/1/0/all/0/1"&gt;Laili Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Xiang_W/0/1/0/all/0/1"&gt;Wei Xiang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[FVC: A New Framework towards Deep Video Compression in Feature Space. (arXiv:2105.09600v1 [eess.IV])]]></title>
        <id>http://arxiv.org/abs/2105.09600</id>
        <link href="http://arxiv.org/abs/2105.09600"/>
        <updated>2021-05-22T06:24:27.021Z</updated>
        <summary type="html"><![CDATA[Learning based video compression attracts increasing attention in the past
few years. The previous hybrid coding approaches rely on pixel space operations
to reduce spatial and temporal redundancy, which may suffer from inaccurate
motion estimation or less effective motion compensation. In this work, we
propose a feature-space video coding network (FVC) by performing all major
operations (i.e., motion estimation, motion compression, motion compensation
and residual compression) in the feature space. Specifi…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Hu_Z/0/1/0/all/0/1"&gt;Zhihao Hu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Lu_G/0/1/0/all/0/1"&gt;Guo Lu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Xu_D/0/1/0/all/0/1"&gt;Dong Xu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Crowd Counting by Self-supervised Transfer Colorization Learning and Global Prior Classification. (arXiv:2105.09684v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09684</id>
        <link href="http://arxiv.org/abs/2105.09684"/>
        <updated>2021-05-22T06:24:27.004Z</updated>
        <summary type="html"><![CDATA[Labeled crowd scene images are expensive and scarce. To significantly reduce
the requirement of the labeled images, we propose ColorCount, a novel CNN-based
approach by combining self-supervised transfer colorization learning and global
prior classification to leverage the abundantly available unlabeled data. The
self-supervised colorization branch learns the semantics and surface texture of
the image by using its color components as pseudo labels. The classification
branch extracts global group priors by l…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Bai_H/0/1/0/all/0/1"&gt;Haoyue Bai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wen_S/0/1/0/all/0/1"&gt;Song Wen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chan_S/0/1/0/all/0/1"&gt;S.-H. Gary Chan&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Intra-Model Collaborative Learning of Neural Networks. (arXiv:2105.09590v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09590</id>
        <link href="http://arxiv.org/abs/2105.09590"/>
        <updated>2021-05-22T06:24:26.985Z</updated>
        <summary type="html"><![CDATA[Recently, collaborative learning proposed by Song and Chai has achieved
remarkable improvements in image classification tasks by simultaneously
training multiple classifier heads. However, huge memory footprints required by
such multi-head structures may hinder the training of large-capacity baseline
models. The natural question is how to achieve collaborative learning within a
single network without duplicating any modules. In this paper, we propose four
ways of collaborative learning among different parts…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Fang_S/0/1/0/all/0/1"&gt;Shijie Fang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1"&gt;Tong Lin&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Medical Image Segmentation using Squeeze-and-Expansion Transformers. (arXiv:2105.09511v1 [eess.IV])]]></title>
        <id>http://arxiv.org/abs/2105.09511</id>
        <link href="http://arxiv.org/abs/2105.09511"/>
        <updated>2021-05-22T06:24:26.974Z</updated>
        <summary type="html"><![CDATA[Medical image segmentation is important for computer-aided diagnosis. Good
segmentation demands the model to see the big picture and fine details
simultaneously, i.e., to learn image features that incorporate large context
while keep high spatial resolutions. To approach this goal, the most widely
used methods -- U-Net and variants, extract and fuse multi-scale features.
However, the fused features still have small "effective receptive fields" with
a focus on local image cues, limiting their performance. In…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Li_S/0/1/0/all/0/1"&gt;Shaohua Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Sui_X/0/1/0/all/0/1"&gt;Xiuchao Sui&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Luo_X/0/1/0/all/0/1"&gt;Xiangde Luo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Xu_X/0/1/0/all/0/1"&gt;Xinxing Xu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1"&gt;Yong Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Goh_R/0/1/0/all/0/1"&gt;Rick Siow Mong Goh&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Simple Transparent Adversarial Examples. (arXiv:2105.09685v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09685</id>
        <link href="http://arxiv.org/abs/2105.09685"/>
        <updated>2021-05-22T06:24:26.968Z</updated>
        <summary type="html"><![CDATA[There has been a rise in the use of Machine Learning as a Service (MLaaS)
Vision APIs as they offer multiple services including pre-built models and
algorithms, which otherwise take a huge amount of resources if built from
scratch. As these APIs get deployed for high-stakes applications, it's very
important that they are robust to different manipulations. Recent works have
only focused on typical adversarial attacks when evaluating the robustness of
vision APIs. We propose two new aspects of adversarial ima…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Borkar_J/0/1/0/all/0/1"&gt;Jaydeep Borkar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1"&gt;Pin-Yu Chen&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[M4Depth: A motion-based approach for monocular depth estimation on video sequences. (arXiv:2105.09847v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09847</id>
        <link href="http://arxiv.org/abs/2105.09847"/>
        <updated>2021-05-22T06:24:26.961Z</updated>
        <summary type="html"><![CDATA[Getting the distance to objects is crucial for autonomous vehicles. In
instances where depth sensors cannot be used, this distance has to be estimated
from RGB cameras. As opposed to cars, the task of estimating depth from
on-board mounted cameras is made complex on drones because of the lack of
constrains on motion during flights. %In the case of drones, this task is even
more complex than for car-mounted cameras since the camera motion is
unconstrained. In this paper, we present a method to estimate the d…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Fonder_M/0/1/0/all/0/1"&gt;Micha&amp;#xeb;l Fonder&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ernst_D/0/1/0/all/0/1"&gt;Damien Ernst&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Droogenbroeck_M/0/1/0/all/0/1"&gt;Marc Van Droogenbroeck&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Anabranch Network for Camouflaged Object Segmentation. (arXiv:2105.09451v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09451</id>
        <link href="http://arxiv.org/abs/2105.09451"/>
        <updated>2021-05-22T06:24:26.946Z</updated>
        <summary type="html"><![CDATA[Camouflaged objects attempt to conceal their texture into the background and
discriminating them from the background is hard even for human beings. The main
objective of this paper is to explore the camouflaged object segmentation
problem, namely, segmenting the camouflaged object(s) for a given image. This
problem has not been well studied in spite of a wide range of potential
applications including the preservation of wild animals and the discovery of
new species, surveillance systems, search-and-rescue m…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1"&gt;Trung-Nghia Le&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1"&gt;Tam V. Nguyen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Nie_Z/0/1/0/all/0/1"&gt;Zhongliang Nie&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tran_M/0/1/0/all/0/1"&gt;Minh-Triet Tran&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sugimoto_A/0/1/0/all/0/1"&gt;Akihiro Sugimoto&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Spatio-temporal Attention-based Model for Infant Movement Assessment from Videos. (arXiv:2105.09783v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09783</id>
        <link href="http://arxiv.org/abs/2105.09783"/>
        <updated>2021-05-22T06:24:26.939Z</updated>
        <summary type="html"><![CDATA[The absence or abnormality of fidgety movements of joints or limbs is
strongly indicative of cerebral palsy in infants. Developing computer-based
methods for assessing infant movements in videos is pivotal for improved
cerebral palsy screening. Most existing methods use appearance-based features
and are thus sensitive to strong but irrelevant signals caused by background
clutter or a moving camera. Moreover, these features are computed over the
whole frame, thus they measure gross whole body movements rathe…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Nguyen_Thai_B/0/1/0/all/0/1"&gt;Binh Nguyen-Thai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Le_V/0/1/0/all/0/1"&gt;Vuong Le&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Morgan_C/0/1/0/all/0/1"&gt;Catherine Morgan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Badawi_N/0/1/0/all/0/1"&gt;Nadia Badawi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1"&gt;Truyen Tran&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Venkatesh_S/0/1/0/all/0/1"&gt;Svetha Venkatesh&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Content-Augmented Feature Pyramid Network with Light Linear Transformers. (arXiv:2105.09464v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09464</id>
        <link href="http://arxiv.org/abs/2105.09464"/>
        <updated>2021-05-22T06:24:26.933Z</updated>
        <summary type="html"><![CDATA[Recently, plenty of work has tried to introduce transformers into computer
vision tasks, with good results. Unlike classic convolution networks, which
extract features within a local receptive field, transformers can adaptively
aggregate similar features from a global view using self-attention mechanism.
For object detection, Feature Pyramid Network (FPN) proposes feature
interaction across layers and proves its extremely importance. However, its
interaction is still in a local manner, which leaves a lot of…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1"&gt;Yongxiang Gu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Qin_X/0/1/0/all/0/1"&gt;Xiaolin Qin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1"&gt;Yuncong Peng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1"&gt;Lu Li&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Semantic segmentation of multispectral photoacoustic images using deep learning. (arXiv:2105.09624v1 [eess.IV])]]></title>
        <id>http://arxiv.org/abs/2105.09624</id>
        <link href="http://arxiv.org/abs/2105.09624"/>
        <updated>2021-05-22T06:24:26.926Z</updated>
        <summary type="html"><![CDATA[Photoacoustic imaging has the potential to revolutionise healthcare due to
the valuable information on tissue physiology that is contained in
multispectral photoacoustic measurements. Clinical translation of the
technology requires conversion of the high-dimensional acquired data into
clinically relevant and interpretable information. In this work, we present a
deep learning-based approach to semantic segmentation of multispectral
photoacoustic images to facilitate the interpretability of recorded images.
M…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Grohl_J/0/1/0/all/0/1"&gt;Janek Gr&amp;#xf6;hl&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Schellenberg_M/0/1/0/all/0/1"&gt;Melanie Schellenberg&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Dreher_K/0/1/0/all/0/1"&gt;Kris Dreher&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Holzwarth_N/0/1/0/all/0/1"&gt;Niklas Holzwarth&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Tizabi_M/0/1/0/all/0/1"&gt;Minu D. Tizabi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Seitel_A/0/1/0/all/0/1"&gt;Alexander Seitel&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Maier_Hein_L/0/1/0/all/0/1"&gt;Lena Maier-Hein&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Classification of Urban Morphology with Deep Learning: Application on Urban Vitality. (arXiv:2105.09908v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09908</id>
        <link href="http://arxiv.org/abs/2105.09908"/>
        <updated>2021-05-22T06:24:26.919Z</updated>
        <summary type="html"><![CDATA[There is a prevailing trend to study urban morphology quantitatively thanks
to the growing accessibility to various forms of spatial big data, increasing
computing power, and use cases benefiting from such information. The methods
developed up to now measure urban morphology with numerical indices describing
density, proportion, and mixture, but they do not directly represent
morphological features from human's visual and intuitive perspective. We take
the first step to bridge the gap by proposing a deep le…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1"&gt;Wangyang Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1"&gt;Abraham Noah Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Biljecki_F/0/1/0/all/0/1"&gt;Filip Biljecki&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[More Than Just Attention: Learning Cross-Modal Attentions with Contrastive Constraints. (arXiv:2105.09597v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09597</id>
        <link href="http://arxiv.org/abs/2105.09597"/>
        <updated>2021-05-22T06:24:26.901Z</updated>
        <summary type="html"><![CDATA[Attention mechanisms have been widely applied to cross-modal tasks such as
image captioning and information retrieval, and have achieved remarkable
improvements due to its capability to learn fine-grained relevance across
different modalities. However, existing attention models could be sub-optimal
and lack preciseness because there is no direct supervision involved during
training. In this work, we propose Contrastive Content Re-sourcing (CCR) and
Contrastive Content Swapping (CCS) constraints to address s…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1"&gt;Yuxiao Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1"&gt;Jianbo Yuan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1"&gt;Long Zhao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1"&gt;Rui Luo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Davis_L/0/1/0/all/0/1"&gt;Larry Davis&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Metaxas_D/0/1/0/all/0/1"&gt;Dimitris N. Metaxas&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Superpixel-based Domain-Knowledge Infusion in Computer Vision. (arXiv:2105.09448v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09448</id>
        <link href="http://arxiv.org/abs/2105.09448"/>
        <updated>2021-05-22T06:24:26.893Z</updated>
        <summary type="html"><![CDATA[Superpixels are higher-order perceptual groups of pixels in an image, often
carrying much more information than raw pixels. There is an inherent relational
structure to the relationship among different superpixels of an image. This
relational information can convey some form of domain information about the
image, e.g. relationship between superpixels representing two eyes in a cat
image. Our interest in this paper is to construct computer vision models,
specifically those based on Deep Neural Networks (DNNs…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chhablani_G/0/1/0/all/0/1"&gt;Gunjan Chhablani&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1"&gt;Abheesht Sharma&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Pandey_H/0/1/0/all/0/1"&gt;Harshit Pandey&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Dash_T/0/1/0/all/0/1"&gt;Tirtharaj Dash&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Classifying concepts via visual properties. (arXiv:2105.09422v1 [cs.AI])]]></title>
        <id>http://arxiv.org/abs/2105.09422</id>
        <link href="http://arxiv.org/abs/2105.09422"/>
        <updated>2021-05-22T06:24:26.871Z</updated>
        <summary type="html"><![CDATA[We assume that substances in the world are represented by two types of
concepts, namely substance concepts and classification concepts, the former
instrumental to (visual) perception, the latter to (language based)
classification. Based on this distinction, we introduce a general methodology
for building lexico-semantic hierarchies of substance concepts, where nodes are
annotated with the media, e.g.,videos or photos, from which substance concepts
are extracted, and are associated with the corresponding cla…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Giunchiglia_F/0/1/0/all/0/1"&gt;Fausto Giunchiglia&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bagchi_M/0/1/0/all/0/1"&gt;Mayukh Bagchi&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[End-to-End Unsupervised Document Image Blind Denoising. (arXiv:2105.09437v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09437</id>
        <link href="http://arxiv.org/abs/2105.09437"/>
        <updated>2021-05-22T06:24:26.865Z</updated>
        <summary type="html"><![CDATA[Removing noise from scanned pages is a vital step before their submission to
optical character recognition (OCR) system. Most available image denoising
methods are supervised where the pairs of noisy/clean pages are required.
However, this assumption is rarely met in real settings. Besides, there is no
single model that can remove various noise types from documents. Here, we
propose a unified end-to-end unsupervised deep learning model, for the first
time, that can effectively remove multiple types of noise…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Gangeh_M/0/1/0/all/0/1"&gt;Mehrdad J Gangeh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Plata_M/0/1/0/all/0/1"&gt;Marcin Plata&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Motahari_H/0/1/0/all/0/1"&gt;Hamid Motahari&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Duffy_N/0/1/0/all/0/1"&gt;Nigel P Duffy&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Content-adaptive Representation Learning for Fast Image Super-resolution. (arXiv:2105.09645v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09645</id>
        <link href="http://arxiv.org/abs/2105.09645"/>
        <updated>2021-05-22T06:24:26.822Z</updated>
        <summary type="html"><![CDATA[Deep convolutional networks have attracted great attention in image
restoration and enhancement. Generally, restoration quality has been improved
by building more and more convolutional block. However, these methods mostly
learn a specific model to handle all images and ignore difficulty diversity. In
other words, an area in the image with high frequency tend to lose more
information during compressing while an area with low frequency tends to lose
less. In this article, we adrress the efficiency issue in i…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1"&gt;Yukai Shi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1"&gt;Jinghui Qin&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A low-rank representation for unsupervised registration of medical images. (arXiv:2105.09548v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09548</id>
        <link href="http://arxiv.org/abs/2105.09548"/>
        <updated>2021-05-22T06:24:26.780Z</updated>
        <summary type="html"><![CDATA[Registration networks have shown great application potentials in medical
image analysis. However, supervised training methods have a great demand for
large and high-quality labeled datasets, which is time-consuming and sometimes
impractical due to data sharing issues. Unsupervised image registration
algorithms commonly employ intensity-based similarity measures as loss
functions without any manual annotations. These methods estimate the
parameterized transformations between pairs of moving and fixed images …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Jia_D/0/1/0/all/0/1"&gt;Dengqiang Jia&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1"&gt;Shangqi Gao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1"&gt;Qunlong Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1"&gt;Xinzhe Luo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhuang_X/0/1/0/all/0/1"&gt;Xiahai Zhuang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Connected Component Labelling algorithm for multi-pixel per clock cycle video strea. (arXiv:2105.09658v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09658</id>
        <link href="http://arxiv.org/abs/2105.09658"/>
        <updated>2021-05-22T06:24:26.739Z</updated>
        <summary type="html"><![CDATA[This work describes the hardware implementation of a connected component
labelling (CCL) module in reprogammable logic. The main novelty of the design
is the "full", i.e. without any simplifications, support of a 4 pixel per clock
format (4 ppc) and real-time processing of a 4K/UltraHD video stream (3840 x
2160 pixels) at 60 frames per second. To achieve this, a special labelling
method was designed and a functionality that stops the input data stream in
order to process pixel groups which require writing m…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Kowalczyk_M/0/1/0/all/0/1"&gt;Marcin Kowalczyk&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kryjak_T/0/1/0/all/0/1"&gt;Tomasz Kryjak&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DeepCAD: A Deep Generative Network for Computer-Aided Design Models. (arXiv:2105.09492v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09492</id>
        <link href="http://arxiv.org/abs/2105.09492"/>
        <updated>2021-05-22T06:24:26.731Z</updated>
        <summary type="html"><![CDATA[Deep generative models of 3D shapes have received a great deal of research
interest. Yet, almost all of them generate discrete shape representations, such
as voxels, point clouds, and polygon meshes. We present the first 3D generative
model for a drastically different shape representation -- describing a shape as
a sequence of computer-aided design (CAD) operations. Unlike meshes and point
clouds, CAD models encode the user creation process of 3D shapes, widely used
in numerous industrial and engineering de…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1"&gt;Rundi Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1"&gt;Chang Xiao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1"&gt;Changxi Zheng&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[VTNet: Visual Transformer Network for Object Goal Navigation. (arXiv:2105.09447v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09447</id>
        <link href="http://arxiv.org/abs/2105.09447"/>
        <updated>2021-05-22T06:24:26.616Z</updated>
        <summary type="html"><![CDATA[Object goal navigation aims to steer an agent towards a target object based
on observations of the agent. It is of pivotal importance to design effective
visual representations of the observed scene in determining navigation actions.
In this paper, we introduce a Visual Transformer Network (VTNet) for learning
informative visual representation in navigation. VTNet is a highly effective
structure that embodies two key properties for visual representations: First,
the relationships among all the object instan…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Du_H/0/1/0/all/0/1"&gt;Heming Du&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1"&gt;Xin Yu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1"&gt;Liang Zheng&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Lexicon Enhanced Chinese Sequence Labeling Using BERT Adapter. (arXiv:2105.07148v2 [cs.CL] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.07148</id>
        <link href="http://arxiv.org/abs/2105.07148"/>
        <updated>2021-05-22T06:24:26.556Z</updated>
        <summary type="html"><![CDATA[Lexicon information and pre-trained models, such as BERT, have been combined
to explore Chinese sequence labelling tasks due to their respective strengths.
However, existing methods solely fuse lexicon features via a shallow and random
initialized sequence layer and do not integrate them into the bottom layers of
BERT. In this paper, we propose Lexicon Enhanced BERT (LEBERT) for Chinese
sequence labelling, which integrates external lexicon knowledge into BERT
layers directly by a Lexicon Adapter layer. Comp…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1"&gt;Wei Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Fu_X/0/1/0/all/0/1"&gt;Xiyan Fu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1"&gt;Yue Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xiao_W/0/1/0/all/0/1"&gt;Wenming Xiao&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generative Adversarial Neural Architecture Search. (arXiv:2105.09356v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09356</id>
        <link href="http://arxiv.org/abs/2105.09356"/>
        <updated>2021-05-22T06:24:26.543Z</updated>
        <summary type="html"><![CDATA[Despite the empirical success of neural architecture search (NAS) in deep
learning applications, the optimality, reproducibility and cost of NAS schemes
remain hard to assess. In this paper, we propose Generative Adversarial NAS
(GA-NAS) with theoretically provable convergence guarantees, promoting
stability and reproducibility in neural architecture search. Inspired by
importance sampling, GA-NAS iteratively fits a generator to previously
discovered top architectures, thus increasingly focusing on importan…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Rezaei_S/0/1/0/all/0/1"&gt;Seyed Saeed Changiz Rezaei&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Han_F/0/1/0/all/0/1"&gt;Fred X. Han&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Niu_D/0/1/0/all/0/1"&gt;Di Niu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Salameh_M/0/1/0/all/0/1"&gt;Mohammad Salameh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mills_K/0/1/0/all/0/1"&gt;Keith Mills&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lian_S/0/1/0/all/0/1"&gt;Shuo Lian&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1"&gt;Wei Lu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jui_S/0/1/0/all/0/1"&gt;Shangling Jui&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Exploring The Limits Of Data Augmentation For Retinal Vessel Segmentation. (arXiv:2105.09365v1 [eess.IV])]]></title>
        <id>http://arxiv.org/abs/2105.09365</id>
        <link href="http://arxiv.org/abs/2105.09365"/>
        <updated>2021-05-22T06:24:26.505Z</updated>
        <summary type="html"><![CDATA[Retinal Vessel Segmentation is important for diagnosis of various diseases.
The research on retinal vessel segmentation focuses mainly on improvement of
the segmentation model which is usually based on U-Net architecture. In our
study we use the U-Net architecture and we rely on heavy data augmentation in
order to achieve better performance. The success of the data augmentation
relies on successfully addressing the problem of input images. By analyzing
input images and performing the augmentation accordingl…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Uysal_E/0/1/0/all/0/1"&gt;Enes Sadi Uysal&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Bilici_M/0/1/0/all/0/1"&gt;M.&amp;#x15e;afak Bilici&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Zaza_B/0/1/0/all/0/1"&gt;B. Selin Zaza&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Ozgenc_M/0/1/0/all/0/1"&gt;M. Yi&amp;#x11f;it &amp;#xd6;zgen&amp;#xe7;&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Boyar_O/0/1/0/all/0/1"&gt;Onur Boyar&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Birds of a Feather: Capturing Avian Shape Models from Images. (arXiv:2105.09396v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09396</id>
        <link href="http://arxiv.org/abs/2105.09396"/>
        <updated>2021-05-22T06:24:26.485Z</updated>
        <summary type="html"><![CDATA[Animals are diverse in shape, but building a deformable shape model for a new
species is not always possible due to the lack of 3D data. We present a method
to capture new species using an articulated template and images of that
species. In this work, we focus mainly on birds. Although birds represent
almost twice the number of species as mammals, no accurate shape model is
available. To capture a novel species, we first fit the articulated template to
each training sample. By disentangling pose and shape, …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"&gt;Yufu Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kolotouros_N/0/1/0/all/0/1"&gt;Nikos Kolotouros&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Daniilidis_K/0/1/0/all/0/1"&gt;Kostas Daniilidis&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Badger_M/0/1/0/all/0/1"&gt;Marc Badger&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[FastCorrect: Fast Error Correction with Edit Alignment for Automatic Speech Recognition. (arXiv:2105.03842v2 [cs.CL] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.03842</id>
        <link href="http://arxiv.org/abs/2105.03842"/>
        <updated>2021-05-22T06:24:26.478Z</updated>
        <summary type="html"><![CDATA[Error correction techniques have been used to refine the output sentences
from automatic speech recognition (ASR) models and achieve a lower word error
rate (WER) than original ASR outputs. Previous works usually use a
sequence-to-sequence model to correct an ASR output sentence autoregressively,
which causes large latency and cannot be deployed in online ASR services. A
straightforward solution to reduce latency, inspired by non-autoregressive
(NAR) neural machine translation, is to use an NAR sequence gen…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Leng_Y/0/1/0/all/0/1"&gt;Yichong Leng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1"&gt;Xu Tan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1"&gt;Linchen Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1"&gt;Jin Xu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1"&gt;Renqian Luo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1"&gt;Linquan Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1"&gt;Tao Qin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1"&gt;Xiang-Yang Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lin_E/0/1/0/all/0/1"&gt;Ed Lin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1"&gt;Tie-Yan Liu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Encoding Explanatory Knowledge for Zero-shot Science Question Answering. (arXiv:2105.05737v2 [cs.CL] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.05737</id>
        <link href="http://arxiv.org/abs/2105.05737"/>
        <updated>2021-05-22T06:24:26.459Z</updated>
        <summary type="html"><![CDATA[This paper describes N-XKT (Neural encoding based on eXplanatory Knowledge
Transfer), a novel method for the automatic transfer of explanatory knowledge
through neural encoding mechanisms. We demonstrate that N-XKT is able to
improve accuracy and generalization on science Question Answering (QA).
Specifically, by leveraging facts from background explanatory knowledge
corpora, the N-XKT model shows a clear improvement on zero-shot QA.
Furthermore, we show that N-XKT can be fine-tuned on a target QA dataset,
…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1"&gt;Zili Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Valentino_M/0/1/0/all/0/1"&gt;Marco Valentino&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Landers_D/0/1/0/all/0/1"&gt;Donal Landers&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Freitas_A/0/1/0/all/0/1"&gt;Andre Freitas&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[VOILA: Visual-Observation-Only Imitation Learning for Autonomous Navigation. (arXiv:2105.09371v1 [cs.RO])]]></title>
        <id>http://arxiv.org/abs/2105.09371</id>
        <link href="http://arxiv.org/abs/2105.09371"/>
        <updated>2021-05-22T06:24:26.453Z</updated>
        <summary type="html"><![CDATA[While imitation learning for vision based autonomous mobile robot navigation
has recently received a great deal of attention in the research community,
existing approaches typically require state action demonstrations that were
gathered using the deployment platform. However, what if one cannot easily
outfit their platform to record these demonstration signals or worse yet the
demonstrator does not have access to the platform at all? Is imitation learning
for vision based autonomous navigation even possible…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Karnan_H/0/1/0/all/0/1"&gt;Haresh Karnan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Warnell_G/0/1/0/all/0/1"&gt;Garrett Warnell&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1"&gt;Xuesu Xiao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Stone_P/0/1/0/all/0/1"&gt;Peter Stone&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Counterfactual Interventions Reveal the Causal Effect of Relative Clause Representations on Agreement Prediction. (arXiv:2105.06965v2 [cs.CL] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.06965</id>
        <link href="http://arxiv.org/abs/2105.06965"/>
        <updated>2021-05-22T06:24:26.447Z</updated>
        <summary type="html"><![CDATA[When language models process syntactically complex sentences, do they use
abstract syntactic information present in these sentences in a manner that is
consistent with the grammar of English, or do they rely solely on a set of
heuristics? We propose a method to tackle this question, AlterRep. For any
linguistic feature in the sentence, AlterRep allows us to generate
counterfactual representations by altering how this feature is encoded, while
leaving all other aspects of the original representation intact. …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ravfogel_S/0/1/0/all/0/1"&gt;Shauli Ravfogel&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Prasad_G/0/1/0/all/0/1"&gt;Grusha Prasad&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Linzen_T/0/1/0/all/0/1"&gt;Tal Linzen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1"&gt;Yoav Goldberg&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Infinite use of finite means: Zero-Shot Generalization using Compositional Emergent Protocols. (arXiv:2012.05011v3 [cs.CL] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2012.05011</id>
        <link href="http://arxiv.org/abs/2012.05011"/>
        <updated>2021-05-22T06:24:26.438Z</updated>
        <summary type="html"><![CDATA[Human language has been described as a system that makes \textit{use of
finite means to express an unlimited array of thoughts}. Of particular interest
is the aspect of compositionality, whereby, the meaning of a compound language
expression can be deduced from the meaning of its constituent parts. If
artificial agents can develop compositional communication protocols akin to
human language, they can be made to seamlessly generalize to unseen
combinations. However, the real question is, how do we induce com…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Hazra_R/0/1/0/all/0/1"&gt;Rishi Hazra&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Dixit_S/0/1/0/all/0/1"&gt;Sonu Dixit&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sen_S/0/1/0/all/0/1"&gt;Sayambhu Sen&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Endless Loops: Detecting and Animating Periodic Patterns in Still Images. (arXiv:2105.09374v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09374</id>
        <link href="http://arxiv.org/abs/2105.09374"/>
        <updated>2021-05-22T06:24:26.432Z</updated>
        <summary type="html"><![CDATA[We present an algorithm for producing a seamless animated loop from a single
image. The algorithm detects periodic structures, such as the windows of a
building or the steps of a staircase, and generates a non-trivial displacement
vector field that maps each segment of the structure onto a neighboring segment
along a user- or auto-selected main direction of motion. This displacement
field is used, together with suitable temporal and spatial smoothing, to warp
the image and produce the frames of a continuous…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Halperin_T/0/1/0/all/0/1"&gt;Tavi Halperin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hakim_H/0/1/0/all/0/1"&gt;Hanit Hakim&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Vantzos_O/0/1/0/all/0/1"&gt;Orestis Vantzos&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hochman_G/0/1/0/all/0/1"&gt;Gershon Hochman&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Benaim_N/0/1/0/all/0/1"&gt;Netai Benaim&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sassy_L/0/1/0/all/0/1"&gt;Lior Sassy&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kupchik_M/0/1/0/all/0/1"&gt;Michael Kupchik&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bibi_O/0/1/0/all/0/1"&gt;Ofir Bibi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Fried_O/0/1/0/all/0/1"&gt;Ohad Fried&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Robust partial Fourier reconstruction for diffusion-weighted imaging using a recurrent convolutional neural network. (arXiv:2105.09378v1 [eess.IV])]]></title>
        <id>http://arxiv.org/abs/2105.09378</id>
        <link href="http://arxiv.org/abs/2105.09378"/>
        <updated>2021-05-22T06:24:26.414Z</updated>
        <summary type="html"><![CDATA[Purpose: To develop an algorithm for robust partial Fourier (PF)
reconstruction applicable to diffusion-weighted (DW) images with non-smooth
phase variations.

Methods: Based on an unrolled proximal splitting algorithm, a neural network
architecture is derived which alternates between data consistency operations
and regularization implemented by recurrent convolutions. In order to exploit
correlations, multiple repetitions of the same slice are jointly reconstructed
under consideration of permutation-equiva…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Gadjimuradov_F/0/1/0/all/0/1"&gt;Fasil Gadjimuradov&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Benkert_T/0/1/0/all/0/1"&gt;Thomas Benkert&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Nickel_M/0/1/0/all/0/1"&gt;Marcel Dominik Nickel&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Maier_A/0/1/0/all/0/1"&gt;Andreas Maier&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multilingual Offensive Language Identification for Low-resource Languages. (arXiv:2105.05996v3 [cs.CL] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.05996</id>
        <link href="http://arxiv.org/abs/2105.05996"/>
        <updated>2021-05-22T06:24:26.406Z</updated>
        <summary type="html"><![CDATA[Offensive content is pervasive in social media and a reason for concern to
companies and government organizations. Several studies have been recently
published investigating methods to detect the various forms of such content
(e.g. hate speech, cyberbullying, and cyberaggression). The clear majority of
these studies deal with English partially because most annotated datasets
available contain English data. In this paper, we take advantage of available
English datasets by applying cross-lingual contextual wo…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ranasinghe_T/0/1/0/all/0/1"&gt;Tharindu Ranasinghe&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zampieri_M/0/1/0/all/0/1"&gt;Marcos Zampieri&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unsupervised learning of text line segmentationby differentiating coarse patterns. (arXiv:2105.09405v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09405</id>
        <link href="http://arxiv.org/abs/2105.09405"/>
        <updated>2021-05-22T06:24:26.399Z</updated>
        <summary type="html"><![CDATA[Despite recent advances in the field of supervised deep learning for text
line segmentation, unsupervised deep learning solutions are beginning to gain
popularity. In this paper, we present an unsupervised deep learning method that
embeds document image patches to a compact Euclidean space where distances
correspond to a coarse text line pattern similarity. Once this space has been
produced, text line segmentation can be easily implemented using standard
techniques with the embedded feature vectors. To trai…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Barakat_B/0/1/0/all/0/1"&gt;Berat Kurar Barakat&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Droby_A/0/1/0/all/0/1"&gt;Ahmad Droby&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Saabni_R/0/1/0/all/0/1"&gt;Raid Saabni&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+El_Sana_J/0/1/0/all/0/1"&gt;Jihad El-Sana&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Heterogeneous Contrastive Learning. (arXiv:2105.09401v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09401</id>
        <link href="http://arxiv.org/abs/2105.09401"/>
        <updated>2021-05-22T06:24:26.392Z</updated>
        <summary type="html"><![CDATA[With the advent of big data across multiple high-impact applications, we are
often facing the challenge of complex heterogeneity. The newly collected data
usually consist of multiple modalities and characterized with multiple labels,
thus exhibiting the co-existence of multiple types of heterogeneity. Although
state-of-the-art techniques are good at modeling the complex heterogeneity with
sufficient label information, such label information can be quite expensive to
obtain in real applications, leading to s…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1"&gt;Lecheng Zheng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1"&gt;Yada Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1"&gt;Jingrui He&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xiong_J/0/1/0/all/0/1"&gt;Jinjun Xiong&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering. (arXiv:2012.00955v2 [cs.CL] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2012.00955</id>
        <link href="http://arxiv.org/abs/2012.00955"/>
        <updated>2021-05-22T06:24:26.386Z</updated>
        <summary type="html"><![CDATA[Recent works have shown that language models (LM) capture different types of
knowledge regarding facts or common sense. However, because no model is
perfect, they still fail to provide appropriate answers in many cases. In this
paper, we ask the question "how can we know when language models know, with
confidence, the answer to a particular query?" We examine this question from
the point of view of calibration, the property of a probabilistic model's
predicted probabilities actually being well correlated wi…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1"&gt;Zhengbao Jiang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Araki_J/0/1/0/all/0/1"&gt;Jun Araki&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ding_H/0/1/0/all/0/1"&gt;Haibo Ding&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1"&gt;Graham Neubig&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generalized Few-Shot Object Detection without Forgetting. (arXiv:2105.09491v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2105.09491</id>
        <link href="http://arxiv.org/abs/2105.09491"/>
        <updated>2021-05-22T06:24:26.320Z</updated>
        <summary type="html"><![CDATA[Recently few-shot object detection is widely adopted to deal with
data-limited situations. While most previous works merely focus on the
performance on few-shot categories, we claim that detecting all classes is
crucial as test samples may contain any instances in realistic applications,
which requires the few-shot detector to learn new concepts without forgetting.
Through analysis on transfer learning based methods, some neglected but
beneficial properties are utilized to design a simple yet effective few-…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1"&gt;Zhibo Fan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1"&gt;Yuchen Ma&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1"&gt;Zeming Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1"&gt;Jian Sun&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Exploiting News Article Structure for Automatic Corpus Generation. (arXiv:2010.11574v2 [cs.CL] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2010.11574</id>
        <link href="http://arxiv.org/abs/2010.11574"/>
        <updated>2021-05-22T06:24:26.301Z</updated>
        <summary type="html"><![CDATA[Transformers represent the state-of-the-art in Natural Language Processing
(NLP) in recent years, proving effective even in tasks done in low-resource
languages. While pretrained transformers for these languages can be made, it is
challenging to measure their true performance and capacity due to the lack of
hard benchmark datasets, as well as the difficulty and cost of producing them.
In this paper, we present three contributions: First, we propose a methodology
for automatically producing Natural Language …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Cruz_J/0/1/0/all/0/1"&gt;Jan Christian Blaise Cruz&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Resabal_J/0/1/0/all/0/1"&gt;Jose Kristian Resabal&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1"&gt;James Lin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Velasco_D/0/1/0/all/0/1"&gt;Dan John Velasco&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1"&gt;Charibeth Cheng&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Measuring Coding Challenge Competence With APPS. (arXiv:2105.09938v1 [cs.SE])]]></title>
        <id>http://arxiv.org/abs/2105.09938</id>
        <link href="http://arxiv.org/abs/2105.09938"/>
        <updated>2021-05-22T06:24:26.295Z</updated>
        <summary type="html"><![CDATA[While programming is one of the most broadly applicable skills in modern
society, modern machine learning models still cannot code solutions to basic
problems. It can be difficult to accurately assess code generation performance,
and there has been surprisingly little work on evaluating code generation in a
way that is both flexible and rigorous. To meet this challenge, we introduce
APPS, a benchmark for code generation. Unlike prior work in more restricted
settings, our benchmark measures the ability of mo…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Hendrycks_D/0/1/0/all/0/1"&gt;Dan Hendrycks&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Basart_S/0/1/0/all/0/1"&gt;Steven Basart&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kadavath_S/0/1/0/all/0/1"&gt;Saurav Kadavath&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mazeika_M/0/1/0/all/0/1"&gt;Mantas Mazeika&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Arora_A/0/1/0/all/0/1"&gt;Akul Arora&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Guo_E/0/1/0/all/0/1"&gt;Ethan Guo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Burns_C/0/1/0/all/0/1"&gt;Collin Burns&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Puranik_S/0/1/0/all/0/1"&gt;Samir Puranik&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1"&gt;Horace He&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1"&gt;Dawn Song&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Steinhardt_J/0/1/0/all/0/1"&gt;Jacob Steinhardt&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BRUMS at SemEval-2020 Task 3: Contextualised Embeddings for Predicting the (Graded) Effect of Context in Word Similarity. (arXiv:2010.06269v2 [cs.CL] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2010.06269</id>
        <link href="http://arxiv.org/abs/2010.06269"/>
        <updated>2021-05-22T06:24:26.288Z</updated>
        <summary type="html"><![CDATA[This paper presents the team BRUMS submission to SemEval-2020 Task 3: Graded
Word Similarity in Context. The system utilises state-of-the-art contextualised
word embeddings, which have some task-specific adaptations, including stacked
embeddings and average embeddings. Overall, the approach achieves good
evaluation scores across all the languages, while maintaining simplicity.
Following the final rankings, our approach is ranked within the top 5 solutions
of each language while preserving the 1st position o…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Hettiarachchi_H/0/1/0/all/0/1"&gt;Hansi Hettiarachchi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ranasinghe_T/0/1/0/all/0/1"&gt;Tharindu Ranasinghe&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A practical introduction to the Rational Speech Act modeling framework. (arXiv:2105.09867v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2105.09867</id>
        <link href="http://arxiv.org/abs/2105.09867"/>
        <updated>2021-05-22T06:24:26.281Z</updated>
        <summary type="html"><![CDATA[Recent advances in computational cognitive science (i.e., simulation-based
probabilistic programs) have paved the way for significant progress in formal,
implementable models of pragmatics. Rather than describing a pragmatic
reasoning process in prose, these models formalize and implement one, deriving
both qualitative and quantitative predictions of human behavior -- predictions
that consistently prove correct, demonstrating the viability and value of the
framework. The current paper provides a practical i…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Scontras_G/0/1/0/all/0/1"&gt;Gregory Scontras&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tessler_M/0/1/0/all/0/1"&gt;Michael Henry Tessler&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Franke_M/0/1/0/all/0/1"&gt;Michael Franke&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Intra-Document Cascading: Learning to Select Passages for Neural Document Ranking. (arXiv:2105.09816v1 [cs.IR])]]></title>
        <id>http://arxiv.org/abs/2105.09816</id>
        <link href="http://arxiv.org/abs/2105.09816"/>
        <updated>2021-05-22T06:24:26.263Z</updated>
        <summary type="html"><![CDATA[An emerging recipe for achieving state-of-the-art effectiveness in neural
document re-ranking involves utilizing large pre-trained language models -
e.g., BERT - to evaluate all individual passages in the document and then
aggregating the outputs by pooling or additional Transformer layers. A major
drawback of this approach is high query latency due to the cost of evaluating
every passage in the document with BERT. To make matters worse, this high
inference cost and latency varies based on the length of the…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Hofstatter_S/0/1/0/all/0/1"&gt;Sebastian Hofst&amp;#xe4;tter&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mitra_B/0/1/0/all/0/1"&gt;Bhaskar Mitra&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zamani_H/0/1/0/all/0/1"&gt;Hamed Zamani&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Craswell_N/0/1/0/all/0/1"&gt;Nick Craswell&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hanbury_A/0/1/0/all/0/1"&gt;Allan Hanbury&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On Cross-Dataset Generalization in Automatic Detection of Online Abuse. (arXiv:2010.07414v3 [cs.CL] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2010.07414</id>
        <link href="http://arxiv.org/abs/2010.07414"/>
        <updated>2021-05-22T06:24:26.255Z</updated>
        <summary type="html"><![CDATA[NLP research has attained high performances in abusive language detection as
a supervised classification task. While in research settings, training and test
datasets are usually obtained from similar data samples, in practice systems
are often applied on data that are different from the training set in topic and
class distributions. Also, the ambiguity in class definitions inherited in this
task aggravates the discrepancies between source and target datasets. We
explore the topic bias and the task formulati…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Nejadgholi_I/0/1/0/all/0/1"&gt;Isar Nejadgholi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kiritchenko_S/0/1/0/all/0/1"&gt;Svetlana Kiritchenko&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mondegreen: A Post-Processing Solution to Speech Recognition Error Correction for Voice Search Queries. (arXiv:2105.09930v1 [cs.SD])]]></title>
        <id>http://arxiv.org/abs/2105.09930</id>
        <link href="http://arxiv.org/abs/2105.09930"/>
        <updated>2021-05-22T06:24:26.247Z</updated>
        <summary type="html"><![CDATA[As more and more online search queries come from voice, automatic speech
recognition becomes a key component to deliver relevant search results. Errors
introduced by automatic speech recognition (ASR) lead to irrelevant search
results returned to the user, thus causing user dissatisfaction. In this paper,
we introduce an approach, Mondegreen, to correct voice queries in text space
without depending on audio signals, which may not always be available due to
system constraints or privacy or bandwidth (for exa…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Sodhi_S/0/1/0/all/0/1"&gt;Sukhdeep S. Sodhi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chio_E/0/1/0/all/0/1"&gt;Ellie Ka-In Chio&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jash_A/0/1/0/all/0/1"&gt;Ambarish Jash&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ontanon_S/0/1/0/all/0/1"&gt;Santiago Onta&amp;#xf1;&amp;#xf3;n&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Apte_A/0/1/0/all/0/1"&gt;Ajit Apte&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1"&gt;Ankit Kumar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jeje_A/0/1/0/all/0/1"&gt;Ayooluwakunmi Jeje&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kuzmin_D/0/1/0/all/0/1"&gt;Dima Kuzmin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Fung_H/0/1/0/all/0/1"&gt;Harry Fung&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1"&gt;Heng-Tze Cheng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Effrat_J/0/1/0/all/0/1"&gt;Jon Effrat&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bali_T/0/1/0/all/0/1"&gt;Tarush Bali&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jindal_N/0/1/0/all/0/1"&gt;Nitin Jindal&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cao_P/0/1/0/all/0/1"&gt;Pei Cao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1"&gt;Sarvjeet Singh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1"&gt;Senqiang Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Khan_T/0/1/0/all/0/1"&gt;Tameen Khan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wankhede_A/0/1/0/all/0/1"&gt;Amol Wankhede&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Alzantot_M/0/1/0/all/0/1"&gt;Moustafa Alzantot&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1"&gt;Allen Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chandra_T/0/1/0/all/0/1"&gt;Tushar Chandra&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Subverting the Jewtocracy": Online Antisemitism Detection Using Multimodal Deep Learning. (arXiv:2104.05947v2 [cs.MM] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2104.05947</id>
        <link href="http://arxiv.org/abs/2104.05947"/>
        <updated>2021-05-22T06:24:26.233Z</updated>
        <summary type="html"><![CDATA[The exponential rise of online social media has enabled the creation,
distribution, and consumption of information at an unprecedented rate. However,
it has also led to the burgeoning of various forms of online abuse. Increasing
cases of online antisemitism have become one of the major concerns because of
its socio-political consequences. Unlike other major forms of online abuse like
racism, sexism, etc., online antisemitism has not been studied much from a
machine learning perspective. To the best of our k…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chandra_M/0/1/0/all/0/1"&gt;Mohit Chandra&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Pailla_D/0/1/0/all/0/1"&gt;Dheeraj Pailla&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bhatia_H/0/1/0/all/0/1"&gt;Himanshu Bhatia&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sanchawala_A/0/1/0/all/0/1"&gt;Aadilmehdi Sanchawala&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1"&gt;Manish Gupta&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Shrivastava_M/0/1/0/all/0/1"&gt;Manish Shrivastava&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kumaraguru_P/0/1/0/all/0/1"&gt;Ponnurangam Kumaraguru&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unsupervised Cross-Domain Prerequisite Chain Learning using Variational Graph Autoencoders. (arXiv:2105.03505v2 [cs.CL] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.03505</id>
        <link href="http://arxiv.org/abs/2105.03505"/>
        <updated>2021-05-22T06:24:26.197Z</updated>
        <summary type="html"><![CDATA[Learning prerequisite chains is an essential task for efficiently acquiring
knowledge in both known and unknown domains. For example, one may be an expert
in the natural language processing (NLP) domain but want to determine the best
order to learn new concepts in an unfamiliar Computer Vision domain (CV). Both
domains share some common concepts, such as machine learning basics and deep
learning models. In this paper, we propose unsupervised cross-domain concept
prerequisite chain learning using an optimize…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Li_I/0/1/0/all/0/1"&gt;Irene Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yan_V/0/1/0/all/0/1"&gt;Vanessa Yan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1"&gt;Tianxiao Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Qu_R/0/1/0/all/0/1"&gt;Rihao Qu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Radev_D/0/1/0/all/0/1"&gt;Dragomir Radev&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[LAST at SemEval-2021 Task 1: Improving Multi-Word Complexity Prediction Using Bigram Association Measures. (arXiv:2105.09653v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2105.09653</id>
        <link href="http://arxiv.org/abs/2105.09653"/>
        <updated>2021-05-22T06:24:26.169Z</updated>
        <summary type="html"><![CDATA[This paper describes the system developed by the Laboratoire d'analyse
statistique des textes (LAST) for the Lexical Complexity Prediction shared task
at SemEval-2021. The proposed system is made up of a LightGBM model fed with
features obtained from many word frequency lists, published lexical norms and
psychometric data. For tackling the specificity of the multi-word task, it uses
bigram association measures. Despite that the only contextual feature used was
sentence length, the system achieved an honorab…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Bestgen_Y/0/1/0/all/0/1"&gt;Yves Bestgen&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Simplifying Paragraph-level Question Generation via Transformer Language Models. (arXiv:2005.01107v3 [cs.CL] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2005.01107</id>
        <link href="http://arxiv.org/abs/2005.01107"/>
        <updated>2021-05-22T06:24:26.057Z</updated>
        <summary type="html"><![CDATA[Question generation (QG) is a natural language generation task where a model
is trained to ask questions corresponding to some input text. Most recent
approaches frame QG as a sequence-to-sequence problem and rely on additional
features and mechanisms to increase performance; however, these often increase
model complexity, and can rely on auxiliary data unavailable in practical use.
A single Transformer-based unidirectional language model leveraging transfer
learning can be used to produce high quality ques…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Lopez_L/0/1/0/all/0/1"&gt;Luis Enrico Lopez&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cruz_D/0/1/0/all/0/1"&gt;Diane Kathryn Cruz&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cruz_J/0/1/0/all/0/1"&gt;Jan Christian Blaise Cruz&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1"&gt;Charibeth Cheng&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[UNIMO: Towards Unified-Modal Understanding and Generation via Cross-Modal Contrastive Learning. (arXiv:2012.15409v3 [cs.CL] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2012.15409</id>
        <link href="http://arxiv.org/abs/2012.15409"/>
        <updated>2021-05-22T06:24:25.962Z</updated>
        <summary type="html"><![CDATA[Existed pre-training methods either focus on single-modal tasks or
multi-modal tasks, and cannot effectively adapt to each other. They can only
utilize single-modal data (i.e. text or image) or limited multi-modal data
(i.e. image-text pairs). In this work, we propose a unified-modal pre-training
architecture, namely UNIMO, which can effectively adapt to both single-modal
and multi-modal understanding and generation tasks. Large scale of free text
corpus and image collections can be utilized to improve the …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1"&gt;Wei Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1"&gt;Can Gao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1"&gt;Guocheng Niu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1"&gt;Xinyan Xiao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1"&gt;Hao Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1"&gt;Jiachen Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1"&gt;Hua Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1"&gt;Haifeng Wang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[UmlsBERT: Clinical Domain Knowledge Augmentation of Contextual Embeddings Using the Unified Medical Language System Metathesaurus. (arXiv:2010.10391v4 [cs.CL] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2010.10391</id>
        <link href="http://arxiv.org/abs/2010.10391"/>
        <updated>2021-05-22T06:24:25.954Z</updated>
        <summary type="html"><![CDATA[Contextual word embedding models, such as BioBERT and Bio_ClinicalBERT, have
achieved state-of-the-art results in biomedical natural language processing
tasks by focusing their pre-training process on domain-specific corpora.
However, such models do not take into consideration expert domain knowledge.

In this work, we introduced UmlsBERT, a contextual embedding model that
integrates domain knowledge during the pre-training process via a novel
knowledge augmentation strategy. More specifically, the augmenta…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Michalopoulos_G/0/1/0/all/0/1"&gt;George Michalopoulos&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"&gt;Yuanxin Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kaka_H/0/1/0/all/0/1"&gt;Hussam Kaka&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1"&gt;Helen Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1"&gt;Alexander Wong&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[High-Fidelity and Low-Latency Universal Neural Vocoder based on Multiband WaveRNN with Data-Driven Linear Prediction for Discrete Waveform Modeling. (arXiv:2105.09856v1 [cs.SD])]]></title>
        <id>http://arxiv.org/abs/2105.09856</id>
        <link href="http://arxiv.org/abs/2105.09856"/>
        <updated>2021-05-22T06:24:25.882Z</updated>
        <summary type="html"><![CDATA[This paper presents a novel high-fidelity and low-latency universal neural
vocoder framework based on multiband WaveRNN with data-driven linear prediction
for discrete waveform modeling (MWDLP). MWDLP employs a coarse-fine bit WaveRNN
architecture for 10-bit mu-law waveform modeling. A sparse gated recurrent unit
with a relatively large size of hidden units is utilized, while the multiband
modeling is deployed to achieve real-time low-latency usage. A novel technique
for data-driven linear prediction (LP) w…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Tobing_P/0/1/0/all/0/1"&gt;Patrick Lumban Tobing&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Toda_T/0/1/0/all/0/1"&gt;Tomoki Toda&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[KLUE: Korean Language Understanding Evaluation. (arXiv:2105.09680v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2105.09680</id>
        <link href="http://arxiv.org/abs/2105.09680"/>
        <updated>2021-05-22T06:24:25.871Z</updated>
        <summary type="html"><![CDATA[We introduce Korean Language Understanding Evaluation (KLUE) benchmark. KLUE
is a collection of 8 Korean natural language understanding (NLU) tasks,
including Topic Classification, Semantic Textual Similarity, Natural Language
Inference, Named Entity Recognition, Relation Extraction, Dependency Parsing,
Machine Reading Comprehension, and Dialogue State Tracking. We build all of the
tasks from scratch from diverse source corpora while respecting copyrights, to
ensure accessibility for anyone without any rest…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1"&gt;Sungjoon Park&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Moon_J/0/1/0/all/0/1"&gt;Jihyung Moon&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1"&gt;Sungdong Kim&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cho_W/0/1/0/all/0/1"&gt;Won Ik Cho&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1"&gt;Jiyoon Han&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1"&gt;Jangwon Park&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1"&gt;Chisung Song&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1"&gt;Junseong Kim&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1"&gt;Yongsook Song&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Oh_T/0/1/0/all/0/1"&gt;Taehwan Oh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1"&gt;Joohong Lee&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1"&gt;Juhyun Oh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lyu_S/0/1/0/all/0/1"&gt;Sungwon Lyu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jeong_Y/0/1/0/all/0/1"&gt;Younghoon Jeong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lee_I/0/1/0/all/0/1"&gt;Inkwon Lee&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Seo_S/0/1/0/all/0/1"&gt;Sangwoo Seo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1"&gt;Dongjun Lee&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1"&gt;Hyunwoo Kim&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1"&gt;Myeonghwa Lee&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jang_S/0/1/0/all/0/1"&gt;Seongbo Jang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Do_S/0/1/0/all/0/1"&gt;Seungwon Do&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1"&gt;Sunkyoung Kim&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lim_K/0/1/0/all/0/1"&gt;Kyungtae Lim&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1"&gt;Jongwon Lee&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Park_K/0/1/0/all/0/1"&gt;Kyumin Park&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1"&gt;Jamin Shin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1"&gt;Seonghyun Kim&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Park_L/0/1/0/all/0/1"&gt;Lucy Park&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Oh_A/0/1/0/all/0/1"&gt;Alice Oh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ha_J/0/1/0/all/0/1"&gt;Jungwoo Ha&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1"&gt;Kyunghyun Cho Alice Oh Jungwoo Ha Kyunghyun Cho&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Robustness of end-to-end Automatic Speech Recognition Models -- A Case Study using Mozilla DeepSpeech. (arXiv:2105.09742v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2105.09742</id>
        <link href="http://arxiv.org/abs/2105.09742"/>
        <updated>2021-05-22T06:24:25.862Z</updated>
        <summary type="html"><![CDATA[When evaluating the performance of automatic speech recognition models,
usually word error rate within a certain dataset is used. Special care must be
taken in understanding the dataset in order to report realistic performance
numbers. We argue that many performance numbers reported probably underestimate
the expected error rate. We conduct experiments controlling for selection bias,
gender as well as overlap (between training and test data) in content, voices,
and recording conditions. We find that content…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1"&gt;Aashish Agarwal&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zesch_T/0/1/0/all/0/1"&gt;Torsten Zesch&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Low-Latency Real-Time Non-Parallel Voice Conversion based on Cyclic Variational Autoencoder and Multiband WaveRNN with Data-Driven Linear Prediction. (arXiv:2105.09858v1 [cs.SD])]]></title>
        <id>http://arxiv.org/abs/2105.09858</id>
        <link href="http://arxiv.org/abs/2105.09858"/>
        <updated>2021-05-22T06:24:25.853Z</updated>
        <summary type="html"><![CDATA[This paper presents a low-latency real-time (LLRT) non-parallel voice
conversion (VC) framework based on cyclic variational autoencoder (CycleVAE)
and multiband WaveRNN with data-driven linear prediction (MWDLP). CycleVAE is a
robust non-parallel multispeaker spectral model, which utilizes a
speaker-independent latent space and a speaker-dependent code to generate
reconstructed/converted spectral features given the spectral features of an
input speaker. On the other hand, MWDLP is an efficient and a high-qu…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Tobing_P/0/1/0/all/0/1"&gt;Patrick Lumban Tobing&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Toda_T/0/1/0/all/0/1"&gt;Tomoki Toda&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multi-Head Attention: Collaborate Instead of Concatenate. (arXiv:2006.16362v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2006.16362</id>
        <link href="http://arxiv.org/abs/2006.16362"/>
        <updated>2021-05-22T06:24:25.846Z</updated>
        <summary type="html"><![CDATA[Attention layers are widely used in natural language processing (NLP) and are
beginning to influence computer vision architectures. Training very large
transformer models allowed significant improvement in both fields, but once
trained, these networks show symptoms of over-parameterization. For instance,
it is known that many attention heads can be pruned without impacting accuracy.
This work aims to enhance current understanding on how multiple heads interact.
Motivated by the observation that attention he…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Cordonnier_J/0/1/0/all/0/1"&gt;Jean-Baptiste Cordonnier&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Loukas_A/0/1/0/all/0/1"&gt;Andreas Loukas&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1"&gt;Martin Jaggi&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[See, Hear, Read: Leveraging Multimodality with Guided Attention for Abstractive Text Summarization. (arXiv:2105.09601v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09601</id>
        <link href="http://arxiv.org/abs/2105.09601"/>
        <updated>2021-05-22T06:24:25.839Z</updated>
        <summary type="html"><![CDATA[In recent years, abstractive text summarization with multimodal inputs has
started drawing attention due to its ability to accumulate information from
different source modalities and generate a fluent textual summary. However,
existing methods use short videos as the visual modality and short summary as
the ground-truth, therefore, perform poorly on lengthy videos and long
ground-truth summary. Additionally, there exists no benchmark dataset to
generalize this task on videos of varying lengths. In this pape…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Atri_Y/0/1/0/all/0/1"&gt;Yash Kumar Atri&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Pramanick_S/0/1/0/all/0/1"&gt;Shraman Pramanick&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Goyal_V/0/1/0/all/0/1"&gt;Vikram Goyal&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chakraborty_T/0/1/0/all/0/1"&gt;Tanmoy Chakraborty&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Case Study on Pros and Cons of Regular Expression Detection and Dependency Parsing for Negation Extraction from German Medical Documents. Technical Report. (arXiv:2105.09702v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2105.09702</id>
        <link href="http://arxiv.org/abs/2105.09702"/>
        <updated>2021-05-22T06:24:25.829Z</updated>
        <summary type="html"><![CDATA[We describe our work on information extraction in medical documents written
in German, especially detecting negations using an architecture based on the
UIMA pipeline. Based on our previous work on software modules to cover medical
concepts like diagnoses, examinations, etc. we employ a version of the NegEx
regular expression algorithm with a large set of triggers as a baseline. We
show how a significantly smaller trigger set is sufficient to achieve similar
results, in order to reduce adaptation times to n…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Profitlich_H/0/1/0/all/0/1"&gt;Hans-J&amp;#xfc;rgen Profitlich&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sonntag_D/0/1/0/all/0/1"&gt;Daniel Sonntag&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Computational Morphology with Neural Network Approaches. (arXiv:2105.09404v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2105.09404</id>
        <link href="http://arxiv.org/abs/2105.09404"/>
        <updated>2021-05-22T06:24:25.807Z</updated>
        <summary type="html"><![CDATA[Neural network approaches have been applied to computational morphology with
great success, improving the performance of most tasks by a large margin and
providing new perspectives for modeling. This paper starts with a brief
introduction to computational morphology, followed by a review of recent work
on computational morphology with neural network approaches, to provide an
overview of the area. In the end, we will analyze the advantages and problems
of neural network approaches to computational morphology…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1"&gt;Ling Liu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adaptive Knowledge-Enhanced Bayesian Meta-Learning for Few-shot Event Detection. (arXiv:2105.09509v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2105.09509</id>
        <link href="http://arxiv.org/abs/2105.09509"/>
        <updated>2021-05-22T06:24:25.795Z</updated>
        <summary type="html"><![CDATA[Event detection (ED) aims at detecting event trigger words in sentences and
classifying them into specific event types. In real-world applications, ED
typically does not have sufficient labelled data, thus can be formulated as a
few-shot learning problem. To tackle the issue of low sample diversity in
few-shot ED, we propose a novel knowledge-based few-shot event detection method
which uses a definition-based encoder to introduce external event knowledge as
the knowledge prior of event types. Furthermore, a…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Shen_S/0/1/0/all/0/1"&gt;Shirong Shen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1"&gt;Tongtong Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Qi_G/0/1/0/all/0/1"&gt;Guilin Qi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1"&gt;Yuan-Fang Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Haffari_G/0/1/0/all/0/1"&gt;Gholamreza Haffari&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bi_S/0/1/0/all/0/1"&gt;Sheng Bi&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Target-dependent Sentiment Classification in News Articles. (arXiv:2105.09660v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2105.09660</id>
        <link href="http://arxiv.org/abs/2105.09660"/>
        <updated>2021-05-22T06:24:25.778Z</updated>
        <summary type="html"><![CDATA[Extensive research on target-dependent sentiment classification (TSC) has led
to strong classification performances in domains where authors tend to
explicitly express sentiment about specific entities or topics, such as in
reviews or on social media. We investigate TSC in news articles, a much less
researched domain, despite the importance of news as an essential information
source in individual and societal decision making. This article introduces
NewsTSC, a manually annotated dataset to explore TSC on ne…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Hamborg_F/0/1/0/all/0/1"&gt;Felix Hamborg&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Donnay_K/0/1/0/all/0/1"&gt;Karsten Donnay&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gipp_B/0/1/0/all/0/1"&gt;Bela Gipp&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A comprehensive comparative evaluation and analysis of Distributional Semantic Models. (arXiv:2105.09825v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2105.09825</id>
        <link href="http://arxiv.org/abs/2105.09825"/>
        <updated>2021-05-22T06:24:25.758Z</updated>
        <summary type="html"><![CDATA[Distributional semantics has deeply changed in the last decades. First,
predict models stole the thunder from traditional count ones, and more recently
both of them were replaced in many NLP applications by contextualized vectors
produced by Transformer neural language models. Although an extensive body of
research has been devoted to Distributional Semantic Model (DSM) evaluation, we
still lack a thorough comparison with respect to tested models, semantic tasks,
and benchmark datasets. Moreover, previous w…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Lenci_A/0/1/0/all/0/1"&gt;Alessandro Lenci&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sahlgren_M/0/1/0/all/0/1"&gt;Magnus Sahlgren&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jeuniaux_P/0/1/0/all/0/1"&gt;Patrick Jeuniaux&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gyllensten_A/0/1/0/all/0/1"&gt;Amaru Cuba Gyllensten&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Miliani_M/0/1/0/all/0/1"&gt;Martina Miliani&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Head-driven Phrase Structure Parsing in O($n^3$) Time Complexity. (arXiv:2105.09835v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2105.09835</id>
        <link href="http://arxiv.org/abs/2105.09835"/>
        <updated>2021-05-22T06:24:25.726Z</updated>
        <summary type="html"><![CDATA[Constituent and dependency parsing, the two classic forms of syntactic
parsing, have been found to benefit from joint training and decoding under a
uniform formalism, Head-driven Phrase Structure Grammar (HPSG). However,
decoding this unified grammar has a higher time complexity ($O(n^5)$) than
decoding either form individually ($O(n^3)$) since more factors have to be
considered during decoding. We thus propose an improved head scorer that helps
achieve a novel performance-preserved parser in $O$($n^3$) tim…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1"&gt;Zuchao Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1"&gt;Junru Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1"&gt;Hai Zhao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Parnow_K/0/1/0/all/0/1"&gt;Kevin Parnow&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The impact of virtual mirroring on customer satisfaction. (arXiv:2105.09571v1 [cs.SI])]]></title>
        <id>http://arxiv.org/abs/2105.09571</id>
        <link href="http://arxiv.org/abs/2105.09571"/>
        <updated>2021-05-22T06:24:25.685Z</updated>
        <summary type="html"><![CDATA[We investigate the impact of a novel method called "virtual mirroring" to
promote employee self-reflection and impact customer satisfaction. The method
is based on measuring communication patterns, through social network and
semantic analysis, and mirroring them back to the individual. Our goal is to
demonstrate that self-reflection can trigger a change in communication
behaviors, which lead to increased customer satisfaction. We illustrate and
test our approach analyzing e-mails of a large global services …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Gloor_P/0/1/0/all/0/1"&gt;P. Gloor&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Colladon_A/0/1/0/all/0/1"&gt;A. Fronzetti Colladon&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Giacomelli_G/0/1/0/all/0/1"&gt;G. Giacomelli&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Saran_T/0/1/0/all/0/1"&gt;T. Saran&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Grippa_F/0/1/0/all/0/1"&gt;F. Grippa&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Contrastive Learning for Many-to-many Multilingual Neural Machine Translation. (arXiv:2105.09501v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2105.09501</id>
        <link href="http://arxiv.org/abs/2105.09501"/>
        <updated>2021-05-22T06:24:25.677Z</updated>
        <summary type="html"><![CDATA[Existing multilingual machine translation approaches mainly focus on
English-centric directions, while the non-English directions still lag behind.
In this work, we aim to build a many-to-many translation system with an
emphasis on the quality of non-English language directions. Our intuition is
based on the hypothesis that a universal cross-language representation leads to
better multilingual translation performance. To this end, we propose \method, a
training method to obtain a single unified multilingual…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1"&gt;Xiao Pan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1"&gt;Mingxuan Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1"&gt;Liwei Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1"&gt;Lei Li&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Manual Evaluation Matters: Reviewing Test Protocols of Distantly Supervised Relation Extraction. (arXiv:2105.09543v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2105.09543</id>
        <link href="http://arxiv.org/abs/2105.09543"/>
        <updated>2021-05-22T06:24:25.668Z</updated>
        <summary type="html"><![CDATA[Distantly supervised (DS) relation extraction (RE) has attracted much
attention in the past few years as it can utilize large-scale auto-labeled
data. However, its evaluation has long been a problem: previous works either
took costly and inconsistent methods to manually examine a small sample of
model predictions, or directly test models on auto-labeled data -- which, by
our check, produce as much as 53% wrong labels at the entity pair level in the
popular NYT10 dataset. This problem has not only led to ina…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1"&gt;Tianyu Gao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1"&gt;Xu Han&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Qiu_K/0/1/0/all/0/1"&gt;Keyue Qiu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1"&gt;Yuzhuo Bai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1"&gt;Zhiyu Xie&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1"&gt;Yankai Lin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1"&gt;Zhiyuan Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1"&gt;Peng Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1"&gt;Maosong Sun&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1"&gt;Jie Zhou&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Detecting Need for Empathetic Response in Motivational Interviewing. (arXiv:2105.09649v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2105.09649</id>
        <link href="http://arxiv.org/abs/2105.09649"/>
        <updated>2021-05-22T06:24:25.644Z</updated>
        <summary type="html"><![CDATA[Empathetic response from the therapist is key to the success of clinical
psychotherapy, especially motivational interviewing. Previous work on
computational modelling of empathy in motivational interviewing has focused on
offline, session-level assessment of therapist empathy, where empathy captures
all efforts that the therapist makes to understand the client's perspective and
convey that understanding to the client. In this position paper, we propose a
novel task of turn-level detection of client need for…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1"&gt;Zixiu Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Helaoui_R/0/1/0/all/0/1"&gt;Rim Helaoui&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1"&gt;Vivek Kumar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Recupero_D/0/1/0/all/0/1"&gt;Diego Reforgiato Recupero&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Riboni_D/0/1/0/all/0/1"&gt;Daniele Riboni&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unified Dual-view Cognitive Model for Interpretable Claim Verification. (arXiv:2105.09567v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2105.09567</id>
        <link href="http://arxiv.org/abs/2105.09567"/>
        <updated>2021-05-22T06:24:25.615Z</updated>
        <summary type="html"><![CDATA[Recent studies constructing direct interactions between the claim and each
single user response (a comment or a relevant article) to capture evidence have
shown remarkable success in interpretable claim verification. Owing to
different single responses convey different cognition of individual users
(i.e., audiences), the captured evidence belongs to the perspective of
individual cognition. However, individuals' cognition of social things is not
always able to truly reflect the objective. There may be one-si…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1"&gt;Lianwei Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Rao_Y/0/1/0/all/0/1"&gt;Yuan Rao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1"&gt;Yuqian Lan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1"&gt;Ling Sun&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Qi_Z/0/1/0/all/0/1"&gt;Zhaoyin Qi&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MLBiNet: A Cross-Sentence Collective Event Detection Network. (arXiv:2105.09458v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2105.09458</id>
        <link href="http://arxiv.org/abs/2105.09458"/>
        <updated>2021-05-22T06:24:25.551Z</updated>
        <summary type="html"><![CDATA[We consider the problem of collectively detecting multiple events,
particularly in cross-sentence settings. The key to dealing with the problem is
to encode semantic information and model event inter-dependency at a
document-level. In this paper, we reformulate it as a Seq2Seq task and propose
a Multi-Layer Bidirectional Network (MLBiNet) to capture the document-level
association of events and semantic information simultaneously. Specifically, a
bidirectional decoder is firstly devised to model event inter-…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Lou_D/0/1/0/all/0/1"&gt;Dongfang Lou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liao_Z/0/1/0/all/0/1"&gt;Zhilin Liao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1"&gt;Shumin Deng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1"&gt;Ningyu Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1"&gt;Huajun Chen&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dependency Parsing with Bottom-up Hierarchical Pointer Networks. (arXiv:2105.09611v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2105.09611</id>
        <link href="http://arxiv.org/abs/2105.09611"/>
        <updated>2021-05-22T06:24:25.542Z</updated>
        <summary type="html"><![CDATA[Dependency parsing is a crucial step towards deep language understanding and,
therefore, widely demanded by numerous Natural Language Processing
applications. In particular, left-to-right and top-down transition-based
algorithms that rely on Pointer Networks are among the most accurate approaches
for performing dependency parsing. Additionally, it has been observed for the
top-down algorithm that Pointer Networks' sequential decoding can be improved
by implementing a hierarchical variant, more adequate to m…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Fernandez_Gonzalez_D/0/1/0/all/0/1"&gt;Daniel Fern&amp;#xe1;ndez-Gonz&amp;#xe1;lez&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gomez_Rodriguez_C/0/1/0/all/0/1"&gt;Carlos G&amp;#xf3;mez-Rodr&amp;#xed;guez&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[TF-IDF vs Word Embeddings for Morbidity Identification in Clinical Notes: An Initial Study. (arXiv:2105.09632v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2105.09632</id>
        <link href="http://arxiv.org/abs/2105.09632"/>
        <updated>2021-05-22T06:24:25.387Z</updated>
        <summary type="html"><![CDATA[Today, we are seeing an ever-increasing number of clinical notes that contain
clinical results, images, and textual descriptions of patient's health state.
All these data can be analyzed and employed to cater novel services that can
help people and domain experts with their common healthcare tasks. However,
many technologies such as Deep Learning and tools like Word Embeddings have
started to be investigated only recently, and many challenges remain open when
it comes to healthcare domain applications. To a…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Dessi_D/0/1/0/all/0/1"&gt;Danilo Dessi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Helaoui_R/0/1/0/all/0/1"&gt;Rim Helaoui&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1"&gt;Vivek Kumar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Recupero_D/0/1/0/all/0/1"&gt;Diego Reforgiato Recupero&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Riboni_D/0/1/0/all/0/1"&gt;Daniele Riboni&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Explainable Health Risk Predictor with Transformer-based Medicare Claim Encoder. (arXiv:2105.09428v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2105.09428</id>
        <link href="http://arxiv.org/abs/2105.09428"/>
        <updated>2021-05-22T06:24:25.286Z</updated>
        <summary type="html"><![CDATA[In 2019, The Centers for Medicare and Medicaid Services (CMS) launched an
Artificial Intelligence (AI) Health Outcomes Challenge seeking solutions to
predict risk in value-based care for incorporation into CMS Innovation Center
payment and service delivery models. Recently, modern language models have
played key roles in a number of health related tasks. This paper presents, to
the best of our knowledge, the first application of these models to patient
readmission prediction. To facilitate this, we create a…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Lahlou_C/0/1/0/all/0/1"&gt;Chuhong Lahlou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Crayton_A/0/1/0/all/0/1"&gt;Ancil Crayton&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Trier_C/0/1/0/all/0/1"&gt;Caroline Trier&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Willett_E/0/1/0/all/0/1"&gt;Evan Willett&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Estimate The Efficiency Of Multiprocessor's Cash Memory Work Algorithms. (arXiv:2102.03848v2 [cs.NI] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2102.03848</id>
        <link href="http://arxiv.org/abs/2102.03848"/>
        <updated>2021-05-22T06:24:25.243Z</updated>
        <summary type="html"><![CDATA[Many computer systems for calculating the proper organization of memory are
among the most critical issues. Using a tier cache memory (along with branching
prediction) is an effective means of increasing modern multi-core processors'
performance. Designing high-performance processors is a complex task and
requires preliminary verification and analysis of the model level, usually used
in analytical and simulation modeling. The refinement of extreme programming is
an unfortunate challenge. Few experts disagre…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Hamada_M/0/1/0/all/0/1"&gt;Mohamed A. Hamada&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Abdallah_A/0/1/0/all/0/1"&gt;Abdelrahman Abdallah&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Intra-Document Cascading: Learning to Select Passages for Neural Document Ranking. (arXiv:2105.09816v1 [cs.IR])]]></title>
        <id>http://arxiv.org/abs/2105.09816</id>
        <link href="http://arxiv.org/abs/2105.09816"/>
        <updated>2021-05-22T06:24:25.233Z</updated>
        <summary type="html"><![CDATA[An emerging recipe for achieving state-of-the-art effectiveness in neural
document re-ranking involves utilizing large pre-trained language models -
e.g., BERT - to evaluate all individual passages in the document and then
aggregating the outputs by pooling or additional Transformer layers. A major
drawback of this approach is high query latency due to the cost of evaluating
every passage in the document with BERT. To make matters worse, this high
inference cost and latency varies based on the length of the…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Hofstatter_S/0/1/0/all/0/1"&gt;Sebastian Hofst&amp;#xe4;tter&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mitra_B/0/1/0/all/0/1"&gt;Bhaskar Mitra&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zamani_H/0/1/0/all/0/1"&gt;Hamed Zamani&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Craswell_N/0/1/0/all/0/1"&gt;Nick Craswell&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hanbury_A/0/1/0/all/0/1"&gt;Allan Hanbury&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[FreshDiskANN: A Fast and Accurate Graph-Based ANN Index for Streaming Similarity Search. (arXiv:2105.09613v1 [cs.IR])]]></title>
        <id>http://arxiv.org/abs/2105.09613</id>
        <link href="http://arxiv.org/abs/2105.09613"/>
        <updated>2021-05-22T06:24:25.210Z</updated>
        <summary type="html"><![CDATA[Approximate nearest neighbor search (ANNS) is a fundamental building block in
information retrieval with graph-based indices being the current
state-of-the-art and widely used in the industry. Recent advances in
graph-based indices have made it possible to index and search billion-point
datasets with high recall and millisecond-level latency on a single commodity
machine with an SSD.

However, existing graph algorithms for ANNS support only static indices that
cannot reflect real-time changes to the corpus …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1"&gt;Aditi Singh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Subramanya_S/0/1/0/all/0/1"&gt;Suhas Jayaram Subramanya&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Krishnaswamy_R/0/1/0/all/0/1"&gt;Ravishankar Krishnaswamy&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Simhadri_H/0/1/0/all/0/1"&gt;Harsha Vardhan Simhadri&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unified Conversational Recommendation Policy Learning via Graph-based Reinforcement Learning. (arXiv:2105.09710v1 [cs.IR])]]></title>
        <id>http://arxiv.org/abs/2105.09710</id>
        <link href="http://arxiv.org/abs/2105.09710"/>
        <updated>2021-05-22T06:24:25.200Z</updated>
        <summary type="html"><![CDATA[Conversational recommender systems (CRS) enable the traditional recommender
systems to explicitly acquire user preferences towards items and attributes
through interactive conversations. Reinforcement learning (RL) is widely
adopted to learn conversational recommendation policies to decide what
attributes to ask, which items to recommend, and when to ask or recommend, at
each conversation turn. However, existing methods mainly target at solving one
or two of these three decision-making problems in CRS with …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1"&gt;Yang Deng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1"&gt;Yaliang Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1"&gt;Fei Sun&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ding_B/0/1/0/all/0/1"&gt;Bolin Ding&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lam_W/0/1/0/all/0/1"&gt;Wai Lam&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Subverting the Jewtocracy": Online Antisemitism Detection Using Multimodal Deep Learning. (arXiv:2104.05947v2 [cs.MM] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2104.05947</id>
        <link href="http://arxiv.org/abs/2104.05947"/>
        <updated>2021-05-22T06:24:25.176Z</updated>
        <summary type="html"><![CDATA[The exponential rise of online social media has enabled the creation,
distribution, and consumption of information at an unprecedented rate. However,
it has also led to the burgeoning of various forms of online abuse. Increasing
cases of online antisemitism have become one of the major concerns because of
its socio-political consequences. Unlike other major forms of online abuse like
racism, sexism, etc., online antisemitism has not been studied much from a
machine learning perspective. To the best of our k…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chandra_M/0/1/0/all/0/1"&gt;Mohit Chandra&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Pailla_D/0/1/0/all/0/1"&gt;Dheeraj Pailla&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bhatia_H/0/1/0/all/0/1"&gt;Himanshu Bhatia&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sanchawala_A/0/1/0/all/0/1"&gt;Aadilmehdi Sanchawala&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1"&gt;Manish Gupta&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Shrivastava_M/0/1/0/all/0/1"&gt;Manish Shrivastava&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kumaraguru_P/0/1/0/all/0/1"&gt;Ponnurangam Kumaraguru&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Decade Survey of Content Based Image Retrieval using Deep Learning. (arXiv:2012.00641v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2012.00641</id>
        <link href="http://arxiv.org/abs/2012.00641"/>
        <updated>2021-05-22T06:24:25.161Z</updated>
        <summary type="html"><![CDATA[The content based image retrieval aims to find the similar images from a
large scale dataset against a query image. Generally, the similarity between
the representative features of the query image and dataset images is used to
rank the images for retrieval. In early days, various hand designed feature
descriptors have been investigated based on the visual cues such as color,
texture, shape, etc. that represent the images. However, the deep learning has
emerged as a dominating alternative of hand-designed fe…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Dubey_S/0/1/0/all/0/1"&gt;Shiv Ram Dubey&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Graph-Based Behavior-Aware Recommendation for Interactive News. (arXiv:1812.00002v2 [cs.IR] UPDATED)]]></title>
        <id>http://arxiv.org/abs/1812.00002</id>
        <link href="http://arxiv.org/abs/1812.00002"/>
        <updated>2021-05-22T06:24:25.149Z</updated>
        <summary type="html"><![CDATA[Interactive news recommendation has been launched and attracted much
attention recently. In this scenario, user's behavior evolves from single click
behavior to multiple behaviors including like, comment, share etc. However,
most of the existing methods still use single click behavior as the unique
criterion of judging user's preferences. Further, although heterogeneous graphs
have been applied in different areas, a proper way to construct a heterogeneous
graph for interactive news data with an appropriate …]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1"&gt;Mingyuan Ma&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Na_S/0/1/0/all/0/1"&gt;Sen Na&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1"&gt;Hongyu Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1"&gt;Congzhou Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1"&gt;Jin Xu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Geographic Question Answering: Challenges, Uniqueness, Classification, and Future Directions. (arXiv:2105.09392v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2105.09392</id>
        <link href="http://arxiv.org/abs/2105.09392"/>
        <updated>2021-05-22T06:24:25.139Z</updated>
        <summary type="html"><![CDATA[As an important part of Artificial Intelligence (AI), Question Answering (QA)
aims at generating answers to questions phrased in natural language. While
there has been substantial progress in open-domain question answering, QA
systems are still struggling to answer questions which involve geographic
entities or concepts and that require spatial operations. In this paper, we
discuss the problem of geographic question answering (GeoQA). We first
investigate the reasons why geographic questions are difficult t…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Mai_G/0/1/0/all/0/1"&gt;Gengchen Mai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Janowicz_K/0/1/0/all/0/1"&gt;Krzysztof Janowicz&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_R/0/1/0/all/0/1"&gt;Rui Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cai_L/0/1/0/all/0/1"&gt;Ling Cai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lao_N/0/1/0/all/0/1"&gt;Ni Lao&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Personalized Fairness based on Causal Notion. (arXiv:2105.09829v1 [cs.IR])]]></title>
        <id>http://arxiv.org/abs/2105.09829</id>
        <link href="http://arxiv.org/abs/2105.09829"/>
        <updated>2021-05-22T06:24:25.126Z</updated>
        <summary type="html"><![CDATA[Recommender systems are gaining increasing and critical impacts on human and
society since a growing number of users use them for information seeking and
decision making. Therefore, it is crucial to address the potential unfairness
problems in recommendations. Just like users have personalized preferences on
items, users' demands for fairness are also personalized in many scenarios.
Therefore, it is important to provide personalized fair recommendations for
users to satisfy their personalized fairness deman…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1"&gt;Yunqi Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1"&gt;Hanxiong Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1"&gt;Shuyuan Xu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1"&gt;Yingqiang Ge&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1"&gt;Yongfeng Zhang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Distribution Agnostic Symbolic Representations for Time Series Dimensionality Reduction and Online Anomaly Detection. (arXiv:2105.09592v1 [cs.IR])]]></title>
        <id>http://arxiv.org/abs/2105.09592</id>
        <link href="http://arxiv.org/abs/2105.09592"/>
        <updated>2021-05-22T06:24:25.100Z</updated>
        <summary type="html"><![CDATA[Due to the importance of the lower bounding distances and the attractiveness
of symbolic representations, the family of symbolic aggregate approximations
(SAX) has been used extensively for encoding time series data. However, typical
SAX-based methods rely on two restrictive assumptions; the Gaussian
distribution and equiprobable symbols. This paper proposes two novel
data-driven SAX-based symbolic representations, distinguished by their
discretization steps. The first representation, oriented for general d…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Bountrogiannis_K/0/1/0/all/0/1"&gt;Konstantinos Bountrogiannis&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tzagkarakis_G/0/1/0/all/0/1"&gt;George Tzagkarakis&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tsakalides_P/0/1/0/all/0/1"&gt;Panagiotis Tsakalides&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Interactive Query Formulation using Query By Navigation. (arXiv:2105.09562v1 [cs.IR])]]></title>
        <id>http://arxiv.org/abs/2105.09562</id>
        <link href="http://arxiv.org/abs/2105.09562"/>
        <updated>2021-05-22T06:24:25.084Z</updated>
        <summary type="html"><![CDATA[Effective information disclosure in the context of databases with a large
conceptual schema is known to be a non-trivial problem. In particular the
formulation of ad-hoc queries is a major problem in such contexts. Existing
approaches for tackling this problem include graphical query interfaces, query
by navigation, query by construction, and point to point queries. In this
report we propose an adoption of the query by navigation mechanism that is
especially geared towards the InfoAssistant product. Query b…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Proper_H/0/1/0/all/0/1"&gt;H. A. Proper&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Probabilistic and Variational Recommendation Denoising. (arXiv:2105.09605v1 [cs.IR])]]></title>
        <id>http://arxiv.org/abs/2105.09605</id>
        <link href="http://arxiv.org/abs/2105.09605"/>
        <updated>2021-05-22T06:24:25.056Z</updated>
        <summary type="html"><![CDATA[Learning from implicit feedback is one of the most common cases in the
application of recommender systems. Generally speaking, interacted examples are
considered as positive while negative examples are sampled from uninteracted
ones. However, noisy examples are prevalent in real-world implicit feedback. A
noisy positive example could be interacted but it actually leads to negative
user preference. A noisy negative example which is uninteracted because of
unawareness of the user could also denote potential p…]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"&gt;Yu Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xin_X/0/1/0/all/0/1"&gt;Xin Xin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Meng_Z/0/1/0/all/0/1"&gt;Zaiqiao Meng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1"&gt;Xiangnan He&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jose_J/0/1/0/all/0/1"&gt;Joemon Jose&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1"&gt;Fuli Feng&lt;/a&gt;</name>
        </author>
    </entry>
</feed>